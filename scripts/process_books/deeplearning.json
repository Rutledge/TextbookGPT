[
  {
    "id": "1",
    "text": "www.deeplearningbook.org",
    "chapter": "",
    "chapter_id": "main-1.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2",
    "text": "This book is accompanied by the above website. The website provides a variety of supplementary material, including exercises, lecture slides, corrections of\u00a0mistakes, and other resources that should be useful to both readers and instructors.",
    "chapter": "",
    "chapter_id": "main-1.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3",
    "text": "This book would not have been possible without the contributions of many people.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4",
    "text": "We would like to thank those who commented on our proposal for the book and helped plan its contents and organization: Guillaume Alain, Kyunghyun Cho,\u00a0Qaglar Gulgehre, David Krueger, Hugo Larochelle, Razvan Pascanu and Thomas\u00a0Rohee.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5",
    "text": "We would like to thank the people who offered feedback on the content of the book itself. Some offered feedback on many chapters: Martm Abadi, Guillaume\u00a0Alain, Ion Androutsopoulos, Fred Bertsch, Olexa Bilaniuk, Ufuk Can Bigici, Matko\u00a0Bosnjak, John Boersma, Greg Brockman, Alexandre de Brebisson, Pierre Luc\u00a0Carrier, Sarath Chandar, Pawel Chilinski, Mark Daoust, Oleg Dashevskii, Laurent\u00a0Dinh, Stephan Dreseitl, Jim Fan, Miao Fan, Meire Fortunato, Frederic Francis,\u00a0Nando de Freitas, Qaglar Gulgehre, Jurgen Van Gael, Javier Alonso Garaa,\u00a0Jonathan Hunt, Gopi Jeyaram, Chingiz Kabytayev, Lukasz Kaiser, Varun Kanade,\u00a0Akiel Khan, John King, Diederik P. Kingma, Yann LeCun, Rudolf Mathey, Matias\u00a0Mattamala, Abhinav Maurya, Kevin Murphy, Oleg Murk, Roman Novak, Augustus\u00a0Q. Odena, Simon Pavlik, Karl Pichotta, Kari Pulli, Roussel Rahman, Tapani Raiko,\u00a0Anurag Ranjan, Johannes Roith, Mihaela Rosca, Halis Sak, Cesar Salgado, Grigory\u00a0Sapunov, Yoshinori Sasaki, Mike Schuster, Julian Serban, Nir Shabat, Ken Shirriff,\u00a0Andre Simpelo, Scott Stanley, David Sussillo, Ilya Sutskever, Carles Gelada Saez,\u00a0Graham Taylor, Valentin Tolmer, An Tran, Shubhendu Trivedi, Alexey Umnov,\u00a0Vincent Vanhoucke, Marco Visentini-Scarzanella, David Warde-Farley, Dustin\u00a0Webb, Kelvin Xu, Wei Xue, Ke Yang, Li Yao, Zygmunt Zaj^c and Ozan Qaglayan.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6",
    "text": "We would also like to thank those who provided us with useful feedback on individual chapters:",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7",
    "text": "\u2022 \u00a0\u00a0\u00a0Notation: Zhang Yuanhang.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "8",
    "text": "\u2022 \u00a0\u00a0\u00a0Chapter 1, Introduction: Yusuf Akgul, Sebastien Bratieres, Samira Ebrahimi,\u00a0Charlie Gorichanaz, Brendan Loudermilk, Eric Morris, Cosmin Parvulescu\u00a0and Alfredo Solano.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "9",
    "text": "\u2022 \u00a0\u00a0\u00a0Chapter 2, Linear Algebra: Amjad Almahairi, Nikola Banic, Kevin Bennett,\u00a0Philippe Castonguay, Oscar Chang, Eric Fosler-Lussier, Andrey Khalyavin,\u00a0Sergey Oreshkov, Istvan Petras, Dennis Prangle, Thomas Rohee, Colby\u00a0Toland, Massimiliano Tomassoli, Alessandro Vitale and Bob Welland.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "10",
    "text": "\u2022 \u00a0\u00a0\u00a0Chapter 3, Probability and Information Theory: John Philip Anderson, Kai\u00a0Arulkumaran, Vincent Dumoulin, Rui Fa, Stephan Gouws, Artem Oboturov,\u00a0Antti Rasmus, Alexey Surkov and Volker Tresp.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "11",
    "text": "\u2022 \u00a0\u00a0\u00a0Chapter 4, Numerical Computation: Tran Lam An, Ian Fischer, and Hu\u00a0Yuhuang.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "12",
    "text": "\u2022 \u00a0\u00a0\u00a0Chapter 5, Machine Learning Basics: Dzmitry Bahdanau, Nikhil Garg,\u00a0Makoto Otsuka, Bob Pepin, Philip Popien, Emmanuel Rayner, Kee-Bong\u00a0Song, Zheng Sun and Andy Wu.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "13",
    "text": "\u2022 \u00a0\u00a0\u00a0Chapter 6, Deep Feedforward Networks: Uriel Berdugo, Fabrizio Bottarel,\u00a0Elizabeth Burl, Ishan Durugkar, Jeff Hlywa, Jong Wook Kim, David Krueger\u00a0and Aditya Kumar Praharaj.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "14",
    "text": "\u2022 \u00a0\u00a0\u00a0Chapter 7, Regularization for Deep Learning: Kshitij Lauria, Inkyu Lee,\u00a0Sunil Mohan and Joshua Salisbury.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "15",
    "text": "\u2022 \u00a0\u00a0\u00a0Chapter 8, Optimization for Training Deep Models: Marcel Ackermann,\u00a0Rowel Atienza, Andrew Brock, Tegan Maharaj, James Martens, Klaus Strobl\u00a0and Martin Vita.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "16",
    "text": "\u2022 \u00a0\u00a0\u00a0Chapter 9, Convolutional Networks: Martin Arjovsky, Eugene Brevdo, Konstantin Divilov, Eric Jensen, Asifullah Khan, Mehdi Mirza, Alex Paino, Eddie\u00a0Pierce, Marjorie Sayer, Ryan Stout and Wentao Wu.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "17",
    "text": "\u2022 \u00a0\u00a0\u00a0Chapter 10, Sequence Modeling: Recurrent and Recursive Nets: Gokgen\u00a0Eraslan, Steven Hickson, Razvan Pascanu, Lorenzo von Ritter, Rui Rodrigues,\u00a0Dmitriy Serdyuk, Dongyu Shi and Kaiyu Yang.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "18",
    "text": "\u2022 \u00a0\u00a0\u00a0Chapter 11, Practical Methodology: Daniel Beckstein.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "19",
    "text": "\u2022 \u00a0\u00a0\u00a0Chapter 12, Applications: George Dahl and Ribana Roscher.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "20",
    "text": "\u2022 \u00a0\u00a0\u00a0Chapter 15, Representation Learning: Kunal Ghosh.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "21",
    "text": "\u2022 \u00a0\u00a0\u00a0Chapter 16, Structured Probabilistic Models for Deep Learning: Minh Le\u00a0and Anton Varfolom.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "22",
    "text": "\u2022 \u00a0\u00a0\u00a0Chapter 18, Confronting the Partition Function: Sam Bowman.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "23",
    "text": "\u2022 \u00a0\u00a0\u00a0Chapter 19, Approximate Inference: Yujia Bao.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "24",
    "text": "\u2022 \u00a0\u00a0\u00a0Chapter 20, Deep Generative Models: Nicolas Chapados, Daniel Galvez,\u00a0Wenming Ma, Fady Medhat, Shakir Mohamed and Gregoire Montavon.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "25",
    "text": "\u2022 \u00a0\u00a0\u00a0Bibliography: Lukas Michelbacher and Leslie N. Smith.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "26",
    "text": "We also want to thank those who allowed us to reproduce images, figures or data from their publications. We indicate their contributions in the figure captions\u00a0throughout the text.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "27",
    "text": "We would like to thank Lu Wang for writing pdf2htmlEX, which we used to make the web version of the book, and for offering support to improve the quality\u00a0of the resulting HTML.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "28",
    "text": "We would like to thank Ian\u2019s wife Daniela Flori Goodfellow for patiently supporting Ian during the writing of the book as well as for help with proofreading.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "29",
    "text": "We would like to thank the Google Brain team for providing an intellectual environment where Ian could devote a tremendous amount of time to writing this\u00a0book and receive feedback and guidance from colleagues. We would especially like\u00a0to thank Ian\u2019s former manager, Greg Corrado, and his current manager, Samy\u00a0Bengio, for their support of this project. Finally, we would like to thank Geoffrey\u00a0Hinton for encouragement when writing was difficult.",
    "chapter": "",
    "chapter_id": "main-2.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "30",
    "text": "This section provides a concise reference describing the notation used throughout this book. If you are unfamiliar with any of the corresponding mathematical\u00a0concepts, this notation reference may seem intimidating. However, do not despair,\u00a0we describe most of these ideas in chapters 2-4.",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "31",
    "text": "",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "32",
    "text": "Numbers and Arrays",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "33",
    "text": "a",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "34",
    "text": "A scalar (integer or real)",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "35",
    "text": "a",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "36",
    "text": "A vector",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "37",
    "text": "A",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "38",
    "text": "A matrix",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "39",
    "text": "A",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "40",
    "text": "A tensor",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "41",
    "text": "In",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "42",
    "text": "Identity matrix with n rows and n columns",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "43",
    "text": "I",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "44",
    "text": "Identity matrix with dimensionality implied by",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "45",
    "text": "context",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "46",
    "text": "e(i)",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "47",
    "text": "Standard basis vector [0,..., 0, 1,0,..., 0] with a 1 at position i",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "48",
    "text": "diag(a)",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "49",
    "text": "A square, diagonal matrix with diagonal entries given by a",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "50",
    "text": "a",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "51",
    "text": "A scalar random variable",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "52",
    "text": "a",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "53",
    "text": "A vector-valued random variable",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "54",
    "text": "A",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "55",
    "text": "A matrix-valued random variable",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "56",
    "text": "Xi",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "57",
    "text": "Sets and Graphs",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "58",
    "text": "A",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "59",
    "text": "A set",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "60",
    "text": "R",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "61",
    "text": "The set of real numbers",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "62",
    "text": "{0,1}",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "63",
    "text": "The set containing 0 and 1",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "64",
    "text": "{0,1,... ,n}",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "65",
    "text": "The set of all integers between 0 and n",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "66",
    "text": "[a, b]",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "67",
    "text": "The real interval including a and b",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "68",
    "text": "(a, b]",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "69",
    "text": "The real interval excluding a but including b",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "70",
    "text": "A\\B",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "71",
    "text": "Set subtraction, i.e., the set containing the ele\u25a0 ments of A that are not in B",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "72",
    "text": "G",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "73",
    "text": "A graph",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "74",
    "text": "Pa g(x i)",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "75",
    "text": "The parents of xi in G",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "76",
    "text": "Indexing",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "77",
    "text": "a* \u00a0\u00a0\u00a0Element i of vector a, with indexing starting at 1",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "78",
    "text": "a\u2014 All elements of vector a except for element i Ai7j\u00a0\u00a0\u00a0\u00a0Element i, j of matrix A",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "79",
    "text": "A; Row i of matrix A A;,i Column i of matrix A\u00a0Ajk Element (i, j, k) of a 3-D tensor A\u00a0A;; i 2-D slice of a 3-D tensor",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "80",
    "text": "\u05f31\u05d5\u05d9\u05d5\u2022",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "81",
    "text": "a* \u00a0\u00a0\u00a0Element i of the random vector a",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "82",
    "text": "Linear Algebra Operations",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "83",
    "text": "AJ Transpose of matrix A",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "84",
    "text": "A+ Moore-Penrose pseudoinverse of A A 0 B Element-wise (Hadamard) product of A and B\u00a0det(A) Determinant of A",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "85",
    "text": "dy",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "86",
    "text": "dx",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "87",
    "text": "dy",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "88",
    "text": "dx",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "89",
    "text": "V xy",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "90",
    "text": "Vx y Vxy",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "91",
    "text": "df",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "92",
    "text": "d x",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "93",
    "text": "Calculus",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "94",
    "text": "Derivative of y with respect to x",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "95",
    "text": "Partial derivative of y with respect to x",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "96",
    "text": "Gradient of y with respect to x",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "97",
    "text": "Matrix derivatives of y with respect to X",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "98",
    "text": "Tensor containing derivatives of y with respect to X",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "99",
    "text": "Jacobian matrix J G Rm",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "100",
    "text": "of f : Rn",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "101",
    "text": "Rm",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "102",
    "text": "VX f (x) or H(f )(x) The Hessian matrix of f at input point x",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "103",
    "text": "f (x)dx f (x)dx",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "104",
    "text": "Definite integral over the entire domain of x Definite integral with respect to x over the set S",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "105",
    "text": "Probability and Information Theory",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "106",
    "text": "aRb",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "107",
    "text": "The random variables a and b are independent",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "108",
    "text": "aRb | c",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "109",
    "text": "They are are conditionally independent given c",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "110",
    "text": "P (a)",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "111",
    "text": "A probability distribution over a discrete variable",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "112",
    "text": "p(a)",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "113",
    "text": "A probability distribution over a continuous variable, or over a variable whose type has not been specified",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "114",
    "text": "a ~ P",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "115",
    "text": "Random variable a has distribution P",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "116",
    "text": "Ex-P[f (x)] or Ef (x)",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "117",
    "text": "Expectation of f (x) with respect to P(x)",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "118",
    "text": "Var(f (x))",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "119",
    "text": "Variance of f (x) under P(x)",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "120",
    "text": "Cov(f (x), g(x))",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "121",
    "text": "Covariance of f (x) and g(x) under P(x)",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "122",
    "text": "H (x)",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "123",
    "text": "Shannon entropy of the random variable x",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "124",
    "text": "Dkl(p ||q)",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "125",
    "text": "Kullback-Leibler divergence of P and Q",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "126",
    "text": "N(x; i, S)",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "127",
    "text": "Gaussian distribution over x with mean fi and covariance S",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "128",
    "text": "xill",
    "chapter": "",
    "chapter_id": "main-3.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "129",
    "text": "Inventors have long dreamed of creating machines that think. This desire dates back to at least the time of ancient Greece. The mythical figures Pygmalion,\u00a0Daedalus, and Hephaestus may all be interpreted as legendary inventors, and\u00a0Galatea, Talos, and Pandora may all be regarded as artificial life (Ovid and Martin,\u00a02004; Sparkes, 1996; Tandy, 1997).",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "130",
    "text": "When programmable computers were first conceived, people wondered whether they might become intelligent, over a hundred years before one was built (Lovelace,\u00a01842). Today, artificial intelligence (AI) is a thriving field with many practical\u00a0applications and active research topics. We look to intelligent software to automate\u00a0routine labor, understand speech or images, make diagnoses in medicine and\u00a0support basic scientific research.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "131",
    "text": "In the early days of artificial intelligence, the field rapidly tackled and solved problems that are intellectually difficult for human beings but relatively straightforward for computers\u2014problems that can be described by a list of formal, mathematical rules. The true challenge to artificial intelligence proved to be solving\u00a0the tasks that are easy for people to perform but hard for people to describe\u00a0formally\u2014problems that we solve intuitively, that feel automatic, like recognizing\u00a0spoken words or faces in images.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "132",
    "text": "This book is about a solution to these more intuitive problems. This solution is to allow computers to learn from experience and understand the world in terms of a\u00a0hierarchy of concepts, with each concept defined in terms of its relation to simpler\u00a0concepts. By gathering knowledge from experience, this approach avoids the need\u00a0for human operators to formally specify all of the knowledge that the computer\u00a0needs. The hierarchy of concepts allows the computer to learn complicated concepts\u00a0by building them out of simpler ones. If we draw a graph showing how these\u00a0concepts are built on top of each other, the graph is deep, with many layers. For\u00a0this reason, we call this approach to AI deep learning.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "133",
    "text": "Many of the early successes of AI took place in relatively sterile and formal environments and did not require computers to have much knowledge about\u00a0the world. For example, IBM\u2019s Deep Blue chess-playing system defeated world\u00a0champion Garry Kasparov in 1997 (Hsu, 2002). Chess is of course a very simple\u00a0world, containing only sixty-four locations and thirty-two pieces that can move\u00a0in only rigidly circumscribed ways. Devising a successful chess strategy is a\u00a0tremendous accomplishment, but the challenge is not due to the difficulty of\u00a0describing the set of chess pieces and allowable moves to the computer. Chess\u00a0can be completely described by a very brief list of completely formal rules, easily\u00a0provided ahead of time by the programmer.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "134",
    "text": "Ironically, abstract and formal tasks that are among the most difficult mental undertakings for a human being are among the easiest for a computer. Computers\u00a0have long been able to defeat even the best human chess player, but are only\u00a0recently matching some of the abilities of average human beings to recognize objects\u00a0or speech. A person\u2019s everyday life requires an immense amount of knowledge\u00a0about the world. Much of this knowledge is subjective and intuitive, and therefore\u00a0difficult to articulate in a formal way. Computers need to capture this same\u00a0knowledge in order to behave in an intelligent way. One of the key challenges in\u00a0artificial intelligence is how to get this informal knowledge into a computer.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "135",
    "text": "Several artificial intelligence projects have sought to hard-code knowledge about the world in formal languages. A computer can reason about statements in these\u00a0formal languages automatically using logical inference rules. This is known as the\u00a0knowledge base approach to artificial intelligence. None of these projects has led to\u00a0a major success. One of the most famous such projects is Cyc (Lenat and Guha,\u00a01989). Cyc is an inference engine and a database of statements in a language\u00a0called CycL. These statements are entered by a staff of human supervisors. It is an\u00a0unwieldy process. People struggle to devise formal rules with enough complexity\u00a0to accurately describe the world. For example, Cyc failed to understand a story\u00a0about a person named Fred shaving in the morning (Linde, 1992). Its inference\u00a0engine detected an inconsistency in the story: it knew that people do not have\u00a0electrical parts, but because Fred was holding an electric razor, it believed the\u00a0entity \u201cFredWhileShaving\u201d contained electrical parts. It therefore asked whether\u00a0Fred was still a person while he was shaving.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "136",
    "text": "The difficulties faced by systems relying on hard-coded knowledge suggest that AI systems need the ability to acquire their own knowledge, by extracting patterns\u00a0from raw data. This capability is known as machine learning. The introduction\u00a0of machine learning allowed computers to tackle problems involving knowledge\u00a0of the real world and make decisions that appear subjective. A simple machine\u00a0learning algorithm called logistic regression can determine whether to recommend\u00a0cesarean delivery (Mor-Yosef et al., 1990). A simple machine learning algorithm\u00a0called naive Bayes can separate legitimate e-mail from spam e-mail.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "137",
    "text": "The performance of these simple machine learning algorithms depends heavily on the representation of the data they are given. For example, when logistic\u00a0regression is used to recommend cesarean delivery, the AI system does not examine\u00a0the patient directly. Instead, the doctor tells the system several pieces of relevant\u00a0information, such as the presence or absence of a uterine scar. Each piece of\u00a0information included in the representation of the patient is known as a feature.\u00a0Logistic regression learns how each of these features of the patient correlates with\u00a0various outcomes. However, it cannot influence the way that the features are\u00a0defined in any way. If logistic regression was given an MRI scan of the patient,\u00a0rather than the doctor\u2019s formalized report, it would not be able to make useful\u00a0predictions. Individual pixels in an MRI scan have negligible correlation with any\u00a0complications that might occur during delivery.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "138",
    "text": "This dependence on representations is a general phenomenon that appears throughout computer science and even daily life. In computer science, operations such as searching a collection of data can proceed exponentially faster if\u00a0the collection is structured and indexed intelligently. People can easily perform\u00a0arithmetic on Arabic numerals, but find arithmetic on Roman numerals much\u00a0more time-consuming. It is not surprising that the choice of representation has an\u00a0enormous effect on the performance of machine learning algorithms. For a simple\u00a0visual example, see Fig. 1.1.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "139",
    "text": "Many artificial intelligence tasks can be solved by designing the right set of features to extract for that task, then providing these features to a simple machine\u00a0learning algorithm. For example, a useful feature for speaker identification from\u00a0sound is an estimate of the size of speaker\u2019s vocal tract. It therefore gives a strong\u00a0clue as to whether the speaker is a man, woman, or child.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "140",
    "text": "However, for many tasks, it is difficult to know what features should be extracted. For example, suppose that we would like to write a program to detect cars in\u00a0photographs. We know that cars have wheels, so we might like to use the presence\u00a0of a wheel as a feature. Unfortunately, it is difficult to describe exactly what a\u00a0wheel looks like in terms of pixel values. A wheel has a simple geometric shape but\u00a0its image may be complicated by shadows falling on the wheel, the sun glaring off\u00a0the metal parts of the wheel, the fender of the car or an object in the foreground\u00a0obscuring part of the wheel, and so on.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "141",
    "text": "Polar coordinates",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "142",
    "text": "Cartesian coordinates",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "143",
    "text": "X",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "144",
    "text": "\u05d4\u05e1",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "145",
    "text": "r",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "146",
    "text": "Figure 1.1: Example of different representations: suppose we want to separate two categories of data by drawing a line between them in a scatterplot. In the plot on the left,\u00a0we represent some data using Cartesian coordinates, and the task is impossible. In the plot\u00a0on the right, we represent the data with polar coordinates and the task becomes simple to\u00a0solve with a vertical line. (Figure produced in collaboration with David Warde-Farley)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "147",
    "text": "One solution to this problem is to use machine learning to discover not only the mapping from representation to output but also the representation itself.\u00a0This approach is known as representation learning. Learned representations often\u00a0result in much better performance than can be obtained with hand-designed\u00a0representations. They also allow AI systems to rapidly adapt to new tasks, with\u00a0minimal human intervention. A representation learning algorithm can discover a\u00a0good set of features for a simple task in minutes, or a complex task in hours to\u00a0months. Manually designing features for a complex task requires a great deal of\u00a0human time and effort; it can take decades for an entire community of researchers.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "148",
    "text": "The quintessential example of a representation learning algorithm is the autoencoder. An autoencoder is the combination of an encoder function that converts the input data into a different representation, and a decoder function that converts\u00a0the new representation back into the original format. Autoencoders are trained to\u00a0preserve as much information as possible when an input is run through the encoder\u00a0and then the decoder, but are also trained to make the new representation have\u00a0various nice properties. Different kinds of autoencoders aim to achieve different\u00a0kinds of properties.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "149",
    "text": "When designing features or algorithms for learning features, our goal is usually to separate the factors of variation that explain the observed data. In this context,\u00a0we use the word \u201cfactors\u201d simply to refer to separate sources of influence; the factors\u00a0are usually not combined by multiplication. Such factors are often not quantities\u00a0that are directly observed. Instead, they may exist either as unobserved objects\u00a0or unobserved forces in the physical world that affect observable quantities. They\u00a0may also exist as constructs in the human mind that provide useful simplifying\u00a0explanations or inferred causes of the observed data. They can be thought of as\u00a0concepts or abstractions that help us make sense of the rich variability in the data.\u00a0When analyzing a speech recording, the factors of variation include the speaker\u2019s\u00a0age, their sex, their accent and the words that they are speaking. When analyzing\u00a0an image of a car, the factors of variation include the position of the car, its color,\u00a0and the angle and brightness of the sun.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "150",
    "text": "A major source of difficulty in many real-world artificial intelligence applications is that many of the factors of variation influence every single piece of data we are\u00a0able to observe. The individual pixels in an image of a red car might be very close\u00a0to black at night. The shape of the car\u2019s silhouette depends on the viewing angle.\u00a0Most applications require us to disentangle the factors of variation and discard the\u00a0ones that we do not care about.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "151",
    "text": "Of course, it can be very difficult to extract such high-level, abstract features from raw data. Many of these factors of variation, such as a speaker\u2019s accent,\u00a0can be identified only using sophisticated, nearly human-level understanding of\u00a0the data. When it is nearly as difficult to obtain a representation as to solve the\u00a0original problem, representation learning does not, at first glance, seem to help us.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "152",
    "text": "Deep learning solves this central problem in representation learning by introducing representations that are expressed in terms of other, simpler representations. Deep learning allows the computer to build complex concepts out of simpler concepts. Fig. 1.2 shows how a deep learning system can represent the concept of an\u00a0image of a person by combining simpler concepts, such as corners and contours,\u00a0which are in turn defined in terms of edges.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "153",
    "text": "The quintessential example of a deep learning model is the feedforward deep network or multilayer perceptron (MLP). A multilayer perceptron is just a mathematical function mapping some set of input values to output values. The function\u00a0is formed by composing many simpler functions. We can think of each application\u00a0of a different mathematical function as providing a new representation of the input.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "154",
    "text": "The idea of learning the right representation for the data provides one perspective on deep learning. Another perspective on deep learning is that depth allows the computer to learn a multi-step computer program. Each layer of the representation\u00a0can be thought of as the state of the computer\u2019s memory after executing another\u00a0set of instructions in parallel. Networks with greater depth can execute more\u00a0instructions in sequence. Sequential instructions offer great power because later\u00a0instructions can refer back to the results of earlier instructions. According to this",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "155",
    "text": "Output",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "156",
    "text": "(object identity)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "157",
    "text": "3rd hidden layer (object parts)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "158",
    "text": "2nd hidden layer (corners and\u00a0contours)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "159",
    "text": "1st hidden layer (edges)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "160",
    "text": "Visible layer (input pixels)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "161",
    "text": "Figure 1.2: Illustration of a deep learning model. It is difficult for a computer to understand the meaning of raw sensory input data, such as this image represented as a collection\u00a0of pixel values. The function mapping from a set of pixels to an object identity is very\u00a0complicated. Learning or evaluating this mapping seems insurmountable if tackled directly.\u00a0Deep learning resolves this difficulty by breaking the desired complicated mapping into a\u00a0series of nested simple mappings, each described by a different layer of the model. The\u00a0input is presented at the visible layer, so named because it contains the variables that we\u00a0are able to observe. Then a series of hidden layers extracts increasingly abstract features\u00a0from the image. These layers are called \u201chidden\u201d because their values are not given in\u00a0the data; instead the model must determine which concepts are useful for explaining\u00a0the relationships in the observed data. The images here are visualizations of the kind\u00a0of feature represented by each hidden unit. Given the pixels, the first layer can easily\u00a0identify edges, by comparing the brightness of neighboring pixels. Given the first hidden\u00a0layer\u2019s description of the edges, the second hidden layer can easily search for corners and\u00a0extended contours, which are recognizable as collections of edges. Given the second hidden\u00a0layer\u2019s description of the image in terms of corners and contours, the third hidden layer\u00a0can detect entire parts of specific objects, by finding specific collections of contours and\u00a0corners. Finally, this description of the image in terms of the object parts it contains can\u00a0be used to recognize the objects present in the image. Images reproduced with permission\u00a0from Zeiler and Fergus (2014).",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "162",
    "text": "Figure 1.3: Illustration of computational graphs mapping an input to an output where each node performs an operation. Depth is the length of the longest path from input to\u00a0output but depends on the definition of what constitutes a possible computational step.\u00a0The computation depicted in these graphs is the output of a logistic regression model,\u00a0a(wTx), where a is the logistic sigmoid function. If we use addition, multiplication and\u00a0logistic sigmoids as the elements of our computer language, then this model has depth\u00a0three. If we view logistic regression as an element itself, then this model has depth one.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "163",
    "text": "view of deep learning, not all of the information in a layer\u2019s activations necessarily encodes factors of variation that explain the input. The representation also stores\u00a0state information that helps to execute a program that can make sense of the input.\u00a0This state information could be analogous to a counter or pointer in a traditional\u00a0computer program. It has nothing to do with the content of the input specifically,\u00a0but it helps the model to organize its processing.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "164",
    "text": "There are two main ways of measuring the depth of a model. The first view is based on the number of sequential instructions that must be executed to evaluate\u00a0the architecture. We can think of this as the length of the longest path through\u00a0a flow chart that describes how to compute each of the model\u2019s outputs given\u00a0its inputs. Just as two equivalent computer programs will have different lengths\u00a0depending on which language the program is written in, the same function may be\u00a0drawn as a flowchart with different depths depending on which functions we allow\u00a0to be used as individual steps in the flowchart. Fig. 1.3 illustrates how this choice\u00a0of language can give two different measurements for the same architecture.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "165",
    "text": "Another approach, used by deep probabilistic models, regards the depth of a model as being not the depth of the computational graph but the depth of the\u00a0graph describing how concepts are related to each other. In this case, the depth\u00a0of the flowchart of the computations needed to compute the representation of\u00a0each concept may be much deeper than the graph of the concepts themselves.\u00a0This is because the system\u2019s understanding of the simpler concepts can be refined\u00a0given information about the more complex concepts. For example, an AI system\u00a0observing an image of a face with one eye in shadow may initially only see one eye.\u00a0After detecting that a face is present, it can then infer that a second eye is probably\u00a0present as well. In this case, the graph of concepts only includes two layers\u2014a\u00a0layer for eyes and a layer for faces\u2014but the graph of computations includes 2n\u00a0layers if we refine our estimate of each concept given the other n times.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "166",
    "text": "Because it is not always clear which of these two views\u2014the depth of the computational graph, or the depth of the probabilistic modeling graph\u2014is most\u00a0relevant, and because different people choose different sets of smallest elements\u00a0from which to construct their graphs, there is no single correct value for the\u00a0depth of an architecture, just as there is no single correct value for the length of\u00a0a computer program. Nor is there a consensus about how much depth a model\u00a0requires to qualify as \u201cdeep.\u201d However, deep learning can safely be regarded as the\u00a0study of models that either involve a greater amount of composition of learned\u00a0functions or learned concepts than traditional machine learning does.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "167",
    "text": "To summarize, deep learning, the subject of this book, is an approach to AI. Specifically, it is a type of machine learning, a technique that allows computer\u00a0systems to improve with experience and data. According to the authors of this\u00a0book, machine learning is the only viable approach to building AI systems that\u00a0can operate in complicated, real-world environments. Deep learning is a particular\u00a0kind of machine learning that achieves great power and flexibility by learning to\u00a0represent the world as a nested hierarchy of concepts, with each concept defined in\u00a0relation to simpler concepts, and more abstract representations computed in terms\u00a0of less abstract ones. Fig. 1.4 illustrates the relationship between these different\u00a0AI disciplines. Fig. 1.5 gives a high-level schematic of how each works.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "168",
    "text": "This book can be useful for a variety of readers, but we wrote it with two main target audiences in mind. One of these target audiences is university students\u00a0(undergraduate or graduate) learning about machine learning, including those who\u00a0are beginning a career in deep learning and artificial intelligence research. The\u00a0other target audience is software engineers who do not have a machine learning\u00a0or statistics background, but want to rapidly acquire one and begin using deep\u00a0learning in their product or platform. Deep learning has already proven useful in\u00a0many software disciplines including computer vision, speech and audio processing,",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "169",
    "text": "Figure 1.4: A Venn diagram showing how deep learning is a kind of representation learning, which is in turn a kind of machine learning, which is used for many but not all approaches\u00a0to AI. Each section of the Venn diagram includes an example of an AI technology.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "170",
    "text": "systems \u00a0\u00a0\u00a0learning\u00a0\u00a0\u00a0\u00a0Representation",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "171",
    "text": "learning",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "172",
    "text": "Figure 1.5: Flowcharts showing how the different parts of an AI system relate to each other within different AI disciplines. Shaded boxes indicate components that are able to\u00a0learn from data.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "173",
    "text": "natural language processing, robotics, bioinformatics and chemistry, video games, search engines, online advertising and finance.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "174",
    "text": "This book has been organized into three parts in order to best accommodate a variety of readers. Part I introduces basic mathematical tools and machine learning\u00a0concepts. Part II describes the most established deep learning algorithms that are\u00a0essentially solved technologies. Part III describes more speculative ideas that are\u00a0widely believed to be important for future research in deep learning.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "175",
    "text": "Readers should feel free to skip parts that are not relevant given their interests or background. Readers familiar with linear algebra, probability, and fundamental\u00a0machine learning concepts can skip Part I, for example, while readers who just want\u00a0to implement a working system need not read beyond Part II. To help choose which\u00a0chapters to read, Fig. 1.6 provides a flowchart showing the high-level organization\u00a0of the book.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "176",
    "text": "We do assume that all readers come from a computer science background. We assume familiarity with programming, a basic understanding of computational\u00a0performance issues, complexity theory, introductory level calculus and some of the\u00a0terminology of graph theory.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "177",
    "text": "It is easiest to understand deep learning with some historical context. Rather than providing a detailed history of deep learning, we identify a few key trends:",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "178",
    "text": "\u2022 \u00a0\u00a0\u00a0Deep learning has had a long and rich history, but has gone by many names\u00a0reflecting different philosophical viewpoints, and has waxed and waned in\u00a0popularity.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "179",
    "text": "\u2022 \u00a0\u00a0\u00a0Deep learning has become more useful as the amount of available training\u00a0data has increased.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "180",
    "text": "\u2022 \u00a0\u00a0\u00a0Deep learning models have grown in size over time as computer hardware\u00a0and software infrastructure for deep learning has improved.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "181",
    "text": "\u2022 \u00a0\u00a0\u00a0Deep learning has solved increasingly complicated applications with increasing\u00a0accuracy over time.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "182",
    "text": "Figure 1.6: The high-level organization of the book. An arrow from one chapter to another indicates that the former chapter is prerequisite material for understanding the latter.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "183",
    "text": "We expect that many readers of this book have heard of deep learning as an exciting new technology, and are surprised to see a mention of \u201chistory\u201d in a book\u00a0about an emerging field. In fact, deep learning dates back to the 1940s. Deep\u00a0learning only appears to be new, because it was relatively unpopular for several\u00a0years preceding its current popularity, and because it has gone through many\u00a0different names, and has only recently become called \u201cdeep learning.\u201d The field\u00a0has been rebranded many times, reflecting the influence of different researchers\u00a0and different perspectives.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "184",
    "text": "A comprehensive history of deep learning is beyond the scope of this textbook. However, some basic context is useful for understanding deep learning. Broadly\u00a0speaking, there have been three waves of development of deep learning: deep learning known as cybernetics in the 1940s-1960s, deep learning known as connectionism\u00a0in the 1980s-1990s, and the current resurgence under the name deep learning\u00a0beginning in 2006. This is quantitatively illustrated in Fig. 1.7.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "185",
    "text": "Some of the earliest learning algorithms we recognize today were intended to be computational models of biological learning, i.e. models of how learning\u00a0happens or could happen in the brain. As a result, one of the names that deep\u00a0learning has gone by is artificial neural networks (ANNs). The corresponding\u00a0perspective on deep learning models is that they are engineered systems inspired\u00a0by the biological brain (whether the human brain or the brain of another animal).\u00a0While the kinds of neural networks used for machine learning have sometimes\u00a0been used to understand brain function (Hinton and Shallice, 1991), they are\u00a0generally not designed to be realistic models of biological function. The neural\u00a0perspective on deep learning is motivated by two main ideas. One idea is that\u00a0the brain provides a proof by example that intelligent behavior is possible, and a\u00a0conceptually straightforward path to building intelligence is to reverse engineer the\u00a0computational principles behind the brain and duplicate its functionality. Another\u00a0perspective is that it would be deeply interesting to understand the brain and the\u00a0principles that underlie human intelligence, so machine learning models that shed\u00a0light on these basic scientific questions are useful apart from their ability to solve\u00a0engineering applications.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "186",
    "text": "The modern term \u201cdeep learning\u201d goes beyond the neuroscientific perspective on the current breed of machine learning models. It appeals to a more general\u00a0principle of learning multiple levels of composition, which can be applied in machine\u00a0learning frameworks that are not necessarily neurally inspired.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "187",
    "text": "Figure 1.7: The figure shows two of the three historical waves of artificial neural nets research, as measured by the frequency of the phrases \u201ccybernetics\u201d and \u201cconnectionism\u201d or\u00a0\u201cneural networks\u201d according to Google Books (the third wave is too recent to appear). The\u00a0first wave started with cybernetics in the 1940s-1960s, with the development of theories\u00a0of biological learning (McCulloch and Pitts, 1943; Hebb, 1949) and implementations of\u00a0the first models such as the perceptron (Rosenblatt, 1958) allowing the training of a single\u00a0neuron. The second wave started with the connectionist approach of the 1980-1995 period,\u00a0with back-propagation (Rumelhart et al., 1986a) to train a neural network with one or two\u00a0hidden layers. The current and third wave, deep learning, started around 2006 (Hinton\u00a0et al., 2006; Bengio et al., 2007; Ranzato et al., 2007a), and is just now appearing in book\u00a0form as of 2016. The other two waves similarly appeared in book form much later than\u00a0the corresponding scientific activity occurred.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "188",
    "text": "The earliest predecessors of modern deep learning were simple linear models motivated from a neuroscientific perspective. These models were designed to\u00a0take a set of n input values x1,..., xn and associate them with an output y.\u00a0These models would learn a set of weights w1,..., wn and compute their output\u00a0f (x, w) = x 1w1 + \u25a0 \u25a0 \u25a0 + xn wn. This first wave of neural networks research was\u00a0known as cybernetics, as illustrated in Fig. 1.7.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "189",
    "text": "The McCulloch-Pitts Neuron (McCulloch and Pitts, 1943) was an early model of brain function. This linear model could recognize two different categories of\u00a0inputs by testing whether f (x, w) is positive or negative. Of course, for the model\u00a0to correspond to the desired definition of the categories, the weights needed to be\u00a0set correctly. These weights could be set by the human operator. In the 1950s,\u00a0the perceptron (Rosenblatt, 1958, 1962) became the first model that could learn\u00a0the weights defining the categories given examples of inputs from each category.\u00a0The adaptive linear element (ADALINE), which dates from about the same time,\u00a0simply returned the value of f (x) itself to predict a real number (Widrow and\u00a0Hoff, 1960), and could also learn to predict these numbers from data.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "190",
    "text": "These simple learning algorithms greatly affected the modern landscape of machine learning. The training algorithm used to adapt the weights of the ADA-LINE was a special case of an algorithm called stochastic gradient descent. Slightly\u00a0modified versions of the stochastic gradient descent algorithm remain the dominant\u00a0training algorithms for deep learning models today.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "191",
    "text": "Models based on the f(x, w) used by the perceptron and ADALINE are called linea,r models. These models remain some of the most widely used machine learning\u00a0models, though in many cases they are trained in different ways than the original\u00a0models were trained.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "192",
    "text": "Linear models have many limitations. Most famously, they cannot learn the XOR function, where f ([0,1] , w) = 1 and f ([1,0], w) = 1 but f ([1,1], w) = 0\u00a0and f ([0, 0], w) = 0. Critics who observed these flaws in linear models caused\u00a0a backlash against biologically inspired learning in general (Minsky and Papert,\u00a01969). This was the first major dip in the popularity of neural networks.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "193",
    "text": "Today, neuroscience is regarded as an important source of inspiration for deep learning researchers, but it is no longer the predominant guide for the field.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "194",
    "text": "The main reason for the diminished role of neuroscience in deep learning research today is that we simply do not have enough information about the brain\u00a0to use it as a guide. To obtain a deep understanding of the actual algorithms used\u00a0by the brain, we would need to be able to monitor the activity of (at the very\u00a0least) thousands of interconnected neurons simultaneously. Because we are not\u00a0able to do this, we are far from understanding even some of the most simple and",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "195",
    "text": "well-studied parts of the brain (Olshausen and Field, 2005).",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "196",
    "text": "Neuroscience has given us a reason to hope that a single deep learning algorithm can solve many different tasks. Neuroscientists have found that ferrets can learn to\u00a0\u201csee\u201d with the auditory processing region of their brain if their brains are rewired\u00a0to send visual signals to that area (Von Melchner et al., 2000). This suggests that\u00a0much of the mammalian brain might use a single algorithm to solve most of the\u00a0different tasks that the brain solves. Before this hypothesis, machine learning\u00a0research was more fragmented, with different communities of researchers studying\u00a0natural language processing, vision, motion planning and speech recognition. Today,\u00a0these application communities are still separate, but it is common for deep learning\u00a0research groups to study many or even all of these application areas simultaneously.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "197",
    "text": "We are able to draw some rough guidelines from neuroscience. The basic idea of having many computational units that become intelligent only via their interactions\u00a0with each other is inspired by the brain. The Neocognitron (Fukushima, 1980)\u00a0introduced a powerful model architecture for processing images that was inspired\u00a0by the structure of the mammalian visual system and later became the basis for\u00a0the modern convolutional network (LeCun et al., 1998b), as we will see in Sec. 9.10.\u00a0Most neural networks today are based on a model neuron called the rectified linear\u00a0unit. The original Cognitron (Fukushima, 1975) introduced a more complicated\u00a0version that was highly inspired by our knowledge of brain function. The simplified\u00a0modern version was developed incorporating ideas from many viewpoints, with Nair\u00a0and Hinton (2010) and Glorot et al. (2011a) citing neuroscience as an influence, and\u00a0Jarrett et al. (2009) citing more engineering-oriented influences. While neuroscience\u00a0is an important source of inspiration, it need not be taken as a rigid guide. We\u00a0know that actual neurons compute very different functions than modern rectified\u00a0linear units, but greater neural realism has not yet led to an improvement in\u00a0machine learning performance. Also, while neuroscience has successfully inspired\u00a0several neural network architectures, we do not yet know enough about biological\u00a0learning for neuroscience to offer much guidance for the learning algorithms we\u00a0use to train these architectures.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "198",
    "text": "Media accounts often emphasize the similarity of deep learning to the brain. While it is true that deep learning researchers are more likely to cite the brain as an\u00a0influence than researchers working in other machine learning fields such as kernel\u00a0machines or Bayesian statistics, one should not view deep learning as an attempt\u00a0to simulate the brain. Modern deep learning draws inspiration from many fields,\u00a0especially applied math fundamentals like linear algebra, probability, information\u00a0theory, and numerical optimization. While some deep learning researchers cite\u00a0neuroscience as an important source of inspiration, others are not concerned with",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "199",
    "text": "neuroscience at all.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "200",
    "text": "It is worth noting that the effort to understand how the brain works on an algorithmic level is alive and well. This endeavor is primarily known as\u00a0\u201ccomputational neuroscience\u201d and is a separate field of study from deep learning.\u00a0It is common for researchers to move back and forth between both fields. The\u00a0field of deep learning is primarily concerned with how to build computer systems\u00a0that are able to successfully solve tasks requiring intelligence, while the field of\u00a0computational neuroscience is primarily concerned with building more accurate\u00a0models of how the brain actually works.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "201",
    "text": "In the 1980s, the second wave of neural network research emerged in great part via a movement called connectionism or parallel distributed processing (Rumelhart\u00a0et al., 1986c; McClelland et al., 1995). Connectionism arose in the context of\u00a0cognitive science. Cognitive science is an interdisciplinary approach to understanding the mind, combining multiple different levels of analysis. During the early\u00a01980s, most cognitive scientists studied models of symbolic reasoning. Despite their\u00a0popularity, symbolic models were difficult to explain in terms of how the brain\u00a0could actually implement them using neurons. The connectionists began to study\u00a0models of cognition that could actually be grounded in neural implementations\u00a0(Touretzky and Minton, 1985), reviving many ideas dating back to the work of\u00a0psychologist Donald Hebb in the 1940s (Hebb, 1949).",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "202",
    "text": "The central idea in connectionism is that a large number of simple computational units can achieve intelligent behavior when networked together. This insight\u00a0applies equally to neurons in biological nervous systems and to hidden units in\u00a0computational models.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "203",
    "text": "Several key concepts arose during the connectionism movement of the 1980s that remain central to today\u2019s deep learning.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "204",
    "text": "One of these concepts is that of distributed representation (Hinton et al., 1986). This is the idea that each input to a system should be represented by many features,\u00a0and each feature should be involved in the representation of many possible inputs.\u00a0For example, suppose we have a vision system that can recognize cars, trucks, and\u00a0birds and these objects can each be red, green, or blue. One way of representing\u00a0these inputs would be to have a separate neuron or hidden unit that activates for\u00a0each of the nine possible combinations: red truck, red car, red bird, green truck, and\u00a0so on. This requires nine different neurons, and each neuron must independently\u00a0learn the concept of color and object identity. One way to improve on this situation\u00a0is to use a distributed representation, with three neurons describing the color and\u00a0three neurons describing the object identity. This requires only six neurons total\u00a0instead of nine, and the neuron describing redness is able to learn about redness",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "205",
    "text": "from images of cars, trucks and birds, not only from images of one specific category of objects. The concept of distributed representation is central to this book, and\u00a0will be described in greater detail in Chapter 15.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "206",
    "text": "Another major accomplishment of the connectionist movement was the successful use of back-propagation to train deep neural networks with internal representations and the popularization of the back-propagation algorithm (Rumelhart et al., 1986a; LeCun, 1987). This algorithm has waxed and waned in popularity\u00a0but as of this writing is currently the dominant approach to training deep models.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "207",
    "text": "During the 1990s, researchers made important advances in modeling sequences with neural networks. Hochreiter (1991) and Bengio et al. (1994) identified some\u00a0of the fundamental mathematical difficulties in modeling long sequences, described\u00a0in Sec. 10.7. Hochreiter and Schmidhuber (1997) introduced the long short-term\u00a0memory or LSTM network to resolve some of these difficulties. Today, the LSTM\u00a0is widely used for many sequence modeling tasks, including many natural language\u00a0processing tasks at Google.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "208",
    "text": "The second wave of neural networks research lasted until the mid-1990s. Ventures based on neural networks and other AI technologies began to make unrealistically ambitious claims while seeking investments. When AI research did not fulfill these unreasonable expectations, investors were disappointed. Simultaneously,\u00a0other fields of machine learning made advances. Kernel machines (Boser et al.,\u00a01992; Cortes and Vapnik, 1995; Scholkopf et al., 1999) and graphical models (Jordan, 1998) both achieved good results on many important tasks. These two factors\u00a0led to a decline in the popularity of neural networks that lasted until 2007.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "209",
    "text": "During this time, neural networks continued to obtain impressive performance on some tasks (LeCun et al., 1998b; Bengio et al., 2001). The Canadian Institute\u00a0for Advanced Research (CIFAR) helped to keep neural networks research alive\u00a0via its Neural Computation and Adaptive Perception (NCAP) research initiative.\u00a0This program united machine learning research groups led by Geoffrey Hinton\u00a0at University of Toronto, Yoshua Bengio at University of Montreal, and Yann\u00a0LeCun at New York University. The CIFAR NCAP research initiative had a\u00a0multi-disciplinary nature that also included neuroscientists and experts in human\u00a0and computer vision.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "210",
    "text": "At this point in time, deep networks were generally believed to be very difficult to train. We now know that algorithms that have existed since the 1980s work\u00a0quite well, but this was not apparent circa 2006. The issue is perhaps simply that\u00a0these algorithms were too computationally costly to allow much experimentation\u00a0with the hardware available at the time.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "211",
    "text": "The third wave of neural networks research began with a breakthrough in 2006. Geoffrey Hinton showed that a kind of neural network called a deep belief\u00a0network could be efficiently trained using a strategy called greedy layer-wise\u00a0pretraining (Hinton et al., 2006), which will be described in more detail in Sec.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "212",
    "text": "15.1. The other CIFAR-affiliated research groups quickly showed that the same\u00a0strategy could be used to train many other kinds of deep networks (Bengio et al.,\u00a02007; Ranzato et al., 2007a) and systematically helped to improve generalization\u00a0on test examples. This wave of neural networks research popularized the use of the\u00a0term deep learning to emphasize that researchers were now able to train deeper\u00a0neural networks than had been possible before, and to focus attention on the\u00a0theoretical importance of depth (Bengio and LeCun, 2007; Delalleau and Bengio,\u00a02011; Pascanu et al., 2014a; Montufar et al., 2014). At this time, deep neural\u00a0networks outperformed competing AI systems based on other machine learning\u00a0technologies as well as hand-designed functionality. This third wave of popularity\u00a0of neural networks continues to the time of this writing, though the focus of deep\u00a0learning research has changed dramatically within the time of this wave. The\u00a0third wave began with a focus on new unsupervised learning techniques and the\u00a0ability of deep models to generalize well from small datasets, but today there is\u00a0more interest in much older supervised learning algorithms and the ability of deep\u00a0models to leverage large labeled datasets.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "213",
    "text": "One may wonder why deep learning has only recently become recognized as a crucial technology though the first experiments with artificial neural networks were\u00a0conducted in the 1950s. Deep learning has been successfully used in commercial\u00a0applications since the 1990s, but was often regarded as being more of an art than\u00a0a technology and something that only an expert could use, until recently. It is true\u00a0that some skill is required to get good performance from a deep learning algorithm.\u00a0Fortunately, the amount of skill required reduces as the amount of training data\u00a0increases. The learning algorithms reaching human performance on complex tasks\u00a0today are nearly identical to the learning algorithms that struggled to solve toy\u00a0problems in the 1980s, though the models we train with these algorithms have\u00a0undergone changes that simplify the training of very deep architectures. The most\u00a0important new development is that today we can provide these algorithms with\u00a0the resources they need to succeed. Fig. 1.8 shows how the size of benchmark\u00a0datasets has increased remarkably over time. This trend is driven by the increasing\u00a0digitization of society. As more and more of our activities take place on computers,\u00a0more and more of what we do is recorded. As our computers are increasingly\u00a0networked together, it becomes easier to centralize these records and curate them\u00a0into a dataset appropriate for machine learning applications. The age of \u201cBig\u00a0Data\u201d has made machine learning much easier because the key burden of statistical\u00a0estimation\u2014generalizing well to new data after observing only a small amount\u00a0of data\u2014has been considerably lightened. As of 2016, a rough rule of thumb\u00a0is that a supervised deep learning algorithm will generally achieve acceptable\u00a0performance with around 5,000 labeled examples per category, and will match or\u00a0exceed human performance when trained with a dataset containing at least 10\u00a0million labeled examples. Working successfully with datasets smaller than this is\u00a0an important research area, focusing in particular on how we can take advantage\u00a0of large quantities of unlabeled examples, with unsupervised or semi-supervised\u00a0learning.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "214",
    "text": "Another key reason that neural networks are wildly successful today after enjoying comparatively little success since the 1980s is that we have the computational\u00a0resources to run much larger models today. One of the main insights of connection-ism is that animals become intelligent when many of their neurons work together.\u00a0An individual neuron or small collection of neurons is not particularly useful.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "215",
    "text": "Biological neurons are not especially densely connected. As seen in Fig. 1.10, our machine learning models have had a number of connections per neuron that\u00a0was within an order of magnitude of even mammalian brains for decades.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "216",
    "text": "In terms of the total number of neurons, neural networks have been astonishingly small until quite recently, as shown in Fig. 1.11. Since the introduction of hidden\u00a0units, artificial neural networks have doubled in size roughly every 2.4 years. This\u00a0growth is driven by faster computers with larger memory and by the availability\u00a0of larger datasets. Larger networks are able to achieve higher accuracy on more\u00a0complex tasks. This trend looks set to continue for decades. Unless new technologies\u00a0allow faster scaling, artificial neural networks will not have the same number of\u00a0neurons as the human brain until at least the 2050s. Biological neurons may\u00a0represent more complicated functions than current artificial neurons, so biological\u00a0neural networks may be even larger than this plot portrays.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "217",
    "text": "In retrospect, it is not particularly surprising that neural networks with fewer neurons than a leech were unable to solve sophisticated artificial intelligence problems. Even today\u2019s networks, which we consider quite large from a computational\u00a0systems point of view, are smaller than the nervous system of even relatively\u00a0primitive vertebrate animals like frogs.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "218",
    "text": "The increase in model size over time, due to the availability of faster CPUs,",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "219",
    "text": "10 108\u00a0107\u00a0106",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "220",
    "text": "Increasing dataset size over time",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "221",
    "text": "",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "222",
    "text": "* \u05be *T",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "223",
    "text": "",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "224",
    "text": "WMT",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "225",
    "text": ". /-",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "226",
    "text": "Sports-IM",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "227",
    "text": "ImageNetlOk -",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "228",
    "text": "Public SVHN",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "229",
    "text": "10",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "230",
    "text": "\u05e0\u05e1",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "231",
    "text": "\u05de\u05d6",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "232",
    "text": "\"cl",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "233",
    "text": "p",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "234",
    "text": "ILSVRC 2014",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "235",
    "text": "Criminals \u00a0\u00a0\u00a0ImageNet 0",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "236",
    "text": "^ \\",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "237",
    "text": "CIFAR-10",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "238",
    "text": "MNIST ' ' f",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "239",
    "text": "Rotated T vs C",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "240",
    "text": "104 103\u00a0102",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "241",
    "text": "10 10\u00b0",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "242",
    "text": "1985 2000 2015",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "243",
    "text": "1950",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "244",
    "text": "1900",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "245",
    "text": "Figure 1.8: Dataset sizes have increased greatly over time. In the early 1900s, statisticians studied datasets using hundreds or thousands of manually compiled measurements (Garson,\u00a01900; Gosset, 1908; Anderson, 1935; Fisher, 1936). In the 1950s through 1980s, the pioneers\u00a0of biologically inspired machine learning often worked with small, synthetic datasets, such\u00a0as low-resolution bitmaps of letters, that were designed to incur low computational cost and\u00a0demonstrate that neural networks were able to learn specific kinds of functions (Widrow\u00a0and Hoff, 1960; Rumelhart et al., 1986b). In the 1980s and 1990s, machine learning\u00a0became more statistical in nature and began to leverage larger datasets containing tens\u00a0of thousands of examples such as the MNIST dataset (shown in Fig. 1.9) of scans of\u00a0handwritten numbers (LeCun et al., 1998b). In the first decade of the 2000s, more\u00a0sophisticated datasets of this same size, such as the CIFAR-10 dataset (Krizhevsky and\u00a0Hinton, 2009) continued to be produced. Toward the end of that decade and throughout\u00a0the first half of the 2010s, significantly larger datasets, containing hundreds of thousands\u00a0to tens of millions of examples, completely changed what was possible with deep learning.\u00a0These datasets included the public Street View House Numbers dataset (Netzer et al.,\u00a02011), various versions of the ImageNet dataset (Deng et al., 2009, 2010a; Russakovsky\u00a0et al., 2014a), and the Sports-1M dataset (Karpathy et al., 2014). At the top of the\u00a0graph, we see that datasets of translated sentences, such as IBM\u2019s dataset constructed\u00a0from the Canadian Hansard (Brown et al., 1990) and the WMT 2014 English to French\u00a0dataset (Schwenk, 2014) are typically far ahead of other dataset sizes.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "246",
    "text": "Figure 1.9: Example inputs from the MNIST dataset. The \u201cNIST\u201d stands for National Institute of Standards and Technology, the agency that originally collected this data.\u00a0The \u201cM\u201d stands for \u201cmodified,\u201d since the data has been preprocessed for easier use with\u00a0machine learning algorithms. The MNIST dataset consists of scans of handwritten digits\u00a0and associated labels describing which digit 0-9 is contained in each image. This simple\u00a0classification problem is one of the simplest and most widely used tests in deep learning\u00a0research. It remains popular despite being quite easy for modern techniques to solve.\u00a0Geoffrey Hinton has described it as \u201cthe drosophila of machine learning,\u201d meaning that\u00a0it allows machine learning researchers to study their algorithms in controlled laboratory\u00a0conditions, much as biologists often study fruit flies.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "247",
    "text": "the advent of general purpose GPUs (described in Sec. 12.1.2), faster network connectivity and better software infrastructure for distributed computing, is one of\u00a0the most important trends in the history of deep learning. This trend is generally\u00a0expected to continue well into the future.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "248",
    "text": "Since the 1980s, deep learning has consistently improved in its ability to provide accurate recognition or prediction. Moreover, deep learning has consistently been\u00a0applied with success to broader and broader sets of applications.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "249",
    "text": "The earliest deep models were used to recognize individual objects in tightly cropped, extremely small images (Rumelhart et al., 1986a). Since then there has\u00a0been a gradual increase in the size of images neural networks could process. Modern\u00a0object recognition networks process rich high-resolution photographs and do not\u00a0have a requirement that the photo be cropped near the object to be recognized\u00a0(Krizhevsky et al., 2012). Similarly, the earliest networks could only recognize\u00a0two kinds of objects (or in some cases, the absence or presence of a single kind of\u00a0object), while these modern networks typically recognize at least 1,000 different\u00a0categories of objects. The largest contest in object recognition is the ImageNet\u00a0Large-Scale Visual Recognition Challenge (ILSVRC) held each year. A dramatic\u00a0moment in the meteoric rise of deep learning came when a convolutional network\u00a0won this challenge for the first time and by a wide margin, bringing down the\u00a0state-of-the-art top-5 error rate from 26.1% to 15.3% (Krizhevsky et al., 2012),\u00a0meaning that the convolutional network produces a ranked list of possible categories\u00a0for each image and the correct category appeared in the first five entries of this\u00a0list for all but 15.3% of the test examples. Since then, these competitions are\u00a0consistently won by deep convolutional nets, and as of this writing, advances in\u00a0deep learning have brought the latest top-5 error rate in this contest down to 3.6%,\u00a0as shown in Fig. 1.12.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "250",
    "text": "Deep learning has also had a dramatic impact on speech recognition. After improving throughout the 1990s, the error rates for speech recognition stagnated\u00a0starting in about 2000. The introduction of deep learning (Dahl et al., 2010; Deng\u00a0et al., 2010b; Seide et al., 2011; Hinton et al., 2012a) to speech recognition resulted\u00a0in a sudden drop of error rates, with some error rates cut in half. We will explore\u00a0this history in more detail in Sec. 12.3.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "251",
    "text": "Deep networks have also had spectacular successes for pedestrian detection and image segmentation (Sermanet et al., 2013; Farabet et al., 2013; Couprie et al.,",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "252",
    "text": "2013) and yielded superhuman performance in traffic sign classification (Ciresan",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "253",
    "text": "101 2 3 4 5 6 7 8 9 10",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "254",
    "text": "a",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "255",
    "text": "o",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "256",
    "text": "u",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "257",
    "text": "3",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "258",
    "text": "a",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "259",
    "text": "f-H",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "260",
    "text": "<D",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "261",
    "text": "co",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "262",
    "text": "a",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "263",
    "text": "o",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "264",
    "text": "10'",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "265",
    "text": "o",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "266",
    "text": "<D",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "267",
    "text": "a",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "268",
    "text": "s",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "269",
    "text": "o",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "270",
    "text": "O",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "271",
    "text": "102",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "272",
    "text": "101",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "273",
    "text": "1950 \u00a0\u00a0\u00a01985\u00a0\u00a0\u00a0\u00a02000\u00a0\u00a0\u00a0\u00a02015",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "274",
    "text": "Figure 1.10: Initially, the number of connections between neurons in artificial neural networks was limited by hardware capabilities. Today, the number of connections between\u00a0neurons is mostly a design consideration. Some artificial neural networks have nearly as\u00a0many connections per neuron as a cat, and it is quite common for other neural networks\u00a0to have as many connections per neuron as smaller mammals like mice. Even the human\u00a0brain does not have an exorbitant amount of connections per neuron. Biological neural\u00a0network sizes from Wikipedia (2015).",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "275",
    "text": "et al., 2012).",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "276",
    "text": "At the same time that the scale and accuracy of deep networks has increased, so has the complexity of the tasks that they can solve. Goodfellow et al. (2014d)\u00a0showed that neural networks could learn to output an entire sequence of characters\u00a0transcribed from an image, rather than just identifying a single object. Previously,\u00a0it was widely believed that this kind of learning required labeling of the individual\u00a0elements of the sequence (Gulgehre and Bengio, 2013). Recurrent neural networks,\u00a0such as the LSTM sequence model mentioned above, are now used to model\u00a0relationships between sequences and other sequences rather than just fixed inputs.\u00a0This sequence-to-sequence learning seems to be on the cusp of revolutionizing\u00a0another application: machine translation (Sutskever et al., 2014; Bahdanau et al.,\u00a02015).",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "277",
    "text": "This trend of increasing complexity has been pushed to its logical conclusion with the introduction of neural Turing machines (Graves et al., 2014a) that learn\u00a0to read from memory cells and write arbitrary content to memory cells. Such\u00a0neural networks can learn simple programs from examples of desired behavior. For\u00a0example, they can learn to sort lists of numbers given examples of scrambled and\u00a0sorted sequences. This self-programming technology is in its infancy, but in the\u00a0future could in principle be applied to nearly any task.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "278",
    "text": "Another crowning achievement of deep learning is its extension to the domain of reinforcement learning. In the context of reinforcement learning, an autonomous\u00a0agent must learn to perform a task by trial and error, without any guidance from\u00a0the human operator. DeepMind demonstrated that a reinforcement learning system\u00a0based on deep learning is capable of learning to play Atari video games, reaching\u00a0human-level performance on many tasks (Mnih et al., 2015). Deep learning has\u00a0also significantly improved the performance of reinforcement learning for robotics\u00a0(Finn et al., 2015).",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "279",
    "text": "Many of these applications of deep learning are highly profitable. Deep learning is now used by many top technology companies including Google, Microsoft,\u00a0Facebook, IBM, Baidu, Apple, Adobe, Netflix, NVIDIA and NEC.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "280",
    "text": "Advances in deep learning have also depended heavily on advances in software infrastructure. Software libraries such as Theano (Bergstra et al., 2010; Bastien\u00a0et al., 2012), PyLearn2 (Goodfellow et al., 2013c), Torch (Collobert et al., 2011b),\u00a0DistBelief (Dean et al., 2012), Caffe (Jia, 2013), MXNet (Chen et al., 2015), and\u00a0TensorFlow (Abadi et al., 2015) have all supported important research projects or\u00a0commercial products.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "281",
    "text": "Deep learning has also made contributions back to other sciences. Modern convolutional networks for object recognition provide a model of visual processing\u00a0that neuroscientists can study (DiCarlo, 2013). Deep learning also provides useful\u00a0tools for processing massive amounts of data and making useful predictions in\u00a0scientific fields. It has been successfully used to predict how molecules will interact\u00a0in order to help pharmaceutical companies design new drugs (Dahl et al., 2014),\u00a0to search for subatomic particles (Baldi et al., 2014), and to automatically parse\u00a0microscope images used to construct a 3-D map of the human brain (Knowles-Barley et al., 2014). We expect deep learning to appear in more and more scientific\u00a0fields in the future.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "282",
    "text": "In summary, deep learning is an approach to machine learning that has drawn heavily on our knowledge of the human brain, statistics and applied math as it\u00a0developed over the past several decades. In recent years, it has seen tremendous\u00a0growth in its popularity and usefulness, due in large part to more powerful computers, larger datasets and techniques to train deeper networks. The years ahead\u00a0are full of challenges and opportunities to improve deep learning even further and\u00a0bring it to new frontiers.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "283",
    "text": "1011",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "284",
    "text": "Figure 1.11: Since the introduction of hidden units, artificial neural networks have doubled in size roughly every 2.4 years. Biological neural network sizes from Wikipedia (2015).",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "285",
    "text": "1010",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "286",
    "text": "109",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "287",
    "text": "108",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "288",
    "text": "107",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "289",
    "text": "106",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "290",
    "text": "105",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "291",
    "text": "104",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "292",
    "text": "103",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "293",
    "text": "102",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "294",
    "text": "101",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "295",
    "text": "100",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "296",
    "text": "1\u05be10 2\u05be10",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "297",
    "text": "1. \u00a0\u00a0\u00a0Perceptron (Rosenblatt, 1958, 1962)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "298",
    "text": "2. \u00a0\u00a0\u00a0Adaptive linear element (Widrow and Hoff, 1960)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "299",
    "text": "3. \u00a0\u00a0\u00a0Neocognitron (Fukushima, 1980)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "300",
    "text": "4. \u00a0\u00a0\u00a0Early back-propagation network (Rumelhart et al., 1986b)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "301",
    "text": "5. \u00a0\u00a0\u00a0Recurrent neural network for speech recognition (Robinson and Fallside, 1991)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "302",
    "text": "6. \u00a0\u00a0\u00a0Multilayer perceptron for speech recognition (Bengio et al., 1991)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "303",
    "text": "7. \u00a0\u00a0\u00a0Mean field sigmoid belief network (Saul et al., 1996)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "304",
    "text": "8. \u00a0\u00a0\u00a0LeNet-5 (LeCun et al., 1998b)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "305",
    "text": "9. \u00a0\u00a0\u00a0Echo state network (Jaeger and Haas, 2004)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "306",
    "text": "10. \u00a0\u00a0\u00a0Deep belief network (Hinton et al., 2006)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "307",
    "text": "11. \u00a0\u00a0\u00a0GPU-accelerated convolutional network (Chellapilla et al., 2006)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "308",
    "text": "12. \u00a0\u00a0\u00a0Deep Boltzmann machine (Salakhutdinov and Hinton, 2009a)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "309",
    "text": "13. \u00a0\u00a0\u00a0GPU-accelerated deep belief network (Raina et al., 2009)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "310",
    "text": "14. \u00a0\u00a0\u00a0Unsupervised convolutional network (Jarrett et al., 2009)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "311",
    "text": "15. \u00a0\u00a0\u00a0GPU-accelerated multilayer perceptron (Ciresan et al., 2010)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "312",
    "text": "16. \u00a0\u00a0\u00a0OMP-1 network (Coates and Ng, 2011)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "313",
    "text": "17. \u00a0\u00a0\u00a0Distributed autoencoder (Le et al., 2012)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "314",
    "text": "18. \u00a0\u00a0\u00a0Multi-GPU convolutional network (Krizhevsky et al., 2012)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "315",
    "text": "19. \u00a0\u00a0\u00a0COTS HPC unsupervised convolutional network (Coates et al., 2013)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "316",
    "text": "20. \u00a0\u00a0\u00a0GoogLeNet (Szegedy et al., 2014a)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "317",
    "text": "Figure 1.12: Since deep networks reached the scale necessary to compete in the ImageNet Large Scale Visual Recognition Challenge, they have consistently won the competition\u00a0every year, and yielded lower and lower error rates each time. Data from Russakovsky\u00a0et al. (2014b) and He et al. (2015).",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "318",
    "text": "Part I",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "319",
    "text": "Applied Math and Machine Learning Basics",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "320",
    "text": "This part of the book introduces the basic mathematical concepts needed to understand deep learning. We begin with general ideas from applied math that\u00a0allow us to define functions of many variables, find the highest and lowest points\u00a0on these functions and quantify degrees of belief.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "321",
    "text": "Next, we describe the fundamental goals of machine learning. We describe how to accomplish these goals by specifying a model that represents certain beliefs,\u00a0designing a cost function that measures how well those beliefs correspond with\u00a0reality and using a training algorithm to minimize that cost function.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "322",
    "text": "This elementary framework is the basis for a broad variety of machine learning algorithms, including approaches to machine learning that are not deep. In the\u00a0subsequent parts of the book, we develop deep learning algorithms within this\u00a0framework.",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "323",
    "text": "1",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "324",
    "text": " \u00a0\u00a0\u00a0Adaptive linear element (Widrow and Hoff, 1960)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "325",
    "text": "2",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "326",
    "text": " \u00a0\u00a0\u00a0Neocognitron (Fukushima, 1980)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "327",
    "text": "3",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "328",
    "text": " \u00a0\u00a0\u00a0GPU-accelerated convolutional network (Chellapilla et al., 2006)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "329",
    "text": "4",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "330",
    "text": " \u00a0\u00a0\u00a0Deep Boltzmann machine (Salakhutdinov and Hinton, 2009a)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "331",
    "text": "5",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "332",
    "text": " \u00a0\u00a0\u00a0Unsupervised convolutional network (Jarrett et al., 2009)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "333",
    "text": "6",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "334",
    "text": " \u00a0\u00a0\u00a0GPU-accelerated multilayer perceptron (Ciresan et al., 2010)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "335",
    "text": "7",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "336",
    "text": " \u00a0\u00a0\u00a0Distributed autoencoder (Le et al., 2012)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "337",
    "text": "8",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "338",
    "text": " \u00a0\u00a0\u00a0Multi-GPU convolutional network (Krizhevsky et al., 2012)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "339",
    "text": "9",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "340",
    "text": " \u00a0\u00a0\u00a0COTS HPC unsupervised convolutional network (Coates et al., 2013)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "341",
    "text": "10",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "342",
    "text": " GoogLeNet (Szegedy et al., 2014a)",
    "chapter": "Introduction",
    "chapter_id": "main-4.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "343",
    "text": "Linear algebra is a branch of mathematics that is widely used throughout science and engineering. However, because linear algebra is a form of continuous rather\u00a0than discrete mathematics, many computer scientists have little experience with it.\u00a0A good understanding of linear algebra is essential for understanding and working\u00a0with many machine learning algorithms, especially deep learning algorithms. We\u00a0therefore precede our introduction to deep learning with a focused presentation of\u00a0the key linear algebra prerequisites.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "344",
    "text": "If you are already familiar with linear algebra, feel free to skip this chapter. If you have previous experience with these concepts but need a detailed reference\u00a0sheet to review key formulas, we recommend The Matrix Cookbook (Petersen and\u00a0Pedersen, 2006). If you have no exposure at all to linear algebra, this chapter\u00a0will teach you enough to read this book, but we highly recommend that you also\u00a0consult another resource focused exclusively on teaching linear algebra, such as\u00a0Shilov (1977). This chapter will completely omit many important linear algebra\u00a0topics that are not essential for understanding deep learning.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "345",
    "text": "The study of linear algebra involves several types of mathematical objects:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "346",
    "text": "\u2022 Scalars: A scalar is just a single number, in contrast to most of the other objects studied in linear algebra, which are usually arrays of multiple numbers.\u00a0We write scalars in italics. We usually give scalars lower-case variable names.\u00a0When we introduce them, we specify what kind of number they are. For\u00a0example, we might say \u201cLet s G R be the slope of the line,\u201d while defining a\u00a0real-valued scalar, or \u201cLet n G N be the number of units,\u201d while defining a\u00a0natural number scalar.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "347",
    "text": "\u2022 Vectors: A vector is an array of numbers. The numbers are arranged in order. We can identify each individual number by its index in that ordering.\u00a0Typically we give vectors lower case names written in bold typeface, such\u00a0as x. The elements of the vector are identified by writing its name in italic\u00a0typeface, with a subscript. The first element of x is x!, the second element\u00a0is x2 and so on. We also need to say what kind of numbers are stored in\u00a0the vector. If each element is in R, and the vector has n elements, then the\u00a0vector lies in the set formed by taking the Cartesian product of R n times,\u00a0denoted as Rn. When we need to explicitly identify the elements of a vector,\u00a0we write them as a column enclosed in square brackets:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "348",
    "text": "x =",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "349",
    "text": "x1",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "350",
    "text": "x2",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "351",
    "text": "-2.1",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "352",
    "text": "Xn",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "353",
    "text": "We can think of vectors as identifying points in space, with each element giving the coordinate along a different axis.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "354",
    "text": "Sometimes we need to index a set of elements of a vector. In this case, we define a set containing the indices and write the set as a subscript. For\u00a0example, to access x 1, X3 and X6, we define the set S = {1, 3,6} and write\u00a0xs. We use the \u2014 sign to index the complement of a set. For example x-1 is\u00a0the vector containing all elements of x except for x!, and x-s is the vector\u00a0containing all of the elements of x except for x!, x3 and x6.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "355",
    "text": "\u2022 Matrices: A matrix is a 2-D array of numbers, so each element is identified by two indices instead of just one. We usually give matrices upper-case variable\u00a0names with bold typeface, such as A. If a real-valued matrix A has a height\u00a0of m and a width of n, then we say that A G Rmxn. We usually identify\u00a0the elements of a matrix using its name in italic but not bold font, and the\u00a0indices are listed with separating commas. For example, A!,! is the upper\u00a0left entry of A and Am,n is the bottom right entry. We can identify all of\u00a0the numbers with vertical coordinate i by writing a \u201c:\u201d for the horizontal\u00a0coordinate. For example, Ai;: denotes the horizontal cross section of A with\u00a0vertical coordinate i. This is known as the i-th row of A. Likewise, A:;i is",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "356",
    "text": "the i-th column of A. When we need to explicitly identify the elements of a matrix, we write them as an array enclosed in square brackets:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "357",
    "text": "-2.2",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "358",
    "text": "A1,1",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "359",
    "text": "A1,2",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "360",
    "text": "Figure 2.1: The transpose of the matrix can be thought of as a mirror image across the main diagonal.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "361",
    "text": "A2,1",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "362",
    "text": "A2,2",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "363",
    "text": "A3,1",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "364",
    "text": "A3,2",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "365",
    "text": "A1,1 \u00a0\u00a0\u00a0A 1,2",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "366",
    "text": "A2,1 \u00a0\u00a0\u00a0A 2,2",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "367",
    "text": "Sometimes we may need to index matrix-valued expressions that are not just a single letter. In this case, we use subscripts after the expression, but do\u00a0not convert anything to lower case. For example, f (A)i,j gives element (i, j)\u00a0of the matrix computed by applying the function f to A.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "368",
    "text": "\u2022 Tensors: In some cases we will need an array with more than two axes. In the general case, an array of numbers arranged on a regular grid with a\u00a0variable number of axes is known as a tensor. We denote a tensor named \u201cA\u201d\u00a0with this typeface: A. We identify the element of A at coordinates (i, j, k)\u00a0by writing Aj\u25a0",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "369",
    "text": "One important operation on matrices is the transpose. The transpose of a matrix is the mirror image of the matrix across a diagonal line, called the main\u00a0diagonal, running down and to the right, starting from its upper left corner. See\u00a0Fig. 2.1 for a graphical depiction of this operation. We denote the transpose of a\u00a0matrix A as AT, and it is defined such that",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "370",
    "text": "(A )i,j = Aj,i2-3) \u00a0\u00a0\u00a0\u05be)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "371",
    "text": "Vectors can be thought of as matrices that contain only one column. The transpose of a vector is therefore a matrix with only one row. Sometimes we\u00a0define a vector by writing out its elements in the text inline as a row matrix,\u00a0then using the transpose operator to turn it into a standard column vector, e.g.,",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "372",
    "text": "X = [X1,X2,X3] T.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "373",
    "text": "A scalar can be thought of as a matrix with only a single entry. From this, we can see that a scalar is its own transpose: a = aT.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "374",
    "text": "We can add matrices to each other, as long as they have the same shape, just by adding their corresponding elements: C = A + B where Ci;j = Ai7j + Bi7j.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "375",
    "text": "We can also add a scalar to a matrix or multiply a matrix by a scalar, just by performing that operation on each element of a matrix: D = a \u2022 B + c where\u00a0Di,j \u2014 a \u2022 Bi,j + c\u2022",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "376",
    "text": "In the context of deep learning, we also use some less conventional notation. We allow the addition of matrix and a vector, yielding another matrix: C \u2014 A + b,\u00a0where Ci;j \u2014 Ai;j + bj. In other words, the vector b is added to each row of the\u00a0matrix. This shorthand eliminates the need to define a matrix with b copied into\u00a0each row before doing the addition. This implicit copying of b to many locations\u00a0is called broadcasting.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "377",
    "text": "One of the most important operations involving matrices is multiplication of two matrices. The matrix product of matrices A and B is a third matrix C. In order\u00a0for this product to be defined, A must have the same number of columns as B has\u00a0rows. If A is of shape m x n and B is of shape n x p, then C is of shape m x p.\u00a0We can write the matrix product just by placing two or more matrices together,",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "378",
    "text": "e.g.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "379",
    "text": "C \u2014 AB.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "380",
    "text": "-2.4",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "381",
    "text": "The product operation is defined by",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "382",
    "text": "Ci,j \u00a0\u00a0\u00a0Ai,kBk,j.\u00a0\u00a0\u00a0\u00a0(2-5)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "383",
    "text": "k",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "384",
    "text": "Note that the standard product of two matrices is not just a matrix containing the product of the individual elements. Such an operation exists and is called the\u00a0element-wise product or Hadamard product, and is denoted as A 0 B.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "385",
    "text": "The dot product between two vectors x and y of the same dimensionality is the matrix product xTy. We can think of the matrix product C \u2014 AB as computing\u00a0Ci;j as the dot product between row i of A and column j of B.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "386",
    "text": "Matrix product operations have many useful properties that make mathematical analysis of matrices more convenient. For example, matrix multiplication is\u00a0distributive:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "387",
    "text": "This allows us to demonstrate Eq. 2.8, by exploiting the fact that the value of such a product is a scalar and therefore equal to its own transpose:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "388",
    "text": "xy = (x Ty) = yT x. \u00a0\u00a0\u00a0(2.10)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "389",
    "text": "Since the focus of this textbook is not linear algebra, we do not attempt to develop a comprehensive list of useful properties of the matrix product here, but\u00a0the reader should be aware that many more exist.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "390",
    "text": "We now know enough linear algebra notation to write down a system of linear equations:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "391",
    "text": "-2.11",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "392",
    "text": "Ax = b",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "393",
    "text": "where A G Rmxn is a known matrix, b G Rm is a known vector, and x G Rn is a vector of unknown variables we would like to solve for. Each element xi of x is one\u00a0of these unknown variables. Each row of A and each element of b provide another\u00a0constraint. We can rewrite Eq. 2.11 as:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "394",
    "text": "A1,:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "395",
    "text": "x =",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "396",
    "text": "- b1",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "397",
    "text": "-2.12",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "398",
    "text": "A2,:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "399",
    "text": "x =",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "400",
    "text": "main-1.xhtml",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "401",
    "text": "-2.13",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "402",
    "text": "",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "403",
    "text": "",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "404",
    "text": "",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "405",
    "text": "-2.14",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "406",
    "text": "A",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "407",
    "text": "Am,",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "408",
    "text": ": x =",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "409",
    "text": "- bm",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "410",
    "text": "-2.15",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "411",
    "text": ",2X2",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "412",
    "text": "+ \u25a0",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "413",
    "text": " ' + A 1,nxn = b1",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "414",
    "text": "-2.16",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "415",
    "text": "or, even more explicitly, as:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "416",
    "text": "1 0 0 0 1 0\u00a00 0 1",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "417",
    "text": "Figure 2.2: Example identity matrix: This is I.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "418",
    "text": "A2,1 X1 + A2,2x2 +-----+ A 2,nXn = &2 \u00a0\u00a0\u00a0(2-17)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "419",
    "text": "... (2.18) Am,1x1 + Am,2x2 + ' ' ' + Am,nxn = fym \u2022\u00a0\u00a0\u00a0\u00a0(2-19)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "420",
    "text": "Matrix-vector product notation provides a more compact representation for equations of this form.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "421",
    "text": "Linear algebra offers a powerful tool called matrix inversion that allows us to analytically solve Eq. 2.11 for many values of A.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "422",
    "text": "To describe matrix inversion, we first need to define the concept of an identity matrix. An identity matrix is a matrix that does not change any vector when we\u00a0multiply that vector by that matrix. We denote the identity matrix that preserves\u00a0n-dimensional vectors as In. Formally, In G Rnxn, and",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "423",
    "text": "Vx G Rn, Inx = x. \u00a0\u00a0\u00a0(2.20)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "424",
    "text": "The structure of the identity matrix is simple: all of the entries along the main diagonal are 1, while all of the other entries are zero. See Fig. 2.2 for an example.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "425",
    "text": "The matrix inverse of A is denoted as A-1, and it is defined as the matrix such that",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "426",
    "text": "A-1 A = In.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "427",
    "text": "We can now solve Eq. 2.11 by the following steps:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "428",
    "text": "-2.21",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "429",
    "text": "Ax = b",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "430",
    "text": "-2.22",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "431",
    "text": "A-1 Ax = A-1b",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "432",
    "text": "-2.23",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "433",
    "text": "In x = A-1 b",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "434",
    "text": "-2.24",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "435",
    "text": "x = A-1b. \u00a0\u00a0\u00a0(2.25)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "436",
    "text": "Of course, this depends on it being possible to find A-1. We discuss the conditions for the existence of A-1 in the following section.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "437",
    "text": "When A-1 exists, several different algorithms exist for finding it in closed form. In theory, the same inverse matrix can then be used to solve the equation many\u00a0times for different values of b. However, A -1 is primarily useful as a theoretical\u00a0tool, and should not actually be used in practice for most software applications.\u00a0Because A-1 can be represented with only limited precision on a digital computer,\u00a0algorithms that make use of the value of b can usually obtain more accurate\u00a0estimates of x.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "438",
    "text": "In order for A-1 to exist, Eq. 2.11 must have exactly one solution for every value of b. However, it is also possible for the system of equations to have no solutions\u00a0or infinitely many solutions for some values of b. It is not possible to have more\u00a0than one but less than infinitely many solutions for a particular b; if both x and y\u00a0are solutions then",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "439",
    "text": "z = ax + (1 \u2014 a)y \u00a0\u00a0\u00a0(2.26)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "440",
    "text": "is also a solution for any real a.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "441",
    "text": "To analyze how many solutions the equation has, we can think of the columns of A as specifying different directions we can travel from the origin (the point\u00a0specified by the vector of all zeros), and determine how many ways there are of\u00a0reaching b. In this view, each element of x specifies how far we should travel in\u00a0each of these directions, with xi specifying how far to move in the direction of\u00a0column i:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "442",
    "text": "Ax = ^ xiA:,i. \u00a0\u00a0\u00a0(2.27)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "443",
    "text": "i",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "444",
    "text": "In general, this kind of operation is called a linear combination. Formally, a linear combination of some set of vectors {v(1),..., v(n)} is given by multiplying each\u00a0vector v(i) by a corresponding scalar coefficient and adding the results:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "445",
    "text": "J^ci v(i). \u00a0\u00a0\u00a0(2.28)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "446",
    "text": "i",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "447",
    "text": "The span of a set of vectors is the set of all points obtainable by linear combination of the original vectors.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "448",
    "text": "Determining whether Ax = b has a solution thus amounts to testing whether b is in the span of the columns of A. This particular span is known as the column\u00a0space or the range of A.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "449",
    "text": "In order for the system Ax = b to have a solution for all values of b G Rm, we therefore require that the column space of A be all of Rm. If any point inR m\u00a0is excluded from the column space, that point is a potential value of b that has\u00a0no solution. The requirement that the column space of A be all of Rm implies\u00a0immediately that A must have at least m columns, i.e., n > m. Otherwise, the\u00a0dimensionality of the column space would be less than m. For example, consider a\u00a03 x 2 matrix. The target b is 3-D, but x is only 2-D, so modifying the value of x\u00a0at best allows us to trace out a 2-D plane within R 3 The equation has a solution\u00a0if and only if b lies on that plane.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "450",
    "text": "Having n > m is only a necessary condition for every point to have a solution. It is not a sufficient condition, because it is possible for some of the columns to\u00a0be redundant. Consider a 2 x 2 matrix where both of the columns are identical.\u00a0This has the same column space as a 2 x 1 matrix containing only one copy of the\u00a0replicated column. In other words, the column space is still just a line, and fails to\u00a0encompass all of R2, even though there are two columns.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "451",
    "text": "Formally, this kind of redundancy is known as linear dependence. A set of vectors is linearly independent if no vector in the set is a linear combination of the\u00a0other vectors. If we add a vector to a set that is a linear combination of the other\u00a0vectors in the set, the new vector does not add any points to the set\u2019s span. This\u00a0means that for the column space of the matrix to encompass all of Rm, the matrix\u00a0must contain at least one set of m linearly independent columns. This condition\u00a0is both necessary and sufficient for Eq. 2.11 to have a solution for every value of\u00a0b. Note that the requirement is for a set to have exactly m linear independent\u00a0columns, not at least m. No set of m-dimensional vectors can have more than m\u00a0mutually linearly independent columns, but a matrix with more than m columns\u00a0may have more than one such set.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "452",
    "text": "In order for the matrix to have an inverse, we additionally need to ensure that Eq. 2.11 has at most one solution for each value of b. To do so, we need to ensure\u00a0that the matrix has at most m columns. Otherwise there is more than one way of\u00a0parametrizing each solution.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "453",
    "text": "Together, this means that the matrix must be square, that is, we require that m = n and that all of the columns must be linearly independent. A square matrix\u00a0with linearly dependent columns is known as singular.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "454",
    "text": "If A is not square or is square but singular, it can still be possible to solve the equation. However, we can not use the method of matrix inversion to find the\u00a0solution.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "455",
    "text": "So far we have discussed matrix inverses as being multiplied on the left. It is also possible to define an inverse that is multiplied on the right:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "456",
    "text": "AA-1 = I. \u00a0\u00a0\u00a0(2.29)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "457",
    "text": "For square matrices, the left inverse and right inverse are equal.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "458",
    "text": "Sometimes we need to measure the size of a vector. In machine learning, we usually measure the size of vectors using a function called a norm. Formally, the Lp norm\u00a0is given by",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "459",
    "text": "x",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "460",
    "text": "p",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "461",
    "text": "(\u05f4?)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "462",
    "text": "-2.3",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "463",
    "text": "for p e R,p > 1.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "464",
    "text": "Norms, including the Lp norm, are functions mapping vectors to non-negative values. On an intuitive level, the norm of a vector x measures the distance from\u00a0the origin to the point x. More rigorously, a norm is any function f that satisfies\u00a0the following properties:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "465",
    "text": "\u2022 \u00a0\u00a0\u00a0f (x) = 0 ^ x = 0",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "466",
    "text": "\u2022 f (x + y) < f (x) + f (y) (the triangle inequality)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "467",
    "text": "\u2022 Va e R, f (ax) = |a|f (x)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "468",
    "text": "The L2 norm, with p = 2, is known as the Euclidean norm. It is simply the Euclidean distance from the origin to the point identified by x. The L2 norm is\u00a0used so frequently in machine learning that it is often denoted simply as ||x||, with\u00a0the subscript 2 omitted. It is also common to measure the size of a vector using\u00a0the squared L2 norm, which can be calculated simply as xTx.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "469",
    "text": "The squared L2 norm is more convenient to work with mathematically and computationally than the L2 norm itself. For example, the derivatives of the\u00a0squared L2 norm with respect to each element of x each depend only on the\u00a0corresponding element of x, while all of the derivatives of the L norm depend\u00a0on the entire vector. In many contexts, the squared L2 norm may be undesirable",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "470",
    "text": "because it increases very slowly near the origin. In several machine learning applications, it is important to discriminate between elements that are exactly\u00a0zero and elements that are small but nonzero. In these cases, we turn to a function\u00a0that grows at the same rate in all locations, but retains mathematical simplicity:\u00a0the L1 norm. The L1 norm may be simplified to",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "471",
    "text": "x1",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "472",
    "text": "Y |xi 1\u2022",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "473",
    "text": "-2.31",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "474",
    "text": "The L1 norm is commonly used in machine learning when the difference between zero and nonzero elements is very important. Every time an element of x moves\u00a0away from 0 by e, the L1 norm increases by e.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "475",
    "text": "We sometimes measure the size of the vector by counting its number of nonzero elements. Some authors refer to this function as the \u201cL0 norm,\u201d but this is incorrect\u00a0terminology. The number of non-zero entries in a vector is not a norm, because\u00a0scaling the vector by a does not change the number of nonzero entries. The L1\u00a0norm is often used as a substitute for the number of nonzero entries.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "476",
    "text": "One other norm that commonly arises in machine learning is the LM norm, also known as the max norm. This norm simplifies to the absolute value of the\u00a0element with the largest magnitude in the vector,",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "477",
    "text": "x",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "478",
    "text": "max \\xi |\u2022",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "479",
    "text": "-2.32",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "480",
    "text": "i",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "481",
    "text": "Sometimes we may also wish to measure the size of a matrix. In the context of deep learning, the most common way to do this is with the otherwise obscure\u00a0Frobenius norm",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "482",
    "text": "-2.33",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "483",
    "text": "which is analogous to the L2 norm of a vector.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "484",
    "text": "The dot product of two vectors can be rewritten in terms of norms. Specifically,",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "485",
    "text": "xT y = ||x||2||y|| 2 cos 6 \u00a0\u00a0\u00a0(2.34)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "486",
    "text": "where 6 is the angle between x and y.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "487",
    "text": "Some special kinds of matrices and vectors are particularly useful.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "488",
    "text": "Diagonal matrices consist mostly of zeros and have non-zero entries only along the main diagonal. Formally, a matrix D is diagonal if and only if Di,j = 0 for\u00a0all i = j. We have already seen one example of a diagonal matrix: the identity\u00a0matrix, where all of the diagonal entries are 1. We write diag(v) to denote a square\u00a0diagonal matrix whose diagonal entries are given by the entries of the vector v.\u00a0Diagonal matrices are of interest in part because multiplying by a diagonal matrix\u00a0is very computationally efficient. To compute diag(v)x, we only need to scale each\u00a0element xi by vi. In other words, diag( v) x = v 0 x. Inverting a square diagonal\u00a0matrix is also efficient. The inverse exists only if every diagonal entry is nonzero,\u00a0and in that case, diag(v)-1 = diag([1/v 1,..., 1/vn]T). In many cases, we may\u00a0derive some very general machine learning algorithm in terms of arbitrary matrices,\u00a0but obtain a less expensive (and less descriptive) algorithm by restricting some\u00a0matrices to be diagonal.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "489",
    "text": "Not all diagonal matrices need be square. It is possible to construct a rectangular diagonal matrix. Non-square diagonal matrices do not have inverses but it is still\u00a0possible to multiply by them cheaply. For a non-square diagonal matrix D, the\u00a0product Dx will involve scaling each element of x, and either concatenating some\u00a0zeros to the result if D is taller than it is wide, or discarding some of the last\u00a0elements of the vector if D is wider than it is tall.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "490",
    "text": "A symmetric matrix is any matrix that is equal to its own transpose:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "491",
    "text": "A = A T. \u00a0\u00a0\u00a0(2.35)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "492",
    "text": "Symmetric matrices often arise when the entries are generated by some function of two arguments that does not depend on the order of the arguments. For example,\u00a0if A is a matrix of distance measurements, with Ai;j\u25a0 giving the distance from point\u00a0i to point j, then Aj j = Aj;i because distance functions are symmetric.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "493",
    "text": "A unit vector is a vector with unit norm:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "494",
    "text": "||x||2 = 1. \u00a0\u00a0\u00a0(2.36)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "495",
    "text": "A vector x and a vector y are orthogonal to each other if xTy = 0. If both vectors have nonzero norm, this means that they are at a 90 degree angle to each\u00a0other. In Rn ,at most n vectors may be mutually orthogonal with nonzero norm.\u00a0If the vectors are not only orthogonal but also have unit norm, we call them\u00a0orthonormal.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "496",
    "text": "An orthogonal matrix is a square matrix whose rows are mutually orthonormal and whose columns are mutually orthonormal:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "497",
    "text": "At A = AAt = I. \u00a0\u00a0\u00a0(2.37)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "498",
    "text": "This implies that",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "499",
    "text": "A-1 = At , \u00a0\u00a0\u00a0(2.38)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "500",
    "text": "so orthogonal matrices are of interest because their inverse is very cheap to compute. Pay careful attention to the definition of orthogonal matrices. Counterintuitively,\u00a0their rows are not merely orthogonal but fully orthonormal. There is no special\u00a0term for a matrix whose rows or columns are orthogonal but not orthonormal.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "501",
    "text": "Many mathematical objects can be understood better by breaking them into constituent parts, or finding some properties of them that are universal, not caused\u00a0by the way we choose to represent them.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "502",
    "text": "For example, integers can be decomposed into prime factors. The way we represent the number 12 will change depending on whether we write it in base ten\u00a0or in binary, but it will always be true that 12 = 2 x 2 x 3. From this representation\u00a0we can conclude useful properties, such as that 12 is not divisible by 5, or that any\u00a0integer multiple of 12 will be divisible by 3.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "503",
    "text": "Much as we can discover something about the true nature of an integer by decomposing it into prime factors, we can also decompose matrices in ways that\u00a0show us information about their functional properties that is not obvious from the\u00a0representation of the matrix as an array of elements.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "504",
    "text": "One of the most widely used kinds of matrix decomposition is called eigen-decomposition, in which we decompose a matrix into a set of eigenvectors and eigenvalues.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "505",
    "text": "An eigenvector of a square matrix A is a non-zero vector v such that multiplication by A alters only the scale of v:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "506",
    "text": "Av = Av. \u00a0\u00a0\u00a0(2.39)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "507",
    "text": "The scalar A is known as the eigenvalue corresponding to this eigenvector. (One can also find a left eigenvector such that vt A = AvT, but we are usually concerned\u00a0with right eigenvectors).",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "508",
    "text": "If v is an eigenvector of A, then so is any rescaled vector sv for s G R, s = 0. Moreover, sv still has the same eigenvalue. For this reason, we usually only look\u00a0for unit eigenvectors.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "509",
    "text": "Suppose that a matrix A has n linearly independent eigenvectors, {v(1),..., v(n)}, with corresponding eigenvalues {A1,..., An}. We may concatenate all of the",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "510",
    "text": "Effect of eigenvectors and eigenvalues",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "511",
    "text": "Q Before multiplication",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "512",
    "text": "x 0",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "513",
    "text": "After multiplication",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "514",
    "text": "Figure 2.3: An example of the effect of eigenvectors and eigenvalues. Here, we have a matrix A with two orthonormal eigenvectors, v(1) with eigenvalue A! and v(2) with\u00a0eigenvalue A2. (Left) We plot the set of all unit vectors u E R2 as a unit circle. (Right)\u00a0We plot the set of all points Au. By observing the way that A distorts the unit circle, we\u00a0can see that it scales space in direction v(i) by Ai.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "515",
    "text": "eigenvectors to form a matrix V with one eigenvector per column: V = [v(1),..., v(n)]. Likewise, we can concatenate the eigenvalues to form a vector A = [A1,...,\u00a0An]T. The eigendecomposition of A is then given by",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "516",
    "text": "A = V diag(A) V-1. \u00a0\u00a0\u00a0(2.40)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "517",
    "text": "We have seen that constructing matrices with specific eigenvalues and eigenvectors allows us to stretch space in desired directions. However, we often want to decompose matrices into their eigenvalues and eigenvectors. Doing so can help us\u00a0to analyze certain properties of the matrix, much as decomposing an integer into\u00a0its prime factors can help us understand the behavior of that integer.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "518",
    "text": "Not every matrix can be decomposed into eigenvalues and eigenvectors. In some cases, the decomposition exists, but may involve complex rather than real numbers.\u00a0Fortunately, in this book, we usually need to decompose only a specific class of\u00a0matrices that have a simple decomposition. Specifically, every real symmetric\u00a0matrix can be decomposed into an expression using only real-valued eigenvectors\u00a0and eigenvalues:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "519",
    "text": "A = QAQt, \u00a0\u00a0\u00a0(2.41)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "520",
    "text": "where Q is an orthogonal matrix composed of eigenvectors of A, and A is a diagonal matrix. The eigenvalue A%,% is associated with the eigenvector in column i\u00a0of Q, denoted as Q,%. Because Q is an orthogonal matrix, we can think of A as\u00a0scaling space by A % in direction v(i). See Fig. 2.3 for an example.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "521",
    "text": "While any real symmetric matrix A is guaranteed to have an eigendecomposi-tion, the eigendecomposition may not be unique. If any two or more eigenvectors share the same eigenvalue, then any set of orthogonal vectors lying in their span\u00a0are also eigenvectors with that eigenvalue, and we could equivalently choose a Q\u00a0using those eigenvectors instead. By convention, we usually sort the entries of A\u00a0in descending order. Under this convention, the eigendecomposition is unique only\u00a0if all of the eigenvalues are unique.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "522",
    "text": "The eigendecomposition of a matrix tells us many useful facts about the matrix. The matrix is singular if and only if any of the eigenvalues are zero.\u00a0The eigendecomposition of a real symmetric matrix can also be used to optimize\u00a0quadratic expressions of the form f (x) = xT Ax subject to ||x||2 = 1. Whenever x\u00a0is equal to an eigenvector of A, f takes on the value of the corresponding eigenvalue.\u00a0The maximum value of f within the constraint region is the maximum eigenvalue\u00a0and its minimum value within the constraint region is the minimum eigenvalue.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "523",
    "text": "A matrix whose eigenvalues are all positive is called positive definite. A matrix whose eigenvalues are all positive or zero-valued is called positive semidefinite.\u00a0Likewise, if all eigenvalues are negative, the matrix is negative definite, and if\u00a0all eigenvalues are negative or zero-valued, it is negative semidefinite. Positive\u00a0semidefinite matrices are interesting because they guarantee that Vx, xAx > 0.\u00a0Positive definite matrices additionally guarantee that x Ax = 0 ^ x = 0.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "524",
    "text": "In Sec. 2.7, we saw how to decompose a matrix into eigenvectors and eigenvalues. The singular value decomposition (SVD) provides another way to factorize a matrix,\u00a0into singular vectors and singular values. The SVD allows us to discover some of\u00a0the same kind of information as the eigendecomposition. However, the SVD is\u00a0more generally applicable. Every real matrix has a singular value decomposition,\u00a0but the same is not true of the eigenvalue decomposition. For example, if a matrix\u00a0is not square, the eigendecomposition is not defined, and we must use a singular\u00a0value decomposition instead.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "525",
    "text": "Recall that the eigendecomposition involves analyzing a matrix A to discover a matrix V of eigenvectors and a vector of eigenvalues A such that we can rewrite\u00a0A as",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "526",
    "text": "A = V diag(A) V-1. \u00a0\u00a0\u00a0(2.42)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "527",
    "text": "The singular value decomposition is similar, except this time we will write A as a product of three matrices:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "528",
    "text": "A = UDVt . \u00a0\u00a0\u00a0(2.43)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "529",
    "text": "Suppose that A is an m x n matrix. Then U is defined to be an m x m matrix, D to be an m x n matrix, and V to be an n x n matrix.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "530",
    "text": "Each of these matrices is defined to have a special structure. The matrices U and V are both defined to be orthogonal matrices. The matrix D is defined to be\u00a0a diagonal matrix. Note that D is not necessarily square.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "531",
    "text": "The elements along the diagonal of D are known as the singular values of the matrix A. The columns of U are known as the left-singular vectors. The columns\u00a0of V are known as as the right-singular vectors.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "532",
    "text": "We can actually interpret the singular value decomposition of A in terms of the eigendecomposition of functions of A. The left-singular vectors of A are the\u00a0eigenvectors of AAt . The right-singular vectors of A are the eigenvectors of At A\u00a0The non-zero singular values of A are the square roots of the eigenvalues of At A\u00a0The same is true for AA t .",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "533",
    "text": "Perhaps the most useful feature of the SVD is that we can use it to partially generalize matrix inversion to non-square matrices, as we will see in the next\u00a0section.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "534",
    "text": "Matrix inversion is not defined for matrices that are not square. Suppose we want to make a left-inverse B of a matrix A, so that we can solve a linear equation",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "535",
    "text": "Ax = y \u00a0\u00a0\u00a0(2.44)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "536",
    "text": "by left-multiplying each side to obtain",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "537",
    "text": "x = By. \u00a0\u00a0\u00a0(2.45)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "538",
    "text": "Depending on the structure of the problem, it may not be possible to design a unique mapping from A to B.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "539",
    "text": "If A is taller than it is wide, then it is possible for this equation to have no solution. If A is wider than it is tall, then there could be multiple possible\u00a0solutions.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "540",
    "text": "The Moore-Penrose pseudoinverse allows us to make some headway in these cases. The pseudoinverse of A is defined as a matrix",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "541",
    "text": "A+ = lim(A tA + al )-1AT. \u00a0\u00a0\u00a0(2.46)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "542",
    "text": "a\\0",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "543",
    "text": "Practical algorithms for computing the pseudoinverse are not based on this definition, but rather the formula",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "544",
    "text": "A + = VD+ UT, \u00a0\u00a0\u00a0(2.47)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "545",
    "text": "where U, D and V are the singular value decomposition of A, and the pseudoinverse D+ of a diagonal matrix D is obtained by taking the reciprocal of its non-zero\u00a0elements then taking the transpose of the resulting matrix.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "546",
    "text": "When A has more columns than rows, then solving a linear equation using the pseudoinverse provides one of the many possible solutions. Specifically, it provides\u00a0the solution x = A+ y with minimal Euclidean norm ||x||2 among all possible\u00a0solutions.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "547",
    "text": "When A has more rows than columns, it is possible for there to be no solution. In this case, using the pseudoinverse gives us the x for which Ax is as close as\u00a0possible to y in terms of Euclidean norm ||Ax \u2014 y||2.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "548",
    "text": "The trace operator gives the sum of all of the diagonal entries of a matrix:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "549",
    "text": "Tr(A) \u00a0\u00a0\u00a0Am .\u00a0\u00a0\u00a0\u00a0(2.48)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "550",
    "text": "i",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "551",
    "text": "The trace operator is useful for a variety of reasons. Some operations that are difficult to specify without resorting to summation notation can be specified using\u00a0matrix products and the trace operator. For example, the trace operator provides\u00a0an alternative way of writing the Frobenius norm of a matrix:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "552",
    "text": "||A|| F = ^Tr(AAT). \u00a0\u00a0\u00a0(2.49)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "553",
    "text": "Writing an expression in terms of the trace operator opens up opportunities to manipulate the expression using many useful identities. For example, the trace\u00a0operator is invariant to the transpose operator:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "554",
    "text": "Tr(A) = Tr(AT). \u00a0\u00a0\u00a0(2.50)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "555",
    "text": "The trace of a square matrix composed of many factors is also invariant to moving the last factor into the first position, if the shapes of the corresponding\u00a0matrices allow the resulting product to be defined:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "556",
    "text": "Tr( ABC) = Tr(CAB) = Tr(BCA) \u00a0\u00a0\u00a0(2.51)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "557",
    "text": "or more generally,",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "558",
    "text": "n \u00a0\u00a0\u00a0n-1",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "559",
    "text": "-2.52",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "560",
    "text": "Tr(JJ F(i)) = Tr(F(n) \u00a0\u00a0\u00a0F(i)).",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "561",
    "text": "i=1 \u00a0\u00a0\u00a0i=1",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "562",
    "text": "This invariance to cyclic permutation holds even if the resulting product has a different shape. For example, for A G Rmxn and B G Rnxm, we have",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "563",
    "text": "-2.53",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "564",
    "text": "Tr(a).",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "565",
    "text": "Tr(AB) = Tr(BA)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "566",
    "text": "even though AB G Rmxm and BA G Rnxn.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "567",
    "text": "Another useful fact to keep in mind is that a scalar is its own trace: a",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "568",
    "text": "The determinant of a square matrix, denoted det(A), is a function mapping matrices to real scalars. The determinant is equal to the product of all the\u00a0eigenvalues of the matrix. The absolute value of the determinant can be thought\u00a0of as a measure of how much multiplication by the matrix expands or contracts\u00a0space. If the determinant is 0, then space is contracted completely along at least\u00a0one dimension, causing it to lose all of its volume. If the determinant is 1, then\u00a0the transformation is volume-preserving.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "569",
    "text": "One simple machine learning algorithm, principal components analysis or PCA can be derived using only knowledge of basic linear algebra.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "570",
    "text": "Suppose we have a collection of m points {x(1),..., x(m)} in Rn. Suppose we would like to apply lossy compression to these points. Lossy compression means\u00a0storing the points in a way that requires less memory but may lose some precision.\u00a0We would like to lose as little precision as possible.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "571",
    "text": "One way we can encode these points is to represent a lower-dimensional version of them. For each point x(i) e Rn we will find a corresponding code vector c(i) e Rl.\u00a0If l is smaller than n, it will take less memory to store the code points than the\u00a0original data. We will want to find some encoding function that produces the code\u00a0for an input, f (x) = c, and a decoding function that produces the reconstructed\u00a0input given its code, x\u00a0\u00a0\u00a0\u00a0g(f (x)).",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "572",
    "text": "PCA is defined by our choice of the decoding function. Specifically, to make the decoder very simple, we choose to use matrix multiplication to map the code back\u00a0into Rn. Let g(c) = Dc, where D e Rnx1 is the matrix defining the decoding.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "573",
    "text": "Computing the optimal code for this decoder could be a difficult problem. To keep the encoding problem easy, PCA constrains the columns of D to be orthogonal\u00a0to each other. (Note that D is still not technically \u201can orthogonal matrix\u201d unless\u00a0l = n)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "574",
    "text": "With the problem as described so far, many solutions are possible, because we can increase the scale of D:i if we decrease ci proportionally for all points. To give\u00a0the problem a unique solution, we constrain all of the columns of D to have unit\u00a0norm.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "575",
    "text": "In order to turn this basic idea into an algorithm we can implement, the first thing we need to do is figure out how to generate the optimal code point c* for\u00a0each input point x. One way to do this is to minimize the distance between the\u00a0input point x and its reconstruction, g( c*). We can measure this distance using a\u00a0norm. In the principal components algorithm, we use the L2 norm:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "576",
    "text": "c* = argmin||x \u2014 g(c)||2. \u00a0\u00a0\u00a0(2.54)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "577",
    "text": "c",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "578",
    "text": "We can switch to the squared L2 norm instead of the L2 norm itself, because both are minimized by the same value of c. This is because the L2 norm is nonnegative and the squaring operation is monotonically increasing for non-negative",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "579",
    "text": "arguments.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "580",
    "text": "c* = argmin||x \u2014 g(c) ||2.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "581",
    "text": "c",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "582",
    "text": "-2.55",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "583",
    "text": "The function being minimized simplifies to",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "584",
    "text": "",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "585",
    "text": "(x \u2014 g(c))T (x \u2014 g(c))",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "586",
    "text": "-2.56",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "587",
    "text": "(by the definition of the L2 norm, Eq. 2.30)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "588",
    "text": "",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "589",
    "text": "#ERROR!",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "590",
    "text": "-2.57",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "591",
    "text": "(by the distributive property)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "592",
    "text": "",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "593",
    "text": "#ERROR!",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "594",
    "text": "-2.58",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "595",
    "text": "(because the scalar g(x)Tx is equal to the transpose of itself).",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "596",
    "text": "We can now change the function being minimized again, to omit the first term, since this term does not depend on c:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "597",
    "text": "c* = argmin \u20142x Tg(c) + g (c) Tg(c).",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "598",
    "text": "c",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "599",
    "text": "-2.59",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "600",
    "text": "To make further progress, we must substitute in the definition of g(c):",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "601",
    "text": "c* = argmin \u20142xT Dc + cT DT Dc",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "602",
    "text": "c",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "603",
    "text": "-2.6",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "604",
    "text": "#ERROR!",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "605",
    "text": "c",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "606",
    "text": "-2.61",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "607",
    "text": "(by the orthogonality and unit norm constraints on D)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "608",
    "text": "",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "609",
    "text": "#ERROR!",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "610",
    "text": "c",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "611",
    "text": "-2.62",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "612",
    "text": "We can solve this optimization problem using vector calculus (see Sec. 4.3 if you do not know how to do this):",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "613",
    "text": "Vc(\u20142xDc + c T c) = 0",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "614",
    "text": "-2.63",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "615",
    "text": "\u2014 2Dx + 2c = 0",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "616",
    "text": "-2.64",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "617",
    "text": "c = D x.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "618",
    "text": "-2.65",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "619",
    "text": "This makes the algorithm efficient: we can optimally encode x just using a matrix-vector operation. To encode a vector, we apply the encoder function",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "620",
    "text": "f (x) = D Tx.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "621",
    "text": "-2.66",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "622",
    "text": "Using a further matrix multiplication, we can also define the PCA reconstruction operation:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "623",
    "text": "r(x) = g (f (x)) = DDTx. \u00a0\u00a0\u00a0(2.67)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "624",
    "text": "Next, we need to choose the encoding matrix D. To do so, we revisit the",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "625",
    "text": "C\\",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "626",
    "text": "idea of minimizing the L distance between inputs and reconstructions. However, since we will use the same matrix D to decode all of the points, we can no longer\u00a0consider the points in isolation. Instead, we must minimize the Frobenius norm of\u00a0the matrix of errors computed over all dimensions and all points:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "627",
    "text": "D *",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "628",
    "text": "#ERROR!",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "629",
    "text": "in /^~^ (yXj \u2014 r(x(i))^ subject to",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "630",
    "text": "DtD = I",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "631",
    "text": "-2.68",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "632",
    "text": "To derive the algorithm for finding D*, we will start by considering the case where l = 1. In this case, D is just a single vector, d. Substituting Eq. 2.67 into\u00a0Eq. 2.68 and simplifying D into d, the problem reduces to",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "633",
    "text": "d",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "634",
    "text": "#ERROR!",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "635",
    "text": "\\x(i) - ddTx(i) I",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "636",
    "text": "v \u00a0\u00a0\u00a01 1\u00a0\u00a0\u00a0\u00a01 1",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "637",
    "text": "2 subject to ||d||2 = 1.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "638",
    "text": "-2.69",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "639",
    "text": "The above formulation is the most direct way of performing the substitution, but is not the most stylistically pleasing way to write the equation. It places the\u00a0scalar value dTx(i) on the right of the vector d. It is more conventional to write\u00a0scalar coefficients on the left of vector they operate on. We therefore usually write\u00a0such a formula as",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "640",
    "text": "d * = arg min d",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "641",
    "text": "x(i)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "642",
    "text": "dx (i)d||2 subject to ||d||2 = 1,",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "643",
    "text": "-2.7",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "644",
    "text": "or, exploiting the fact that a scalar is its own transpose, as",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "645",
    "text": "d * = arg min d",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "646",
    "text": "x(i) \u2014 x(i)Tdd||2 subject to ||d||2 = 1.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "647",
    "text": "-2.71",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "648",
    "text": "The reader should aim to become familiar with such cosmetic rearrangements.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "649",
    "text": "At this point, it can be helpful to rewrite the problem in terms of a single design matrix of examples, rather than as a sum over separate example vectors.\u00a0This will allow us to use more compact notation. Let X G Rmxn be the matrix\u00a0defined by stacking all of the vectors describing the points, such that Xi: = x(i) .\u00a0We can now rewrite the problem as",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "650",
    "text": "d* = argmin||X \u2014 XddT|F subject to dTd = 1. \u00a0\u00a0\u00a0(2.72)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "651",
    "text": "d",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "652",
    "text": "Disregarding the constraint for the moment, we can simplify the Frobenius norm portion as follows:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "653",
    "text": "^ ~ \u00a0\u00a0\u00a0(2.73)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "654",
    "text": "11 \u00a0\u00a0\u00a0-r 11o",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "655",
    "text": "argmin ||X \u2014 Xdd1 ||F",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "656",
    "text": "d",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "657",
    "text": "argminTr ^(x \u2014 Xdd^ (x \u2014 XddT)^",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "658",
    "text": "-2.74",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "659",
    "text": "(by Eq. 2.49)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "660",
    "text": "argminTr(X 'X \u2014 X 1 Xdd1 \u2014 dd 1 X 'X + ddTXTXddT) \u00a0\u00a0\u00a0(2.75)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "661",
    "text": "min d",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "662",
    "text": "-T-",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "663",
    "text": "-TvjjT",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "664",
    "text": "#ERROR!",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "665",
    "text": "d",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "666",
    "text": "-2.76",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "667",
    "text": "#ERROR!",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "668",
    "text": "d",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "669",
    "text": "(because terms not involving d do not affect the arg min)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "670",
    "text": "#ERROR!",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "671",
    "text": "d",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "672",
    "text": "(because we can cycle the order of the matrices inside a trace, Eq. 2.52)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "673",
    "text": "#ERROR!",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "674",
    "text": "d",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "675",
    "text": "(using the same property again)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "676",
    "text": "At this point, we re-introduce the constraint:",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "677",
    "text": "argmin \u20142Tr(XTXddT) + Tr(XTXddTddT) subject to d d = 1 \u00a0\u00a0\u00a0(2.80)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "678",
    "text": "d",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "679",
    "text": "#ERROR!",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "680",
    "text": "d",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "681",
    "text": "(due to the constraint)",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "682",
    "text": "#ERROR!",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "683",
    "text": "d",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "684",
    "text": "#ERROR!",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "685",
    "text": "d",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "686",
    "text": "#ERROR!",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "687",
    "text": "d",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "688",
    "text": "This optimization problem may be solved using eigendecomposition. Specifically, the optimal d is given by the eigenvector of XT X corresponding to the largest\u00a0eigenvalue.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "689",
    "text": "In the general case, where l > 1, the matrix D is given by the l eigenvectors corresponding to the largest eigenvalues. This may be shown using proof by\u00a0induction. We recommend writing this proof as an exercise.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "690",
    "text": "Linear algebra is one of the fundamental mathematical disciplines that is necessary to understand deep learning. Another key area of mathematics that is\u00a0ubiquitous in machine learning is probability theory, presented next.",
    "chapter": "Linear Algebra",
    "chapter_id": "main-5.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "691",
    "text": "In this chapter, we describe probability theory and information theory.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "692",
    "text": "Probability theory is a mathematical framework for representing uncertain statements. It provides a means of quantifying uncertainty and axioms for deriving\u00a0new uncertain statements. In artificial intelligence applications, we use probability\u00a0theory in two major ways. First, the laws of probability tell us how AI systems\u00a0should reason, so we design our algorithms to compute or approximate various\u00a0expressions derived using probability theory. Second, we can use probability and\u00a0statistics to theoretically analyze the behavior of proposed AI systems.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "693",
    "text": "Probability theory is a fundamental tool of many disciplines of science and engineering. We provide this chapter to ensure that readers whose background is\u00a0primarily in software engineering with limited exposure to probability theory can\u00a0understand the material in this book.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "694",
    "text": "While probability theory allows us to make uncertain statements and reason in the presence of uncertainty, information allows us to quantify the amount of\u00a0uncertainty in a probability distribution.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "695",
    "text": "If you are already familiar with probability theory and information theory, you may wish to skip all of this chapter except for Sec. 3.14, which describes the\u00a0graphs we use to describe structured probabilistic models for machine learning. If\u00a0you have absolutely no prior experience with these subjects, this chapter should\u00a0be sufficient to successfully carry out deep learning research projects, but we do\u00a0suggest that you consult an additional resource, such as Jaynes (2003).",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "696",
    "text": "Many branches of computer science deal mostly with entities that are entirely deterministic and certain. A programmer can usually safely assume that a CPU will\u00a0execute each machine instruction flawlessly. Errors in hardware do occur, but are\u00a0rare enough that most software applications do not need to be designed to account\u00a0for them. Given that many computer scientists and software engineers work in a\u00a0relatively clean and certain environment, it can be surprising that machine learning\u00a0makes heavy use of probability theory.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "697",
    "text": "This is because machine learning must always deal with uncertain quantities, and sometimes may also need to deal with stochastic (non-deterministic) quantities.\u00a0Uncertainty and stochasticity can arise from many sources. Researchers have made\u00a0compelling arguments for quantifying uncertainty using probability since at least\u00a0the 1980s. Many of the arguments presented here are summarized from or inspired\u00a0by Pearl (1988).",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "698",
    "text": "Nearly all activities require some ability to reason in the presence of uncertainty. In fact, beyond mathematical statements that are true by definition, it is difficult\u00a0to think of any proposition that is absolutely true or any event that is absolutely\u00a0guaranteed to occur.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "699",
    "text": "There are three possible sources of uncertainty:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "700",
    "text": "1. \u00a0\u00a0\u00a0Inherent stochasticity in the system being modeled. For example, most\u00a0interpretations of quantum mechanics describe the dynamics of subatomic\u00a0particles as being probabilistic. We can also create theoretical scenarios that\u00a0we postulate to have random dynamics, such as a hypothetical card game\u00a0where we assume that the cards are truly shuffled into a random order.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "701",
    "text": "2. \u00a0\u00a0\u00a0Incomplete observability. Even deterministic systems can appear stochastic\u00a0when we cannot observe all of the variables that drive the behavior of the\u00a0system. For example, in the Monty Hall problem, a game show contestant is\u00a0asked to choose between three doors and wins a prize held behind the chosen\u00a0door. Two doors lead to a goat while a third leads to a car. The outcome\u00a0given the contestant\u2019s choice is deterministic, but from the contestant\u2019s point\u00a0of view, the outcome is uncertain. 1\u00a0robot discretizes space when predicting the future location of these objects,\u00a0then the discretization makes the robot immediately become uncertain about\u00a0the precise position of objects: each object could be anywhere within the\u00a0discrete cell that it was observed to occupy.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "702",
    "text": "In many cases, it is more practical to use a simple but uncertain rule rather than a complex but certain one, even if the true rule is deterministic and our\u00a0modeling system has the fidelity to accommodate a complex rule. For example, the\u00a0simple rule \u201cMost birds fly\u201d is cheap to develop and is broadly useful, while a rule\u00a0of the form, \u201cBirds fly, except for very young birds that have not yet learned to\u00a0fly, sick or injured birds that have lost the ability to fly, flightless species of birds\u00a0including the cassowary, ostrich and kiwi...\u201d is expensive to develop, maintain and\u00a0communicate, and after all of this effort is still very brittle and prone to failure.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "703",
    "text": "Given that we need a means of representing and reasoning about uncertainty, it is not immediately obvious that probability theory can provide all of the tools\u00a0we want for artificial intelligence applications. Probability theory was originally\u00a0developed to analyze the frequencies of events. It is easy to see how probability\u00a0theory can be used to study events like drawing a certain hand of cards in a\u00a0game of poker. These kinds of events are often repeatable. When we say that\u00a0an outcome has a probability p of occurring, it means that if we repeated the\u00a0experiment (e.g., draw a hand of cards) infinitely many times, then proportion p\u00a0of the repetitions would result in that outcome. This kind of reasoning does not\u00a0seem immediately applicable to propositions that are not repeatable. If a doctor\u00a0analyzes a patient and says that the patient has a 40% chance of having the flu,\u00a0this means something very different\u2014we can not make infinitely many replicas of\u00a0the patient, nor is there any reason to believe that different replicas of the patient\u00a0would present with the same symptoms yet have varying underlying conditions. In\u00a0the case of the doctor diagnosing the patient, we use probability to represent a\u00a0degree of belief, with 1 indicating absolute certainty that the patient has the flu\u00a0and 0 indicating absolute certainty that the patient does not have the flu. The\u00a0former kind of probability, related directly to the rates at which events occur, is\u00a0known as frequentist probability, while the latter, related to qualitative levels of\u00a0certainty, is known as Bayesian probability.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "704",
    "text": "If we list several properties that we expect common sense reasoning about uncertainty to have, then the only way to satisfy those properties is to treat\u00a0Bayesian probabilities as behaving exactly the same as frequentist probabilities.\u00a0For example, if we want to compute the probability that a player will win a poker\u00a0game given that she has a certain set of cards, we use exactly the same formulas\u00a0as when we compute the probability that a patient has a disease given that she\u00a0has certain symptoms. For more details about why a small set of common sense\u00a0assumptions implies that the same axioms must control both kinds of probability,\u00a0see Ramsey (1926).",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "705",
    "text": "Probability can be seen as the extension of logic to deal with uncertainty. Logic provides a set of formal rules for determining what propositions are implied to\u00a0be true or false given the assumption that some other set of propositions is true\u00a0or false. Probability theory provides a set of formal rules for determining the\u00a0likelihood of a proposition being true given the likelihood of other propositions.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "706",
    "text": "A random variable is a variable that can take on different values randomly. We typically denote the random variable itself with a lower case letter in plain typeface,\u00a0and the values it can take on with lower case script letters. For example, x1 and x2\u00a0are both possible values that the random variable x can take on. For vector-valued\u00a0variables, we would write the random variable as x and one of its values as x. On\u00a0its own, a random variable is just a description of the states that are possible; it\u00a0must be coupled with a probability distribution that specifies how likely each of\u00a0these states are.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "707",
    "text": "Random variables may be discrete or continuous. A discrete random variable is one that has a finite or countably infinite number of states. Note that these\u00a0states are not necessarily the integers; they can also just be named states that\u00a0are not considered to have any numerical value. A continuous random variable is\u00a0associated with a real value.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "708",
    "text": "A probability distribution is a description of how likely a random variable or set of random variables is to take on each of its possible states. The way we\u00a0describe probability distributions depends on whether the variables are discrete or\u00a0continuous.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "709",
    "text": "A probability distribution over discrete variables may be described using a probability mass function (PMF). We typically denote probability mass functions with a capital P. Often we associate each random variable with a different probability\u00a0mass function and the reader must infer which probability mass function to use\u00a0based on the identity of the random variable, rather than the name of the function;\u00a0P(x) is usually not the same as P(y).",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "710",
    "text": "The probability mass function maps from a state of a random variable to the probability of that random variable taking on that state. The probability\u00a0that x = x is denoted as P(x), with a probability of 1 indicating that x = x is\u00a0certain and a probability of 0 indicating that x = x is impossible. Sometimes\u00a0to disambiguate which PMF to use, we write the name of the random variable\u00a0explicitly: P(x = x). Sometimes we define a variable first, then use ~ notation to\u00a0specify which distribution it follows later: x ~ P(x).",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "711",
    "text": "Probability mass functions can act on many variables at the same time. Such a probability distribution over many variables is known as a joint probability\u00a0distribution. P(x = x, y = y) denotes the probability that x = x and y = y\u00a0simultaneously. We may also write P(x,y) for brevity.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "712",
    "text": "To be a probability mass function on a random variable x, a function P must satisfy the following properties:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "713",
    "text": "\u2022 \u00a0\u00a0\u00a0The domain of P must be the set of all possible states of x.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "714",
    "text": "\u2022 Vx E x,0 < P(x) < 1. An impossible event has probability 0 and no state can be less probable than that. Likewise, an event that is guaranteed to happen\u00a0has probability 1, and no state can have a greater chance of occurring.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "715",
    "text": "\u2022 \u00a0\u00a0\u00a0^x P(x) = 1. We refer to this property as being normalized. Without this\u00a0property, we could obtain probabilities greater than one by computing the\u00a0probability of one of many events occurring.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "716",
    "text": "For example, consider a single discrete random variable x with k different states. We can place a uniform distribution on x\u2014that is, make each of its states equally\u00a0likely\u2014by setting its probability mass function to",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "717",
    "text": "1",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "718",
    "text": "P (x = x i) = k \u00a0\u00a0\u00a0(3.1)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "719",
    "text": "for all i. We can see that this fits the requirements for a probability mass function. The value | is positive because k is a positive integer. We also see that",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "720",
    "text": "^ P (x = xi) = ^ k = k 1 \u00a0\u00a0\u00a0(3.2)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "721",
    "text": "ii",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "722",
    "text": "so the distribution is properly normalized.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "723",
    "text": "When working with continuous random variables, we describe probability distributions using a probability density function (PDF) rather than a probability mass function. To be a probability density function, a function p must satisfy the\u00a0following properties:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "724",
    "text": "\u2022 \u00a0\u00a0\u00a0The domain of p must be the set of all possible states of x.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "725",
    "text": "\u2022 Vx E x,p(x) > 0. Note that we do not require p(x) < 1.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "726",
    "text": "\u2022 \u00a0\u00a0\u00a0f p(x)dx = 1.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "727",
    "text": "A probability density function p(x) does not give the probability of a specific state directly, instead the probability of landing inside an infinitesimal region with\u00a0volume Sx is given by p(x)Sx.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "728",
    "text": "We can integrate the density function to find the actual probability mass of a set of points. Specifically, the probability that x lies in some set S is given by the\u00a0integral of p (x) over that set. In the univariate example, the probability that x\u00a0lies in the interval [a, b] is given by J[ab] p(x)dx.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "729",
    "text": "For an example of a probability density function corresponding to a specific probability density over a continuous random variable, consider a uniform distribution on an interval of the real numbers. We can do this with a function u(x; a,b),\u00a0where a and b are the endpoints of the interval, with b > a. The \u201c;\u201d notation means\u00a0\u201cparametrized by\u201d; we consider x to be the argument of the function, while a and\u00a0b are parameters that define the function. To ensure that there is no probability\u00a0mass outside the interval, we say u(x; a, b) = 0 for all x E [a,b]. Within [a, b],\u00a0u(x; a, b) = bza. We can see that this is nonnegative everywhere. Additionally, it\u00a0integrates to 1. We often denote that x follows the uniform distribution on [a,b]\u00a0by writing x\u00a0\u00a0\u00a0\u00a0U(a, b).",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "730",
    "text": "Sometimes we know the probability distribution over a set of variables and we want to know the probability distribution over just a subset of them. The probability\u00a0distribution over the subset is known as the marginal probability distribution.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "731",
    "text": "For example, suppose we have discrete random variables x and y, and we know P(x, y). We can find P(x) with the sum rule:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "732",
    "text": "Vx E x,P (x = x) \u00a0\u00a0\u00a0P (x = x, y = y).\u00a0\u00a0\u00a0\u00a0(3.3)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "733",
    "text": "y",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "734",
    "text": "The name \u201cmarginal probability\u201d comes from the process of computing marginal probabilities on paper. When the values of P(x, y) are written in a grid with\u00a0different values of x in rows and different values of y in columns, it is natural to\u00a0sum across a row of the grid, then write P(x) in the margin of the paper just to\u00a0the right of the row.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "735",
    "text": "For continuous variables, we need to use integration instead of summation:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "736",
    "text": "p(x) = \u00a0\u00a0\u00a0p(x,y )dy.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "737",
    "text": "x",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "738",
    "text": "x",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "739",
    "text": "-3.4",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "740",
    "text": "In many cases, we are interested in the probability of some event, given that some other event has happened. This is called a conditional probability. We denote\u00a0the conditional probability that y = y given x = x as P(y = y | x = x). This\u00a0conditional probability can be computed with the formula",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "741",
    "text": "p (y = y | x = x) =",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "742",
    "text": "p (y = y, x = x)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "743",
    "text": "P (x = x)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "744",
    "text": "-3.5",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "745",
    "text": "The conditional probability is only defined when P( x = x) > 0. We cannot compute the conditional probability conditioned on an event that never happens.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "746",
    "text": "It is important not to confuse conditional probability with computing what would happen if some action were undertaken. The conditional probability that\u00a0a person is from Germany given that they speak German is quite high, but if\u00a0a randomly selected person is taught to speak German, their country of origin\u00a0does not change. Computing the consequences of an action is called making an\u00a0intervention query. Intervention queries are the domain of causal modeling, which\u00a0we do not explore in this book.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "747",
    "text": "Any joint probability distribution over many random variables may be decomposed into conditional distributions over only one variable:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "748",
    "text": "P(x(1),...,x(n)) = P(x(1))nn=2P(x(i) | x(1),...,x(i-1)). \u00a0\u00a0\u00a0(3.6)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "749",
    "text": "This observation is known as the chain rule or product rule of probability. It follows immediately from the definition of conditional probability in Eq. 3.5. For\u00a0example, applying the definition twice, we get",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "750",
    "text": "P(a, b, c) \u00a0\u00a0\u00a0= P(a | b, c)P(b, c)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "751",
    "text": "P(b, c) \u00a0\u00a0\u00a0= P(b | c)P(c)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "752",
    "text": "P(a, b, c) = P(a | b, c)P(b | c)P(c).",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "753",
    "text": "Two random variables x and y are independent if their probability distribution can be expressed as a product of two factors, one involving only x and one involving\u00a0only y:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "754",
    "text": "Vx e x, y e y, p(x = x, y = y) = p(x = x)p(y = y). \u00a0\u00a0\u00a0(3.7)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "755",
    "text": "Two random variables x and y are conditionally independent given a random variable z if the conditional probability distribution over x and y factorizes in this\u00a0way for every value of z:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "756",
    "text": "Vx e x, y e y, z e z, p(x = x, y = y | z = z) = p(x = x | z = z)p(y = y | z = z).",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "757",
    "text": "-3.8",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "758",
    "text": "We can denote independence and conditional independence with compact notation: xTy means that x and y are independent, while xTy | z means that x\u00a0and y are conditionally independent given z.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "759",
    "text": "The expectation or expected value of some function f (x) with respect to a probability distribution P(x) is the average or mean value that f takes on when x is drawn\u00a0from P. For discrete variables this can be computed with a summation:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "760",
    "text": "Ex~p[f (x)] = ^ P(x)f (x) \u00a0\u00a0\u00a0(3-9)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "761",
    "text": "X",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "762",
    "text": "while for continuous variables, it is computed with an integral:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "763",
    "text": "Ex~p [f (x)] \u00a0\u00a0\u00a0p(x)f (x)dx.\u00a0\u00a0\u00a0\u00a0(3.10)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "764",
    "text": "When the identity of the distribution is clear from the context, we may simply write the name of the random variable that the expectation is over, as in Ex[f (x)].\u00a0If it is clear which random variable the expectation is over, we may omit the\u00a0subscript entirely, as in E[f (x)]. By default, we can assume that E[\u25a0] averages over\u00a0the values of all the random variables inside the brackets. Likewise, when there is\u00a0no ambiguity, we may omit the square brackets.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "765",
    "text": "Expectations are linear, for example,",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "766",
    "text": "Ex[af (x) + Pg(x)\\ = aEx [f (x)] + 3 E x[g(x)], \u00a0\u00a0\u00a0(3.U)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "767",
    "text": "when a and 3 are not dependent on x.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "768",
    "text": "The variance gives a measure of how much the values of a function of a random variable x vary as we sample different values of x from its probability distribution:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "769",
    "text": "Var (f (x)) = E",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "770",
    "text": "(f (x) - E[f (x)\\)2",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "771",
    "text": "-3.12",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "772",
    "text": "When the variance is low, the values of f (x) cluster near their expected value. The square root of the variance is known as the standard deviation.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "773",
    "text": "The covariance gives some sense of how much two values are linearly related to each other, as well as the scale of these variables:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "774",
    "text": "Cov(f (x), g(y)) = E [(f (x) - E [f (x)]) (g(y) - E [g(y)])\\. \u00a0\u00a0\u00a0(3.13)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "775",
    "text": "High absolute values of the covariance mean that the values change very much and are both far from their respective means at the same time. If the sign of the\u00a0covariance is positive, then both variables tend to take on relatively high values\u00a0simultaneously. If the sign of the covariance is negative, then one variable tends to\u00a0take on a relatively high value at the times that the other takes on a relatively low\u00a0value and vice versa. Other measures such as correlation normalize the contribution\u00a0of each variable in order to measure only how much the variables are related, rather\u00a0than also being affected by the scale of the separate variables.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "776",
    "text": "The notions of covariance and dependence are related, but are in fact distinct concepts. They are related because two variables that are independent have zero\u00a0covariance, and two variables that have non-zero covariance are dependent. However, independence is a distinct property from covariance. For two variables to have\u00a0zero covariance, there must be no linear dependence between them. Independence\u00a0is a stronger requirement than zero covariance, because independence also excludes\u00a0nonlinear relationships. It is possible for two variables to be dependent but have\u00a0zero covariance. For example, suppose we first sample a real number x from a\u00a0uniform distribution over the interval [-1, 1\\. We next sample a random variable\u00a0s. With probability 1, we choose the value of s to be 1. Otherwise, we choose\u00a0the value of s to be \u2014 1. We can then generate a random variable y by assigning\u00a0y = sx. Clearly, x and y are not independent, because x completely determines\u00a0the magnitude of y. However, Cov(x, y) = 0.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "777",
    "text": "The covariance matrix of a random vector x \u00a3 Rn is an n x n matrix, such that",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "778",
    "text": "Cov(xkj",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "779",
    "text": "Cov(x\u05f4 x j).",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "780",
    "text": "-3.14",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "781",
    "text": "The diagonal elements of the covariance give the variance:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "782",
    "text": "-3.15",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "783",
    "text": "Cov(x!, x!) = Var(x!).",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "784",
    "text": "Several simple probability distributions are useful in many contexts in machine learning.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "785",
    "text": "The Bernoulli distribution is a distribution over a single binary random variable. It is controlled by a single parameter 0 \u00a3 [0,1], which gives the probability of the\u00a0random variable being equal to 1. It has the following properties:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "786",
    "text": "-3.16",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "787",
    "text": "-3.17",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "788",
    "text": "-3.18",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "789",
    "text": "-3.19",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "790",
    "text": "-3.2",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "791",
    "text": "P (x = 1) = 0 P (x = 0) = 1 \u2014 0\u00a0P (x = x) = 0x (1 \u2014 0)1-x\u00a0Ex[x] = 0",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "792",
    "text": "Var x(x) = 0(1 \u2014 0)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "793",
    "text": "The multinoulli or categorical distribution is a distribution over a single discrete variable with k different states, where k is finite.2 The multinoulli distribution is\u00a0parametrized by a vector p G [0,1]k-1, where pi gives the probability of the i-th\u00a0state. The final, k-th state\u2019s probability is given by 1 \u2014 1Tp. Note that we must\u00a0constrain 1Tp < 1. Multinoulli distributions are often used to refer to distributions\u00a0over categories of objects, so we do not usually assume that state 1 has numerical\u00a0value 1, etc. For this reason, we do not usually need to compute the expectation\u00a0or variance of multinoulli-distributed random variables.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "794",
    "text": "The Bernoulli and multinoulli distributions are sufficient to describe any distribution over their domain. This is because they model discrete variables for which it is feasible to simply enumerate all of the states. When dealing with continuous\u00a0variables, there are uncountably many states, so any distribution described by a\u00a0small number of parameters must impose strict limits on the distribution.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "795",
    "text": "The most commonly used distribution over real numbers is the normal distribution, also known as the Gaussian distribution:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "796",
    "text": "N(x;p,a2) =y[J\u00b1\u05beexp \u00a0\u00a0\u00a0-2\u20142(x \u2014 p))2j .\u00a0\u00a0\u00a0\u00a0(3.21)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "797",
    "text": "See Fig. 3.1 for a plot of the density function.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "798",
    "text": "The two parameters p G R and a G (0, to) control the normal distribution. The parameter p gives the coordinate of the central peak. This is also the mean of\u00a0the distribution: E[x] = p. The standard deviation of the distribution is given by\u00a0a, and the variance by a2.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "799",
    "text": "When we evaluate the PDF, we need to square and invert a. When we need to frequently evaluate the PDF with different parameter values, a more efficient way\u00a0of parametrizing the distribution is to use a parameter (3 G (0, to) to control the\u00a0precision or inverse variance of the distribution:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "800",
    "text": ".",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "801",
    "text": "-3.22",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "802",
    "text": "N(x; p, 3-1) = y\u2014. exP ^\u201413(x \u2014 p)2",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "803",
    "text": "Normal distributions are a sensible choice for many applications. In the absence of prior knowledge about what form a distribution over the real numbers should\u00a0take, the normal distribution is a good default choice for two major reasons.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "804",
    "text": "First, many distributions we wish to model are truly close to being normal distributions. The central limit theorem shows that the sum of many independent\u00a0random variables is approximately normally distributed. This means that in",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "805",
    "text": "The normal distribution",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "806",
    "text": "0.4",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "807",
    "text": "0.35",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "808",
    "text": "^ 0.20",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "809",
    "text": "0",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "810",
    "text": "Figure 3.1: The normal distribution: The normal distributionN(x; ^, a2) exhibits a classic \u201cbell curve\u201d shape, with the x coordinate of its central peak given by and the width\u00a0of its peak controlled by a. In this example, we depict the standard normal distribution,\u00a0with !! = 0 and a = 1.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "811",
    "text": "practice, many complicated systems can be modeled successfully as normally distributed noise, even if the system can be decomposed into parts with more\u00a0structured behavior.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "812",
    "text": "Second, out of all possible probability distributions with the same variance, the normal distribution encodes the maximum amount of uncertainty over the\u00a0real numbers. We can thus think of the normal distribution as being the one that\u00a0inserts the least amount of prior knowledge into a model. Fully developing and\u00a0justifying this idea requires more mathematical tools, and is postponed to Sec.\u00a019.4.2.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "813",
    "text": "The normal distribution generalizes to Rn, in which case it is known as the multivariate normal distribution. It may be parametrized with a positive definite\u00a0symmetric matrix S:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "814",
    "text": "N(X; 1, S) =^l",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "815",
    "text": "1",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "816",
    "text": "(2n) ndet(S)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "817",
    "text": "exp",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "818",
    "text": "(-2(",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "819",
    "text": "-2(x - l)TS 1",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "820",
    "text": "(x - .",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "821",
    "text": "-3.23",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "822",
    "text": "The parameter i still gives the mean of the distribution, though now it is vector-valued. The parameter S gives the covariance matrix of the distribution.\u00a0As in the univariate case, when we wish to evaluate the PDF several times for",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "823",
    "text": "many different values of the parameters, the covariance is not a computationally efficient way to parametrize the distribution, since we need to invert \u00a3 to evaluate\u00a0the PDF. We can instead use a precision matrix 3:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "824",
    "text": "N(x;3 \u00a0\u00a0\u00a0) =",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "825",
    "text": "1 ) exp (- 2(X - \u05f4d3(x - \u00a0\u00a0\u00a0\u2022",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "826",
    "text": "-3.24",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "827",
    "text": "We often fix the covariance matrix to be a diagonal matrix. An even simpler version is the isotropic Gaussian distribution, whose covariance matrix is a scalar\u00a0times the identity matrix.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "828",
    "text": "In the context of deep learning, we often want to have a probability distribution with a sharp point at x = 0. To accomplish this, we can use the exponential\u00a0distribution:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "829",
    "text": "p(x; A) = A1x>0exp(-Ax). \u00a0\u00a0\u00a0(3.25)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "830",
    "text": "The exponential distribution uses the indicator function 1x>0 to assign probability zero to all negative values of x.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "831",
    "text": "A closely related probability distribution that allows us to place a sharp peak of probability mass at an arbitrary point p is the Laplace distribution",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "832",
    "text": "Laplace(x; p, y) = \u2014 exp 2y",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "833",
    "text": "-3.26",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "834",
    "text": "1 \u00a0\u00a0\u00a0/\u00a0\u00a0\u00a0\u00a0|x \u2014 p\\",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "835",
    "text": "In some cases, we wish to specify that all of the mass in a probability distribution clusters around a single point. This can be accomplished by defining a PDF using\u00a0the Dirac delta function, 5(x):",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "836",
    "text": "p(x) = S(x \u2014 p). \u00a0\u00a0\u00a0(3.27)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "837",
    "text": "The Dirac delta function is defined such that it is zero-valued everywhere except 0, yet integrates to 1. The Dirac delta function is not an ordinary function that\u00a0associates each value x with a real-valued output, instead it is a different kind of\u00a0mathematical object called a generalized function that is defined in terms of its\u00a0properties when integrated. We can think of the Dirac delta function as being the\u00a0limit point of a series of functions that put less and less mass on all points other\u00a0than p.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "838",
    "text": "By defining p( x) to be 5 shifted by \u2014p we obtain an infinitely narrow and infinitely high peak of probability mass where x = p.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "839",
    "text": "A common use of the Dirac delta distribution is as a component of an empirical distribution,",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "840",
    "text": "1",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "841",
    "text": "p(x) = m^25(x",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "842",
    "text": "-x(i",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "843",
    "text": "-3.28",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "844",
    "text": "i=1",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "845",
    "text": "which puts probability mass m on each of the m points x(1),..., xforming a given data set or collection of samples. The Dirac delta distribution is only\u00a0necessary to define the empirical distribution over continuous variables. For discrete\u00a0variables, the situation is simpler: an empirical distribution can be conceptualized\u00a0as a multinoulli distribution, with a probability associated to each possible input\u00a0value that is simply equal to the empirical frequency of that value in the training\u00a0set.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "846",
    "text": "We can view the empirical distribution formed from a dataset of training examples as specifying the distribution that we sample from when we train a model\u00a0on this dataset. Another important perspective on the empirical distribution is\u00a0that it is the probability density that maximizes the likelihood of the training data\u00a0(see Sec. 5.5).",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "847",
    "text": "It is also common to define probability distributions by combining other simpler probability distributions. One common way of combining distributions is to\u00a0construct a mixture distribution. A mixture distribution is made up of several\u00a0component distributions. On each trial, the choice of which component distribution\u00a0generates the sample is determined by sampling a component identity from a\u00a0multinoulli distribution:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "848",
    "text": "P(x) = ^P(c = i)P(x | c = i) \u00a0\u00a0\u00a0(3.29)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "849",
    "text": "i",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "850",
    "text": "where P(c) is the multinoulli distribution over component identities.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "851",
    "text": "We have already seen one example of a mixture distribution: the empirical distribution over real-valued variables is a mixture distribution with one Dirac\u00a0component for each training example.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "852",
    "text": "The mixture model is one simple strategy for combining probability distributions to create a richer distribution. In Chapter 16, we explore the art of building complex\u00a0probability distributions from simple ones in more detail.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "853",
    "text": "The mixture model allows us to briefly glimpse a concept that will be of paramount importance later\u2014the latent variable. A latent variable is a random\u00a0variable that we cannot observe directly. The component identity variable c of the\u00a0mixture model provides an example. Latent variables may be related to x through\u00a0the joint distribution, in this case, P(x, c) = P(x | c)P(c). The distribution P(c)\u00a0over the latent variable and the distribution P(x | c) relating the latent variables\u00a0to the visible variables determines the shape of the distribution P (x) even though\u00a0it is possible to describe P(x) without reference to the latent variable. Latent\u00a0variables are discussed further in Sec. 16.5.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "854",
    "text": "A very powerful and common type of mixture model is the Gaussian mixture model, in which the componentsp(x | c = i) are Gaussians. Each component has\u00a0a separately parametrized mean ^(i) and covariance S(i). Some mixtures can have\u00a0more constraints. For example, the covariances could be shared across components\u00a0via the constraint S(i) = SVi. As with a single Gaussian distribution, the mixture\u00a0of Gaussians might constrain the covariance matrix for each component to be\u00a0diagonal or isotropic.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "855",
    "text": "In addition to the means and covariances, the parameters of a Gaussian mixture specify the prior probability ai = P(c = i) given to each component i. The word\u00a0\u201cprior\u201d indicates that it expresses the model\u2019s beliefs about c before it has observed\u00a0x. By comparison, P(c | x) is a posterior probability, because it is computed after\u00a0observation of x. A Gaussian mixture model is a universal a,pproximator of\u00a0densities, in the sense that any smooth density can be approximated with any\u00a0specific, non-zero amount of error by a Gaussian mixture model with enough\u00a0components.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "856",
    "text": "Fig. 3.2 shows samples from a Gaussian mixture model.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "857",
    "text": "Certain functions arise often while working with probability distributions, especially the probability distributions used in deep learning models.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "858",
    "text": "One of these functions is the logistic sigmoid:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "859",
    "text": "1",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "860",
    "text": "\u05f4(x) = 1 + exp(-x)30'3) \u00a0\u00a0\u00a0\u05d9)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "861",
    "text": "The logistic sigmoid is commonly used to produce the <p parameter of a Bernoulli distribution because its range is (0,1), which lies within the valid range of values\u00a0for the ^ parameter. See Fig. 3.3 for a graph of the sigmoid function. The sigmoid",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "862",
    "text": "Figure 3.2: Samples from a Gaussian mixture model. In this example, there are three components. From left to right, the first component has an isotropic covariance matrix,\u00a0meaning it has the same amount of variance in each direction. The second has a diagonal\u00a0covariance matrix, meaning it can control the variance separately along each axis-aligned\u00a0direction. This example has more variance along thex2 axis than along the x1 axis. The\u00a0third component has a full-rank covariance matrix, allowing it to control the variance\u00a0separately along an arbitrary basis of directions.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "863",
    "text": "function saturates when its argument is very positive or very negative, meaning that the function becomes very flat and insensitive to small changes in its input.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "864",
    "text": "Another commonly encountered function is the softplus function (Dugas et al., 2001):",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "865",
    "text": "Z(x) = log (1 + exp(x)) . \u00a0\u00a0\u00a0(3.31)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "866",
    "text": "The softplus function can be useful for producing the 3 or a parameter of a normal distribution because its range is (Q to ). It also arises commonly when manipulating\u00a0expressions involving sigmoids. The name of the softplus function comes from the\u00a0fact that it is a smoothed or \u201csoftened\u201d version of",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "867",
    "text": "-3.32",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "868",
    "text": "x+ = max(0, x). See Fig. 3.4 for a graph of the softplus function.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "869",
    "text": "The following properties are all useful enough that you may wish to memorize them:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "870",
    "text": "a",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "871",
    "text": "(x)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "872",
    "text": "exp(x)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "873",
    "text": "exp(x) + exp(0)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "874",
    "text": "d",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "875",
    "text": "dx",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "876",
    "text": "a(x) = a(x)(1 \u2014 a(x))",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "877",
    "text": "-3.33",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "878",
    "text": "-3.34",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "879",
    "text": "(x)d \u00a0\u00a0\u00a0(x)\u05dc",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "880",
    "text": "The logistic sigmoid function",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "881",
    "text": "Figure 3.3: The logistic sigmoid function.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "882",
    "text": "The softplus function",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "883",
    "text": "Figure 3.4: The softplus function.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "884",
    "text": "1 \u2014 a(x) \u2014 a (\u2014x) log a(x) = \u2014Z (\u2014x)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "885",
    "text": "-3.35",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "886",
    "text": "-3.36",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "887",
    "text": "-3.37",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "888",
    "text": "-3.38",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "889",
    "text": "-3.39",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "890",
    "text": "-3.4",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "891",
    "text": "-3.41",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "892",
    "text": "Txc (x) = a (x)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "893",
    "text": "Vx e (0,1), a-1 (x) = 1^(\u05e5\u2014",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "894",
    "text": "Vx > 0, Z-1(x) \u2014 log(exp(x) \u2014 1)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "895",
    "text": "/x",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "896",
    "text": "a(y)dy Z (x) \u2014 Z (\u2014x) = x",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "897",
    "text": "The function a 1(x) is called the logit in statistics, but this term is more rarely used in machine learning.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "898",
    "text": "Eq. 3.41 provides extra justification for the name \u201csoftplus.\u201d The softplus function is intended as a smoothed version of the positive part function, x + \u2014\u00a0max{0, x}. The positive part function is the counterpart of the negative part\u00a0function, x- \u2014 max{0, \u2014x}. To obtain a smooth function that is analogous to the\u00a0negative part, one can use Z(\u2014x). Just as x can be recovered from its positive part\u00a0and negative part via the identity x x \u2014 x, it is also possible to recover x\u00a0using the same relationship between Z(x) and Z(\u2014x), as shown in Eq. 3.41.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "899",
    "text": "We often find ourselves in a situation where we know P(y | x) and need to know P(x | y). Fortunately, if we also know P(x), we can compute the desired quantity\u00a0using Bayes\u2019 rule:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "900",
    "text": "P(x | y)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "901",
    "text": "-3.42",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "902",
    "text": "P(x)P(y | x)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "903",
    "text": "P(y)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "904",
    "text": "Note that while P (y) appears in the formula, it is usually feasible to compute P(y) \u2014 X}x P(y I x)P(x), so we do not need to begin with knowledge of P(y).",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "905",
    "text": "Bayes\u2019 rule is straightforward to derive from the definition of conditional probability, but it is useful to know the name of this formula since many texts\u00a0refer to it by name. It is named after the Reverend Thomas Bayes, who first\u00a0discovered a special case of the formula. The general version presented here was\u00a0independently discovered by Pierre-Simon Laplace.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "906",
    "text": "A proper formal understanding of continuous random variables and probability density functions requires developing probability theory in terms of a branch of\u00a0mathematics known as measure theory. Measure theory is beyond the scope of\u00a0this textbook, but we can briefly sketch some of the issues that measure theory is\u00a0employed to resolve.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "907",
    "text": "In Sec. 3.3.2, we saw that the probability of a continuous vector-valued x lying in some set S is given by the integral of p (x) over the set S. Some choices of set S\u00a0can produce paradoxes. For example, it is possible to construct two sets S! and\u00a0S2 such that p (x E S!) + p(x E S2) > 1 but S! \u05d7 S2 = 0. These sets are generally\u00a0constructed making very heavy use of the infinite precision of real numbers, for\u00a0example by making fractal-shaped sets or sets that are defined by transforming\u00a0the set of rational numbers.3 One of the key contributions of measure theory is to\u00a0provide a characterization of the set of sets that we can compute the probability\u00a0of without encountering paradoxes. In this book, we only integrate over sets with\u00a0relatively simple descriptions, so this aspect of measure theory never becomes a\u00a0relevant concern.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "908",
    "text": "For our purposes, measure theory is more useful for describing theorems that apply to most points in Rn but do not apply to some corner cases. Measure theory\u00a0provides a rigorous way of describing that a set of points is negligibly small. Such\u00a0a set is said to have \u201c measure zero.\" We do not formally define this concept in this\u00a0textbook. However, it is useful to understand the intuition that a set of measure\u00a0zero occupies no volume in the space we are measuring. For example, within R3, a\u00a0line has measure zero, while a filled polygon has positive measure. Likewise, an\u00a0individual point has measure zero. Any union of countably many sets that each\u00a0have measure zero also has measure zero (so the set of all the rational numbers\u00a0has measure zero, for instance).",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "909",
    "text": "Another useful term from measure theory is \u201c almost everywhere.\u201d A property that holds almost everywhere holds throughout all of space except for on a set of\u00a0measure zero. Because the exceptions occupy a negligible amount of space, they\u00a0can be safely ignored for many applications. Some important results in probability\u00a0theory hold for all discrete values but only hold \u201calmost everywhere\u201d for continuous\u00a0values.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "910",
    "text": "Another technical detail of continuous variables relates to handling continuous random variables that are deterministic functions of one another. Suppose we have\u00a0two random variables, x and y, such that y = g(x), where g is an invertible, continuous, differentiable transformation. One might expect that py (y) = px (g 1(y)).\u00a0This is actually not the case.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "911",
    "text": "As a simple example, suppose we have scalar random variables x and y. Suppose y = X and x ~ U(0, 1). If we use the rule py(y) = px(2y) then py will be 0\u00a0everywhere except the interval [0, 2], and it will be 1 on this interval. This means",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "912",
    "text": "-3.43",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "913",
    "text": "p y (y)dy = 2 \u2019",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "914",
    "text": "which violates the definition of a probability distribution.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "915",
    "text": "This common mistake is wrong because it fails to account for the distortion of space introduced by the function g. Recall that the probability of x lying in\u00a0an infinitesimally small region with volume 5x is given by p( x)Sx. Since g can\u00a0expand or contract space, the infinitesimal volume surrounding x in x space may\u00a0have different volume in y space.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "916",
    "text": "To see how to correct the problem, we return to the scalar case. We need to preserve the property",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "917",
    "text": "p x(x) = py(g(x))",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "918",
    "text": "px (x)dx |.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "919",
    "text": "-3.44",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "920",
    "text": "(y\u00bb S",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "921",
    "text": "-3.45",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "922",
    "text": ") 9g(x) dx",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "923",
    "text": "-3.46",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "924",
    "text": "|py(g(x))dy|",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "925",
    "text": "Solving from this, we obtain",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "926",
    "text": "py(y) = px (g 1(y))",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "927",
    "text": "or equivalently",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "928",
    "text": "In higher dimensions, the derivative generalizes to the determinant of the Jacobian matrix\u2014the matrix with Jjj =\u00a0\u00a0\u00a0\u00a0. Thus, for real-valued vectors x and y,",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "929",
    "text": "p x (x) = py(g(x))",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "930",
    "text": "det",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "931",
    "text": "dg(x)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "932",
    "text": "d x",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "933",
    "text": "-3.47",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "934",
    "text": "Information theory is a branch of applied mathematics that revolves around quantifying how much information is present in a signal. It was originally invented\u00a0to study sending messages from discrete alphabets over a noisy channel, such as\u00a0communication via radio transmission. In this context, information theory tells how\u00a0to design optimal codes and calculate the expected length of messages sampled from\u00a0specific probability distributions using various encoding schemes. In the context of\u00a0machine learning, we can also apply information theory to continuous variables\u00a0where some of these message length interpretations do not apply. This field is\u00a0fundamental to many areas of electrical engineering and computer science. In this\u00a0textbook, we mostly use a few key ideas from information theory to characterize\u00a0probability distributions or quantify similarity between probability distributions.\u00a0For more detail on information theory, see Cover and Thomas (2006) or MacKay\u00a0(2003).",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "935",
    "text": "The basic intuition behind information theory is that learning that an unlikely event has occurred is more informative than learning that a likely event has\u00a0occurred. A message saying \u201cthe sun rose this morning\u201d is so uninformative as\u00a0to be unnecessary to send, but a message saying \u201cthere was a solar eclipse this\u00a0morning\u201d is very informative.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "936",
    "text": "We would like to quantify information in a way that formalizes this intuition. Specifically,",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "937",
    "text": "\u2022 \u00a0\u00a0\u00a0Likely events should have low information content, and in the extreme case,\u00a0events that are guaranteed to happen should have no information content\u00a0whatsoever.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "938",
    "text": "\u2022 \u00a0\u00a0\u00a0Less likely events should have higher information content.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "939",
    "text": "\u2022 \u00a0\u00a0\u00a0Independent events should have additive information. For example, finding\u00a0out that a tossed coin has come up as heads twice should convey twice as\u00a0much information as finding out that a tossed coin has come up as heads\u00a0once.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "940",
    "text": "In order to satisfy all three of these properties, we define the self-information of an event x = x to be",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "941",
    "text": "I (x) = \u2014 log P (x). \u00a0\u00a0\u00a0(3.48)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "942",
    "text": "In this book, we always use log to mean the natural logarithm, with base e. Our definition of I(x) is therefore written in units of nats. One nat is the amount of\u00a0information gained by observing an event of probability -1. Other texts use base-2\u00a0logarithms and units called bits or shannons; information measured in bits is just\u00a0a rescaling of information measured in nats.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "943",
    "text": "When x is continuous, we use the same definition of information by analogy, but some of the properties from the discrete case are lost. For example, an event\u00a0with unit density still has zero information, despite not being an event that is\u00a0guaranteed to occur.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "944",
    "text": "0.7 0.6\u00a00.5\u00a00.4\u00a00.3\u00a00.2\u00a00.1\u00a00.0",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "945",
    "text": "Figure 3.5: This plot shows how distributions that are closer to deterministic have low Shannon entropy while distributions that are close to uniform have high Shannon entropy.\u00a0On the horizontal axis, we plot p, the probability of a binary random variable being equal\u00a0to 1. The entropy is given by (p \u2014 1) log(1 \u2014 p) \u2014 p logp. When p is near 0, the distribution\u00a0is nearly deterministic, because the random variable is nearly always 0. Whenp is near 1,\u00a0the distribution is nearly deterministic, because the random variable is nearly always 1.\u00a0When p = 0.5, the entropy is maximal, because the distribution is uniform over the two\u00a0outcomes.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "946",
    "text": "Self-information deals only with a single outcome. We can quantify the amount of uncertainty in an entire probability distribution using the Shannon entropy:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "947",
    "text": "-3.49",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "948",
    "text": "H (x) = E x~p [I (x)] = \u2014E x~p [log P (x)].",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "949",
    "text": "also denoted H(P). In other words, the Shannon entropy of a distribution is the expected amount of information in an event drawn from that distribution. It gives\u00a0a lower bound on the number of bits (if the logarithm is base 2, otherwise the units\u00a0are different) needed on average to encode symbols drawn from a distribution P.\u00a0Distributions that are nearly deterministic (where the outcome is nearly certain)\u00a0have low entropy; distributions that are closer to uniform have high entropy. See\u00a0Fig. 3.5 for a demonstration. When x is continuous, the Shannon entropy is known\u00a0as the differential entropy.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "950",
    "text": "If we have two separate probability distributions P(x) and Q(x) over the same random variable x, we can measure how different these two distributions are using\u00a0the Kullback-Leibler (KL) divergence:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "951",
    "text": "D KL (P ||Q) = Ex^p log",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "952",
    "text": "P (x)\u05be",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "953",
    "text": "Q(x)_",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "954",
    "text": "#ERROR!",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "955",
    "text": "-3.5",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "956",
    "text": "In the case of discrete variables, it is the extra amount of information (measured in bits if we use the base 2 logarithm, but in machine learning we usually use nats\u00a0and the natural logarithm) needed to send a message containing symbols drawn\u00a0from probability distribution P, when we use a code that was designed to minimize\u00a0the length of messages drawn from probability distribution Q.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "957",
    "text": "The KL divergence has many useful properties, most notably that it is nonnegative. The KL divergence is 0 if and only if P and Q are the same distribution in the case of discrete variables, or equal \u201calmost everywhere\u201d in the case of continuous\u00a0variables. Because the KL divergence is non-negative and measures the difference\u00a0between two distributions, it is often conceptualized as measuring some sort of\u00a0distance between these distributions. However, it is not a true distance measure\u00a0because it is not symmetric: DKL(P||Q) = DKL(Q||P) for some P and Q. This\u00a0asymmetry means that there are important consequences to the choice of whether\u00a0to use DKL(P||Q) or Dkl(Q||P). See Fig. 3.6 for more detail.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "958",
    "text": "A quantity that is closely related to the KL divergence is the cross-entropy H(P, Q) = H(P) + DKL(P||Q), which is similar to the KL divergence but lacking\u00a0the term on the left:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "959",
    "text": "H(P, Q) = -E^p log Q(x). \u00a0\u00a0\u00a0(3.51)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "960",
    "text": "Minimizing the cross-entropy with respect to Q is equivalent to minimizing the KL divergence, because Q does not participate in the omitted term.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "961",
    "text": "When computing many of these quantities, it is common to encounter expressions of the form 0log0. By convention, in the context of information theory, we treat these expressions as limx^0 x log x = 0.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "962",
    "text": "Machine learning algorithms often involve probability distributions over a very large number of random variables. Often, these probability distributions involve\u00a0direct interactions between relatively few variables. Using a single function to\u00a0describe the entire joint probability distribution can be very inefficient (both\u00a0computationally and statistically).",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "963",
    "text": "Instead of using a single function to represent a probability distribution, we can split a probability distribution into many factors that we multiply together.\u00a0For example, suppose we have three random variables: a, b and c. Suppose that\u00a0a influences the value of b and b influences the value of c, but that a and c are\u00a0independent given b. We can represent the probability distribution over all three",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "964",
    "text": "q * = argmin qD kl (p|q)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "965",
    "text": "q * = argmin qDkl (q||p)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "966",
    "text": "Figure 3.6: The KL divergence is asymmetric. Suppose we have a distributionp(x) and wish to approximate it with another distribution q (x). We have the choice of minimizing\u00a0either Dkl (p||q) or Dkl (q||p). We illustrate the effect of this choice using a mixture of\u00a0two Gaussians for p, and a single Gaussian for q. The choice of which direction of the\u00a0KL divergence to use is problem-dependent. Some applications require an approximation\u00a0that usually places high probability anywhere that the true distribution places high\u00a0probability, while other applications require an approximation that rarely places high\u00a0probability anywhere that the true distribution places low probability. The choice of the\u00a0direction of the KL divergence reflects which of these considerations takes priority for each\u00a0application. (Left) The effect of minimizingDkl(p||q). In this case, we select a q that has\u00a0high probability where p has high probability. When p has multiple modes, q chooses to\u00a0blur the modes together, in order to put high probability mass on all of them. (Right) The\u00a0effect of minimizing Dkl (q||p). In this case, we select a q that has low probability where\u00a0p has low probability. When p has multiple modes that are sufficiently widely separated,\u00a0as in this figure, the KL divergence is minimized by choosing a single mode, in order to\u00a0avoid putting probability mass in the low-probability areas between modes ofp. Here, we\u00a0illustrate the outcome when q is chosen to emphasize the left mode. We could also have\u00a0achieved an equal value of the KL divergence by choosing the right mode. If the modes\u00a0are not separated by a sufficiently strong low probability region, then this direction of the\u00a0KL divergence can still choose to blur the modes.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "967",
    "text": "variables as a product of probability distributions over two variables:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "968",
    "text": "p(a, b, c) = p(a)p(b | a)p(c | b). \u00a0\u00a0\u00a0(3.52)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "969",
    "text": "These factorizations can greatly reduce the number of parameters needed to describe the distribution. Each factor uses a number of parameters that is\u00a0exponential in the number of variables in the factor. This means that we can greatly\u00a0reduce the cost of representing a distribution if we are able to find a factorization\u00a0into distributions over fewer variables.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "970",
    "text": "We can describe these kinds of factorizations using graphs. Here we use the word \u201cgraph\u201d in the sense of graph theory: a set of vertices that may be connected\u00a0to each other with edges. When we represent the factorization of a probability\u00a0distribution with a graph, we call it a structured probabilistic model or graphical\u00a0model.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "971",
    "text": "There are two main kinds of structured probabilistic models: directed and undirected. Both kinds of graphical models use a graph G in which each node\u00a0in the graph corresponds to a random variable, and an edge connecting two\u00a0random variables means that the probability distribution is able to represent direct\u00a0interactions between those two random variables.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "972",
    "text": "Directed models use graphs with directed edges, and they represent factorizations into conditional probability distributions, as in the example above. Specifically, a directed model contains one factor for every random variable xi in the distribution,\u00a0and that factor consists of the conditional distribution over xi given the parents of\u00a0xi, denoted Pag(xi):",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "973",
    "text": "p(x) = JJp (xi1 Pag (xi)). \u00a0\u00a0\u00a0(3.53)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "974",
    "text": "i",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "975",
    "text": "See Fig. 3.7 for an example of a directed graph and the factorization of probability distributions it represents.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "976",
    "text": "Undirected models use graphs with undirected edges, and they represent factorizations into a set of functions; unlike in the directed case, these functions are usually not probability distributions of any kind. Any set of nodes that are all\u00a0connected to each other in G is called a clique. Each clique C(i) in an undirected\u00a0model is associated with a factor G(i)(C(i)). These factors are just functions, not\u00a0probability distributions. The output of each factor must be non-negative, but\u00a0there is no constraint that the factor must sum or integrate to 1 like a probability\u00a0distribution.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "977",
    "text": "The probability of a configuration of random variables is proportional to the product of all of these factors\u2014assignments that result in larger factor values are",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "978",
    "text": "Figure 3.7: A directed graphical model over random variables a, b, c, d and e. This graph corresponds to probability distributions that can be factored as",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "979",
    "text": "p(a, b, c, d, e) = p(a)p(b | a)p(c | a, b)p(d | b)p(e | c). \u00a0\u00a0\u00a0(3.54)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "980",
    "text": "This graph allows us to quickly see some properties of the distribution. For example,a and c interact directly, but a and e interact only indirectly via c.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "981",
    "text": "more likely. Of course, there is no guarantee that this product will sum to 1. We therefore divide by a normalizing constant Z, defined to be the sum or integral\u00a0over all states of the product of the ^ functions, in order to obtain a normalized\u00a0probability distribution:",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "982",
    "text": "\u05da",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "983",
    "text": "p(x) = Znd\u05be)(C\u00ab) . \u00a0\u00a0\u00a0(3.55)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "984",
    "text": "i",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "985",
    "text": "See Fig. 3.8 for an example of an undirected graph and the factorization of probability distributions it represents.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "986",
    "text": "Keep in mind that these graphical representations of factorizations are a language for describing probability distributions. They are not mutually exclusive\u00a0families of probability distributions. Being directed or undirected is not a property\u00a0of a probability distribution; it is a property of a particular description of a\u00a0probability distribution, but any probability distribution may be described in both\u00a0ways.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "987",
    "text": "Throughout Part I and Part II of this book, we will use structured probabilistic models merely as a language to describe which direct probabilistic relationships\u00a0different machine learning algorithms choose to represent. No further understanding\u00a0of structured probabilistic models is needed until the discussion of research topics,\u00a0in Part III, where we will explore structured probabilistic models in much greater\u00a0detail.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "988",
    "text": "Figure 3.8: An undirected graphical model over random variablesa, b, c, d ande. This graph corresponds to probability distributions that can be factored as",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "989",
    "text": "p(a, b, c, d, e) = \u2014 ^>(1) (a, b, c)^(2)(b, d)^>(3) (c, e). \u00a0\u00a0\u00a0(3.56)",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "990",
    "text": "Z",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "991",
    "text": "This graph allows us to quickly see some properties of the distribution. For example,a and c interact directly, but a and e interact only indirectly via c.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "992",
    "text": "This chapter has reviewed the basic concepts of probability theory that are most relevant to deep learning. One more set of fundamental mathematical tools\u00a0remains: numerical methods.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "993",
    "text": "1",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "994",
    "text": " \u00a0\u00a0\u00a0Incomplete modeling. When we use a model that must discard some of\u00a0the information we have observed, the discarded information results in\u00a0uncertainty in the model\u2019s predictions. For example, suppose we build a\u00a0robot that can exactly observe the location of every object around it. If the",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "995",
    "text": "2",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "996",
    "text": " \u201cMultinoulli\u201d is a term that was recently coined by Gustavo Lacerdo and popularized by Murphy (2012). The multinoulli distribution is a special case of the multinomial distribution. A\u00a0multinomial distribution is the distribution over vectors in {0,..., n}k representing how many\u00a0times each of the k categories is visited when n samples are drawn from a multinoulli distribution.\u00a0Many texts use the term \u201cmultinomial\u201d to refer to multinoulli distributions without clarifying\u00a0that they refer only to the n = 1 case.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "997",
    "text": "3",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "998",
    "text": "The Banach-Tarski theorem provides a fun example of such sets.",
    "chapter": "Probability and Information Theory",
    "chapter_id": "main-6.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "999",
    "text": "Machine learning algorithms usually require a high amount of numerical computation. This typically refers to algorithms that solve mathematical problems by methods that update estimates of the solution via an iterative process, rather than\u00a0analytically deriving a formula providing a symbolic expression for the correct solution. Common operations include optimization (finding the value of an argument\u00a0that minimizes or maximizes a function) and solving systems of linear equations.\u00a0Even just evaluating a mathematical function on a digital computer can be difficult\u00a0when the function involves real numbers, which cannot be represented precisely\u00a0using a finite amount of memory.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1000",
    "text": "The fundamental difficulty in performing continuous math on a digital computer is that we need to represent infinitely many real numbers with a finite number\u00a0of bit patterns. This means that for almost all real numbers, we incur some\u00a0approximation error when we represent the number in the computer. In many\u00a0cases, this is just rounding error. Rounding error is problematic, especially when\u00a0it compounds across many operations, and can cause algorithms that work in\u00a0theory to fail in practice if they are not designed to minimize the accumulation of\u00a0rounding error.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1001",
    "text": "One form of rounding error that is particularly devastating is underflow. Underflow occurs when numbers near zero are rounded to zero. Many functions behave qualitatively differently when their argument is zero rather than a small positive\u00a0number. For example, we usually want to avoid division by zero (some software\u00a0environments will raise exceptions when this occurs, others will return a result\u00a0with a placeholder not-a-number value) or taking the logarithm of zero (this is\u00a0usually treated as \u2014to, which then becomes not-a-number if it is used for many\u00a0further arithmetic operations).",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1002",
    "text": "Another highly damaging form of numerical error is overflow. Overflow occurs when numbers with large magnitude are approximated as to or \u2014to. Further\u00a0arithmetic will usually change these infinite values into not-a-number values.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1003",
    "text": "One example of a function that must be stabilized against underflow and overflow is the softmax function. The softmax function is often used to predict the\u00a0probabilities associated with a multinoulli distribution. The softmax function is\u00a0defined to be",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1004",
    "text": "softmax(\u00ae)! = \u00a0\u00a0\u00a0nexp(xi)\u2014 .\u00a0\u00a0\u00a0\u00a0(4.1)",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1005",
    "text": "j=1 exP(X)",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1006",
    "text": "Consider what happens when all of the x! are equal to some constant c. Analytically, we can see that all of the outputs should be equal to n. Numerically, this may\u00a0not occur when c has large magnitude. If c is very negative, then exp(c) will\u00a0underflow. This means the denominator of the softmax will become 0, so the final\u00a0result is undefined. When c is very large and positive, exp(c) will overflow, again\u00a0resulting in the expression as a whole being undefined. Both of these difficulties\u00a0can be resolved by instead evaluating softmax(z) where z = x - max! x!. Simple\u00a0algebra shows that the value of the softmax function is not changed analytically by\u00a0adding or subtracting a scalar from the input vector. Subtracting max* x! results\u00a0in the largest argument to exp being 0, which rules out the possibility of overflow.\u00a0Likewise, at least one term in the denominator has a value of 1, which rules out\u00a0the possibility of underflow in the denominator leading to a division by zero.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1007",
    "text": "There is still one small problem. Underflow in the numerator can still cause the expression as a whole to evaluate to zero. This means that if we implement\u00a0log softmax(x) by first running the softmax subroutine then passing the result to\u00a0the log function, we could erroneously obtain \u2014to. Instead, we must implement\u00a0a separate function that calculates log softmax in a numerically stable way. The\u00a0log softmax function can be stabilized using the same trick as we used to stabilize\u00a0the softmax function.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1008",
    "text": "For the most part, we do not explicitly detail all of the numerical considerations involved in implementing the various algorithms described in this book. Developers\u00a0of low-level libraries should keep numerical issues in mind when implementing\u00a0deep learning algorithms. Most readers of this book can simply rely on low-level libraries that provide stable implementations. In some cases, it is possible\u00a0to implement a new algorithm and have the new implementation automatically",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1009",
    "text": "stabilized. Theano (Bergstra et al., 2010; Bastien et al., 2012) is an example of a software package that automatically detects and stabilizes many common\u00a0numerically unstable expressions that arise in the context of deep learning.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1010",
    "text": "Conditioning refers to how rapidly a function changes with respect to small changes in its inputs. Functions that change rapidly when their inputs are perturbed slightly\u00a0can be problematic for scientific computation because rounding errors in the inputs\u00a0can result in large changes in the output.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1011",
    "text": "Consider the function f (x) = A-1x. When A E Rnxn has an eigenvalue decomposition, its condition number is",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1012",
    "text": "max",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1013",
    "text": "A,",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1014",
    "text": "A\u05f4",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1015",
    "text": "-4.2",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1016",
    "text": "This is the ratio of the magnitude of the largest and smallest eigenvalue. When this number is large, matrix inversion is particularly sensitive to error in the input.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1017",
    "text": "This sensitivity is an intrinsic property of the matrix itself, not the result of rounding error during matrix inversion. Poorly conditioned matrices amplify\u00a0pre-existing errors when we multiply by the true matrix inverse. In practice, the\u00a0error will be compounded further by numerical errors in the inversion process itself.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1018",
    "text": "Most deep learning algorithms involve optimization of some sort. Optimization refers to the task of either minimizing or maximizing some function f (x) by altering\u00a0x. We usually phrase most optimization problems in terms of minimizing f (x).\u00a0Maximization may be accomplished via a minimization algorithm by minimizing",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1019",
    "text": "-f (x).",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1020",
    "text": "The function we want to minimize or maximize is called the objective function or criterion. When we are minimizing it, we may also call it the cost function,\u00a0loss function, or error function. In this book, we use these terms interchangeably,\u00a0though some machine learning publications assign special meaning to some of these\u00a0terms.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1021",
    "text": "We often denote the value that minimizes or maximizes a function with a superscript *. For example, we might say x* = argminf (x).",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1022",
    "text": "Gradient descent",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1023",
    "text": "Figure 4.1: An illustration of how the derivatives of a function can be used to follow the function downhill to a minimum. This technique is called gradient descent.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1024",
    "text": "We assume the reader is already familiar with calculus, but provide a brief review of how calculus concepts relate to optimization here.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1025",
    "text": "Suppose we have a function y = f (x), where both x and y are real numbers. The derivative of this function is denoted as f'(x) or as . The derivative f'(x)\u00a0gives the slope of f (x) at the point x. In other words, it specifies how to scale\u00a0a small change in the input in order to obtain the corresponding change in the\u00a0output: f (x + e) ~ f (x) + ef '(x).",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1026",
    "text": "The derivative is therefore useful for minimizing a function because it tells us how to change x in order to make a small improvement in y. For example, we\u00a0know that f (x \u2014 e sign (f (x))) is less than f (x) for small enough e. We can thus\u00a0reduce f (x) by moving x in small steps with opposite sign of the derivative. This\u00a0technique is called gradient descent (Cauchy, 1847). See Fig. 4.1 for an example of\u00a0this technique.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1027",
    "text": "When f' (x) = 0, the derivative provides no information about which direction to move. Points where f'(x) = 0 are known as critical points or stationary points.\u00a0A local minimum is a point where f (x) is lower than at all neighboring points,\u00a0so it is no longer possible to decrease f (x) by making infinitesimal steps. A local\u00a0maximum is a point where f (x) is higher than at all neighboring points, so it is",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1028",
    "text": "Types of critical points",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1029",
    "text": "Minimum",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1030",
    "text": "Maximum \u00a0\u00a0\u00a0Saddle point",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1031",
    "text": "/A",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1032",
    "text": "Figure 4.2: Examples of each of the three types of critical points in 1-D. A critical point is a point with zero slope. Such a point can either be a local minimum, which is lower than\u00a0the neighboring points, a local maximum, which is higher than the neighboring points, or\u00a0a saddle point, which has neighbors that are both higher and lower than the point itself.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1033",
    "text": "not possible to increase f(x) by making infinitesimal steps. Some critical points are neither maxima nor minima. These are known as saddle points. See Fig. 4.2\u00a0for examples of each type of critical point.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1034",
    "text": "A point that obtains the absolute lowest value of f (x) is a global minimum. It is possible for there to be only one global minimum or multiple global minima of\u00a0the function. It is also possible for there to be local minima that are not globally\u00a0optimal. In the context of deep learning, we optimize functions that may have\u00a0many local minima that are not optimal, and many saddle points surrounded by\u00a0very flat regions. All of this makes optimization very difficult, especially when the\u00a0input to the function is multidimensional. We therefore usually settle for finding a\u00a0value of f that is very low, but not necessarily minimal in any formal sense. See\u00a0Fig. 4.3 for an example.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1035",
    "text": "We often minimize functions that have multiple inputs: f : Rn ^ R. For the concept of \u201cminimization\u201d to make sense, there must still be only one (scalar)\u00a0output.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1036",
    "text": "For functions with multiple inputs, we must make use of the concept of partial derivatives. The partial derivative\u00a0\u00a0\u00a0\u00a0f (x) measures how f changes as only the",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1037",
    "text": "variable x increases at point x. The gradient generalizes the notion of derivative to the case where the derivative is with respect to a vector: the gradient of f is the\u00a0vector containing all of the partial derivatives, denoted Vxf (x). Element i of the\u00a0gradient is the partial derivative of f with respect to Xi In multiple dimensions,",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1038",
    "text": "Approximate minimization",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1039",
    "text": "This local minimum performs nearly as well as\u00a0the global one,\u00a0so it is an acceptable\u00a0halting point.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1040",
    "text": "Ideally, we would like to arrive at the global\u00a0minimum, but this\u00a0might not be possible.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1041",
    "text": "This local minimum performs poorly, and should be avoided.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1042",
    "text": "Figure 4.3: Optimization algorithms may fail to find a global minimum when there are multiple local minima or plateaus present. In the context of deep learning, we generally\u00a0accept such solutions even though they are not truly minimal, so long as they correspond\u00a0to significantly low values of the cost function.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1043",
    "text": "X",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1044",
    "text": "critical points are points where every element of the gradient is equal to zero.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1045",
    "text": "The directional derivative in direction u (a unit vector) is the slope of the function f in direction u. In other words, the directional derivative is the derivative\u00a0of the function f (x + au) with respect to a, evaluated at a = 0. Using the chain\u00a0rule, we can see that d\u05be f (x + au) = uT Vxf (x).",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1046",
    "text": "To minimize f, we would like to find the direction in which f decreases the fastest. We can do this using the directional derivative:",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1047",
    "text": "min uTV xf (x) \u00a0\u00a0\u00a0(4.3)",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1048",
    "text": "u,u Tu=1",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1049",
    "text": "#ERROR!",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1050",
    "text": "u,uT u=1",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1051",
    "text": "where 6 is the angle between u and the gradient. Substituting in ||u||2 = 1 and ignoring factors that do not depend on u, this simplifies to minu cos 6. This is\u00a0minimized when u points in the opposite direction as the gradient. In other\u00a0words, the gradient points directly uphill, and the negative gradient points directly\u00a0downhill. We can decrease f by moving in the direction of the negative gradient.\u00a0This is known as the method of steepest descent or gradient descent.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1052",
    "text": "Steepest descent proposes a new point",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1053",
    "text": "x' = x \u2014 eVx f (x) \u00a0\u00a0\u00a0(4.5)",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1054",
    "text": "where e is the learning rate, a positive scalar determining the size of the step. We can choose e in several different ways. A popular approach is to set e to a small\u00a0constant. Sometimes, we can solve for the step size that makes the directional\u00a0derivative vanish. Another approach is to evaluate f (x \u2014 eVxf (x)) for several\u00a0values of e and choose the one that results in the smallest objective function value.\u00a0This last strategy is called a line search.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1055",
    "text": "Steepest descent converges when every element of the gradient is zero (or, in practice, very close to zero). In some cases, we may be able to avoid running this\u00a0iterative algorithm, and just jump directly to the critical point by solving the\u00a0equation Vxf (x) = 0 for x.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1056",
    "text": "Although gradient descent is limited to optimization in continuous spaces, the general concept of making small moves (that are approximately the best small move)\u00a0towards better configurations can be generalized to discrete spaces. Ascending an\u00a0objective function of discrete parameters is called hill climbing (Russel and Norvig,\u00a02003).",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1057",
    "text": "Sometimes we need to find all of the partial derivatives of a function whose input and output are both vectors. The matrix containing all such partial derivatives is\u00a0known as a Jacobian matrix. Specifically, if we have a function f : Rm ^ Rn, then\u00a0the Jacobian matrix J G Rnxm of f is defined such that Jij = JX. f (x)%.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1058",
    "text": "We are also sometimes interested in a derivative of a derivative. This is known as a second derivative. For example, for a function f : Rn ^ R, the derivative\u00a0with respect to x of the derivative of f with respect to xj is denoted as",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1059",
    "text": "In a single dimension, we can denote ^\u05be2\u05be f by f \"(x). The second derivative tells us how the first derivative will change as we vary the input. This is important\u00a0because it tells us whether a gradient step will cause as much of an improvement\u00a0as we would expect based on the gradient alone. We can think of the second\u00a0derivative as measuring curvature. Suppose we have a quadratic function (many\u00a0functions that arise in practice are not quadratic but can be approximated well\u00a0as quadratic, at least locally). If such a function has a second derivative of zero,\u00a0then there is no curvature. It is a perfectly flat line, and its value can be predicted\u00a0using only the gradient. If the gradient is 1, then we can make a step of size e\u00a0along the negative gradient, and the cost function will decrease by e. If the second\u00a0derivative is negative, the function curves downward, so the cost function will\u00a0actually decrease by more than e. Finally, if the second derivative is positive, the\u00a0function curves upward, so the cost function can decrease by less than e. See Fig.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1060",
    "text": "Negative curvature No curvature Positive curvature",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1061",
    "text": "Figure 4.4: The second derivative determines the curvature of a function. Here we show quadratic functions with various curvature. The dashed line indicates the value of the cost\u00a0function we would expect based on the gradient information alone as we make a gradient\u00a0step downhill. In the case of negative curvature, the cost function actually decreases\u00a0faster than the gradient predicts. In the case of no curvature, the gradient predicts the\u00a0decrease correctly. In the case of positive curvature, the function decreases slower than\u00a0expected and eventually begins to increase, so too large of step sizes can actually increase\u00a0the function inadvertently.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1062",
    "text": "4.4 to see how different forms of curvature affect the relationship between the value\u00a0of the cost function predicted by the gradient and the true value.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1063",
    "text": "When our function has multiple input dimensions, there are many second derivatives. These derivatives can be collected together into a matrix called the\u00a0Hessian matrix. The Hessian matrix H(f )(x) is defined such that",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1064",
    "text": "d2",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1065",
    "text": "dxi dxj",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1066",
    "text": "f (x)\u2022",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1067",
    "text": "-4.6",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1068",
    "text": "Equivalently, the Hessian is the Jacobian of the gradient.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1069",
    "text": "Anywhere that the second partial derivatives are continuous, the differential operators are commutative, i.e. their order can be swapped:",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1070",
    "text": "d2 \u00a0\u00a0\u00a0N\u00a0\u00a0\u00a0\u00a0d2",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1071",
    "text": "dx idx",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1072",
    "text": "f (x) =",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1073",
    "text": "dxjdx",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1074",
    "text": "f (x)\u2022",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1075",
    "text": "-4.7",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1076",
    "text": "This implies that Hi,j = Hj,i, so the Hessian matrix is symmetric at such points. Most of the functions we encounter in the context of deep learning have a symmetric\u00a0Hessian almost everywhere. Because the Hessian matrix is real and symmetric,\u00a0we can decompose it into a set of real eigenvalues and an orthogonal basis of\u00a0eigenvectors. The second derivative in a specific direction represented by a unit\u00a0vector d is given by dTHd. When d is an eigenvector of H, the second derivative\u00a0in that direction is given by the corresponding eigenvalue. For other directions of\u00a0d, the directional second derivative is a weighted average of all of the eigenvalues,\u00a0with weights between 0 and 1, and eigenvectors that have smaller angle with d\u00a0receiving more weight. The maximum eigenvalue determines the maximum second\u00a0derivative and the minimum eigenvalue determines the minimum second derivative.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1077",
    "text": "The (directional) second derivative tells us how well we can expect a gradient descent step to perform. We can make a second-order Taylor series approximation\u00a0to the function f (x) around the current point x(0):",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1078",
    "text": "1",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1079",
    "text": "f (x) \u00ab f (x(0)) + (x - x(0))Tg + 2(x - x(0))TH(x - x(0)). \u00a0\u00a0\u00a0(4.8)",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1080",
    "text": "2",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1081",
    "text": "where g is the gradient and H is the Hessian at x(0). If we use a learning rate of e, then the new point x will be given by x(0) \u2014 eg. Substituting this into our\u00a0approximation, we obtain",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1082",
    "text": "1",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1083",
    "text": "-4.9",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1084",
    "text": "f (x(0) - eg) \u00ab f (x(0)) - egTg + 2e2gTHg.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1085",
    "text": "There are three terms here: the original value of the function, the expected improvement due to the slope of the function, and the correction we must apply\u00a0to account for the curvature of the function. When this last term is too large, the\u00a0gradient descent step can actually move uphill. When gTHg is zero or negative,\u00a0the Taylor series approximation predicts that increasing e forever will decrease f\u00a0forever. In practice, the Taylor series is unlikely to remain accurate for large e, so\u00a0one must resort to more heuristic choices of e in this case. When gTHg is positive,\u00a0solving for the optimal step size that decreases the Taylor series approximation of\u00a0the function the most yields",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1086",
    "text": "g g",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1087",
    "text": "-4.1",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1088",
    "text": "gT Hg",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1089",
    "text": "In the worst case, when g aligns with the eigenvector of H corresponding to the maximal eigenvalue Amax, then this optimal step size is given by ^ . To the\u00a0extent that the function we minimize can be approximated well by a quadratic\u00a0function, the eigenvalues of the Hessian thus determine the scale of the learning\u00a0rate.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1090",
    "text": "The second derivative can be used to determine whether a critical point is a local maximum, a local minimum, or saddle point. Recall that on a critical point,\u00a0f '(x) = 0. When f \"(x) > 0, this means that f '(x) increases as we move to the\u00a0right, and f' (x) decreases as we move to the left. This means f (x - e) < 0 and\u00a0f '(x + e) > 0 for small enough e. In other words, as we move right, the slope begins\u00a0to point uphill to the right, and as we move left, the slope begins to point uphill\u00a0to the left. Thus, when f' (x) = 0 and f'' (x) > 0, we can conclude that x is a local\u00a0minimum. Similarly, when f '(x) = 0 and f \u05d9\u05d9 (x) < 0, we can conclude that x is a\u00a0local maximum. This is known as the second derivative test. Unfortunately, when\u00a0f''(x) = 0, the test is inconclusive. In this case x may be a saddle point, or a part\u00a0of a flat region.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1091",
    "text": "In multiple dimensions, we need to examine all of the second derivatives of the function. Using the eigendecomposition of the Hessian matrix, we can generalize\u00a0the second derivative test to multiple dimensions. At a critical point, where\u00a0Vx f(x) = 0, we can examine the eigenvalues of the Hessian to determine whether\u00a0the critical point is a local maximum, local minimum, or saddle point. When the\u00a0Hessian is positive definite (all its eigenvalues are positive), the point is a local\u00a0minimum. This can be seen by observing that the directional second derivative\u00a0in any direction must be positive, and making reference to the univariate second\u00a0derivative test. Likewise, when the Hessian is negative definite (all its eigenvalues\u00a0are negative), the point is a local maximum. In multiple dimensions, it is actually\u00a0possible to find positive evidence of saddle points in some cases. When at least\u00a0one eigenvalue is positive and at least one eigenvalue is negative, we know that\u00a0x is a local maximum on one cross section of f but a local minimum on another\u00a0cross section. See Fig. 4.5 for an example. Finally, the multidimensional second\u00a0derivative test can be inconclusive, just like the univariate version. The test is\u00a0inconclusive whenever all of the non-zero eigenvalues have the same sign, but at\u00a0least one eigenvalue is zero. This is because the univariate second derivative test is\u00a0inconclusive in the cross section corresponding to the zero eigenvalue.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1092",
    "text": "In multiple dimensions, there can be a wide variety of different second derivatives at a single point, because there is a different second derivative for each direction.\u00a0The condition number of the Hessian measures how much the second derivatives\u00a0vary. When the Hessian has a poor condition number, gradient descent performs\u00a0poorly. This is because in one direction, the derivative increases rapidly, while in\u00a0another direction, it increases slowly. Gradient descent is unaware of this change\u00a0in the derivative so it does not know that it needs to explore preferentially in\u00a0the direction where the derivative remains negative for longer. It also makes it\u00a0difficult to choose a good step size. The step size must be small enough to avoid\u00a0overshooting the minimum and going uphill in directions with strong positive\u00a0curvature. This usually means that the step size is too small to make significant\u00a0progress in other directions with less curvature. See Fig. 4.6 for an example.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1093",
    "text": "This issue can be resolved by using information from the Hessian matrix to",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1094",
    "text": "Figure 4.5: A saddle point containing both positive and negative curvature. The function in this example is f (x) = xf \u2014 xf. Along the axis corresponding to x1: the function\u00a0curves upward. This axis is an eigenvector of the Hessian and has a positive eigenvalue.\u00a0Along the axis corresponding to x 2, the function curves downward. This direction is an\u00a0eigenvector of the Hessian with negative eigenvalue. The name \u201csaddle point\u201d derives from\u00a0the saddle-like shape of this function. This is the quintessential example of a function\u00a0with a saddle point. In more than one dimension, it is not necessary to have an eigenvalue\u00a0of 0 in order to get a saddle point: it is only necessary to have both positive and negative\u00a0eigenvalues. We can think of a saddle point with both signs of eigenvalues as being a local\u00a0maximum within one cross section and a local minimum within another cross section.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1095",
    "text": "Figure 4.6: Gradient descent fails to exploit the curvature information contained in the Hessian matrix. Here we use gradient descent to minimize a quadratic function f( x) whose\u00a0Hessian matrix has condition number 5. This means that the direction of most curvature\u00a0has five times more curvature than the direction of least curvature. In this case, the most\u00a0curvature is in the direction [1,1]T and the least curvature is in the direction [1 \u2014 1]T. The\u00a0red lines indicate the path followed by gradient descent. This very elongated quadratic\u00a0function resembles a long canyon. Gradient descent wastes time repeatedly descending\u00a0canyon walls, because they are the steepest feature. Because the step size is somewhat\u00a0too large, it has a tendency to overshoot the bottom of the function and thus needs to\u00a0descend the opposite canyon wall on the next iteration. The large positive eigenvalue\u00a0of the Hessian corresponding to the eigenvector pointed in this direction indicates that\u00a0this directional derivative is rapidly increasing, so an optimization algorithm based on\u00a0the Hessian could predict that the steepest direction is not actually a promising search\u00a0direction in this context.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1096",
    "text": "guide the search. The simplest method for doing so is known as Newton\u2019s method. Newton\u2019s method is based on using a second-order Taylor series expansion to\u00a0approximate f (x) near some point x(0):",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1097",
    "text": "1",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1098",
    "text": "f (x) \u00ab f (x(0) ) + (x-x(0) )TVxf (x(0))+- (x-x(0))TH(f )(x(0))(x\u2014x(0)). (4.11)",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1099",
    "text": "\u2014",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1100",
    "text": "If we then solve for the critical point of this function, we obtain:",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1101",
    "text": "x* = x(0) \u2014 H (f )(x(0) )-1Vx f (x(0)). \u00a0\u00a0\u00a0(4.12)",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1102",
    "text": "When f is a positive definite quadratic function, Newton\u2019s method consists of applying Eq. 4.12 once to jump to the minimum of the function directly. When f is\u00a0not truly quadratic but can be locally approximated as a positive definite quadratic,\u00a0Newton\u2019s method consists of applying Eq. 4.12 multiple times. Iteratively updating\u00a0the approximation and jumping to the minimum of the approximation can reach\u00a0the critical point much faster than gradient descent would. This is a useful property\u00a0near a local minimum, but it can be a harmful property near a saddle point. As\u00a0discussed in Sec. 8.2.3, Newton\u2019s method is only appropriate when the nearby\u00a0critical point is a minimum (all the eigenvalues of the Hessian are positive), whereas\u00a0gradient descent is not attracted to saddle points unless the gradient points toward\u00a0them.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1103",
    "text": "Optimization algorithms such as gradient descent that use only the gradient are called first-order optimization algorithms. Optimization algorithms such as Newton\u2019s method that also use the Hessian matrix are called second-order optimization\u00a0algorithms (Nocedal and Wright, 2006).",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1104",
    "text": "The optimization algorithms employed in most contexts in this book are applicable to a wide variety of functions, but come with almost no guarantees. This\u00a0is because the family of functions used in deep learning is quite complicated. In\u00a0many other fields, the dominant approach to optimization is to design optimization\u00a0algorithms for a limited family of functions.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1105",
    "text": "In the context of deep learning, we sometimes gain some guarantees by restricting ourselves to functions that are either Lipschitz continuous or have Lipschitz continuous derivatives. A Lipschitz continuous function is a function f whose rate\u00a0of change is bounded by a Lipschitz consta,nt L:",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1106",
    "text": "Vx, Vy, |f(x) \u2014 f(y)| < L||x \u2014 y||2. \u00a0\u00a0\u00a0(4.13)",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1107",
    "text": "This property is useful because it allows us to quantify our assumption that a small change in the input made by an algorithm such as gradient descent will have\u00a0a small change in the output. Lipschitz continuity is also a fairly weak constraint,\u00a0and many optimization problems in deep learning can be made Lipschitz continuous\u00a0with relatively minor modifications.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1108",
    "text": "Perhaps the most successful field of specialized optimization is convex optimization. Convex optimization algorithms are able to provide many more guarantees by making stronger restrictions. Convex optimization algorithms are applicable\u00a0only to convex functions\u2014functions for which the Hessian is positive semidefinite\u00a0everywhere. Such functions are well-behaved because they lack saddle points and\u00a0all of their local minima are necessarily global minima. However, most problems\u00a0in deep learning are difficult to express in terms of convex optimization. Convex\u00a0optimization is used only as a subroutine of some deep learning algorithms. Ideas\u00a0from the analysis of convex optimization algorithms can be useful for proving the\u00a0convergence of deep learning algorithms. However, in general, the importance of\u00a0convex optimization is greatly diminished in the context of deep learning. For\u00a0more information about convex optimization, see Boyd and Vandenberghe (2004)\u00a0or Rockafellar (1997).",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1109",
    "text": "Sometimes we wish not only to maximize or minimize a function f (x) over all possible values of x. Instead we may wish to find the maximal or minimal value of\u00a0f (x) for values of x in some set S. This is known as constrained optimization. Points\u00a0x that lie within the set S are called feasible points in constrained optimization\u00a0terminology.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1110",
    "text": "We often wish to find a solution that is small in some sense. A common approach in such situations is to impose a norm constraint, such as ||x|| < 1.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1111",
    "text": "One simple approach to constrained optimization is simply to modify gradient descent taking the constraint into account. If we use a small constant step size e,\u00a0we can make gradient descent steps, then project the result back into S. If we use\u00a0a line search, we can search only over step sizes e that yield new x points that are\u00a0feasible, or we can project each point on the line back into the constraint region.\u00a0When possible, this method can be made more efficient by projecting the gradient\u00a0into the tangent space of the feasible region before taking the step or beginning\u00a0the line search (Rosen, 1960).",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1112",
    "text": "A more sophisticated approach is to design a different, unconstrained optimization problem whose solution can be converted into a solution to the original, constrained optimization problem. For example, if we want to minimize f( x) for\u00a0x \u00a3 R2 with x constrained to have exactly unit L2 norm, we can instead minimize\u00a0g(9) = f ([cos 9, sin 9]T) with respect to 9, then return [cos 9, sin 9] as the solution\u00a0to the original problem. This approach requires creativity; the transformation\u00a0between optimization problems must be designed specifically for each case we\u00a0encounter.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1113",
    "text": "The Karush-Kuhn-Tucker (KKT) approach1 provides a very general solution to constrained optimization. With the KKT approach, we introduce a new function\u00a0called the generalized La,grangian or generalized Lagrange function.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1114",
    "text": "To define the Lagrangian, we first need to describe S in terms of equations and inequalities. We want a description of S in terms of m functions g(i) and n\u00a0functions h(j) so that S = {x | Vi,g(i)(x) = 0 and Vj, h(j) (x) < 0}. The equations\u00a0involving g(i) are called the equality constraints and the inequalities involving h(j)\u00a0are called inequality constraints.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1115",
    "text": "We introduce new variables Ai and aj for each constraint, these are called the KKT multipliers. The generalized Lagrangian is then defined as",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1116",
    "text": "L(x, A, a) = f (x) + ^ Aig(i)(x) + ^ajh(j) (x). \u00a0\u00a0\u00a0(4T4)",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1117",
    "text": "ij",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1118",
    "text": "We can now solve a constrained minimization problem using unconstrained optimization of the generalized Lagrangian. Observe that, so long as at least one\u00a0feasible point exists and f (x) is not permitted to have value to, then",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1119",
    "text": "-4.15",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1120",
    "text": "min max max L(x, A, a). x A a,a 0",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1121",
    "text": "has the same optimal objective function value and set of optimal points x as",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1122",
    "text": "-4.16",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1123",
    "text": "-4.17",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1124",
    "text": "-4.18",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1125",
    "text": "min f (x).",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1126",
    "text": "xSS",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1127",
    "text": "This follows because any time the constraints are satisfied,",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1128",
    "text": "max max L(x, A, a) = f (x),",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1129",
    "text": "A a,a>0",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1130",
    "text": "while any time a constraint is violated,",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1131",
    "text": "max max L(x, A, a) = oo. A a,a 0",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1132",
    "text": "These properties guarantee that no infeasible point will ever be optimal, and that the optimum within the feasible points is unchanged.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1133",
    "text": "To perform constrained maximization, we can construct the generalized Lagrange function of \u2014 f (x), which leads to this optimization problem:",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1134",
    "text": "min max max \u2014 f (x",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1135",
    "text": "x A a,a>0",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1136",
    "text": "f (x) + \u00a0\u00a0\u00a0^ig(i)(x) +\u00a0\u00a0\u00a0\u00a0ah(j) (x).",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1137",
    "text": "-4.19",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1138",
    "text": "We may also convert this to a problem with maximization in the outer loop:",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1139",
    "text": "maxmin min x A a,a> 0",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1140",
    "text": "f (x) + ^2Xi9 (i)",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1141",
    "text": "i",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1142",
    "text": "(x) \u2014 \u00a0\u00a0\u00a0aj h(j) (x).",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1143",
    "text": "j",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1144",
    "text": "-4.2",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1145",
    "text": "The sign of the term for the equality constraints does not matter; we may define it with addition or subtraction as we wish, because the optimization is free to choose\u00a0any sign for each Ai.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1146",
    "text": "The inequality constraints are particularly interesting. We say that a constraint h(i) (x) is active if h(i)(x*) = 0. If a constraint is not active, then the solution to\u00a0the problem found using that constraint would remain at least a local solution if\u00a0that constraint were removed. It is possible that an inactive constraint excludes\u00a0other solutions. For example, a convex problem with an entire region of globally\u00a0optimal points (a wide, flat, region of equal cost) could have a subset of this\u00a0region eliminated by constraints, or a non-convex problem could have better local\u00a0stationary points excluded by a constraint that is inactive at convergence. However,\u00a0the point found at convergence remains a stationary point whether or not the\u00a0inactive constraints are included. Because an inactive h(i) has negative value, then\u00a0the solution to minx maxA maxa,a>0 L(x, A, a) will have ai = 0. We can thus\u00a0observe that at the solution, ah(x) = 0 .In other words, for all i, we know that at\u00a0least one of the constraints ai > 0 and h(i)(x) < 0 must be active at the solution.\u00a0To gain some intuition for this idea, we can say that either the solution is on\u00a0the boundary imposed by the inequality and we must use its KKT multiplier to\u00a0influence the solution to x, or the inequality has no influence on the solution and\u00a0we represent this by zeroing out its KKT multiplier.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1147",
    "text": "The properties that the gradient of the generalized Lagrangian is zero, all constraints on both x and the KKT multipliers are satisfied, and a 0 h(x) = 0\u00a0are called the Karush-Kuhn-Tucker (KKT) conditions (Karush, 1939; Kuhn and\u00a0Tucker, 1951). Together, these properties describe the optimal points of constrained\u00a0optimization problems.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1148",
    "text": "For more information about the KKT approach, see Nocedal and Wright (2006).",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1149",
    "text": "Suppose we want to find the value of x that minimizes",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1150",
    "text": "1",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1151",
    "text": "f(x) = 2 1|Ax - b||2\u2022 \u00a0\u00a0\u00a0(4\u202221)",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1152",
    "text": "There are specialized linear algebra algorithms that can solve this problem efficiently. However, we can also explore how to solve it using gradient-based optimization as\u00a0a simple example of how these techniques work.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1153",
    "text": "First, we need to obtain the gradient:",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1154",
    "text": "Vxf (x) = AT (Ax \u2014 b) = ATAx \u2014 A b. \u00a0\u00a0\u00a0(4.22)",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1155",
    "text": "We can then follow this gradient downhill, taking small steps. See Algorithm 4.1 for details.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1156",
    "text": "Algorithm 4.1 An algorithm to minimize f (x) = 1 ||Ax \u2014 b||2 with respect to x using gradient descent.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1157",
    "text": "Set the step size (e) and tolerance (5) to small, positive numbers. while ||At Ax \u2014 ATb||2 >5 do\u00a0x ^ x \u2014 e (ATAx \u2014 At bj\u00a0end while",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1158",
    "text": "One can also solve this problem using Newton\u2019s method. In this case, because the true function is quadratic, the quadratic approximation employed by Newton\u2019s\u00a0method is exact, and the algorithm converges to the global minimum in a single\u00a0step.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1159",
    "text": "Now suppose we wish to minimize the same function, but subject to the constraint xTx < 1. To do so, we introduce the Lagrangian",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1160",
    "text": "L(x, A) = f (x) + A ^xTx \u2014 1^ \u2022 \u00a0\u00a0\u00a0(4.23)",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1161",
    "text": "We can now solve the problem",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1162",
    "text": "min max L(x, A). \u00a0\u00a0\u00a0(4.24)",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1163",
    "text": "x A,A>0",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1164",
    "text": "The smallest-norm solution to the unconstrained least squares problem may be found using the Moore-Penrose pseudoinverse: x = A+ b. If this point is feasible,\u00a0then it is the solution to the constrained problem. Otherwise, we must find a\u00a0solution where the constraint is active. By differentiating the Lagrangian with\u00a0respect to x, we obtain the equation",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1165",
    "text": "ATAx \u2014 Ab + 2Ax = 0. \u00a0\u00a0\u00a0(4.25)",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1166",
    "text": "This tells us that the solution will take the form",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1167",
    "text": "x = (AtA + 2A1)-1A b. \u00a0\u00a0\u00a0(4.26)",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1168",
    "text": "The magnitude of A must be chosen such that the result obeys the constraint. We can find this value by performing gradient ascent on A. To do so, observe",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1169",
    "text": "d",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1170",
    "text": "L(x, A) = xT x \u2014 1. \u00a0\u00a0\u00a0(4.27)",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1171",
    "text": "dA",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1172",
    "text": "When the norm of x exceeds 1, this derivative is positive, so to follow the derivative uphill and increase the Lagrangian with respect to A, we increase A. Because the\u00a0coefficient on the xTx penalty has increased, solving the linear equation for x will\u00a0now yield a solution with smaller norm. The process of solving the linear equation\u00a0and adjusting A continues until x has the correct norm and the derivative on A is",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1173",
    "text": "0",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1174",
    "text": "This concludes the mathematical preliminaries that we use to develop machine learning algorithms. We are now ready to build and analyze some full-fledged\u00a0learning systems.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1175",
    "text": "1",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1176",
    "text": "The KKT approach generalizes the method of Lagrange multipliers which allows equality constraints but not inequality constraints.",
    "chapter": "Numerical Computation",
    "chapter_id": "main-7.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1177",
    "text": "Deep learning is a specific kind of machine learning. In order to understand deep learning well, one must have a solid understanding of the basic principles\u00a0of machine learning. This chapter provides a brief course in the most important\u00a0general principles that will be applied throughout the rest of the book. Novice\u00a0readers or those who want a wider perspective are encouraged to consider machine\u00a0learning textbooks with a more comprehensive coverage of the fundamentals, such\u00a0as Murphy (2012) or Bishop (2006). If you are already familiar with machine\u00a0learning basics, feel free to skip ahead to Sec. 5.11. That section covers some perspectives on traditional machine learning techniques that have strongly influenced\u00a0the development of deep learning algorithms.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1178",
    "text": "We begin with a definition of what a learning algorithm is, and present an example: the linear regression algorithm. We then proceed to describe how the\u00a0challenge of fitting the training data differs from the challenge of finding patterns\u00a0that generalize to new data. Most machine learning algorithms have settings\u00a0called hyperparameters that must be determined external to the learning algorithm\u00a0itself; we discuss how to set these using additional data. Machine learning is\u00a0essentially a form of applied statistics with increased emphasis on the use of\u00a0computers to statistically estimate complicated functions and a decreased emphasis\u00a0on proving confidence intervals around these functions; we therefore present the\u00a0two central approaches to statistics: frequentist estimators and Bayesian inference.\u00a0Most machine learning algorithms can be divided into the categories of supervised\u00a0learning and unsupervised learning; we describe these categories and give some\u00a0examples of simple learning algorithms from each category. Most deep learning\u00a0algorithms are based on an optimization algorithm called stochastic gradient\u00a0descent. We describe how to combine various algorithm components such as an\u00a0optimization algorithm, a cost function, a model, and a dataset to build a machine\u00a0learning algorithm. Finally, in Sec. 5.11, we describe some of the factors that have\u00a0limited the ability of traditional machine learning to generalize. These challenges\u00a0have motivated the development of deep learning algorithms that overcome these\u00a0obstacles.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1179",
    "text": "A machine learning algorithm is an algorithm that is able to learn from data. But what do we mean by learning? Mitchell (1997) provides the definition \u201cA computer\u00a0program is said to learn from experience E with respect to some class of tasks T\u00a0and performance measure P, if its performance at tasks in T, as measured by P,\u00a0improves with experience E.\u201d One can imagine a very wide variety of experiences\u00a0E, tasks T, and performance measures P, and we do not make any attempt in this\u00a0book to provide a formal definition of what may be used for each of these entities.\u00a0Instead, the following sections provide intuitive descriptions and examples of the\u00a0different kinds of tasks, performance measures and experiences that can be used\u00a0to construct machine learning algorithms.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1180",
    "text": "Machine learning allows us to tackle tasks that are too difficult to solve with fixed programs written and designed by human beings. From a scientific and\u00a0philosophical point of view, machine learning is interesting because developing our\u00a0understanding of machine learning entails developing our understanding of the\u00a0principles that underlie intelligence.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1181",
    "text": "In this relatively formal definition of the word \u201ctask,\u201d the process of learning itself is not the task. Learning is our means of attaining the ability to perform the\u00a0task. For example, if we want a robot to be able to walk, then walking is the task.\u00a0We could program the robot to learn to walk, or we could attempt to directly write\u00a0a program that specifies how to walk manually.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1182",
    "text": "Machine learning tasks are usually described in terms of how the machine learning system should process an example. An example is a collection of features\u00a0that have been quantitatively measured from some object or event that we want\u00a0the machine learning system to process. We typically represent an example as a\u00a0vector x E Rn where each entry xi of the vector is another feature. For example,\u00a0the features of an image are usually the values of the pixels in the image.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1183",
    "text": "Many kinds of tasks can be solved with machine learning. Some of the most common machine learning tasks include the following:",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1184",
    "text": "\u2022 \u00a0\u00a0\u00a0Classification: In this type of task, the computer program is asked to specify\u00a0which of k categories some input belongs to. To solve this task, the learning\u00a0algorithm is usually asked to produce a function f : Rn \u2014^ {1,..., k}. When\u00a0y = f (x), the model assigns an input described by vector x to a category\u00a0identified by numeric code y. There are other variants of the classification\u00a0task, for example, where f outputs a probability distribution over classes.\u00a0An example of a classification task is object recognition, where the input\u00a0is an image (usually described as a set of pixel brightness values), and the\u00a0output is a numeric code identifying the object in the image. For example,\u00a0the Willow Garage PR2 robot is able to act as a waiter that can recognize\u00a0different kinds of drinks and deliver them to people on command (Good-fellow et al., 2010). Modern object recognition is best accomplished with\u00a0deep learning (Krizhevsky et al., 2012; Ioffe and Szegedy, 2015). Object\u00a0recognition is the same basic technology that allows computers to recognize\u00a0faces (Taigman et al., 2014), which can be used to automatically tag people\u00a0in photo collections and allow computers to interact more naturally with\u00a0their users.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1185",
    "text": "\u2022 \u00a0\u00a0\u00a0Classification with missing inputs: Classification becomes more challenging if\u00a0the computer program is not guaranteed that every measurement in its input\u00a0vector will always be provided. In order to solve the classification task, the\u00a0learning algorithm only has to define a single function mapping from a vector\u00a0input to a categorical output. When some of the inputs may be missing,\u00a0rather than providing a single classification function, the learning algorithm\u00a0must learn a set of functions. Each function corresponds to classifying x with\u00a0a different subset of its inputs missing. This kind of situation arises frequently\u00a0in medical diagnosis, because many kinds of medical tests are expensive or\u00a0invasive. One way to efficiently define such a large set of functions is to learn\u00a0a probability distribution over all of the relevant variables, then solve the\u00a0classification task by marginalizing out the missing variables. With n input\u00a0variables, we can now obtain all 2n different classification functions needed\u00a0for each possible set of missing inputs, but we only need to learn a single\u00a0function describing the joint probability distribution. See Goodfellow et al.\u00a0(2013b) for an example of a deep probabilistic model applied to such a task\u00a0in this way. Many of the other tasks described in this section can also be\u00a0generalized to work with missing inputs; classification with missing inputs is\u00a0just one example of what machine learning can do.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1186",
    "text": "\u2022 \u00a0\u00a0\u00a0Regression: In this type of task, the computer program is asked to predict a\u00a0numerical value given some input. To solve this task, the learning algorithm\u00a0is asked to output a function f : Rn ^ R. This type of task is similar to\u00a0classification, except that the format of output is different. An example of\u00a0a regression task is the prediction of the expected claim amount that an\u00a0insured person will make (used to set insurance premiums), or the prediction\u00a0of future prices of securities. These kinds of predictions are also used for\u00a0algorithmic trading.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1187",
    "text": "\u2022 \u00a0\u00a0\u00a0Transcription: In this type of task, the machine learning system is asked to\u00a0observe a relatively unstructured representation of some kind of data and\u00a0transcribe it into discrete, textual form. For example, in optical character\u00a0recognition, the computer program is shown a photograph containing an\u00a0image of text and is asked to return this text in the form of a sequence\u00a0of characters (e.g., in ASCII or Unicode format). Google Street View uses\u00a0deep learning to process address numbers in this way (Goodfellow et al.,\u00a02014d). Another example is speech recognition, where the computer program\u00a0is provided an audio waveform and emits a sequence of characters or word\u00a0ID codes describing the words that were spoken in the audio recording. Deep\u00a0learning is a crucial component of modern speech recognition systems used\u00a0at major companies including Microsoft, IBM and Google (Hinton et al.,\u00a02012b).",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1188",
    "text": "\u2022 \u00a0\u00a0\u00a0Machine translation: In a machine translation task, the input already consists\u00a0of a sequence of symbols in some language, and the computer program must\u00a0convert this into a sequence of symbols in another language. This is commonly\u00a0applied to natural languages, such as to translate from English to French.\u00a0Deep learning has recently begun to have an important impact on this kind\u00a0of task (Sutskever et al., 2014; Bahdanau et al., 2015).",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1189",
    "text": "\u2022 \u00a0\u00a0\u00a0Structured output: Structured output tasks involve any task where the output\u00a0is a vector (or other data structure containing multiple values) with important\u00a0relationships between the different elements. This is a broad category, and\u00a0subsumes the transcription and translation tasks described above, but also\u00a0many other tasks. One example is parsing\u2014mapping a natural language\u00a0sentence into a tree that describes its grammatical structure and tagging nodes\u00a0of the trees as being verbs, nouns, or adverbs, and so on. See Collobert (2011)\u00a0for an example of deep learning applied to a parsing task. Another example\u00a0is pixel-wise segmentation of images, where the computer program assigns\u00a0every pixel in an image to a specific category. For example, deep learning can\u00a0be used to annotate the locations of roads in aerial photographs (Mnih and\u00a0Hinton, 2010). The output need not have its form mirror the structure of\u00a0the input as closely as in these annotation-style tasks. For example, in image\u00a0captioning, the computer program observes an image and outputs a natural\u00a0language sentence describing the image (Kiros et al., 2014a,b; Mao et al.,\u00a02015; Vinyals et al., 2015b; Donahue et al., 2014; Karpathy and Li, 2015;\u00a0Fang et al., 2015; Xu et al., 2015). These tasks are called structured output\u00a0tasks because the program must output several values that are all tightly\u00a0inter-related. For example, the words produced by an image captioning\u00a0program must form a valid sentence.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1190",
    "text": "\u2022 \u00a0\u00a0\u00a0Anomaly detection: In this type of task, the computer program sifts through\u00a0a set of events or objects, and flags some of them as being unusual or atypical.\u00a0An example of an anomaly detection task is credit card fraud detection. By\u00a0modeling your purchasing habits, a credit card company can detect misuse\u00a0of your cards. If a thief steals your credit card or credit card information,\u00a0the thief\u2019s purchases will often come from a different probability distribution\u00a0over purchase types than your own. The credit card company can prevent\u00a0fraud by placing a hold on an account as soon as that card has been used\u00a0for an uncharacteristic purchase. See Chandola et al. (2009) for a survey of\u00a0anomaly detection methods.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1191",
    "text": "\u2022 \u00a0\u00a0\u00a0Synthesis and sampling: In this type of task, the machine learning algorithm\u00a0is asked to generate new examples that are similar to those in the training\u00a0data. Synthesis and sampling via machine learning can be useful for media\u00a0applications where it can be expensive or boring for an artist to generate large\u00a0volumes of content by hand. For example, video games can automatically\u00a0generate textures for large objects or landscapes, rather than requiring an\u00a0artist to manually label each pixel (Luo et al., 2013). In some cases, we\u00a0want the sampling or synthesis procedure to generate some specific kind of\u00a0output given the input. For example, in a speech synthesis task, we provide a\u00a0written sentence and ask the program to emit an audio waveform containing\u00a0a spoken version of that sentence. This is a kind of structured output task,\u00a0but with the added qualification that there is no single correct output for\u00a0each input, and we explicitly desire a large amount of variation in the output,\u00a0in order for the output to seem more natural and realistic.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1192",
    "text": "\u2022 \u00a0\u00a0\u00a0Imputation of missing values: In this type of task, the machine learning\u00a0algorithm is given a new example x G Rn, but with some entries xi of x\u00a0missing. The algorithm must provide a prediction of the values of the missing\u00a0entries.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1193",
    "text": "\u2022 \u00a0\u00a0\u00a0Denoising: In this type of task, the machine learning algorithm is given in\u00a0input a corrupted example x E Rn obtained by an unknown corruption process\u00a0from a clean example x E Rn. The learner must predict the clean example\u00a0x from its corrupted version x, or more generally predict the conditional\u00a0probability distribution p(x | x).",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1194",
    "text": "\u2022 \u00a0\u00a0\u00a0Density estimation or probability mass function estimation: In the density\u00a0estimation problem, the machine learning algorithm is asked to learn a\u00a0function pmode1 : Rn ^ R, where Pm0de1 (x) can be interpreted as a probability\u00a0density function (if x is continuous) or a probability mass function (if x is\u00a0discrete) on the space that the examples were drawn from. To do such a task\u00a0well (we will specify exactly what that means when we discuss performance\u00a0measures P), the algorithm needs to learn the structure of the data it\u00a0has seen. It must know where examples cluster tightly and where they\u00a0are unlikely to occur. Most of the tasks described above require that the\u00a0learning algorithm has at least implicitly captured the structure of the\u00a0probability distribution. Density estimation allows us to explicitly capture\u00a0that distribution. In principle, we can then perform computations on that\u00a0distribution in order to solve the other tasks as well. For example, if we\u00a0have performed density estimation to obtain a probability distribution p(x),\u00a0we can use that distribution to solve the missing value imputation task. If\u00a0a value xi is missing and all of the other values, denoted x-i, are given,\u00a0then we know the distribution over it is given by p(xi | x -i). In practice,\u00a0density estimation does not always allow us to solve all of these related tasks,\u00a0because in many cases the required operations on px) are computationally\u00a0intractable.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1195",
    "text": "Of course, many other tasks and types of tasks are possible. The types of tasks we list here are intended only to provide examples of what machine learning can\u00a0do, not to define a rigid taxonomy of tasks.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1196",
    "text": "In order to evaluate the abilities of a machine learning algorithm, we must design a quantitative measure of its performance. Usually this performance measure P is\u00a0specific to the task T being carried out by the system.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1197",
    "text": "For tasks such as classification, classification with missing inputs, and transcription, we often measure the accuracy of the model. Accuracy is just the proportion of examples for which the model produces the correct output. We can also obtain\u00a0equivalent information by measuring the error rate, the proportion of examples for\u00a0which the model produces an incorrect output. We often refer to the error rate as\u00a0the expected 0-1 loss. The 0-1 loss on a particular example is 0 if it is correctly\u00a0classified and 1 if it is not. For tasks such as density estimation, it does not make\u00a0sense to measure accuracy, error rate, or any other kind of 0-1 loss. Instead, we\u00a0must use a different performance metric that gives the model a continuous-valued\u00a0score for each example. The most common approach is to report the average\u00a0log-probability the model assigns to some examples.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1198",
    "text": "Usually we are interested in how well the machine learning algorithm performs on data that it has not seen before, since this determines how well it will work when\u00a0deployed in the real world. We therefore evaluate these performance measures\u00a0using a test set of data that is separate from the data used for training the machine\u00a0learning system.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1199",
    "text": "The choice of performance measure may seem straightforward and objective, but it is often difficult to choose a performance measure that corresponds well to\u00a0the desired behavior of the system.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1200",
    "text": "In some cases, this is because it is difficult to decide what should be measured. For example, when performing a transcription task, should we measure the accuracy\u00a0of the system at transcribing entire sequences, or should we use a more fine-grained\u00a0performance measure that gives partial credit for getting some elements of the\u00a0sequence correct? When performing a regression task, should we penalize the\u00a0system more if it frequently makes medium-sized mistakes or if it rarely makes\u00a0very large mistakes? These kinds of design choices depend on the application.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1201",
    "text": "In other cases, we know what quantity we would ideally like to measure, but measuring it is impractical. For example, this arises frequently in the context of\u00a0density estimation. Many of the best probabilistic models represent probability\u00a0distributions only implicitly. Computing the actual probability value assigned to\u00a0a specific point in space in many such models is intractable. In these cases, one\u00a0must design an alternative criterion that still corresponds to the design objectives,\u00a0or design a good approximation to the desired criterion.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1202",
    "text": "Machine learning algorithms can be broadly categorized as unsupervised or supervised by what kind of experience they are allowed to have during the learning process.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1203",
    "text": "Most of the learning algorithms in this book can be understood as being allowed to experience an entire dataset. A dataset is a collection of many examples, as\u00a0defined in Sec. 5.1.1. Sometimes we will also call examples data points.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1204",
    "text": "One of the oldest datasets studied by statisticians and machine learning researchers is the Iris dataset (Fisher, 1936). It is a collection of measurements of different parts of 150 iris plants. Each individual plant corresponds to one example.\u00a0The features within each example are the measurements of each of the parts of the\u00a0plant: the sepal length, sepal width, petal length and petal width. The dataset\u00a0also records which species each plant belonged to. Three different species are\u00a0represented in the dataset.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1205",
    "text": "Unsupervised learning algorithms experience a dataset containing many features, then learn useful properties of the structure of this dataset. In the context of deep\u00a0learning, we usually want to learn the entire probability distribution that generated\u00a0a dataset, whether explicitly as in density estimation or implicitly for tasks like\u00a0synthesis or denoising. Some other unsupervised learning algorithms perform other\u00a0roles, like clustering, which consists of dividing the dataset into clusters of similar\u00a0examples.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1206",
    "text": "Supervised learning algorithms experience a dataset containing features, but each example is also associated with a label or target. For example, the Iris dataset\u00a0is annotated with the species of each iris plant. A supervised learning algorithm\u00a0can study the Iris dataset and learn to classify iris plants into three different species\u00a0based on their measurements.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1207",
    "text": "Roughly speaking, unsupervised learning involves observing several examples of a random vector x, and attempting to implicitly or explicitly learn the probability distribution p(x), or some interesting properties of that distribution, while\u00a0supervised learning involves observing several examples of a random vector x and\u00a0an associated value or vector y, and learning to predict y from x, usually by\u00a0estimating p (y | x). The term supervised learning originates from the view of\u00a0the target y being provided by an instructor or teacher who shows the machine\u00a0learning system what to do. In unsupervised learning, there is no instructor or\u00a0teacher, and the algorithm must learn to make sense of the data without this guide.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1208",
    "text": "Unsupervised learning and supervised learning are not formally defined terms. The lines between them are often blurred. Many machine learning technologies can\u00a0be used to perform both tasks. For example, the chain rule of probability states\u00a0that for a vector x E Rn, the joint distribution can be decomposed as",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1209",
    "text": "n",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1210",
    "text": "p(x) =np(xi I x 1,...,xi-1). \u00a0\u00a0\u00a0(5.1)",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1211",
    "text": "i=1",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1212",
    "text": "This decomposition means that we can solve the ostensibly unsupervised problem of modeling p(x) by splitting it into n supervised learning problems. Alternatively, we\u00a0can solve the supervised learning problem of learning p (y | x) by using traditional\u00a0unsupervised learning technologies to learn the joint distribution p(x, y) and\u00a0inferring",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1213",
    "text": "p(y|x) = \u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0(5.2)",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1214",
    "text": "y p(x,y )",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1215",
    "text": "Though unsupervised learning and supervised learning are not completely formal or distinct concepts, they do help to roughly categorize some of the things we do with\u00a0machine learning algorithms. Traditionally, people refer to regression, classification\u00a0and structured output problems as supervised learning. Density estimation in\u00a0support of other tasks is usually considered unsupervised learning.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1216",
    "text": "Other variants of the learning paradigm are possible. For example, in semi-supervised learning, some examples include a supervision target but others do not. In multi-instance learning, an entire collection of examples is labeled as\u00a0containing or not containing an example of a class, but the individual members\u00a0of the collection are not labeled. For a recent example of multi-instance learning\u00a0with deep models, see Kotzias et al. (2015).",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1217",
    "text": "Some machine learning algorithms do not just experience a fixed dataset. For example, reinforcement learning algorithms interact with an environment, so there\u00a0is a feedback loop between the learning system and its experiences. Such algorithms\u00a0are beyond the scope of this book. Please see Sutton and Barto (1998) or Bertsekas\u00a0and Tsitsiklis (1996) for information about reinforcement learning, and Mnih et al.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1218",
    "text": "(2013) for the deep learning approach to reinforcement learning.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1219",
    "text": "Most machine learning algorithms simply experience a dataset. A dataset can be described in many ways. In all cases, a dataset is a collection of examples,\u00a0which are in turn collections of features.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1220",
    "text": "One common way of describing a dataset is with a design matrix. A design matrix is a matrix containing a different example in each row. Each column of the\u00a0matrix corresponds to a different feature. For instance, the Iris dataset contains\u00a0150 examples with four features for each example. This means we can represent\u00a0the dataset with a design matrix X e R150x4, where Xi;1 is the sepal length of\u00a0plant i, Xi,2 is the sepal width of plant i, etc. We will describe most of the learning\u00a0algorithms in this book in terms of how they operate on design matrix datasets.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1221",
    "text": "Of course, to describe a dataset as a design matrix, it must be possible to describe each example as a vector, and each of these vectors must be the same size.\u00a0This is not always possible. For example, if you have a collection of photographs\u00a0with different widths and heights, then different photographs will contain different\u00a0numbers of pixels, so not all of the photographs may be described with the same\u00a0length of vector. Sec. 9.7 and Chapter 10 describe how to handle different types\u00a0of such heterogeneous data. In cases like these, rather than describing the dataset\u00a0as a matrix with m rows, we will describe it as a set containing m elements:\u00a0{x(1), x(2),..., x(m)}. This notation does not imply that any two example vectors\u00a0x(i) and xj) have the same size.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1222",
    "text": "In the case of supervised learning, the example contains a label or target as well as a collection of features. For example, if we want to use a learning algorithm\u00a0to perform object recognition from photographs, we need to specify which object\u00a0appears in each of the photos. We might do this with a numeric code, with 0\u00a0signifying a person, 1 signifying a car, 2 signifying a cat, etc. Often when working\u00a0with a dataset containing a design matrix of feature observations X, we also\u00a0provide a vector of labels y, with y providing the label for example i.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1223",
    "text": "Of course, sometimes the label may be more than just a single number. For example, if we want to train a speech recognition system to transcribe entire\u00a0sentences, then the label for each example sentence is a sequence of words.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1224",
    "text": "Just as there is no formal definition of supervised and unsupervised learning, there is no rigid taxonomy of datasets or experiences. The structures described here\u00a0cover most cases, but it is always possible to design new ones for new applications.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1225",
    "text": "Our definition of a machine learning algorithm as an algorithm that is capable of improving a computer program\u2019s performance at some task via experience is\u00a0somewhat abstract. To make this more concrete, we present an example of a simple\u00a0machine learning algorithm: linear regression. We will return to this example\u00a0repeatedly as we introduce more machine learning concepts that help to understand\u00a0its behavior.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1226",
    "text": "As the name implies, linear regression solves a regression problem. In other words, the goal is to build a system that can take a vector x E Rn as input and\u00a0predict the value of a scalar y E R as its output. In the case of linear regression,\u00a0the output is a linear function of the input. Let y be the value that our model\u00a0predicts y should take on. We define the output to be",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1227",
    "text": "y = w Tx \u00a0\u00a0\u00a0(5.3)",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1228",
    "text": "where w E Rn is a vector of parameters.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1229",
    "text": "Parameters are values that control the behavior of the system. In this case, wi is the coefficient that we multiply by feature xi before summing up the contributions\u00a0from all the features. We can think of w as a set of weights that determine how\u00a0each feature affects the prediction. If a feature xi receives a positive weight wi,\u00a0then increasing the value of that feature increases the value of our prediction y.\u00a0If a feature receives a negative weight, then increasing the value of that feature\u00a0decreases the value of our prediction. If a feature\u2019s weight is large in magnitude,\u00a0then it has a large effect on the prediction. If a feature\u2019s weight is zero, it has no\u00a0effect on the prediction.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1230",
    "text": "We thus have a definition of our task T: to predict y from x by outputting y = wTx. Next we need a definition of our performance measure, P.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1231",
    "text": "Suppose that we have a design matrix of m example inputs that we will not use for training, only for evaluating how well the model performs. We also have\u00a0a vector of regression targets providing the correct value of y for each of these\u00a0examples. Because this dataset will only be used for evaluation, we call it the test\u00a0set. We refer to the design matrix of inputs as X(test) and the vector of regression\u00a0targets as y(test).",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1232",
    "text": "One way of measuring the performance of the model is to compute the mean squared error of the model on the test set. If y(test) gives the predictions of the\u00a0model on the test set, then the mean squared error is given by",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1233",
    "text": "1",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1234",
    "text": "MSEtest = - V(y(test) - y(test))i2. \u00a0\u00a0\u00a0(5.4)",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1235",
    "text": "m",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1236",
    "text": "i",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1237",
    "text": "Intuitively, one can see that this error measure decreases to 0 when y(test) = y(test). We can also see that",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1238",
    "text": "MSEtest =- ||y(test) - y(test) |2, \u00a0\u00a0\u00a0(5.5)",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1239",
    "text": "m",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1240",
    "text": "so the error increases whenever the Euclidean distance between the predictions and the targets increases.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1241",
    "text": "To make a machine learning algorithm, we need to design an algorithm that will improve the weights w in a way that reduces MSEtest when the algorithm\u00a0is allowed to gain experience by observing a training set (X(tra1n), y(tra1n)). One\u00a0intuitive way of doing this (which we will justify later, in Sec. 5.5.1) is just to\u00a0minimize the mean squared error on the training set, MSEtra!n.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1242",
    "text": "To minimize MSEtra!n, we can simply solve for where its gradient is 0:",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1243",
    "text": "m",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1244",
    "text": "Figure 5.1: A linear regression problem, with a training set consisting of ten data points, each containing one feature. Because there is only one feature, the weight vector w\u00a0contains only a single parameter to learn, w1. (Left) Observe that linear regression learns\u00a0to set w1 such that the line y _ w1 x comes as close as possible to passing through all the\u00a0training points. (Right) The plotted point indicates the value ofw 1 found by the normal\u00a0equations, which we can see minimizes the mean squared error on the training set.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1245",
    "text": "^ Vw (X (train)w - y(train) \u00a0\u00a0\u00a0X(train) w - y(train)) = 0",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1246",
    "text": "/wTX(train)TX(train)w _ 2wTX(tram)Ty(tram) + y(train)Ty(trainA",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1247",
    "text": "2x(train)TX(train)w _ 2X(train)Ty(train) _ 0",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1248",
    "text": "-1",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1249",
    "text": "w",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1250",
    "text": "_ / X(train)TX(train) j \u00a0\u00a0\u00a0X(train)Ty(train)",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1251",
    "text": "-5.9",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1252",
    "text": "0",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1253",
    "text": "-5.1",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1254",
    "text": "-5.11",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1255",
    "text": "-5.12",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1256",
    "text": "The system of equations whose solution is given by Eq. 5.12 is known as the normal equations. Evaluating Eq. 5.12 constitutes a simple learning algorithm.\u00a0For an example of the linear regression learning algorithm in action, see Fig. 5.1.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1257",
    "text": "It is worth noting that the term linear regression is often used to refer to a slightly more sophisticated model with one additional parameter\u2014an intercept\u00a0term b. In this model",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1258",
    "text": "y _ wTx + b \u00a0\u00a0\u00a0(5.13)",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1259",
    "text": "so the mapping from parameters to predictions is still a linear function but the mapping from features to predictions is now an affine function. This extension to\u00a0affine functions means that the plot of the model\u2019s predictions still looks like a\u00a0line, but it need not pass through the origin. Instead of adding the bias parameter\u00a0b, one can continue to use the model with only weights but augment x with an\u00a0extra entry that is always set to 1. The weight corresponding to the extra 1 entry\u00a0plays the role of the bias parameter. We will frequently use the term \u201clinear\u201d when\u00a0referring to affine functions throughout this book.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1260",
    "text": "The intercept term b is often called the bias parameter of the affine transformation. This terminology derives from the point of view that the output of the transformation is biased toward being b in the absence of any input. This term\u00a0is different from the idea of a statistical bias, in which a statistical estimation\u00a0algorithm\u2019s expected estimate of a quantity is not equal to the true quantity.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1261",
    "text": "Linear regression is of course an extremely simple and limited learning algorithm, but it provides an example of how a learning algorithm can work. In the subsequent\u00a0sections we will describe some of the basic principles underlying learning algorithm\u00a0design and demonstrate how these principles can be used to build more complicated\u00a0learning algorithms.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1262",
    "text": "The central challenge in machine learning is that we must perform well on new, previously unseen inputs\u2014not just those on which our model was trained. The\u00a0ability to perform well on previously unobserved inputs is called generalization.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1263",
    "text": "Typically, when training a machine learning model, we have access to a training set, we can compute some error measure on the training set called the training\u00a0error, and we reduce this training error. So far, what we have described is simply\u00a0an optimization problem. What separates machine learning from optimization is\u00a0that we want the generalization error, also called the test error, to be low as well.\u00a0The generalization error is defined as the expected value of the error on a new\u00a0input. Here the expectation is taken across different possible inputs, drawn from\u00a0the distribution of inputs we expect the system to encounter in practice.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1264",
    "text": "We typically estimate the generalization error of a machine learning model by measuring its performance on a test set of examples that were collected separately\u00a0from the training set.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1265",
    "text": "In our linear regression example, we trained the model by minimizing the training error,",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1266",
    "text": "1",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1267",
    "text": "m(train)",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1268",
    "text": "but we actually care about the test error,",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1269",
    "text": "X (tram) w \u2014 y(tram) || 2,",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1270",
    "text": "-5.14",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1271",
    "text": "1",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1272",
    "text": "|X(test)w - y(test) ||2",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1273",
    "text": "How can we affect performance on the test set when we get to observe only the training set? The field of statistical learning theory provides some answers. If the\u00a0training and the test set are collected arbitrarily, there is indeed little we can do.\u00a0If we are allowed to make some assumptions about how the training and test set\u00a0are collected, then we can make some progress.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1274",
    "text": "The train and test data are generated by a probability distribution over datasets called the data generating process. We typically make a set of assumptions known\u00a0collectively as the i.i.d. assumptions These assumptions are that the examples\u00a0in each dataset are independent from each other, and that the train set and test\u00a0set are identically distributed, drawn from the same probability distribution as\u00a0each other. This assumption allows us to describe the data generating process\u00a0with a probability distribution over a single example. The same distribution is\u00a0then used to generate every train example and every test example. We call that\u00a0shared underlying distribution the data generating distribution, denoted pdata. This\u00a0probabilistic framework and the i.i.d. assumptions allow us to mathematically\u00a0study the relationship between training error and test error.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1275",
    "text": "One immediate connection we can observe between the training and test error is that the expected training error of a randomly selected model is equal to the\u00a0expected test error of that model. Suppose we have a probability distribution\u00a0p(x,y) and we sample from it repeatedly to generate the train set and the test\u00a0set. For some fixed value w, the expected training set error is exactly the same as\u00a0the expected test set error, because both expectations are formed using the same\u00a0dataset sampling process. The only difference between the two conditions is the\u00a0name we assign to the dataset we sample.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1276",
    "text": "Of course, when we use a machine learning algorithm, we do not fix the parameters ahead of time, then sample both datasets. We sample the training set,\u00a0then use it to choose the parameters to reduce training set error, then sample the\u00a0test set. Under this process, the expected test error is greater than or equal to\u00a0the expected value of training error. The factors determining how well a machine\u00a0learning algorithm will perform are its ability to:",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1277",
    "text": "1. \u00a0\u00a0\u00a0Make the training error small.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1278",
    "text": "2. \u00a0\u00a0\u00a0Make the gap between training and test error small.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1279",
    "text": "These two factors correspond to the two central challenges in machine learning: underfitting and overfitting. Underfitting occurs when the model is not able to\u00a0obtain a sufficiently low error value on the training set. Overfitting occurs when\u00a0the gap between the training error and test error is too large.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1280",
    "text": "We can control whether a model is more likely to overfit or underfit by altering its capacity. Informally, a model\u2019s capacity is its ability to fit a wide variety of\u00a0functions. Models with low capacity may struggle to fit the training set. Models\u00a0with high capacity can overfit by memorizing properties of the training set that do\u00a0not serve them well on the test set.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1281",
    "text": "One way to control the capacity of a learning algorithm is by choosing its hypothesis space, the set of functions that the learning algorithm is allowed to\u00a0select as being the solution. For example, the linear regression algorithm has the\u00a0set of all linear functions of its input as its hypothesis space. We can generalize\u00a0linear regression to include polynomials, rather than just linear functions, in its\u00a0hypothesis space. Doing so increases the model\u2019s capacity.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1282",
    "text": "A polynomial of degree one gives us the linear regression model with which we are already familiar, with prediction",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1283",
    "text": "y = b + wx. \u00a0\u00a0\u00a0(5.15)",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1284",
    "text": "By introducing XX as another feature provided to the linear regression model, we can learn a model that is quadratic as a function of x:",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1285",
    "text": "y = b + w1x + w2XX . \u00a0\u00a0\u00a0(5.16)",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1286",
    "text": "Though this model implements a quadratic function of its input, the output is still a linear function of the parameters, so we can still use the normal equations\u00a0to train the model in closed form. We can continue to add more powers of x as\u00a0additional features, for example to obtain a polynomial of degree 9:",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1287",
    "text": "9",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1288",
    "text": "y = b + \u00a0\u00a0\u00a0wiX.\u00a0\u00a0\u00a0\u00a0(5.17)",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1289",
    "text": "i=1",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1290",
    "text": "Machine learning algorithms will generally perform best when their capacity is appropriate in regard to the true complexity of the task they need to perform\u00a0and the amount of training data they are provided with. Models with insufficient\u00a0capacity are unable to solve complex tasks. Models with high capacity can solve\u00a0complex tasks, but when their capacity is higher than needed to solve the present\u00a0task they may overfit.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1291",
    "text": "Fig. 5.2 shows this principle in action. We compare a linear, quadratic and degree-9 predictor attempting to fit a problem where the true underlying function\u00a0is quadratic. The linear function is unable to capture the curvature in the true underlying problem, so it underfits. The degree-9 predictor is capable of representing\u00a0the correct function, but it is also capable of representing infinitely many other\u00a0functions that pass exactly through the training points, because we have more\u00a0parameters than training examples. We have little chance of choosing a solution\u00a0that generalizes well when so many wildly different solutions exist. In this example,\u00a0the quadratic model is perfectly matched to the true structure of the task so it\u00a0generalizes well to new data.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1292",
    "text": "Underfitting",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1293",
    "text": "A",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1294",
    "text": "ppropriate capacity",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1295",
    "text": "Overfitting",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1296",
    "text": "\u2022",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1297",
    "text": "",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1298",
    "text": "",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1299",
    "text": "",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1300",
    "text": ">",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1301",
    "text": "",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1302",
    "text": "x0",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1303",
    "text": "",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1304",
    "text": "x 0",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1305",
    "text": "",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1306",
    "text": "",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1307",
    "text": "x0",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1308",
    "text": "Figure 5.2: We fit three models to this example training set. The training data was generated synthetically, by randomly sampling x values and choosing y deterministically\u00a0by evaluating a quadratic function. (Left) A linear function fit to the data suffers from\u00a0underfitting\u2014it cannot capture the curvature that is present in the data. (Center) A\u00a0quadratic function fit to the data generalizes well to unseen points. It does not suffer from\u00a0a significant amount of overfitting or underfitting. (Right) A polynomial of degree 9 fit to\u00a0the data suffers from overfitting. Here we used the Moore-Penrose pseudoinverse to solve\u00a0the underdetermined normal equations. The solution passes through all of the training\u00a0points exactly, but we have not been lucky enough for it to extract the correct structure.\u00a0It now has a deep valley in between two training points that does not appear in the true\u00a0underlying function. It also increases sharply on the left side of the data, while the true\u00a0function decreases in this area. 1",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1309",
    "text": "of the optimization algorithm, mean that the learning algorithm\u2019s effective capacity may be less than the representational capacity of the model family.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1310",
    "text": "Our modern ideas about improving the generalization of machine learning models are refinements of thought dating back to philosophers at least as early\u00a0as Ptolemy. Many early scholars invoke a principle of parsimony that is now\u00a0most widely known as Occam\u2019s razor (c. 1287-1347). This principle states that\u00a0among competing hypotheses that explain known observations equally well, one\u00a0should choose the \u201csimplest\u201d one. This idea was formalized and made more precise\u00a0in the 20th century by the founders of statistical learning theory (Vapnik and\u00a0Chervonenkis, 1971; Vapnik, 1982; Blumer et al., 1989; Vapnik, 1995).",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1311",
    "text": "Statistical learning theory provides various means of quantifying model capacity. Among these, the most well-known is the Vapnik-Chervonenkis dimension, or VC\u00a0dimension. The VC dimension measures the capacity of a binary classifier. The\u00a0VC dimension is defined as being the largest possible value of m for which there\u00a0exists a training set of m different x points that the classifier can label arbitrarily.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1312",
    "text": "Quantifying the capacity of the model allows statistical learning theory to make quantitative predictions. The most important results in statistical learning\u00a0theory show that the discrepancy between training error and generalization error\u00a0is bounded from above by a quantity that grows as the model capacity grows but\u00a0shrinks as the number of training examples increases (Vapnik and Chervonenkis,\u00a01971; Vapnik, 1982; Blumer et al., 1989; Vapnik, 1995). These bounds provide\u00a0intellectual justification that machine learning algorithms can work, but they are\u00a0rarely used in practice when working with deep learning algorithms. This is in\u00a0part because the bounds are often quite loose and in part because it can be quite\u00a0difficult to determine the capacity of deep learning algorithms. The problem of\u00a0determining the capacity of a deep learning model is especially difficult because the\u00a0effective capacity is limited by the capabilities of the optimization algorithm, and\u00a0we have little theoretical understanding of the very general non-convex optimization\u00a0problems involved in deep learning.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1313",
    "text": "We must remember that while simpler functions are more likely to generalize (to have a small gap between training and test error) we must still choose a\u00a0sufficiently complex hypothesis to achieve low training error. Typically, training\u00a0error decreases until it asymptotes to the minimum possible error value as model\u00a0capacity increases (assuming the error measure has a minimum value). Typically,\u00a0generalization error has a U-shaped curve as a function of model capacity. This is\u00a0illustrated in Fig. 5.3.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1314",
    "text": "To reach the most extreme case of arbitrarily high capacity, we introduce the concept of non-parametric models. So far, we have seen only parametric",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1315",
    "text": "Figure 5.3: Typical relationship between capacity and error. Training and test error behave differently. At the left end of the graph, training error and generalization error\u00a0are both high. This is the underfitting regime. As we increase capacity, training error\u00a0decreases, but the gap between training and generalization error increases. Eventually,\u00a0the size of this gap outweighs the decrease in training error, and we enter the overfitting\u00a0regime, where capacity is too large, above the optimal capacity.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1316",
    "text": "models, such as linear regression. Parametric models learn a function described by a parameter vector whose size is finite and fixed before any data is observed.\u00a0Non-parametric models have no such limitation.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1317",
    "text": "Sometimes, non-parametric models are just theoretical abstractions (such as an algorithm that searches over all possible probability distributions) that cannot\u00a0be implemented in practice. However, we can also design practical non-parametric\u00a0models by making their complexity a function of the training set size. One example\u00a0of such an algorithm is nearest neighbor regression. Unlike linear regression, which\u00a0has a fixed-length vector of weights, the nearest neighbor regression model simply\u00a0stores the X and y from the training set. When asked to classify a test point x,\u00a0the model looks up the nearest entry in the training set and returns the associated\u00a0regression target. In other words, y = y where i = argmin ||Xi,: \u2014 x|||. The\u00a0algorithm can also be generalized to distance metrics other than the L2 norm, such\u00a0as learned distance metrics (Goldberger et al., 2005). If the algorithm is allowed\u00a0to break ties by averaging the y values for all Xi,: that are tied for nearest, then\u00a0this algorithm is able to achieve the minimum possible training error (which might\u00a0be greater than zero, if two identical inputs are associated with different outputs)\u00a0on any regression dataset.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1318",
    "text": "Finally, we can also create a non-parametric learning algorithm by wrapping a parametric learning algorithm inside another algorithm that increases the number\u00a0of parameters as needed. For example, we could imagine an outer loop of learning\u00a0that changes the degree of the polynomial learned by linear regression on top of a\u00a0polynomial expansion of the input.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1319",
    "text": "The ideal model is an oracle that simply knows the true probability distribution that generates the data. Even such a model will still incur some error on many\u00a0problems, because there may still be some noise in the distribution. In the case\u00a0of supervised learning, the mapping from x to y may be inherently stochastic,\u00a0or y may be a deterministic function that involves other variables besides those\u00a0included in x. The error incurred by an oracle making predictions from the true\u00a0distribution p(x,y) is called the Bayes error.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1320",
    "text": "Training and generalization error vary as the size of the training set varies. Expected generalization error can never increase as the number of training examples\u00a0increases. For non-parametric models, more data yields better generalization until\u00a0the best possible error is achieved. Any fixed parametric model with less than\u00a0optimal capacity will asymptote to an error value that exceeds the Bayes error. See\u00a0Fig. 5.4 for an illustration. Note that it is possible for the model to have optimal\u00a0capacity and yet still have a large gap between training and generalization error.\u00a0In this situation, we may be able to reduce this gap by gathering more training\u00a0examples.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1321",
    "text": "Learning theory claims that a machine learning algorithm can generalize well from a finite training set of examples. This seems to contradict some basic principles of\u00a0logic. Inductive reasoning, or inferring general rules from a limited set of examples,\u00a0is not logically valid. To logically infer a rule describing every member of a set,\u00a0one must have information about every member of that set.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1322",
    "text": "In part, machine learning avoids this problem by offering only probabilistic rules, rather than the entirely certain rules used in purely logical reasoning. Machine\u00a0learning promises to find rules that are probably correct about most members of\u00a0the set they concern.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1323",
    "text": "Unfortunately, even this does not resolve the entire problem. The no free lunch theorem for machine learning (Wolpert, 1996) states that, averaged over all possible\u00a0data generating distributions, every classification algorithm has the same error\u00a0rate when classifying previously unobserved points. In other words, in some sense,\u00a0no machine learning algorithm is universally any better than any other. The most\u00a0sophisticated algorithm we can conceive of has the same average performance (over\u00a0all possible tasks) as merely predicting that every point belongs to the same class.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1324",
    "text": "H",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1325",
    "text": "\u05e0\u05e2",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1326",
    "text": "H",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1327",
    "text": "3.5",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1328",
    "text": "3",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1329",
    "text": "2.5",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1330",
    "text": "2",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1331",
    "text": "1.5 1.0\u00a00.5\u00a00.0",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1332",
    "text": "rr. j.i.i.iji . \u05d5 . . . .1 . .1.1 jjui . . . j . .1. ! .i.ijn . . . j . .1. 1 .1.1.11 r",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1333",
    "text": "100 \u00a0\u00a0\u00a0101\u00a0\u00a0\u00a0\u00a0102 103 10\u00a0\u00a0\u00a0\u00a0105",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1334",
    "text": "_ \u25a0 Bayes error",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1335",
    "text": "Train (quadratic)",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1336",
    "text": "Test (quadratic)",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1337",
    "text": "H Test (optimal capacity) Train (optimal capacity)",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1338",
    "text": "Number of training examples",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1339",
    "text": "Figure 5.4: The effect of the training dataset size on the train and test error, as well as on the optimal model capacity. We constructed a synthetic regression problem based on\u00a0adding moderate amount of noise to a degree 5 polynomial, generated a single test set,\u00a0and then generated several different sizes of training set. For each size, we generated 40\u00a0different training sets in order to plot error bars showing 95% confidence intervals. (Top)\u00a0The MSE on the train and test set for two different models: a quadratic model, and a\u00a0model with degree chosen to minimize the test error. Both are fit in closed form. For\u00a0the quadratic model, the training error increases as the size of the training set increases.\u00a0This is because larger datasets are harder to fit. Simultaneously, the test error decreases,\u00a0because fewer incorrect hypotheses are consistent with the training data. The quadratic\u00a0model does not have enough capacity to solve the task, so its test error asymptotes to\u00a0a high value. The test error at optimal capacity asymptotes to the Bayes error. The\u00a0training error can fall below the Bayes error, due to the ability of the training algorithm\u00a0to memorize specific instances of the training set. As the training size increases to infinity,\u00a0the training error of any fixed-capacity model (here, the quadratic model) must rise to at\u00a0least the Bayes error. (Bottom) As the training set size increases, the optimal capacity\u00a0(shown here as the degree of the optimal polynomial regressor) increases. The optimal\u00a0capacity plateaus after reaching sufficient complexity to solve the task.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1340",
    "text": "Fortunately, these results hold only when we average over all possible data generating distributions. If we make assumptions about the kinds of probability\u00a0distributions we encounter in real-world applications, then we can design learning\u00a0algorithms that perform well on these distributions.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1341",
    "text": "This means that the goal of machine learning research is not to seek a universal learning algorithm or the absolute best learning algorithm. Instead, our goal is to\u00a0understand what kinds of distributions are relevant to the \u201creal world\u201d that an AI\u00a0agent experiences, and what kinds of machine learning algorithms perform well on\u00a0data drawn from the kinds of data generating distributions we care about.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1342",
    "text": "The no free lunch theorem implies that we must design our machine learning algorithms to perform well on a specific task. We do so by building a set of\u00a0preferences into the learning algorithm. When these preferences are aligned with\u00a0the learning problems we ask the algorithm to solve, it performs better.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1343",
    "text": "So far, the only method of modifying a learning algorithm we have discussed is to increase or decrease the model\u2019s capacity by adding or removing functions from\u00a0the hypothesis space of solutions the learning algorithm is able to choose. We gave\u00a0the specific example of increasing or decreasing the degree of a polynomial for a\u00a0regression problem. The view we have described so far is oversimplified.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1344",
    "text": "The behavior of our algorithm is strongly affected not just by how large we make the set of functions allowed in its hypothesis space, but by the specific identity\u00a0of those functions. The learning algorithm we have studied so far, linear regression,\u00a0has a hypothesis space consisting of the set of linear functions of its input. These\u00a0linear functions can be very useful for problems where the relationship between\u00a0inputs and outputs truly is close to linear. They are less useful for problems\u00a0that behave in a very nonlinear fashion. For example, linear regression would\u00a0not perform very well if we tried to use it to predict sin(x) from x. We can thus\u00a0control the performance of our algorithms by choosing what kind of functions we\u00a0allow them to draw solutions from, as well as by controlling the amount of these\u00a0functions.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1345",
    "text": "We can also give a learning algorithm a preference for one solution in its hypothesis space to another. This means that both functions are eligible, but one\u00a0is preferred. The unpreferred solution be chosen only if it fits the training data\u00a0significantly better than the preferred solution.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1346",
    "text": "For example, we can modify the training criterion for linear regression to include weight decay. To perform linear regression with weight decay, we minimize\u00a0a sum comprising both the mean squared error on the training and a criterion\u00a0J(w) that expresses a preference for the weights to have smaller squared L2 norm.\u00a0Specifically,",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1347",
    "text": "J (w) = MSEtrain + AwTw, \u00a0\u00a0\u00a0(5.18)",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1348",
    "text": "where A is a value chosen ahead of time that controls the strength of our preference for smaller weights. When A = 0, we impose no preference, and larger A forces the\u00a0weights to become smaller. Minimizing J(w) results in a choice of weights that\u00a0make a tradeoff between fitting the training data and being small. This gives us\u00a0solutions that have a smaller slope, or put weight on fewer of the features. As an\u00a0example of how we can control a model\u2019s tendency to overfit or underfit via weight\u00a0decay, we can train a high-degree polynomial regression model with different values\u00a0of A. See Fig. 5.5 for the results.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1349",
    "text": "Underfitting Appropriate weight decay Overfitting (Excessive A)\u00a0\u00a0\u00a0\u00a0(Medium A)\u00a0\u00a0\u00a0\u00a0(A ^0)",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1350",
    "text": "Figure 5.5: We fit a high-degree polynomial regression model to our example training set from Fig. 5.2. The true function is quadratic, but here we use only models with degree 9.\u00a0We vary the amount of weight decay to prevent these high-degree models from overfitting.\u00a0(Left) With very large A, we can force the model to learn a function with no slope at\u00a0all. This underfits because it can only represent a constant function. (Center) With a\u00a0medium value of A, the learning algorithm recovers a curve with the right general shape.\u00a0Even though the model is capable of representing functions with much more complicated\u00a0shape, weight decay has encouraged it to use a simpler function described by smaller\u00a0coefficients. (Right) With weight decay approaching zero (i.e., using the Moore-Penrose\u00a0pseudoinverse to solve the underdetermined problem with minimal regularization), the\u00a0degree-9 polynomial overfits significantly, as we saw in Fig. 5.2.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1351",
    "text": "More generally, we can regularize a model that learns a function f (x; 6) by adding a penalty called a regularizer to the cost function. In the case of weight\u00a0decay, the regularizer is 0(w) = wTw. In Chapter 7, we will see that many other\u00a0regularizers are possible.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1352",
    "text": "Expressing preferences for one function over another is a more general way of controlling a model\u2019s capacity than including or excluding members from the\u00a0hypothesis space. We can think of excluding a function from a hypothesis space as\u00a0expressing an infinitely strong preference against that function.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1353",
    "text": "In our weight decay example, we expressed our preference for linear functions defined with smaller weights explicitly, via an extra term in the criterion we\u00a0minimize. There are many other ways of expressing preferences for different\u00a0solutions, both implicitly and explicitly. Together, these different approaches are\u00a0known as regularization. Regularization is any modification we make to\u00a0a learning algorithm that is intended to reduce its generalization error\u00a0but not its training error. Regularization is one of the central concerns of the\u00a0field of machine learning, rivaled in its importance only by optimization.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1354",
    "text": "The no free lunch theorem has made it clear that there is no best machine learning algorithm, and, in particular, no best form of regularization. Instead\u00a0we must choose a form of regularization that is well-suited to the particular task\u00a0we want to solve. The philosophy of deep learning in general and this book in\u00a0particular is that a very wide range of tasks (such as all of the intellectual tasks\u00a0that people can do) may all be solved effectively using very general-purpose forms\u00a0of regularization.",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1355",
    "text": "1",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1356",
    "text": " far we have only described changing a model\u2019s capacity by changing the number of input features it has (and simultaneously adding new parameters\u00a0associated with those features). There are in fact many ways of changing a model\u2019s\u00a0capacity. Capacity is not determined only by the choice of model. The model\u00a0specifies which family of functions the learning algorithm can choose from when\u00a0varying the parameters in order to reduce a training objective. This is called the\u00a0representational capacity of the model. In many cases, finding the best function\u00a0within this family is a very difficult optimization problem. In practice, the learning\u00a0algorithm does not actually find the best function, but merely one that significantly\u00a0reduces the training error. These additional limitations, such as the imperfection",
    "chapter": "Machine Learning Basics",
    "chapter_id": "main-8.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1357",
    "text": "Most machine learning algorithms have several settings that we can use to control the behavior of the learning algorithm. These settings are called hyperparameters.\u00a0The values of hyperparameters are not adapted by the learning algorithm itself\u00a0(though we can design a nested learning procedure where one learning algorithm\u00a0learns the best hyperparameters for another learning algorithm).",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1358",
    "text": "In the polynomial regression example we saw in Fig. 5.2, there is a single hyperparameter: the degree of the polynomial, which acts as a capacity hyperparameter. The A value used to control the strength of weight decay is another example of a\u00a0hyp erparameter.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1359",
    "text": "Sometimes a setting is chosen to be a hyperparameter that the learning algorithm does not learn because it is difficult to optimize. More frequently, we do not learn the hyperparameter because it is not appropriate to learn that hyperparameter on the training set. This applies to all hyperparameters that control\u00a0model capacity. If learned on the training set, such hyperparameters would always\u00a0choose the maximum possible model capacity, resulting in overfitting (refer to\u00a0Fig. 5.3). For example, we can always fit the training set better with a higher\u00a0degree polynomial and a weight decay setting of A = 0 than we could with a lower\u00a0degree polynomial and a positive weight decay setting.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1360",
    "text": "To solve this problem, we need a validation set of examples that the training algorithm does not observe.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1361",
    "text": "Earlier we discussed how a held-out test set, composed of examples coming from the same distribution as the training set, can be used to estimate the generalization\u00a0error of a learner, after the learning process has completed. It is important that the\u00a0test examples are not used in any way to make choices about the model, including\u00a0its hyperparameters. For this reason, no example from the test set can be used\u00a0in the validation set. Therefore, we always construct the validation set from the\u00a0training data. Specifically, we split the training data into two disjoint subsets. One\u00a0of these subsets is used to learn the parameters. The other subset is our validation\u00a0set, used to estimate the generalization error during or after training, allowing\u00a0for the hyperparameters to be updated accordingly. The subset of data used to\u00a0learn the parameters is still typically called the training set, even though this\u00a0may be confused with the larger pool of data used for the entire training process.\u00a0The subset of data used to guide the selection of hyperparameters is called the\u00a0validation set. Typically, one uses about 80% of the training data for training and\u00a020% for validation. Since the validation set is used to \u201ctrain\u201d the hyperparameters,\u00a0the validation set error will underestimate the generalization error, though typically\u00a0by a smaller amount than the training error. After all hyperparameter optimization\u00a0is complete, the generalization error may be estimated using the test set.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1362",
    "text": "In practice, when the same test set has been used repeatedly to evaluate performance of different algorithms over many years, and especially if we consider\u00a0all the attempts from the scientific community at beating the reported state-of-the-art performance on that test set, we end up having optimistic evaluations with\u00a0the test set as well. Benchmarks can thus become stale and then do not reflect the\u00a0true field performance of a trained system. Thankfully, the community tends to\u00a0move on to new (and usually more ambitious and larger) benchmark datasets.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1363",
    "text": "Dividing the dataset into a fixed training set and a fixed test set can be problematic if it results in the test set being small. A small test set implies statistical uncertainty\u00a0around the estimated average test error, making it difficult to claim that algorithm\u00a0A works better than algorithm B on the given task.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1364",
    "text": "When the dataset has hundreds of thousands of examples or more, this is not a serious issue. When the dataset is too small, there are alternative procedures,\u00a0which allow one to use all of the examples in the estimation of the mean test\u00a0error, at the price of increased computational cost. These procedures are based on\u00a0the idea of repeating the training and testing computation on different randomly\u00a0chosen subsets or splits of the original dataset. The most common of these is the\u00a0k-fold cross-validation procedure, shown in Algorithm 5.1, in which a partition\u00a0of the dataset is formed by splitting it into k non-overlapping subsets. The test\u00a0error may then be estimated by taking the average test error across k trials. On\u00a0trial i, the i-th subset of the data is used as the test set and the rest of the data is\u00a0used as the training set. One problem is that there exist no unbiased estimators of\u00a0the variance of such average error estimators (Bengio and Grandvalet, 2004), but\u00a0approximations are typically used.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1365",
    "text": "The field of statistics gives us many tools that can be used to achieve the machine learning goal of solving a task not only on the training set but also to generalize.\u00a0Foundational concepts such as parameter estimation, bias and variance are useful\u00a0to formally characterize notions of generalization, underfitting and overfitting.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1366",
    "text": "Point estimation is the attempt to provide the single \u201cbest\u201d prediction of some quantity of interest. In general the quantity of interest can be a single parameter\u00a0or a vector of parameters in some parametric model, such as the weights in our\u00a0linear regression example in Sec. 5.1.4, but it can also be a whole function.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1367",
    "text": "In order to distinguish estimates of parameters from their true value, our convention will be to denote a point estimate of a parameter 6 by 6.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1368",
    "text": "Let ,...,} be a set of m independent and identically distributed (i.i.d.) data points. A point estimator or statistic is any function of the data:",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1369",
    "text": "e m = g(x(1),..., x(m)). \u00a0\u00a0\u00a0(5.19)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1370",
    "text": "The definition does not require that g return a value that is close to the true 6 or even that the range of g is the same as the set of allowable values of 6.\u00a0This definition of a point estimator is very general and allows the designer of an\u00a0estimator great flexibility. While almost any function thus qualifies as an estimator,",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1371",
    "text": "Algorithm 5.1 The k-fold cross-validation algorithm. It can be used to estimate generalization error of a learning algorithm A when the given dataset D is too\u00a0small for a simple train/test or train/valid split to yield accurate estimation of\u00a0generalization error, because the mean of a loss L on a small test set may have too\u00a0high variance. The dataset D contains as elements the abstract examples z(i) (for\u00a0the i-th example), which could stand for an (input,target) pair z(i) = (x(i), y(i))\u00a0in the case of supervised learning, or for just an input z(i) = x(i) in the case\u00a0of unsupervised learning. The algorithm returns the vector of errors e for each\u00a0example in D, whose mean is the estimated generalization error. The errors on\u00a0individual examples can be used to compute a confidence interval around the mean\u00a0(Eq. 5.47). While these confidence intervals are not well-justified after the use of\u00a0cross-validation, it is still common practice to use them to declare that algorithm A\u00a0is better than algorithm B only if the confidence interval of the error of algorithm\u00a0A lies below and does not intersect the confidence interval of algorithm B.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1372",
    "text": "Define KFoldXV(D, A, L, k):",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1373",
    "text": "Require: D, the given dataset, with elements z(i)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1374",
    "text": "Require: A, the learning algorithm, seen as a function that takes a dataset as input and outputs a learned function\u00a0Require: L, the loss function, seen as a function from a learned function f and\u00a0an example z(i) E D to a scalar E R\u00a0Require: k, the number of folds",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1375",
    "text": "Split D into k mutually exclusive subsets D, whose union is D. for i from 1 to k do\u00a0fi = A(D\\D.)\u00a0for z(j) in Di do",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1376",
    "text": "ej = L(k z ( end for\u00a0end for\u00a0Return e",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1377",
    "text": "a good estimator is a function whose output is close to the true underlying 0 that generated the training data.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1378",
    "text": "For now, we take the frequentist perspective on statistics. That is, we assume that the true parameter value 0 is fixed but unknown, while the point estimate\u00a00) is a function of the data. Since the data is drawn from a random process, any\u00a0function of the data is random. Therefore 0 is a random variable.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1379",
    "text": "Point estimation can also refer to the estimation of the relationship between input and target variables. We refer to these types of point estimates as function\u00a0estimators.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1380",
    "text": "Function Estimation As we mentioned above, sometimes we are interested in performing function estimation (or function approximation). Here we are trying to\u00a0predict a variable y given an input vector x. We assume that there is a function\u00a0f (x) that describes the approximate relationship between y and x. For example,\u00a0we may assume that y = f (x) + e, where e stands for the part of y that is not\u00a0predictable from x. In function estimation, we are interested in approximating\u00a0f with a model or estimate f. Function estimation is really just the same as\u00a0estimating a parameter 0; the function estimator f is simply a point estimator in\u00a0function space. The linear regression example (discussed above in Sec. 5.1.4) and\u00a0the polynomial regression example (discussed in Sec. 5.2) are both examples of\u00a0scenarios that may be interpreted either as estimating a parameter w or estimating\u00a0a function f mapping from x to y.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1381",
    "text": "We now review the most commonly studied properties of point estimators and discuss what they tell us about these estimators.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1382",
    "text": "The bias of an estimator is defined as:",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1383",
    "text": "bias(0m) = E(0m) \u2014 0 \u00a0\u00a0\u00a0(5.20)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1384",
    "text": "where the expectation is over the data (seen as samples from a random variable) and 0 is the true underlying value of 0 used to define the data generating distribution.\u00a0An estimator 0m is said to be unbiased if bias(0m) = 0, which implies that E(0m) =",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1385",
    "text": "0. An estimator 0m is said to be asymptotically unbiased if limm^M bias(0m) = 0,\u00a0which implies that limm^M E(0)m) = 0.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1386",
    "text": "Example: Bernoulli Distribution Consider a set of samples {x(1),... ,x(m)} that are independently and identically distributed according to a Bernoulli distri-",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1387",
    "text": "A common estimator for the 0 parameter of this distribution is the mean of the training samples:",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1388",
    "text": "-5.22",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1389",
    "text": "bution with mean 0:",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1390",
    "text": "P(x(i); 0) = 0x(i) (1 - 0)(1\u05bex(i)).",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1391",
    "text": "-5.21",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1392",
    "text": "0m = 1 V X\u00ab",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1393",
    "text": "m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1394",
    "text": "i=1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1395",
    "text": "To determine whether this estimator is biased, we can substitute Eq. 5.22 into Eq. 5.20:",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1396",
    "text": "bias(\u00b0m) = E[0m] \u2014 0",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1397",
    "text": "#NAME?",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1398",
    "text": "1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1399",
    "text": "m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1400",
    "text": "1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1401",
    "text": "(i)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1402",
    "text": "m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1403",
    "text": "x",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1404",
    "text": "(i)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1405",
    "text": "0",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1406",
    "text": "E",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1407",
    "text": "i=1 m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1408",
    "text": "m \u00a0\u00a0\u00a0x(i) 0*(1) (1\u20140)(1\u05bex(1)))",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1409",
    "text": "0",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1410",
    "text": "0",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1411",
    "text": "i=1 x(l)=0",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1412",
    "text": "m \u00a0\u00a0\u00a0(0) \u2014 0",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1413",
    "text": "i= 1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1414",
    "text": "TRUE",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1415",
    "text": "-5.23",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1416",
    "text": "-5.24",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1417",
    "text": "-5.25",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1418",
    "text": "-5.26",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1419",
    "text": "-5.27",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1420",
    "text": "-5.28",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1421",
    "text": "Since bias(0) = 0, we say that our estimator 0 is unbiased.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1422",
    "text": "Example: Gaussian Distribution Estimator of the Mean Now, consider a set of samples {x(1),..., x(m)} that are independently and identically distributed\u00a0according to a Gaussian distribution p(x(i)) = N(x(i); p, a2), where i G {1,..., m}.\u00a0Recall that the Gaussian probability density function is given by",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1423",
    "text": "p(x(i); p, a 2) =",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1424",
    "text": "1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1425",
    "text": "2",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1426",
    "text": "exp",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1427",
    "text": "(\u25a0",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1428",
    "text": "1 (x(i) \u2014 p)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1429",
    "text": "2 \u00a0\u00a0\u00a0a2",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1430",
    "text": ".",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1431",
    "text": "-5.29",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1432",
    "text": "A common estimator of the Gaussian mean parameter is known as the sample mean:",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1433",
    "text": "(i)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1434",
    "text": "-5.3",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1435",
    "text": "1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1436",
    "text": "p0 m = \u00a0\u00a0\u00a0x",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1437",
    "text": "m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1438",
    "text": "i=1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1439",
    "text": "To determine the bias of the sample mean, we are again interested in calculating its expectation:",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1440",
    "text": "bias(h m ) \u2014 E[Am] \u00a0\u00a0\u00a0P",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1441",
    "text": "\u2014 E",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1442",
    "text": "1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1443",
    "text": "X",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1444",
    "text": "(i)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1445",
    "text": "m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1446",
    "text": "i=1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1447",
    "text": "\u05f4 1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1448",
    "text": "\u2014E m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1449",
    "text": "V i=1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1450",
    "text": "1m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1451",
    "text": "m1 i=1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1452",
    "text": "\u2014 p \u2014 h \u2014 0",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1453",
    "text": "X",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1454",
    "text": "(i)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1455",
    "text": "h",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1456",
    "text": ")",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1457",
    "text": "ll",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1458",
    "text": "-5.31",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1459",
    "text": "-5.32",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1460",
    "text": "-5.33",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1461",
    "text": "-5.34",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1462",
    "text": "-5.35",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1463",
    "text": "Thus we find that the sample mean is an unbiased estimator of Gaussian mean parameter.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1464",
    "text": "Example: Estimators of the Variance of a Gaussian Distribution As an",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1465",
    "text": "example, we compare two different estimators of the variance parameter a2 of a Gaussian distribution. We are interested in knowing if either estimator is biased.\u00a0The first estimator of a2 we consider is known as the sample variance:",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1466",
    "text": "1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1467",
    "text": "m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1468",
    "text": "x (i) \u2014 Am ,",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1469",
    "text": "-5.36",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1470",
    "text": "where pm. is the sample mean, defined above. More formally, we are interested in computing",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1471",
    "text": "bias(a m\u2014E[am] -a2 \u00a0\u00a0\u00a0(5.37)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1472",
    "text": "We begin by evaluating the term E[a?\u201c ]:",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1473",
    "text": "E[am ] \u2014e",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1474",
    "text": "\u05df m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1475",
    "text": "2",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1476",
    "text": "m1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1477",
    "text": "a",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1478",
    "text": "-5.38",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1479",
    "text": "-5.39",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1480",
    "text": "Returning to Eq. 5.37, we conclude that the bias of am is \u2014a2/m. Therefore, the sample variance is a biased estimator.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1481",
    "text": "The unbiased sample variance estimator",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1482",
    "text": "a 2 _ \u00a0\u00a0\u00a01",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1483",
    "text": "m m- 1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1484",
    "text": "m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1485",
    "text": "x(i) - Am)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1486",
    "text": "i= 1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1487",
    "text": "2",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1488",
    "text": "-5.4",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1489",
    "text": "\u05f4 m ] _ a2:",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1490",
    "text": "provides an alternative approach. As the name suggests this estimator is unbiased. That is, we find that E[5\u05bem]",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1491",
    "text": "E[5mj _ E",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1492",
    "text": "1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1493",
    "text": "m1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1494",
    "text": "(x(i) - Am)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1495",
    "text": "i=1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1496",
    "text": "2",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1497",
    "text": "m2 E[am]",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1498",
    "text": "m - 1 m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1499",
    "text": "m m \u2014 1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1500",
    "text": "(mzl a 2)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1501",
    "text": "m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1502",
    "text": "m 1 m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1503",
    "text": "a 2.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1504",
    "text": "-5.41",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1505",
    "text": "-5.42",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1506",
    "text": "-5.43",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1507",
    "text": "-5.44",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1508",
    "text": "We have two estimators: one is biased and the other is not. While unbiased estimators are clearly desirable, they are not always the \u201cbest\u201d estimators. As we\u00a0will see we often use biased estimators that possess other important properties.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1509",
    "text": "Another property of the estimator that we might want to consider is how much we expect it to vary as a function of the data sample. Just as we computed the\u00a0expectation of the estimator to determine its bias, we can compute its variance.\u00a0The variance of an estimator is simply the variance",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1510",
    "text": "Var( J \u00a0\u00a0\u00a0(5.45)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1511",
    "text": "where the random variable is the training set. Alternately, the square root of the variance is called the standard error, denoted SE(0).",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1512",
    "text": "The variance or the standard error of an estimator provides a measure of how we would expect the estimate we compute from data to vary as we independently\u00a0resample the dataset from the underlying data generating process. Just as we\u00a0might like an estimator to exhibit low bias we would also like it to have relatively\u00a0low variance.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1513",
    "text": "When we compute any statistic using a finite number of samples, our estimate of the true underlying parameter is uncertain, in the sense that we could have\u00a0obtained other samples from the same distribution and their statistics would have\u00a0been different. The expected degree of variation in any estimator is a source of\u00a0error that we want to quantify.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1514",
    "text": "The standard error of the mean is given by",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1515",
    "text": "SE(A m)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1516",
    "text": ". Var[\u2014 \u00a0\u00a0\u00a0x(i)] = \u2014a=",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1517",
    "text": "m \u00a0\u00a0\u00a0m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1518",
    "text": "i=1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1519",
    "text": "-5.46",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1520",
    "text": "where a2 is the true variance of the samples xl. The standard error is often estimated by using an estimate of a. Unfortunately, neither the square root of\u00a0the sample variance nor the square root of the unbiased estimator of the variance\u00a0provide an unbiased estimate of the standard deviation. Both approaches tend\u00a0to underestimate the true standard deviation, but are still used in practice. The\u00a0square root of the unbiased estimator of the variance is less of an underestimate.\u00a0For large m, the approximation is quite reasonable.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1521",
    "text": "The standard error of the mean is very useful in machine learning experiments. We often estimate the generalization error by computing the sample mean of the\u00a0error on the test set. The number of examples in the test set determines the\u00a0accuracy of this estimate. Taking advantage of the central limit theorem, which\u00a0tells us that the mean will be approximately distributed with a normal distribution,\u00a0we can use the standard error to compute the probability that the true expectation\u00a0falls in any chosen interval. For example, the 95% confidence interval centered on\u00a0the mean is Am is",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1522",
    "text": "-5.47",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1523",
    "text": "(Am - 1.96SE(Am), Am + 1.96SE(Am)),",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1524",
    "text": "under the normal distribution with mean Am and variance SE( Am) 2. In machine learning experiments, it is common to say that algorithm A is better than algorithm\u00a0B if the upper bound of the 95% confidence interval for the error of algorithm A is\u00a0less than the lower bound of the 95% confidence interval for the error of algorithm\u00a0B.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1525",
    "text": "Example: Bernoulli Distribution We once again consider a set of samples ^,..., (m)} drawn independently and identically from a Bernoulli distribution\u00a0(recall P(x(i); 9) = 9xW(1 \u2014 9)(1-xW)). This time we are interested in computing\u00a0the variance of the estimator 9m = \u2014 W m , x(i).",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1526",
    "text": "m m 1=1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1527",
    "text": "-5.48",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1528",
    "text": "Var (9m) = Var ^m ^ x\u00ab^j",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1529",
    "text": "\u2014 \u00a0\u00a0\u00a0m0(1 \u2014 0)\u00a0m2",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1530",
    "text": "-5.51",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1531",
    "text": "-5.52",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1532",
    "text": "1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1533",
    "text": "- \u00a0\u00a0\u00a00(1 \u2014 0)\u00a0m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1534",
    "text": "The variance of the estimator decreases as a function of m, the number of examples in the dataset. This is a common property of popular estimators that we will\u00a0return to when we discuss consistency (see Sec. 5.4.5).",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1535",
    "text": "Bias and variance measure two different sources of error in an estimator. Bias measures the expected deviation from the true value of the function or parameter.\u00a0Variance on the other hand, provides a measure of the deviation from the expected\u00a0estimator value that any particular sampling of the data is likely to cause.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1536",
    "text": "What happens when we are given a choice between two estimators, one with more bias and one with more variance? How do we choose between them? For\u00a0example, imagine that we are interested in approximating the function shown in\u00a0Fig. 5.2 and we are only offered the choice between a model with large bias and\u00a0one that suffers from large variance. How do we choose between them?",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1537",
    "text": "The most common way to negotiate this trade-off is to use cross-validation. Empirically, cross-validation is highly successful on many real-world tasks. Alternatively, we can also compare the mean squared error (MSE) of the estimates:",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1538",
    "text": "MSE = E [(9m \u2014 0)2 ] \u00a0\u00a0\u00a0(5.53)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1539",
    "text": "#ERROR!",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1540",
    "text": "The MSE measures the overall expected deviation\u2014in a squared error sense\u2014 between the estimator and the true value of the parameter 0. As is clear from\u00a0Eq. 5.54, evaluating the MSE incorporates both the bias and the variance. Desirable\u00a0estimators are those with small MSE and these are estimators that manage to keep\u00a0both their bias and variance somewhat in check.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1541",
    "text": "The relationship between bias and variance is tightly linked to the machine learning concepts of capacity, underfitting and overfitting. In the case where gen-",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1542",
    "text": "Figure 5.6: As capacity increases (x>axis), bias (dotted) tends to decrease and variance (dashed) tends to increase, yielding another U-shaped curve for generalization error (bold\u00a0curve). If we vary capacity along one axis, there is an optimal capacity, with underfitting\u00a0when the capacity is below this optimum and overfitting when it is above. This relationship\u00a0is similar to the relationship between capacity, underfitting, and overfitting, discussed in\u00a0Sec. 5.2 and Fig. 5.3.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1543",
    "text": "eralization error is measured by the MSE (where bias and variance are meaningful components of generalization error), increasing capacity tends to increase variance\u00a0and decrease bias. This is illustrated in Fig. 5.6, where we see again the U-shaped\u00a0curve of generalization error as a function of capacity.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1544",
    "text": "So far we have discussed the properties of various estimators for a training set of fixed size. Usually, we are also concerned with the behavior of an estimator as the\u00a0amount of training data grows. In particular, we usually wish that, as the number\u00a0of data points m in our dataset increases, our point estimates converge to the true\u00a0value of the corresponding parameters. More formally, we would like that",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1545",
    "text": "lim 6m A 6. \u00a0\u00a0\u00a0(5.55)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1546",
    "text": "The symbol A means that the convergence is in probability, i.e. for any e > 0, P(|6m \u2014 6| > e) A 0 as m A to . The condition described by Eq. 5.55 is\u00a0known as consistency. It is sometimes referred to as weak consistency, with\u00a0strong consistency referring to the almost sure convergence of 6 to 6. Almost sure\u00a0convergence of a sequence of random variables x(1), x(2),... to a value x occurs\u00a0when p(limm^<x x(m) = x) = 1.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1547",
    "text": "Consistency ensures that the bias induced by the estimator is assured to diminish as the number of data examples grows. However, the reverse is not\u00a0true\u2014asymptotic unbiasedness does not imply consistency. For example, consider\u00a0estimating the mean parameter p of a normal distribution N(x; p, a2), with a\u00a0dataset consisting of m samples: {x(1),..., x(m)}. We could use the first sample\u00a0x(1) of the dataset as an unbiased estimator: 0 = x(1). In that case, E(#m) = 0\u00a0so the estimator is unbiased no matter how many data points are seen. This, of\u00a0course, implies that the estimate is asymptotically unbiased. However, this is not\u00a0a consistent estimator as it is not the case that 0m ^ 0 as m ^ rc>.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1548",
    "text": "Previously, we have seen some definitions of common estimators and analyzed their properties. But where did these estimators come from? Rather than guessing\u00a0that some function might make a good estimator and then analyzing its bias and\u00a0variance, we would like to have some principle from which we can derive specific\u00a0functions that are good estimators for different models.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1549",
    "text": "The most common such principle is the maximum likelihood principle.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1550",
    "text": "Consider a set of m examples X = {x(1),..., x(m)} drawn independently from the true but unknown data generating distribution pdata (x).",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1551",
    "text": "Let pmode1(x; 6) be a parametric family of probability distributions over the same space indexed by 6. In other words, pmode1(x; 6) maps any configuration x\u00a0to a real number estimating the true probability Pdata(x).",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1552",
    "text": "The maximum likelihood estimator for 6 is then defined as",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1553",
    "text": "6ml = arg max pmode1(X; 6) \u00a0\u00a0\u00a0(5.56)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1554",
    "text": "e",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1555",
    "text": "m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1556",
    "text": "#ERROR!",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1557",
    "text": "e",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1558",
    "text": "1=1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1559",
    "text": "This product over many probabilities can be inconvenient for a variety of reasons. For example, it is prone to numerical underflow. To obtain a more convenient\u00a0but equivalent optimization problem, we observe that taking the logarithm of the\u00a0likelihood does not change its arg max but does conveniently transform a product",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1560",
    "text": "0ml = argmax^ logpmodel(x(i); 0).",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1561",
    "text": "-5.58",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1562",
    "text": "into a sum:",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1563",
    "text": "i=1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1564",
    "text": "Because the argmax does not change when we rescale the cost function, we can divide by m to obtain a version of the criterion that is expressed as an expectation\u00a0with respect to the empirical distribution pdata defined by the training data:",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1565",
    "text": "0 ML = argmax E",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1566",
    "text": "8",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1567",
    "text": "X^Pdata",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1568",
    "text": "logpmodel(x; 0).",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1569",
    "text": "-5.59",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1570",
    "text": "One way to interpret maximum likelihood estimation is to view it as minimizing the dissimilarity between the empirical distribution pdata defined by the training\u00a0set and the model distribution, with the degree of dissimilarity between the two\u00a0measured by the KL divergence. The KL divergence is given by",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1571",
    "text": "\u25a0^KL (pdata ||pmodeO \u00a0\u00a0\u00a0\u00aeX^pdata [log pdata(x)\u00a0\u00a0\u00a0\u00a01ogpmodel(x)] .\u00a0\u00a0\u00a0\u00a0(5.60)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1572",
    "text": "The term on the left is a function only of the data generating process, not the model. This means when we train the model to minimize the KL divergence, we\u00a0need only minimize",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1573",
    "text": "\u2014 Ex~pdata [l0gBnodel (x)] \u00a0\u00a0\u00a0(5.61)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1574",
    "text": "which is of course the same as the maximization in Eq. 5.59.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1575",
    "text": "Minimizing this KL divergence corresponds exactly to minimizing the crossentropy between the distributions. Many authors use the term \u201ccross-entropy\u201d to identify specifically the negative log-likelihood of a Bernoulli or softmax distribution,\u00a0but that is a misnomer. Any loss consisting of a negative log-likelihood is a cross\u00a0entropy between the empirical distribution defined by the training set and the\u00a0model. For example, mean squared error is the cross-entropy between the empirical\u00a0distribution and a Gaussian model.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1576",
    "text": "We can thus see maximum likelihood as an attempt to make the model distribution match the empirical distribution pdata. Ideally, we would like to match the true data generating distribution pdata, but we have no direct access to this\u00a0distribution.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1577",
    "text": "While the optimal 0 is the same regardless of whether we are maximizing the likelihood or minimizing the KL divergence, the values of the objective functions\u00a0are different. In software, we often phrase both as minimizing a cost function.\u00a0Maximum likelihood thus becomes minimization of the negative log-likelihood\u00a0(NLL), or equivalently, minimization of the cross entropy. The perspective of\u00a0maximum likelihood as minimum KL divergence becomes helpful in this case\u00a0because the KL divergence has a known minimum value of zero. The negative\u00a0log-likelihood can actually become negative when x is real-valued.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1578",
    "text": "The maximum likelihood estimator can readily be generalized to the case where our goal is to estimate a conditional probability P(y | x; ff) in order to predict y\u00a0given x. This is actually the most common situation because it forms the basis for\u00a0most supervised learning. If X represents all our inputs and Y all our observed\u00a0targets, then the conditional maximum likelihood estimator is",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1579",
    "text": "-5.62",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1580",
    "text": "Oml = arg max P(Y | X;0). e",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1581",
    "text": "If the examples are assumed to be i.i.d., then this can be decomposed into",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1582",
    "text": "m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1583",
    "text": "Oml = arg max \u00a0\u00a0\u00a0log P(y(i) | x(i); ff).\u00a0\u00a0\u00a0\u00a0(5.63)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1584",
    "text": "e",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1585",
    "text": "i=1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1586",
    "text": "Example: Linear Regression as Maximum Likelihood Linear regression, introduced earlier in Sec. 5.1.4, may be justified as a maximum likelihood procedure.\u00a0Previously, we motivated linear regression as an algorithm that learns to take an\u00a0input x and produce an output value y. The mapping from x to y is chosen to\u00a0minimize mean squared error, a criterion that we introduced more or less arbitrarily.\u00a0We now revisit linear regression from the point of view of maximum likelihood\u00a0estimation. Instead of producing a single prediction y, we now think of the model\u00a0as producing a conditional distribution p(y | x). We can imagine that with an\u00a0infinitely large training set, we might see several training examples with the same\u00a0input value x but different values of y. The goal of the learning algorithm is now to\u00a0fit the distribution p (y | x) to all of those different y values that are all compatible\u00a0with x. To derive the same linear regression algorithm we obtained before, we\u00a0define p(y | x) = N (y; y(x; w),2\u05e1 ). The function y(x; w) gives the prediction of\u00a0the mean of the Gaussian. In this example, we assume that the variance is fixed to",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1587",
    "text": "C\\",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1588",
    "text": "some constant 2\u05e1 chosen by the user. We will see that this choice of the functional form of p(y | x) causes the maximum likelihood estimation procedure to yield the\u00a0same learning algorithm as we developed before. Since the examples are assumed\u00a0to be i.i.d., the conditional log-likelihood (Eq. 5.63) is given by",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1589",
    "text": "Eiog p(y(i) 1 x(i); ff)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1590",
    "text": "i=1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1591",
    "text": "m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1592",
    "text": "\u05d5 m l ) \u00a0\u00a0\u00a0|y(i) - y(i)|12",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1593",
    "text": "10g 10\u05be - \u05e1g(2n) - \u00a0\u00a0\u00a0202\u2014",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1594",
    "text": "-5.64",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1595",
    "text": "-5.65",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1596",
    "text": "i=1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1597",
    "text": "where is the output of the linear regression on the i-th input and m is the number of the training examples. Comparing the log-likelihood with the mean\u00a0squared error,",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1598",
    "text": "m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1599",
    "text": "MSEtrain = \u2014 V' || V W - VW ||2 , \u00a0\u00a0\u00a0(5.66)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1600",
    "text": "m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1601",
    "text": "i=1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1602",
    "text": "we immediately see that maximizing the log-likelihood with respect to w yields the same estimate of the parameters w as does minimizing the mean squared error.\u00a0The two criteria have different values but the same location of the optimum. This\u00a0justifies the use of the MSE as a maximum likelihood estimation procedure. As we\u00a0will see, the maximum likelihood estimator has several desirable properties.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1603",
    "text": "The main appeal of the maximum likelihood estimator is that it can be shown to be the best estimator asymptotically, as the number of examples m ^ to ,in terms\u00a0of its rate of convergence as m increases.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1604",
    "text": "Under appropriate conditions, maximum likelihood estimator has the property of consistency (see Sec. 5.4.5 above), meaning that as the number of training\u00a0examples approaches infinity, the maximum likelihood estimate of a parameter\u00a0converges to the true value of the parameter. These conditions are:",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1605",
    "text": "\u2022 \u00a0\u00a0\u00a0The true distribution pdata must lie within the model family pmode1 (\u2022; 6).\u00a0Otherwise, no estimator can recover pdata.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1606",
    "text": "\u2022 \u00a0\u00a0\u00a0The true distribution pdata must correspond to exactly one value of 6. Otherwise, maximum likelihood can recover the correct pdata, but will not be able\u00a0to determine which value of 6 was used by the data generating processing.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1607",
    "text": "There are other inductive principles besides the maximum likelihood estimator, many of which share the property of being consistent estimators. However, consistent estimators can differ in their statistic efficiency, meaning that one consistent\u00a0estimator may obtain lower generalization error for a fixed number of samples m,\u00a0or equivalently, may require fewer examples to obtain a fixed level of generalization\u00a0error.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1608",
    "text": "Statistical efficiency is typically studied in the parametric case (like in linear regression) where our goal is to estimate the value of a parameter (and assuming\u00a0it is possible to identify the true parameter), not the value of a function. A way to\u00a0measure how close we are to the true parameter is by the expected mean squared\u00a0error, computing the squared difference between the estimated and true parameter\u00a0values, where the expectation is over m training samples from the data generating\u00a0distribution. That parametric mean squared error decreases as m increases, and\u00a0for m large, the Cramer-Rao lower bound (Rao, 1945; Cramer, 1946) shows that no\u00a0consistent estimator has a lower mean squared error than the maximum likelihood\u00a0estimator.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1609",
    "text": "For these reasons (consistency and efficiency), maximum likelihood is often considered the preferred estimator to use for machine learning. When the number\u00a0of examples is small enough to yield overfitting behavior, regularization strategies\u00a0such as weight decay may be used to obtain a biased version of maximum likelihood\u00a0that has less variance when training data is limited.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1610",
    "text": "So far we have discussed frequentist statistics and approaches based on estimating a single value of 6, then making all predictions thereafter based on that one estimate.\u00a0Another approach is to consider all possible values of 6 when making a prediction.\u00a0The latter is the domain of Bayesian statistics.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1611",
    "text": "As discussed in Sec. 5.4.1, the frequentist perspective is that the true parameter value 6 is fixed but unknown, while the point estimate 6 is a random variable on\u00a0account of it being a function of the dataset (which is seen as random).",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1612",
    "text": "The Bayesian perspective on statistics is quite different. The Bayesian uses probability to reflect degrees of certainty of states of knowledge. The dataset is\u00a0directly observed and so is not random. On the other hand, the true parameter 6\u00a0is unknown or uncertain and thus is represented as a random variable.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1613",
    "text": "Before observing the data, we represent our knowledge of 6 using the prior probability distribution,p(6) (sometimes referred to as simply \u201cthe prior\u201d). Generally, the machine learning practitioner selects a prior distribution that is quite\u00a0broad (i.e. with high entropy) to reflect a high degree of uncertainty in the value of\u00a06 before observing any data. For example, one might assume a priori that 6 lies\u00a0in some finite range or volume, with a uniform distribution. Many priors instead\u00a0reflect a preference for \u201csimpler\u201d solutions (such as smaller magnitude coefficients,\u00a0or a function that is closer to being constant).",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1614",
    "text": "Now consider that we have a set of data samples {x(1),..., x( m)}. We can recover the effect of data on our belief about 6 by combining the data likelihood\u00a0p(x(1),..., x(m) | 6) with the prior via Bayes\u2019 rule:",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1615",
    "text": "p(6 | x",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1616",
    "text": "(6)1) \u00a0\u00a0\u00a0x(m)) = p(x(1),...,x(m) | 6)p)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1617",
    "text": "(m\u05f3)\u05f4 \u00a0\u00a0\u00a0(1)\u00a0\u00a0\u00a0\u00a0(\u00a0\u00a0\u00a0\u00a0x, . . . ,",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1618",
    "text": "p(x(1),..., x(m))",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1619",
    "text": "-5.67",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1620",
    "text": "In the scenarios where Bayesian estimation is typically used, the prior begins as a relatively uniform or Gaussian distribution with high entropy, and the observation\u00a0of the data usually causes the posterior to lose entropy and concentrate around a\u00a0few highly likely values of the parameters.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1621",
    "text": "Relative to maximum likelihood estimation, Bayesian estimation offers two important differences. First, unlike the maximum likelihood approach that makes\u00a0predictions using a point estimate of 0, the Bayesian approach is to make predictions\u00a0using a full distribution over 0. For example, after observing m examples, the\u00a0predicted distribution over the next data sample,\u00a0\u00a0\u00a0\u00a0, is given by",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1622",
    "text": "p(x(m+1) | x(1),..., x(m)) = J p(x(m+1) | 0)p(0 | x(1),..., x(m)) d0. \u00a0\u00a0\u00a0(5.68)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1623",
    "text": "Here each value of 0 with positive probability density contributes to the prediction of the next example, with the contribution weighted by the posterior density itself.\u00a0After having observed {x(1),...,\u00a0\u00a0\u00a0\u00a0, if we are still quite uncertain about the",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1624",
    "text": "value of 0, then this uncertainty is incorporated directly into any predictions we might make.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1625",
    "text": "In Sec. 5.4, we discussed how the frequentist approach addresses the uncertainty in a given point estimate of 0 by evaluating its variance. The variance of the\u00a0estimator is an assessment of how the estimate might change with alternative\u00a0samplings of the observed data. The Bayesian answer to the question of how to deal\u00a0with the uncertainty in the estimator is to simply integrate over it, which tends to\u00a0protect well against overfitting. This integral is of course just an application of\u00a0the laws of probability, making the Bayesian approach simple to justify, while the\u00a0frequentist machinery for constructing an estimator is based on the rather ad hoc\u00a0decision to summarize all knowledge contained in the dataset with a single point\u00a0estimate.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1626",
    "text": "The second important difference between the Bayesian approach to estimation and the maximum likelihood approach is due to the contribution of the Bayesian\u00a0prior distribution. The prior has an influence by shifting probability mass density\u00a0towards regions of the parameter space that are preferred a priori. In practice,\u00a0the prior often expresses a preference for models that are simpler or more smooth.\u00a0Critics of the Bayesian approach identify the prior as a source of subjective human\u00a0judgment impacting the predictions.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1627",
    "text": "Bayesian methods typically generalize much better when limited training data is available, but typically suffer from high computational cost when the number of\u00a0training examples is large.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1628",
    "text": "Example: Bayesian Linear Regression Here we consider the Bayesian estimation approach to learning the linear regression parameters. In linear regression, we learn a linear mapping from an input vector x E Rn to predict the value of a\u00a0scalar y E R. The prediction is parametrized by the vector w E Rn:",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1629",
    "text": "y _ wT x.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1630",
    "text": "-5.69",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1631",
    "text": "Given a set of m training samples (X (tram), y (tram)), We can express the prediction of y over the entire training set as:",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1632",
    "text": "-5.7",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1633",
    "text": " (train)   x (train) ^",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1634",
    "text": "Expressed as a Gaussian conditional distribution on y(train), we have",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1635",
    "text": "p(y(train) | X(train), w) _ N(y(train); X(train)w, I)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1636",
    "text": "1 2",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1637",
    "text": "-5.71",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1638",
    "text": "x exp",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1639",
    "text": "^_1 (y(train) __ X (train) W)T (y(train) __ X(train) w)^ ,",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1640",
    "text": "-5.72",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1641",
    "text": "where we follow the standard MSE formulation in assuming that the Gaussian variance on y is one. In what follows, to reduce the notational burden, we refer to\u00a0(X(train), y(train)) as simply (X, y).",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1642",
    "text": "To determine the posterior distribution over the model parameter vector w, we first need to specify a prior distribution. The prior should reflect our naive belief\u00a0about the value of these parameters. While it is sometimes difficult or unnatural\u00a0to express our prior beliefs in terms of the parameters of the model, in practice we\u00a0typically assume a fairly broad distribution expressing a high degree of uncertainty\u00a0about 0. For real-valued parameters it is common to use a Gaussian as a prior\u00a0distribution:",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1643",
    "text": "p(w) _ N(w; yo, a0) x exp ^- ^",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1644",
    "text": "w _ y 0)TA0 1(w _ yo",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1645",
    "text": ")",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1646",
    "text": "-5.73",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1647",
    "text": "where yo and A 0 are the prior distribution mean vector and covariance matrix respectively.1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1648",
    "text": "With the prior thus specified, we can now proceed in determining the posterior distribution over the model parameters.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1649",
    "text": "-5.74",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1650",
    "text": "p(w | X, y) x p(y | X, w)p(w)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1651",
    "text": "exp (-1 (y - Xw)T (y \u2014 XwU exp (- ^(w - y0)TA\u00b0 1(w - y0) j",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1652",
    "text": "OC",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1653",
    "text": "-5.75",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1654",
    "text": "(\u20142(",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1655",
    "text": "(X exp ( \u2014 ^ (\u20142yTXw + w TXT Xw + wT A- 1w \u2014 2yT A\u00b0 1w",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1656",
    "text": "-5.76",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1657",
    "text": "We now define Am \u2014 (XTX + A-1 (1\u05be and ym \u2014 Am (XTy + A-\"1yo)\u2022 Using these new variables, we find that the posterior may be rewritten as a Gaussian\u00a0distribution:",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1658",
    "text": "-5.77",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1659",
    "text": "P(w | X, y) X exP 2(w \u2014 ym)T Am1(w \u2014 ym) + 2 y mAmV",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1660",
    "text": "1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1661",
    "text": "X exp \u2014 2(w \u2014 ym)T Am1(w \u2014 y7",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1662",
    "text": "0) \u2022",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1663",
    "text": "-5.78",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1664",
    "text": "All terms that do not include the parameter vector w have been omitted; they are implied by the fact that the distribution must be normalized to integrate to 1.\u00a0Eq. 3.23 shows how to normalize a multivariate Gaussian distribution.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1665",
    "text": "Examining this posterior distribution allows us to gain some intuition for the effect of Bayesian inference. In most situations, we set yo to 0. If we set A0 \u2014 a 1\u00a0then ym gives the same estimate of w as does frequentist linear regression with a\u00a0weight decay penalty of awTw. One difference is that the Bayesian estimate is\u00a0undefined if a is set to zero\u2014-we are not allowed to begin the Bayesian learning\u00a0process with an infinitely wide prior on w. The more important difference is that\u00a0the Bayesian estimate provides a covariance matrix, showing how likely all the\u00a0different values of w are, rather than providing only the estimate ym.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1666",
    "text": "While the most principled approach is to make predictions using the full Bayesian posterior distribution over the parameter 6, it is still often desirable to have a\u00a0single point estimate. One common reason for desiring a point estimate is that\u00a0most operations involving the Bayesian posterior for most interesting models are\u00a0intractable, and a point estimate offers a tractable approximation. Rather than\u00a0simply returning to the maximum likelihood estimate, we can still gain some of\u00a0the benefit of the Bayesian approach by allowing the prior to influence the choice\u00a0of the point estimate. One rational way to do this is to choose the maximum a\u00a0posteriori (MAP) point estimate. The MAP estimate chooses the point of maximal",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1667",
    "text": "posterior probability (or maximal probability density in the more common case of continuous 0):",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1668",
    "text": "0MaP = argmaxp(0 | x) = argmaxlogp(x | 0) + logp(0). \u00a0\u00a0\u00a0(5.79)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1669",
    "text": "0 0",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1670",
    "text": "We recognize, above on the right hand side, logp(x | 0), i.e. the standard log-likelihood term, and logp(0), corresponding to the prior distribution.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1671",
    "text": "As an example, consider a linear regression model with a Gaussian prior on the weights w. If this prior is given by N(w;0, 1\u05beI2), then the log-prior term in Eq.\u00a05.79 is proportional to the familiar AwT w weight decay penalty, plus a term that\u00a0does not depend on w and does not affect the learning process. MAP Bayesian\u00a0inference with a Gaussian prior on the weights thus corresponds to weight decay.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1672",
    "text": "As with full Bayesian inference, MAP Bayesian inference has the advantage of leveraging information that is brought by the prior and cannot be found in the\u00a0training data. This additional information helps to reduce the variance in the\u00a0MAP point estimate (in comparison to the ML estimate). However, it does so at\u00a0the price of increased bias.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1673",
    "text": "Many regularized estimation strategies, such as maximum likelihood learning regularized with weight decay, can be interpreted as making the MAP approximation to Bayesian inference. This view applies when the regularization consists of\u00a0adding an extra term to the objective function that corresponds to logp(0). Not\u00a0all regularization penalties correspond to MAP Bayesian inference. For example,\u00a0some regularizer terms may not be the logarithm of a probability distribution.\u00a0Other regularization terms depend on the data, which of course a prior probability\u00a0distribution is not allowed to do.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1674",
    "text": "MAP Bayesian inference provides a straightforward way to design complicated yet interpretable regularization terms. For example, a more complicated penalty\u00a0term can be derived by using a mixture of Gaussians, rather than a single Gaussian\u00a0distribution, as the prior (Nowlan and Hinton, 1992).",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1675",
    "text": "Recall from Sec. 5.1.3 that supervised learning algorithms are, roughly speaking, learning algorithms that learn to associate some input with some output, given a\u00a0training set of examples of inputs x and outputs y. In many cases the outputs\u00a0y may be difficult to collect automatically and must be provided by a human\u00a0\u201csupervisor,\u201d but the term still applies even when the training set targets were\u00a0collected automatically.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1676",
    "text": "Most supervised learning algorithms in this book are based on estimating a probability distribution p(y | x). We can do this simply by using maximum\u00a0likelihood estimation to find the best parameter vector 0 for a parametric family\u00a0of distributions p(y | x; 0).",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1677",
    "text": "We have already seen that linear regression corresponds to the family",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1678",
    "text": "p(y | x; 0) = N(y; 0Tx,1). \u00a0\u00a0\u00a0(5\u202280)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1679",
    "text": "We can generalize linear regression to the classification scenario by defining a different family of probability distributions. If we have two classes, class 0 and\u00a0class 1, then we need only specify the probability of one of these classes. The\u00a0probability of class 1 determines the probability of class 0, because these two values\u00a0must add up to 1.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1680",
    "text": "The normal distribution over real-valued numbers that we used for linear regression is parametrized in terms of a mean. Any value we supply for this mean\u00a0is valid. A distribution over a binary variable is slightly more complicated, because\u00a0its mean must always be between 0 and 1. One way to solve this problem is to use\u00a0the logistic sigmoid function to squash the output of the linear function into the\u00a0interval (0, 1) and interpret that value as a probability:",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1681",
    "text": "p(y = 1 | x; 0) = a(0Tx). \u00a0\u00a0\u00a0(5.81)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1682",
    "text": "This approach is known as logistic regression (a somewhat strange name since we use the model for classification rather than regression).",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1683",
    "text": "In the case of linear regression, we were able to find the optimal weights by solving the normal equations. Logistic regression is somewhat more difficult. There\u00a0is no closed-form solution for its optimal weights. Instead, we must search for\u00a0them by maximizing the log-likelihood. We can do this by minimizing the negative\u00a0log-likelihood (NLL) using gradient descent.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1684",
    "text": "This same strategy can be applied to essentially any supervised learning problem, by writing down a parametric family of conditional probability distributions over\u00a0the right kind of input and output variables.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1685",
    "text": "One of the most influential approaches to supervised learning is the support vector machine (Boser et al., 1992; Cortes and Vapnik, 1995). This model is similar to\u00a0logistic regression in that it is driven by a linear function wT x + b. Unlike logistic\u00a0regression, the support vector machine does not provide probabilities, but only\u00a0outputs a class identity. The SVM predicts that the positive class is present when\u00a0wTx + b is positive. Likewise, it predicts that the negative class is present when\u00a0wT x + b is negative.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1686",
    "text": "One key innovation associated with support vector machines is the kernel trick. The kernel trick consists of observing that many machine learning algorithms can\u00a0be written exclusively in terms of dot products between examples. For example, it\u00a0can be shown that the linear function used by the support vector machine can be\u00a0re-written as",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1687",
    "text": "m",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1688",
    "text": "wTx + b = b + \u00a0\u00a0\u00a0a{XTx(i)\u00a0\u00a0\u00a0\u00a0(5.82)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1689",
    "text": "i=1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1690",
    "text": "where x(i) is a training example and a is a vector of coefficients. Rewriting the learning algorithm this way allows us to replace x by the output of a given feature\u00a0function ^(x) and the dot product with a function k(x, x(i)) = ^(x) \u25a0 ^ (x(i)) called\u00a0a kernel. The \u25a0 operator represents an inner product analogous to ^(x )T ^(x(i)).\u00a0For some feature spaces, we may not use literally the vector inner product. In\u00a0some infinite dimensional spaces, we need to use other kinds of inner products, for\u00a0example, inner products based on integration rather than summation. A complete\u00a0development of these kinds of inner products is beyond the scope of this book.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1691",
    "text": "After replacing dot products with kernel evaluations, we can make predictions using the function",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1692",
    "text": "f (x) = b + \u00a0\u00a0\u00a0a ik(x, x(i)).\u00a0\u00a0\u00a0\u00a0(5.83)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1693",
    "text": "This function is nonlinear with respect to x, but the relationship between ^ (x) and f (x) is linear. Also, the relationship between a and f(x) is linear. The\u00a0kernel-based function is exactly equivalent to preprocessing the data by applying\u00a0^(x) to all inputs, then learning a linear model in the new transformed space.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1694",
    "text": "The kernel trick is powerful for two reasons. First, it allows us to learn models that are nonlinear as a function of x using convex optimization techniques that are\u00a0guaranteed to converge efficiently. This is possible because we consider ^ fixed and\u00a0optimize only a, i.e., the optimization algorithm can view the decision function\u00a0as being linear in a different space. Second, the kernel function k often admits\u00a0an implementation that is significantly more computational efficient than naively\u00a0constructing two ^(x) vectors and explicitly taking their dot product.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1695",
    "text": "In some cases, \u00a0\u00a0\u00a0x) can even be infinite dimensional, which would result in",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1696",
    "text": "an infinite computational cost for the naive, explicit approach. In many cases, k(x, x') is a nonlinear, tractable function of x even when ^(x) is intractable. As\u00a0an example of an infinite-dimensional feature space with a tractable kernel, we\u00a0construct a feature mapping ^ (x) over the non-negative integers x. Suppose that\u00a0this mapping returns a vector containing x ones followed by infinitely many zeros.\u00a0We can write a kernel function k(x,x(i)) = mm(x,x(i)) that is exactly equivalent\u00a0to the corresponding infinite-dimensional dot product.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1697",
    "text": "The most commonly used kernel is the Gaussian kernel",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1698",
    "text": "k(u, v) = N (u \u2014 v ;0 , a2I) \u00a0\u00a0\u00a0(5.84)",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1699",
    "text": "where N(x; M, s) is the standard normal density. This kernel is also known as the radial basis function (RBF) kernel, because its value decreases along lines in\u00a0v space radiating outward from u. The Gaussian kernel corresponds to a dot\u00a0product in an infinite-dimensional space, but the derivation of this space is less\u00a0straightforward than in our example of the min kernel over the integers.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1700",
    "text": "We can think of the Gaussian kernel as performing a kind of template matching. A training example x associated with training label y becomes a template for class\u00a0y. When a test point x' is near x according to Euclidean distance, the Gaussian\u00a0kernel has a large response, indicating that x' is very similar to the x template.\u00a0The model then puts a large weight on the associated training label y. Overall,\u00a0the prediction will combine many such training labels weighted by the similarity\u00a0of the corresponding training examples.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1701",
    "text": "Support vector machines are not the only algorithm that can be enhanced using the kernel trick. Many other linear models can be enhanced in this way. The\u00a0category of algorithms that employ the kernel trick is known as kernel machines\u00a0or kernel methods (Williams and Rasmussen, 1996; Schdlkopf et al., 1999).",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1702",
    "text": "A major drawback to kernel machines is that the cost of evaluating the decision function is linear in the number of training examples, because the i-th example\u00a0contributes a term aik(x, x(i)) to the decision function. Support vector machines\u00a0are able to mitigate this by learning an a vector that contains mostly zeros.\u00a0Classifying a new example then requires evaluating the kernel function only for\u00a0the training examples that have non-zero ai. These training examples are known\u00a0as support vectors.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1703",
    "text": "Kernel machines also suffer from a high computational cost of training when the dataset is large. We will revisit this idea in Sec. 5.9. Kernel machines with\u00a0generic kernels struggle to generalize well. We will explain why in Sec. 5.11. The\u00a0modern incarnation of deep learning was designed to overcome these limitations of\u00a0kernel machines. The current deep learning renaissance began when Hinton et al.\u00a0(2006) demonstrated that a neural network could outperform the RBF kernel SVM\u00a0on the MNIST benchmark.",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1704",
    "text": "1",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1705",
    "text": "Unless there is a reason to assume a particular covariance structure, we typically assume a diagonal covariance matrix A = diag(A 0).",
    "chapter": "Feedforward Deep Networks",
    "chapter_id": "main-9.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1706",
    "text": "We have already briefly encountered another non-probabilistic supervised learning algorithm, nearest neighbor regression. More generally, k-nearest neighbors is\u00a0a family of techniques that can be used for classification or regression. As a\u00a0non-parametric learning algorithm, k-nearest neighbors is not restricted to a fixed\u00a0number of parameters. We usually think of the k-nearest neighbors algorithm\u00a0as not having any parameters, but rather implementing a simple function of the\u00a0training data. In fact, there is not even really a training stage or learning process.\u00a0Instead, at test time, when we want to produce an output y for a new test input x,\u00a0we find the k-nearest neighbors to x in the training data X. We then return the\u00a0average of the corresponding y values in the training set. This works for essentially\u00a0any kind of supervised learning where we can define an average over y values. In\u00a0the case of classification, we can average over one-hot code vectors c with cy = 1\u00a0and ci = 0 for all other values of i. We can then interpret the average over these\u00a0one-hot codes as giving a probability distribution over classes. As a non-parametric\u00a0learning algorithm, k-nearest neighbor can achieve very high capacity. For example,\u00a0suppose we have a multiclass classification task and measure performance with 0-1\u00a0loss. In this setting, 1-nearest neighbor converges to double the Bayes error as the\u00a0number of training examples approaches infinity. The error in excess of the Bayes\u00a0error results from choosing a single neighbor by breaking ties between equally\u00a0distant neighbors randomly. When there is infinite training data, all test points x\u00a0will have infinitely many training set neighbors at distance zero. If we allow the\u00a0algorithm to use all of these neighbors to vote, rather than randomly choosing one\u00a0of them, the procedure converges to the Bayes error rate. The high capacity of\u00a0k-nearest neighbors allows it to obtain high accuracy given a large training set.\u00a0However, it does so at high computational cost, and it may generalize very badly\u00a0given a small, finite training set. One weakness of k-nearest neighbors is that it\u00a0cannot learn that one feature is more discriminative than another. For example,\u00a0imagine we have a regression task with x G R100 drawn from an isotropic Gaussian\u00a0distribution, but only a single variable x! is relevant to the output. Suppose\u00a0further that this feature simply encodes the output directly, i.e. that y = x! in all\u00a0cases. Nearest neighbor regression will not be able to detect this simple pattern.\u00a0The nearest neighbor of most points x will be determined by the large number of\u00a0features x2 through x !00, not by the lone feature x!. Thus the output on small\u00a0training sets will essentially be random.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1707",
    "text": "Figure 5.7: Diagrams describing how a decision tree works. (Top) Each node of the tree chooses to send the input example to the child node on the left (0) or or the child node on\u00a0the right (1). Internal nodes are drawn as circles and leaf nodes as squares. Each node is\u00a0displayed with a binary string identifier corresponding to its position in the tree, obtained\u00a0by appending a bit to its parent identifier (0=choose left or top, 1=choose right or bottom).\u00a0(Bottom) The tree divides space into regions. The 2D plane shows how a decision tree\u00a0might divide R2. The nodes of the tree are plotted in this plane, with each internal node\u00a0drawn along the dividing line it uses to categorize examples, and leaf nodes drawn in the\u00a0center of the region of examples they receive. The result is a piecewise-constant function,\u00a0with one piece per leaf. Each leaf requires at least one training example to define, so it is\u00a0not possible for the decision tree to learn a function that has more local maxima than the\u00a0number of training examples.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1708",
    "text": "Another type of learning algorithm that also breaks the input space into regions and has separate parameters for each region is the decision tree (Breiman et al.,\u00a01984) and its many variants. As shown in Fig. 5.7, each node of the decision tree\u00a0is associated with a region in the input space, and internal nodes break that region\u00a0into one sub-region for each child of the node (typically using an axis-aligned\u00a0cut). Space is thus sub-divided into non-overlapping regions, with a one-to-one\u00a0correspondence between leaf nodes and input regions. Each leaf node usually maps\u00a0every point in its input region to the same output. Decision trees are usually\u00a0trained with specialized algorithms that are beyond the scope of this book. The\u00a0learning algorithm can be considered non-parametric if it is allowed to learn a tree\u00a0of arbitrary size, though decision trees are usually regularized with size constraints\u00a0that turn them into parametric models in practice. Decision trees as they are\u00a0typically used, with axis-aligned splits and constant outputs within each node,\u00a0struggle to solve some problems that are easy even for logistic regression. For\u00a0example, if we have a two-class problem and the positive class occurs wherever\u00a0x2 > x!, the decision boundary is not axis-aligned. The decision tree will thus\u00a0need to approximate the decision boundary with many nodes, implementing a step\u00a0function that constantly walks back and forth across the true decision function\u00a0with axis-aligned steps.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1709",
    "text": "As we have seen, nearest neighbor predictors and decision trees have many limitations. Nonetheless, they are useful learning algorithms when computational\u00a0resources are constrained. We can also build intuition for more sophisticated\u00a0learning algorithms by thinking about the similarities and differences between\u00a0sophisticated algorithms and k-NN or decision tree baselines.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1710",
    "text": "See Murphy (2012), Bishop (2006), Hastie et al. (2001) or other machine learning textbooks for more material on traditional supervised learning algorithms.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1711",
    "text": "Recall from Sec. 5.1.3 that unsupervised algorithms are those that experience only \u201cfeatures\u201d but not a supervision signal. The distinction between supervised and\u00a0unsupervised algorithms is not formally and rigidly defined because there is no\u00a0objective test for distinguishing whether a value is a feature or a target provided by\u00a0a supervisor. Informally, unsupervised learning refers to most attempts to extract\u00a0information from a distribution that do not require human labor to annotate\u00a0examples. The term is usually associated with density estimation, learning to\u00a0draw samples from a distribution, learning to denoise data from some distribution,\u00a0finding a manifold that the data lies near, or clustering the data into groups of",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1712",
    "text": "related examples.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1713",
    "text": "A classic unsupervised learning task is to find the \u201cbest\u201d representation of the data. By \u2018best\u2019 we can mean different things, but generally speaking we are looking\u00a0for a representation that preserves as much information about x as possible while\u00a0obeying some penalty or constraint aimed at keeping the representation simpler or\u00a0more accessible than x itself.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1714",
    "text": "There are multiple ways of defining a simpler representation. Three of the most common include lower dimensional representations, sparse representations\u00a0and independent representations. Low-dimensional representations attempt to\u00a0compress as much information about x as possible in a smaller representation.\u00a0Sparse representations (Barlow, 1989; Olshausen and Field, 1996; Hinton and\u00a0Ghahramani, 1997) embed the dataset into a representation whose entries are\u00a0mostly zeroes for most inputs. The use of sparse representations typically requires\u00a0increasing the dimensionality of the representation, so that the representation\u00a0becoming mostly zeroes does not discard too much information. This results in an\u00a0overall structure of the representation that tends to distribute data along the axes\u00a0of the representation space. Independent representations attempt to disentangle\u00a0the sources of variation underlying the data distribution such that the dimensions\u00a0of the representation are statistically independent.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1715",
    "text": "Of course these three criteria are certainly not mutually exclusive. Lowdimensional representations often yield elements that have fewer or weaker dependencies than the original high-dimensional data. This is because one way to reduce the size of a representation is to find and remove redundancies. Identifying\u00a0and removing more redundancy allows the dimensionality reduction algorithm to\u00a0achieve more compression while discarding less information.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1716",
    "text": "The notion of representation is one of the central themes of deep learning and therefore one of the central themes in this book. In this section, we develop some\u00a0simple examples of representation learning algorithms. Together, these example\u00a0algorithms show how to operationalize all three of the criteria above. Most of the\u00a0remaining chapters introduce additional representation learning algorithms that\u00a0develop these criteria in different ways or introduce other criteria.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1717",
    "text": "In Sec. 2.12, we saw that the principal components analysis algorithm provides a means of compressing data. We can also view PCA as an unsupervised learning\u00a0algorithm that learns a representation of data. This representation is based on\u00a0two of the criteria for a simple representation described above. PCA learns a",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1718",
    "text": "20",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1719",
    "text": "10",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1720",
    "text": "0",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1721",
    "text": "-10",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1722",
    "text": "20",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1723",
    "text": "\u20141-r",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1724",
    "text": "-1-1-1-",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1725",
    "text": "\u2022",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1726",
    "text": "20",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1727",
    "text": "\u20141-1-1-1-1-",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1728",
    "text": "",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1729",
    "text": "\u2022",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1730",
    "text": "10",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1731",
    "text": "-",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1732",
    "text": "J",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1733",
    "text": "f",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1734",
    "text": "0",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1735",
    "text": "",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1736",
    "text": "t'",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1737",
    "text": "r",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1738",
    "text": "-10",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1739",
    "text": "-",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1740",
    "text": "_1_l_",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1741",
    "text": "_1_1_1_",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1742",
    "text": "-20",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1743",
    "text": "_1_1_1_1_1_",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1744",
    "text": "10 20",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1745",
    "text": "-20 -10 0",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1746",
    "text": "z1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1747",
    "text": "10 20",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1748",
    "text": "-20 -10 0 x1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1749",
    "text": "Figure 5.8: PCA learns a linear projection that aligns the direction of greatest variance with the axes of the new space. (Left) The original data consists of samples of x. In this\u00a0space, the variance might occur along directions that are not axis-aligned. (Right) The\u00a0transformed data z = xT W now varies most along the axis z!. The direction of second\u00a0most variance is now along z2.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1750",
    "text": "representation that has lower dimensionality than the original input. It also learns a representation whose elements have no linear correlation with each other. This\u00a0is a first step toward the criterion of learning representations whose elements are\u00a0statistically independent. To achieve full independence, a representation learning\u00a0algorithm must also remove the nonlinear relationships between variables.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1751",
    "text": "PCA learns an orthogonal, linear transformation of the data that projects an input x to a representation z as shown in Fig. 5.8. In Sec. 2.12, we saw that we\u00a0could learn a one-dimensional representation that best reconstructs the original\u00a0data (in the sense of mean squared error) and that this representation actually\u00a0corresponds to the first principal component of the data. Thus we can use PCA\u00a0as a simple and effective dimensionality reduction method that preserves as much\u00a0of the information in the data as possible (again, as measured by least-squares\u00a0reconstruction error). In the following, we will study how the PCA representation\u00a0decorrelates the original data representation X.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1752",
    "text": "Let us consider the m x n-dimensional design matrix X. We will assume that the data has a mean of zero, E [x] = 0. If this is not the case, the data can easily\u00a0be centered by subtracting the mean from all examples in a preprocessing step.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1753",
    "text": "The unbiased sample covariance matrix associated with X is given by:",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1754",
    "text": "Var[x]",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1755",
    "text": "1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1756",
    "text": "X TX.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1757",
    "text": "-5.85",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1758",
    "text": "PCA finds a representation (through linear transformation) z = xTW where Var[z] is diagonal.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1759",
    "text": "In Sec. 2.12, we saw that the principal components of a design matrix X are given by the eigenvectors of XTX. From this view,",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1760",
    "text": "XTX",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1761",
    "text": "W AW",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1762",
    "text": "\u25a0T",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1763",
    "text": "-5.86",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1764",
    "text": "In this section, we exploit an alternative derivation of the principal components. The principal components may also be obtained via the singular value decomposition.\u00a0Specifically, they are the right singular vectors of X. To see this, let W be the\u00a0right singular vectors in the decomposition X = USWT. We then recover the\u00a0original eigenvector equation with W as the eigenvector basis:",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1765",
    "text": "-5.87",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1766",
    "text": "X TX = (u SW TJ USWT = W S2 WT.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1767",
    "text": "The SVD is helpful to show that PCA results in a diagonal Var[z]. Using the SVD of X, we can express the variance of X as:",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1768",
    "text": "Var[x] =",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1769",
    "text": "1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1770",
    "text": "m\u2014",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1771",
    "text": "1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1772",
    "text": "1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1773",
    "text": "",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1774",
    "text": "m\u2014",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1775",
    "text": "1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1776",
    "text": "1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1777",
    "text": "",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1778",
    "text": "m\u2014",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1779",
    "text": "1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1780",
    "text": "1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1781",
    "text": "",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1782",
    "text": "XT X",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1783",
    "text": "m \u2014 1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1784",
    "text": "(U SW T)T U SW W STUTU SW T\u00a0W S2WT,",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1785",
    "text": "\u25a0T",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1786",
    "text": "-5.88",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1787",
    "text": "-5.89",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1788",
    "text": "-5.9",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1789",
    "text": "-5.91",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1790",
    "text": "where we use the fact that UT U = I because the U matrix of the singular value definition is defined to be orthonormal. This shows that if we take z = xTW, we\u00a0can ensure that the covariance of z is diagonal as required:",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1791",
    "text": "Z TZ",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1792",
    "text": "-5.92",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1793",
    "text": "W TX T XW",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1794",
    "text": "-5.93",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1795",
    "text": "WTWS2WTW",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1796",
    "text": "-5.94",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1797",
    "text": "S 2,",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1798",
    "text": "-5.95",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1799",
    "text": "1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1800",
    "text": "m \u2014 1 1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1801",
    "text": "m \u2014 1 1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1802",
    "text": "m \u2014 1 1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1803",
    "text": "m \u2014 1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1804",
    "text": "Var[z ]",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1805",
    "text": "where this time we use the fact that WTW = I, again from the definition of the SVD.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1806",
    "text": "The above analysis shows that when we project the data x to z, via the linear transformation W, the resulting representation has a diagonal covariance matrix\u00a0(as given by \u00a32) which immediately implies that the individual elements of z are\u00a0mutually uncorrelated.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1807",
    "text": "This ability of PCA to transform data into a representation where the elements are mutually uncorrelated is a very important property of PCA. It is a simple\u00a0example of a representation that attempt to disentangle the unknown factors\u00a0of variation underlying the data. In the case of PCA, this disentangling takes\u00a0the form of finding a rotation of the input space (described by W) that aligns the\u00a0principal axes of variance with the basis of the new representation space associated\u00a0with z.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1808",
    "text": "While correlation is an important category of dependency between elements of the data, we are also interested in learning representations that disentangle more\u00a0complicated forms of feature dependencies. For this, we will need more than what\u00a0can be done with a simple linear transformation.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1809",
    "text": "Another example of a simple representation learning algorithm is k-means clustering. The k-means clustering algorithm divides the training set into k different clusters\u00a0of examples that are near each other. We can thus think of the algorithm as\u00a0providing a k-dimensional one-hot code vector h representing an input x. If x\u00a0belongs to cluster i, then hi = 1 and all other entries of the representation h are\u00a0zero.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1810",
    "text": "The one-hot code provided by k-means clustering is an example of a sparse representation, because the majority of its entries are zero for every input. Later,\u00a0we will develop other algorithms that learn more flexible sparse representations,\u00a0where more than one entry can be non-zero for each input x. One-hot codes\u00a0are an extreme example of sparse representations that lose many of the benefits\u00a0of a distributed representation. The one-hot code still confers some statistical\u00a0advantages (it naturally conveys the idea that all examples in the same cluster are\u00a0similar to each other) and it confers the computational advantage that the entire\u00a0representation may be captured by a single integer.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1811",
    "text": "The k-means algorithm works by initializing k different centroids {^(1),..., to different values, then alternating between two different steps until convergence.\u00a0In one step, each training example is assigned to cluster i, where i is the index of\u00a0the nearest centroid ^(i). In the other step, each centroid ^(i) is updated to the\u00a0mean of all training examples x(j) assigned to cluster i.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1812",
    "text": "One difficulty pertaining to clustering is that the clustering problem is inherently ill-posed, in the sense that there is no single criterion that measures how well a\u00a0clustering of the data corresponds to the real world. We can measure properties of\u00a0the clustering such as the average Euclidean distance from a cluster centroid to the\u00a0members of the cluster. This allows us to tell how well we are able to reconstruct\u00a0the training data from the cluster assignments. We do not know how well the\u00a0cluster assignments correspond to properties of the real world. Moreover, there\u00a0may be many different clusterings that all correspond well to some property of\u00a0the real world. We may hope to find a clustering that relates to one feature but\u00a0obtain a different, equally valid clustering that is not relevant to our task. For\u00a0example, suppose that we run two clustering algorithms on a dataset consisting of\u00a0images of red trucks, images of red cars, images of gray trucks, and images of gray\u00a0cars. If we ask each clustering algorithm to find two clusters, one algorithm may\u00a0find a cluster of cars and a cluster of trucks, while another may find a cluster of\u00a0red vehicles and a cluster of gray vehicles. Suppose we also run a third clustering\u00a0algorithm, which is allowed to determine the number of clusters. This may assign\u00a0the examples to four clusters, red cars, red trucks, gray cars, and gray trucks. This\u00a0new clustering now at least captures information about both attributes, but it has\u00a0lost information about similarity. Red cars are in a different cluster from gray\u00a0cars, just as they are in a different cluster from gray trucks. The output of the\u00a0clustering algorithm does not tell us that red cars are more similar to gray cars\u00a0than they are to gray trucks. They are different from both things, and that is all\u00a0we know.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1813",
    "text": "These issues illustrate some of the reasons that we may prefer a distributed representation to a one-hot representation. A distributed representation could have\u00a0two attributes for each vehicle\u2014one representing its color and one representing\u00a0whether it is a car or a truck. It is still not entirely clear what the optimal\u00a0distributed representation is (how can the learning algorithm know whether the\u00a0two attributes we are interested in are color and car-versus-truck rather than\u00a0manufacturer and age?) but having many attributes reduces the burden on the\u00a0algorithm to guess which single attribute we care about, and allows us to measure\u00a0similarity between objects in a fine-grained way by comparing many attributes\u00a0instead of just testing whether one attribute matches.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1814",
    "text": "Nearly all of deep learning is powered by one very important algorithm: stochastic gradient descent or SGD. Stochastic gradient descent is an extension of the gradient",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1815",
    "text": "descent algorithm introduced in Sec. 4.3.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1816",
    "text": "A recurring problem in machine learning is that large training sets are necessary for good generalization, but large training sets are also more computationally\u00a0expensive.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1817",
    "text": "The cost function used by a machine learning algorithm often decomposes as a sum over training examples of some per-example loss function. For example, the\u00a0negative conditional log-likelihood of the training data can be written as",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1818",
    "text": "1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1819",
    "text": "J(6) = E*,^,\u05f4L(x, y, 6) = m \u00a3l(x\u00ab , y(i), 6)",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1820",
    "text": "lit",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1821",
    "text": "-5.96",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1822",
    "text": "i=1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1823",
    "text": "where L is the per-example loss L(x, y, 6) = \u2014 logp(y | x; 6).",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1824",
    "text": "For these additive cost functions, gradient descent requires computing",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1825",
    "text": "1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1826",
    "text": "V\u00ab J(6) = \u00a0\u00a0\u00a0V8L(x\u00aby\u00ab , 6).",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1827",
    "text": "m",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1828",
    "text": "-5.97",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1829",
    "text": "i=1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1830",
    "text": "The computational cost of this operation is O(m). As the training set size grows to billions of examples, the time to take a single gradient step becomes prohibitively\u00a0long.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1831",
    "text": "The insight of stochastic gradient descent is that the gradient is an expectation. The expectation may be approximately estimated using a small set of samples.\u00a0Specifically, on each step of the algorithm, we can sample a minibatch of examples\u00a0B = {x(1),..., x(m)} drawn uniformly from the training set. The minibatch size\u00a0m1 is typically chosen to be a relatively small number of examples, ranging from\u00a01 to a few hundred. Crucially, ml is usually held fixed as the training set size m\u00a0grows. We may fit a training set with billions of examples using updates computed\u00a0on only a hundred examples.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1832",
    "text": "The estimate of the gradient is formed as",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1833",
    "text": "g",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1834",
    "text": "1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1835",
    "text": "\u2014 VeT L(x(i),y(i),6). m",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1836",
    "text": "-5.98",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1837",
    "text": "i=1",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1838",
    "text": "using examples from the minibatch B. The stochastic gradient descent algorithm then follows the estimated gradient downhill:",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1839",
    "text": "-5.99",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1840",
    "text": "6 ^ 6 \u2014 eg,",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1841",
    "text": "where e is the learning rate.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1842",
    "text": "Gradient descent in general has often been regarded as slow or unreliable. In the past, the application of gradient descent to non-convex optimization problems\u00a0was regarded as foolhardy or unprincipled. Today, we know that the machine\u00a0learning models described in Part II work very well when trained with gradient\u00a0descent. The optimization algorithm may not be guaranteed to arrive at even a\u00a0local minimum in a reasonable amount of time, but it often finds a very low value\u00a0of the cost function quickly enough to be useful.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1843",
    "text": "Stochastic gradient descent has many important uses outside the context of deep learning. It is the main way to train large linear models on very large\u00a0datasets. For a fixed model size, the cost per SGD update does not depend on the\u00a0training set size m. In practice, we often use a larger model as the training set size\u00a0increases, but we are not forced to do so. The number of updates required to reach\u00a0convergence usually increases with training set size. However, as m approaches\u00a0infinity, the model will eventually converge to its best possible test error before\u00a0SGD has sampled every example in the training set. Increasing m further will not\u00a0extend the amount of training time needed to reach the model\u2019s best possible test\u00a0error. From this point of view, one can argue that the asymptotic cost of training\u00a0a model with SGD is O( 1) as a function of m.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1844",
    "text": "Prior to the advent of deep learning, the main way to learn nonlinear models was to use the kernel trick in combination with a linear model. Many kernel learning\u00a0algorithms require constructing an m x m matrix Gi,j = k(x(i), x(j)). Constructing\u00a0this matrix has computational cost O (m2), which is clearly undesirable for datasets\u00a0with billions of examples. In academia, starting in 2006, deep learning was\u00a0initially interesting because it was able to generalize to new examples better\u00a0than competing algorithms when trained on medium-sized datasets with tens of\u00a0thousands of examples. Soon after, deep learning garnered additional interest in\u00a0industry, because it provided a scalable way of training nonlinear models on large\u00a0datasets.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1845",
    "text": "Stochastic gradient descent and many enhancements to it are described further in Chapter 8.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1846",
    "text": "Nearly all deep learning algorithms can be described as particular instances of a fairly simple recipe: combine a specification of a dataset, a cost function, an\u00a0optimization procedure and a model.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1847",
    "text": "For example, the linear regression algorithm combines a dataset consisting of",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1848",
    "text": "X and y, the cost function",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1849",
    "text": "J(w,b) \u00a0\u00a0\u00a0Ex,y~pdata, 10gpmode1 (y 1 x),\u00a0\u00a0\u00a0\u00a0(5.10\u00b0)",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1850",
    "text": "the model specificationpmode1 (y | x) = N(y; xTw + b,1), and, in most cases, the optimization algorithm defined by solving for where the gradient of the cost is zero\u00a0using the normal equations.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1851",
    "text": "By realizing that we can replace any of these components mostly independently from the others, we can obtain a very wide variety of algorithms.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1852",
    "text": "The cost function typically includes at least one term that causes the learning process to perform statistical estimation. The most common cost function is the\u00a0negative log-likelihood, so that minimizing the cost function causes maximum\u00a0likelihood estimation.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1853",
    "text": "The cost function may also include additional terms, such as regularization terms. For example, we can add weight decay to the linear regression cost function\u00a0to obtain",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1854",
    "text": "J (w,6) = A||w|12 - Ex,y~pdata 10g Pmodel (V | x) \u2022 \u00a0\u00a0\u00a0(5.101)",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1855",
    "text": "This still allows closed-form optimization.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1856",
    "text": "If we change the model to be nonlinear, then most cost functions can no longer be optimized in closed form. This requires us to choose an iterative numerical\u00a0optimization procedure, such as gradient descent.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1857",
    "text": "The recipe for constructing a learning algorithm by combining models, costs, and optimization algorithms supports both supervised and unsupervised learning. The\u00a0linear regression example shows how to support supervised learning. Unsupervised\u00a0learning can be supported by defining a dataset that contains only X and providing\u00a0an appropriate unsupervised cost and model. For example, we can obtain the first\u00a0PCA vector by specifying that our loss function is",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1858",
    "text": "J(w) = Ex^pdata \\\\X - r(X; W)||2 \u00a0\u00a0\u00a0(5.102)",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1859",
    "text": "while our model is defined to have w with norm one and reconstruction function r(x) = w xw.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1860",
    "text": "In some cases, the cost function may be a function that we cannot actually evaluate, for computational reasons. In these cases, we can still approximately\u00a0minimize it using iterative numerical optimization so long as we have some way of\u00a0approximating its gradients.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1861",
    "text": "Most machine learning algorithms make use of this recipe, though it may not immediately be obvious. If a machine learning algorithm seems especially unique or\u00a0hand-designed, it can usually be understood as using a special-case optimizer. Some\u00a0models such as decision trees or k-means require special-case optimizers because\u00a0their cost functions have flat regions that make them inappropriate for minimization\u00a0by gradient-based optimizers. Recognizing that most machine learning algorithms\u00a0can be described using this recipe helps to see the different algorithms as part of a\u00a0taxonomy of methods for doing related tasks that work for similar reasons, rather\u00a0than as a long list of algorithms that each have separate justifications.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1862",
    "text": "The simple machine learning algorithms described in this chapter work very well on a wide variety of important problems. However, they have not succeeded in solving\u00a0the central problems in AI, such as recognizing speech or recognizing objects.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1863",
    "text": "The development of deep learning was motivated in part by the failure of traditional algorithms to generalize well on such AI tasks.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1864",
    "text": "This section is about how the challenge of generalizing to new examples becomes exponentially more difficult when working with high-dimensional data, and how\u00a0the mechanisms used to achieve generalization in traditional machine learning\u00a0are insufficient to learn complicated functions in high-dimensional spaces. Such\u00a0spaces also often impose high computational costs. Deep learning was designed to\u00a0overcome these and other obstacles.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1865",
    "text": "Many machine learning problems become exceedingly difficult when the number of dimensions in the data is high. This phenomenon is known as the curse\u00a0of dimensionality. Of particular concern is that the number of possible distinct\u00a0configurations of a set of variables increases exponentially as the number of variables\u00a0increases.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1866",
    "text": "Figure 5.9: As the number of relevant dimensions of the data increases (from left to right), the number of configurations of interest may grow exponentially. (Left) In this\u00a0one-dimensional example, we have one variable for which we only care to distinguish 10\u00a0regions of interest. With enough examples falling within each of these regions (each region\u00a0corresponds to a cell in the illustration), learning algorithms can easily generalize correctly.\u00a0A straightforward way to generalize is to estimate the value of the target function within\u00a0each region (and possibly interpolate between neighboring regions). (Center) With 2\u00a0dimensions (center) it is more difficult to distinguish 10 different values of each variable.\u00a0We need to keep track of up to 10x10=100 regions, and we need at least that many\u00a0examples to cover all those regions. (Right) With 3 dimensions this grows to 10 = 1000\u00a0regions and at least that many examples. For d dimensions and v values to be distinguished\u00a0along each axis, we seem to need O (vd) regions and examples. This is an instance of the\u00a0curse of dimensionality. Figure graciously provided by Nicolas Chapados.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1867",
    "text": "The curse of dimensionality arises in many places in computer science, and especially so in machine learning.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1868",
    "text": "One challenge posed by the curse of dimensionality is a statistical challenge. As illustrated in Fig. 5.9, a statistical challenge arises because the number of\u00a0possible configurations of x is much larger than the number of training examples.\u00a0To understand the issue, let us consider that the input space is organized into a\u00a0grid, like in the figure. In low dimensions we can describe this space with a low\u00a0number of grid cells that are mostly occupied by the data. When generalizing to a\u00a0new data point, we can usually tell what to do simply by inspecting the training\u00a0examples that lie in the same cell as the new input. For example, if estimating\u00a0the probability density at some point x, we can just return the number of training\u00a0examples in the same unit volume cell as x, divided by the total number of training\u00a0examples. If we wish to classify an example, we can return the most common class\u00a0of training examples in the same cell. If we are doing regression we can average\u00a0the target values observed over the examples in that cell. But what about the\u00a0cells for which we have seen no example? Because in high-dimensional spaces the\u00a0number of configurations is going to be huge, much larger than our number of\u00a0examples, most configurations will have no training example associated with it.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1869",
    "text": "How could we possibly say something meaningful about these new configurations? Many traditional machine learning algorithms simply assume that the output at a\u00a0new point should be approximately the same as the output at the nearest training\u00a0point.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1870",
    "text": "In order to generalize well, machine learning algorithms need to be guided by prior beliefs about what kind of function they should learn. Previously, we have seen\u00a0these priors incorporated as explicit beliefs in the form of probability distributions\u00a0over parameters of the model. More informally, we may also discuss prior beliefs as\u00a0directly influencing the function itself and only indirectly acting on the parameters\u00a0via their effect on the function. Additionally, we informally discuss prior beliefs as\u00a0being expressed implicitly, by choosing algorithms that are biased toward choosing\u00a0some class of functions over another, even though these biases may not be expressed\u00a0(or even possible to express) in terms of a probability distribution representing our\u00a0degree of belief in various functions.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1871",
    "text": "Among the most widely used of these implicit \u201cpriors\u201d is the smoothness prior or local constancy prior. This prior states that the function we learn should not\u00a0change very much within a small region.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1872",
    "text": "Many simpler algorithms rely exclusively on this prior to generalize well, and as a result they fail to scale to the statistical challenges involved in solving AI-level tasks. Throughout this book, we will describe how deep learning introduces\u00a0additional (explicit and implicit) priors in order to reduce the generalization\u00a0error on sophisticated tasks. Here, we explain why the smoothness prior alone is\u00a0insufficient for these tasks.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1873",
    "text": "There are many different ways to implicitly or explicitly express a prior belief that the learned function should be smooth or locally constant. All of these different\u00a0methods are designed to encourage the learning process to learn a function f * that\u00a0satisfies the condition",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1874",
    "text": "f* (x) - f *(x + e) \u00a0\u00a0\u00a0(5.103)",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1875",
    "text": "for most configurations x and small change e In other words, if we know a good answer for an input x (for example, if x is a labeled training example) then that\u00a0answer is probably good in the neighborhood of x. If we have several good answers\u00a0in some neighborhood we would combine them (by some form of averaging or\u00a0interpolation) to produce an answer that agrees with as many of them as much as\u00a0possible.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1876",
    "text": "An extreme example of the local constancy approach is the k-nearest neighbors family of learning algorithms. These predictors are literally constant over each\u00a0region containing all the points x that have the same set of k nearest neighbors in\u00a0the training set. For k = 1, the number of distinguishable regions cannot be more\u00a0than the number of training examples.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1877",
    "text": "While the k-nearest neighbors algorithm copies the output from nearby training examples, most kernel machines interpolate between training set outputs associated\u00a0with nearby training examples. An important class of kernels is the family of local\u00a0kernels where k(u, v) is large when u = v and decreases as u and v grow farther\u00a0apart from each other. A local kernel can be thought of as a similarity function\u00a0that performs template matching, by measuring how closely a test example x\u00a0resembles each training example x(i). Much of the modern motivation for deep\u00a0learning is derived from studying the limitations of local template matching and\u00a0how deep models are able to succeed in cases where local template matching fails\u00a0(Bengio et al., 2006b).",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1878",
    "text": "Decision trees also suffer from the limitations of exclusively smoothness-based learning because they break the input space into as many regions as there are\u00a0leaves and use a separate parameter (or sometimes many parameters for extensions\u00a0of decision trees) in each region. If the target function requires a tree with at\u00a0least n leaves to be represented accurately, then at least n training examples are\u00a0required to fit the tree. A multiple of n is needed to achieve some level of statistical\u00a0confidence in the predicted output.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1879",
    "text": "In general, to distinguish O (k) regions in input space, all of these methods require O(k) examples. Typically there are O (k) parameters, with O (1) parameters\u00a0associated with each of the O(k) regions. The case of a nearest neighbor scenario,\u00a0where each training example can be used to define at most one region, is illustrated\u00a0in Fig. 5.10.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1880",
    "text": "Is there a way to represent a complex function that has many more regions to be distinguished than the number of training examples? Clearly, assuming\u00a0only smoothness of the underlying function will not allow a learner to do that.\u00a0For example, imagine that the target function is a kind of checkerboard. A\u00a0checkerboard contains many variations but there is a simple structure to them.\u00a0Imagine what happens when the number of training examples is substantially\u00a0smaller than the number of black and white squares on the checkerboard. Based\u00a0on only local generalization and the smoothness or local constancy prior, we would\u00a0be guaranteed to correctly guess the color of a new point if it lies within the same\u00a0checkerboard square as a training example. There is no guarantee that the learner\u00a0could correctly extend the checkerboard pattern to points lying in squares that do\u00a0not contain training examples. With this prior alone, the only information that an",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1881",
    "text": "o",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1882",
    "text": "Figure 5.10: Illustration of how the nearest neighbor algorithm breaks up the input space into regions. An example (represented here by a circle) within each region defines the\u00a0region boundary (represented here by the lines). They value associated with each example\u00a0defines what the output should be for all points within the corresponding region. The\u00a0regions defined by nearest neighbor matching form a geometric pattern called a Voronoi\u00a0diagram. The number of these contiguous regions cannot grow faster than the number\u00a0of training examples. While this figure illustrates the behavior of the nearest neighbor\u00a0algorithm specifically, other machine learning algorithms that rely exclusively on the\u00a0local smoothness prior for generalization exhibit similar behaviors: each training example\u00a0only informs the learner about how to generalize in some neighborhood immediately\u00a0surrounding that example.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1883",
    "text": "example tells us is the color of its square, and the only way to get the colors of the entire checkerboard right is to cover each of its cells with at least one example.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1884",
    "text": "The smoothness assumption and the associated non-parametric learning algorithms work extremely well so long as there are enough examples for the learning algorithm to observe high points on most peaks and low points on most valleys\u00a0of the true underlying function to be learned. This is generally true when the\u00a0function to be learned is smooth enough and varies in few enough dimensions.\u00a0In high dimensions, even a very smooth function can change smoothly but in a\u00a0different way along each dimension. If the function additionally behaves differently\u00a0in different regions, it can become extremely complicated to describe with a set of\u00a0training examples. If the function is complicated (we want to distinguish a huge\u00a0number of regions compared to the number of examples), is there any hope to\u00a0generalize well?",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1885",
    "text": "The answer to both of these questions is yes. The key insight is that a very large number of regions, e.g., O(2k), can be defined with O(k) examples, so long\u00a0as we introduce some dependencies between the regions via additional assumptions\u00a0about the underlying data generating distribution. In this way, we can actually\u00a0generalize non-locally (Bengio and Monperrus, 2005; Bengio et al., 2006c). Many\u00a0different deep learning algorithms provide implicit or explicit assumptions that are\u00a0reasonable for a broad range of AI tasks in order to capture these advantages.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1886",
    "text": "Other approaches to machine learning often make stronger, task-specific assumptions. For example, we could easily solve the checkerboard task by providing the assumption that the target function is periodic. Usually we do not include such\u00a0strong, task-specific assumptions into neural networks so that they can generalize\u00a0to a much wider variety of structures. AI tasks have structure that is much too\u00a0complex to be limited to simple, manually specified properties such as periodicity,\u00a0so we want learning algorithms that embody more general-purpose assumptions.\u00a0The core idea in deep learning is that we assume that the data was generated\u00a0by the composition of factors or features, potentially at multiple levels in a\u00a0hierarchy. Many other similarly generic assumptions can further improve deep\u00a0learning algorithms. These apparently mild assumptions allow an exponential gain\u00a0in the relationship between the number of examples and the number of regions\u00a0that can be distinguished. These exponential gains are described more precisely in\u00a0Sec. 6.4.1, Sec. 15.4, and Sec. 15.5. The exponential advantages conferred by the\u00a0use of deep, distributed representations counter the exponential challenges posed\u00a0by the curse of dimensionality.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1887",
    "text": "An important concept underlying many ideas in machine learning is that of a manifold.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1888",
    "text": "A manifold is a connected region. Mathematically, it is a set of points, associated with a neighborhood around each point. From any given point, the manifold locally\u00a0appears to be a Euclidean space. In everyday life, we experience the surface of the\u00a0world as a 2-D plane, but it is in fact a spherical manifold in 3-D space.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1889",
    "text": "The definition of a neighborhood surrounding each point implies the existence of transformations that can be applied to move on the manifold from one position\u00a0to a neighboring one. In the example of the world\u2019s surface as a manifold, one can\u00a0walk north, south, east, or west.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1890",
    "text": "Although there is a formal mathematical meaning to the term \u201cmanifold,\u201d in machine learning it tends to be used more loosely to designate a connected\u00a0set of points that can be approximated well by considering only a small number\u00a0of degrees of freedom, or dimensions, embedded in a higher-dimensional space.\u00a0Each dimension corresponds to a local direction of variation. See Fig. 5.11 for an\u00a0example of training data lying near a one-dimensional manifold embedded in twodimensional space. In the context of machine learning, we allow the dimensionality\u00a0of the manifold to vary from one point to another. This often happens when a\u00a0manifold intersects itself. For example, a figure eight is a manifold that has a single\u00a0dimension in most places but two dimensions at the intersection at the center.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1891",
    "text": "Figure 5.11: Data sampled from a distribution in a two-dimensional space that is actually concentrated near a one-dimensional manifold, like a twisted string. The solid line indicates\u00a0the underlying manifold that the learner should infer.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1892",
    "text": "Many machine learning problems seem hopeless if we expect the machine learning algorithm to learn functions with interesting variations across all of\u00a0Rn. Manifold learning algorithms surmount this obstacle by assuming that most\u00a0of Rn consists of invalid inputs, and that interesting inputs occur only along\u00a0a collection of manifolds containing a small subset of points, with interesting\u00a0variations in the output of the learned function occurring only along directions\u00a0that lie on the manifold, or with interesting variations happening only when we\u00a0move from one manifold to another. Manifold learning was introduced in the case\u00a0of continuous-valued data and the unsupervised learning setting, although this\u00a0probability concentration idea can be generalized to both discrete data and the\u00a0supervised learning setting: the key assumption remains that probability mass is\u00a0highly concentrated.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1893",
    "text": "The assumption that the data lies along a low-dimensional manifold may not always be correct or useful. We argue that in the context of AI tasks, such as\u00a0those that involve processing images, sounds, or text, the manifold assumption is\u00a0at least approximately correct. The evidence in favor of this assumption consists\u00a0of two categories of observations.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1894",
    "text": "The first observation in favor of the manifold hypothesis is that the probability distribution over images, text strings, and sounds that occur in real life is highly\u00a0concentrated. Uniform noise essentially never resembles structured inputs from\u00a0these domains. Fig. 5.12 shows how, instead, uniformly sampled points look like the\u00a0patterns of static that appear on analog television sets when no signal is available.\u00a0Similarly, if you generate a document by picking letters uniformly at random, what\u00a0is the probability that you will get a meaningful English-language text? Almost\u00a0zero, again, because most of the long sequences of letters do not correspond to a\u00a0natural language sequence: the distribution of natural language sequences occupies\u00a0a very small volume in the total space of sequences of letters.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1895",
    "text": "Figure 5.12: Sampling images uniformly at random (by randomly picking each pixel according to a uniform distribution) gives rise to noisy images. Although there is a nonzero probability to generate an image of a face or any other object frequently encountered\u00a0in AI applications, we never actually observe this happening in practice. This suggests\u00a0that the images encountered in AI applications occupy a negligible proportion of the\u00a0volume of image space.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1896",
    "text": "Of course, concentrated probability distributions are not sufficient to show that the data lies on a reasonably small number of manifolds. We must also\u00a0establish that the examples we encounter are connected to each other by other\u00a0examples, with each example surrounded by other highly similar examples that\u00a0may be reached by applying transformations to traverse the manifold. The second\u00a0argument in favor of the manifold hypothesis is that we can also imagine such\u00a0neighborhoods and transformations, at least informally. In the case of images, we\u00a0can certainly think of many possible transformations that allow us to trace out a\u00a0manifold in image space: we can gradually dim or brighten the lights, gradually\u00a0move or rotate objects in the image, gradually alter the colors on the surfaces of\u00a0objects, etc. It remains likely that there are multiple manifolds involved in most\u00a0applications. For example, the manifold of images of human faces may not be\u00a0connected to the manifold of images of cat faces.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1897",
    "text": "These thought experiments supporting the manifold hypotheses convey some intuitive reasons supporting it. More rigorous experiments (Cayton, 2005; Narayanan and Mitter, 2010; Scholkopf et al., 1998; Roweis and Saul, 2000; Tenenbaum et al.,\u00a02000; Brand, 2003; Belkin and Niyogi, 2003; Donoho and Grimes, 2003; Weinberger\u00a0and Saul, 2004) clearly support the hypothesis for a large class of datasets of\u00a0interest in AI.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1898",
    "text": "When the data lies on a low-dimensional manifold, it can be most natural for machine learning algorithms to represent the data in terms of coordinates on\u00a0the manifold, rather than in terms of coordinates in Rn. In everyday life, we can\u00a0think of roads as 1-D manifolds embedded in 3-D space. We give directions to\u00a0specific addresses in terms of address numbers along these 1-D roads, not in terms\u00a0of coordinates in 3-D space. Extracting these manifold coordinates is challenging,\u00a0but holds the promise to improve many machine learning algorithms. This general\u00a0principle is applied in many contexts. Fig. 5.13 shows the manifold structure of a\u00a0dataset consisting of faces. By the end of this book, we will have developed the\u00a0methods necessary to learn such a manifold structure. In Fig. 20.6, we will see\u00a0how a machine learning algorithm can successfully accomplish this goal.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1899",
    "text": "This concludes Part I, which has provided the basic concepts in mathematics and machine learning which are employed throughout the remaining parts of the\u00a0book. You are now prepared to embark upon your study of deep learning.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1900",
    "text": "ex rrr r \u00a0\u00a0\u00a0\u05e8",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1901",
    "text": "E\u2019rrr r r",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1902",
    "text": "cfc\u2019fE\u05be t' t r fctE3ssaaa;2.:2.3:*1 cttxtrttttBsaaaaajjaa",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1903",
    "text": "cfKKKaftHMMMaaaaaaMa",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1904",
    "text": "KKKKKh \u00a0\u00a0\u00a0:\u25a0\u25a0\u25a0BIKiliiiii",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1905",
    "text": "Figure 5.13: Training examples from the QMUL Multiview Face Dataset (Gong et al2000) for which the subjects were asked to move in such a way as to cover the two-dimensional\u00a0manifold corresponding to two angles of rotation. We would like learning algorithms to\u00a0be able to discover and disentangle such manifold coordinates. Fig. 20.6 illustrates such a\u00a0feat.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1906",
    "text": "Part II",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1907",
    "text": "Deep Networks: Modern Practices",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1908",
    "text": "This part of the book summarizes the state of modern deep learning as it is used to solve practical applications.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1909",
    "text": "Deep learning has a long history and many aspirations. Several approaches have been proposed that have yet to entirely bear fruit. Several ambitious goals\u00a0have yet to be realized. These less-developed branches of deep learning appear in\u00a0the final part of the book.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1910",
    "text": "This part focuses only on those approaches that are essentially working technologies that are already used heavily in industry.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1911",
    "text": "Modern deep learning provides a very powerful framework for supervised learning. By adding more layers and more units within a layer, a deep network can\u00a0represent functions of increasing complexity. Most tasks that consist of mapping an\u00a0input vector to an output vector, and that are easy for a person to do rapidly, can\u00a0be accomplished via deep learning, given sufficiently large models and sufficiently\u00a0large datasets of labeled training examples. Other tasks, that can not be described\u00a0as associating one vector to another, or that are difficult enough that a person\u00a0would require time to think and reflect in order to accomplish the task, remain\u00a0beyond the scope of deep learning for now.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1912",
    "text": "This part of the book describes the core parametric function approximation technology that is behind nearly all modern practical applications of deep learning.\u00a0We begin by describing the feedforward deep network model that is used to\u00a0represent these functions. Next, we present advanced techniques for regularization\u00a0and optimization of such models. Scaling these models to large inputs such as high\u00a0resolution images or long temporal sequences requires specialization. We introduce\u00a0the convolutional network for scaling to large images and the recurrent neural\u00a0network for processing temporal sequences. Finally, we present general guidelines\u00a0for the practical methodology involved in designing, building, and configuring an\u00a0application involving deep learning, and review some of the applications of deep\u00a0learning.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1913",
    "text": "These chapters are the most important for a practitioner\u2014someone who wants to begin implementing and using deep learning algorithms to solve real-world\u00a0problems today.",
    "chapter": "Regularization for Deep Learning",
    "chapter_id": "main-10.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1914",
    "text": "Deep feedforward networks, also often called feedforward neural networks, or multilayer perceptrons (MLPs), are the quintessential deep learning models. The goal of a feedforward network is to approximate some function /*. For example, for\u00a0a classifier, y = /*(x) maps an input x to a category y. A feedforward network\u00a0defines a mapping y = / (x; 6) and learns the value of the parameters 6 that result\u00a0in the best function approximation.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1915",
    "text": "These models are called feedforward because information flows through the function being evaluated from x, through the intermediate computations used to\u00a0define /, and finally to the output y. There are no feedback connections in which\u00a0outputs of the model are fed back into itself. When feedforward neural networks\u00a0are extended to include feedback connections, they are called recurrent neural\u00a0networks, presented in Chapter 10.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1916",
    "text": "Feedforward networks are of extreme importance to machine learning practitioners. They form the basis of many important commercial applications. For example, the convolutional networks used for object recognition from photos are a\u00a0specialized kind of feedforward network. Feedforward networks are a conceptual\u00a0stepping stone on the path to recurrent networks, which power many natural\u00a0language applications.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1917",
    "text": "Feedforward neural networks are called networks because they are typically represented by composing together many different functions. The model is associated with a directed acyclic graph describing how the functions are composed together.\u00a0For example, we might have three functions /(1), /(2), and /(3) connected in a\u00a0chain, to form /(x) = /(3) (/(2) (/(1)(x))). These chain structures are the most\u00a0commonly used structures of neural networks. In this case, /(1) is called the first\u00a0layer of the network, /(2) is called the second layer, and so on. The overall length",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1918",
    "text": "of the chain gives the depth of the model. It is from this terminology that the name \u201cdeep learning\u201d arises. The final layer of a feedforward network is called the\u00a0output layer. During neural network training, we drive f(x) to match f *(x). The\u00a0training data provides us with noisy, approximate examples of f *(x) evaluated at\u00a0different training points. Each example x is accompanied by a label y\u00a0\u00a0\u00a0\u00a0f*(x).",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1919",
    "text": "The training examples specify directly what the output layer must do at each point x; it must produce a value that is close to y. The behavior of the other layers is\u00a0not directly specified by the training data. The learning algorithm must decide\u00a0how to use those layers to produce the desired output, but the training data does\u00a0not say what each individual layer should do. Instead, the learning algorithm must\u00a0decide how to use these layers to best implement an approximation of f *. Because\u00a0the training data does not show the desired output for each of these layers, these\u00a0layers are called hidden layers.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1920",
    "text": "Finally, these networks are called neural because they are loosely inspired by neuroscience. Each hidden layer of the network is typically vector-valued. The\u00a0dimensionality of these hidden layers determines the width of the model. Each\u00a0element of the vector may be interpreted as playing a role analogous to a neuron.\u00a0Rather than thinking of the layer as representing a single vector-to-vector function,\u00a0we can also think of the layer as consisting of many units that act in parallel,\u00a0each representing a vector-to-scalar function. Each unit resembles a neuron in\u00a0the sense that it receives input from many other units and computes its own\u00a0activation value. The idea of using many layers of vector-valued representation\u00a0is drawn from neuroscience. The choice of the functions f(x) used to compute\u00a0these representations is also loosely guided by neuroscientific observations about\u00a0the functions that biological neurons compute. However, modern neural network\u00a0research is guided by many mathematical and engineering disciplines, and the\u00a0goal of neural networks is not to perfectly model the brain. It is best to think of\u00a0feedforward networks as function approximation machines that are designed to\u00a0achieve statistical generalization, occasionally drawing some insights from what we\u00a0know about the brain, rather than as models of brain function.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1921",
    "text": "One way to understand feedforward networks is to begin with linear models and consider how to overcome their limitations. Linear models, such as logistic\u00a0regression and linear regression, are appealing because they may be fit efficiently\u00a0and reliably, either in closed form or with convex optimization. Linear models also\u00a0have the obvious defect that the model capacity is limited to linear functions, so\u00a0the model cannot understand the interaction between any two input variables.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1922",
    "text": "To extend linear models to represent nonlinear functions of x, we can apply the linear model not to x itself but to a transformed input ^(x), where ^ is a\u00a0nonlinear transformation. Equivalently, we can apply the kernel trick described in\u00a0Sec. 5.7.2, to obtain a nonlinear learning algorithm based on implicitly applying\u00a0the ^ mapping. We can think of ^ as providing a set of features describing x, or\u00a0as providing a new representation for x.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1923",
    "text": "The question is then how to choose the mapping ^.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1924",
    "text": "1. \u00a0\u00a0\u00a0One option is to use a very generic ^>, such as the infinite-dimensional ^ that\u00a0is implicitly used by kernel machines based on the RBF kernel. If ^(x) is\u00a0of high enough dimension, we can always have enough capacity to fit the\u00a0training set, but generalization to the test set often remains poor. Very\u00a0generic feature mappings are usually based only on the principle of local\u00a0smoothness and do not encode enough prior information to solve advanced\u00a0problems.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1925",
    "text": "2. \u00a0\u00a0\u00a0Another option is to manually engineer ^. Until the advent of deep learning,\u00a0this was the dominant approach. This approach requires decades of human\u00a0effort for each separate task, with practitioners specializing in different\u00a0domains such as speech recognition or computer vision, and with little\u00a0transfer between domains.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1926",
    "text": "3. \u00a0\u00a0\u00a0The strategy of deep learning is to learn <p. In this approach, we have a model\u00a0y = f (x; 6, w) = 0(x; 0)Tw. We now have parameters 6 that we use to learn\u00a0^ from a broad class of functions, and parameters w that map from ^>( x) to\u00a0the desired output. This is an example of a deep feedforward network, with\u00a0^ defining a hidden layer. This approach is the only one of the three that\u00a0gives up on the convexity of the training problem, but the benefits outweigh\u00a0the harms. In this approach, we parametrize the representation as ^(x; 6)\u00a0and use the optimization algorithm to find the 6 that corresponds to a good\u00a0representation. If we wish, this approach can capture the benefit of the first\u00a0approach by being highly generic\u2014we do so by using a very broad family\u00a0<p(x; 6). This approach can also capture the benefit of the second approach.\u00a0Human practitioners can encode their knowledge to help generalization by\u00a0designing families ^(x; 6) that they expect will perform well. The advantage\u00a0is that the human designer only needs to find the right general function\u00a0family rather than finding precisely the right function.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1927",
    "text": "This general principle of improving models by learning features extends beyond the feedforward networks described in this chapter. It is a recurring theme of deep\u00a0learning that applies to all of the kinds of models described throughout this book.\u00a0Feedforward networks are the application of this principle to learning deterministic\u00a0mappings from x to y that lack feedback connections. Other models presented\u00a0later will apply these principles to learning stochastic mappings, learning functions\u00a0with feedback, and learning probability distributions over a single vector.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1928",
    "text": "We begin this chapter with a simple example of a feedforward network. Next, we address each of the design decisions needed to deploy a feedforward network.\u00a0First, training a feedforward network requires making many of the same design\u00a0decisions as are necessary for a linear model: choosing the optimizer, the cost\u00a0function, and the form of the output units. We review these basics of gradient-based\u00a0learning, then proceed to confront some of the design decisions that are unique\u00a0to feedforward networks. Feedforward networks have introduced the concept of a\u00a0hidden layer, and this requires us to choose the activation functions that will be\u00a0used to compute the hidden layer values. We must also design the architecture of\u00a0the network, including how many layers the network should contain, how these\u00a0networks should be connected to each other, and how many units should be in\u00a0each layer. Learning in deep neural networks requires computing the gradients of\u00a0complicated functions. We present the back-propagation algorithm and its modern\u00a0generalizations, which can be used to efficiently compute these gradients. Finally,\u00a0we close with some historical perspective.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1929",
    "text": "To make the idea of a feedforward network more concrete, we begin with an example of a fully functioning feedforward network on a very simple task: learning\u00a0the XOR function.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1930",
    "text": "The XOR function (\u201cexclusive or\u201d) is an operation on two binary values, x1 and x2. When exactly one of these binary values is equal to 1, the XOR function\u00a0returns 1. Otherwise, it returns 0. The XOR function provides the target function\u00a0y = f*(x) that we want to learn. Our model provides a function y = f (x;0) and\u00a0our learning algorithm will adapt the parameters 0 to make f as similar as possible\u00a0to f *.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1931",
    "text": "In this simple example, we will not be concerned with statistical generalization. We want our network to perform correctly on the four points X = {[0,0]T, [0,1]T,\u00a0[1, 0]T, and [1,1]T}. We will train the network on all four of these points. The\u00a0only challenge is to fit the training set.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1932",
    "text": "We can treat this problem as a regression problem and use a mean squared error loss function. We choose this loss function to simplify the math for this example\u00a0as much as possible. We will see later that there are other, more appropriate\u00a0approaches for modeling binary data.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1933",
    "text": "Evaluated on our whole training set, the MSE loss function is",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1934",
    "text": "1",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1935",
    "text": "J(6) = 4 \u00a0\u00a0\u00a0(f* (x) - f (x; 6))2 .\u00a0\u00a0\u00a0\u00a0(6.1)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1936",
    "text": "xSX",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1937",
    "text": "Now we must choose the form of our model, f (x; 6). Suppose that we choose a linear model, with 6 consisting of w and b. Our model is defined to be",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1938",
    "text": "f (x; w, b) = xw + b. \u00a0\u00a0\u00a0(6-2)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1939",
    "text": "We can minimize J(6) in closed form with respect to w and b using the normal equations.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1940",
    "text": "After solving the normal equations, we obtain w = 0 and b = 1 The linear model simply outputs 0.5 everywhere. Why does this happen? Fig. 6.1 shows how\u00a0a linear model is not able to represent the XOR function. One way to solve this\u00a0problem is to use a model that learns a different feature space in which a linear\u00a0model is able to represent the solution.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1941",
    "text": "Specifically, we will introduce a very simple feedforward network with one hidden layer containing two hidden units. See Fig. 6.2 for an illustration of\u00a0this model. This feedforward network has a vector of hidden units h that are\u00a0computed by a function f (1)(x; W, c). The values of these hidden units are then\u00a0used as the input for a second layer. The second layer is the output layer of the\u00a0network. The output layer is still just a linear regression model, but now it is\u00a0applied to h rather than to x. The network now contains two functions chained\u00a0together: h = f(1)(x; W, c) and y = f (2)(h; w, b), with the complete model being\u00a0f (x; W, c, w,b) = f (2)(f (1)(x)).",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1942",
    "text": "What function should f(1) compute? Linear models have served us well so far, and it may be tempting to make f(1) be linear as well. Unfortunately, if f(1) were\u00a0linear, then the feedforward network as a whole would remain a linear function of\u00a0its input. Ignoring the intercept terms for the moment, suppose f (1)(x ) = WT x\u00a0and f (2)(h) = hT w. Then f (x) = wT WT x. We could represent this function as\u00a0f (x) = xT w where uf = Ww.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1943",
    "text": "Clearly, we must use a nonlinear function to describe the features. Most neural networks do so using an affine transformation controlled by learned parameters,\u00a0followed by a fixed, nonlinear function called an activation function. We use that\u00a0strategy here, by defining h = g( WTx + c), where W provides the weights of a\u00a0linear transformation and c the biases. Previously, to describe a linear regression\u00a0model, we used a vector of weights and a scalar bias parameter to describe an",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1944",
    "text": "Figure 6.1: Solving the XOR problem by learning a representation. The bold numbers printed on the plot indicate the value that the learned function must output at each point.\u00a0(Left) A linear model applied directly to the original input cannot implement the XOR\u00a0function. When x1 = 0, the model\u2019s output must increase as x 2 increases. When x1 = 1,\u00a0the model\u2019s output must decrease as x2 increases. A linear model must apply a fixed\u00a0coefficient w2 to x2. The linear model therefore cannot use the value of x1 to change\u00a0the coefficient on x2 and cannot solve this problem. (Right) In the transformed space\u00a0represented by the features extracted by a neural network, a linear model can now solve\u00a0the problem. In our example solution, the two points that must have output 1 have been\u00a0collapsed into a single point in feature space. In other words, the nonlinear features have\u00a0mapped both x = [1, 0]T and x = [0,1]T to a single point in feature space, h = [1,0]T.\u00a0The linear model can now describe the function as increasing in h 1 and decreasing in h2.\u00a0In this example, the motivation for learning the feature space is only to make the model\u00a0capacity greater so that it can fit the training set. In more realistic applications, learned\u00a0representations can also help the model to generalize.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1945",
    "text": "Figure 6.2: An example of a feedforward network, drawn in two different styles. Specifically, this is the feedforward network we use to solve the XOR example. It has a single hidden\u00a0layer containing two units. (Left) In this style, we draw every unit as a node in the\u00a0graph. This style is very explicit and unambiguous but for networks larger than this\u00a0example it can consume too much space. (Right) In this style, we draw a node in the\u00a0graph for each entire vector representing a layer\u2019s activations. This style is much more\u00a0compact. Sometimes we annotate the edges in this graph with the name of the parameters\u00a0that describe the relationship between two layers. Here, we indicate that a matrix W\u00a0describes the mapping from x to h, and a vector w describes the mapping from h to y.\u00a0We typically omit the intercept parameters associated with each layer when labeling this\u00a0kind of drawing.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1946",
    "text": "affine transformation from an input vector to an output scalar. Now, we describe an affine transformation from a vector x to a vector h, so an entire vector of bias\u00a0parameters is needed. The activation function g is typically chosen to be a function\u00a0that is applied element-wise, with h = g(xT W:i + c). In modern neural networks,\u00a0the default recommendation is to use the rectified linear unit or ReLU (Jarrett\u00a0et al., 2009; Nair and Hinton, 2010; Glorot et al., 2011a) defined by the activation\u00a0function g(z) = max{0, z} depicted in Fig. 6.3.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1947",
    "text": "We can now specify our complete network as",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1948",
    "text": "f (x; W, c, w, b) = wT max{0, WTx + c} + b. \u00a0\u00a0\u00a0(6.3)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1949",
    "text": "We can now specify a solution to the XOR problem. Let",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1950",
    "text": "W =",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1951",
    "text": "c =",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1952",
    "text": "w =",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1953",
    "text": "1 1 1 1 ,",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1954",
    "text": "-6.4",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1955",
    "text": "0",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1956",
    "text": "-1 , 1",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1957",
    "text": "-2 ,",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1958",
    "text": "-6.5",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1959",
    "text": "-6.6",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1960",
    "text": "Figure 6.3: The rectified linear activation function. This activation function is the default activation function recommended for use with most feedforward neural networks. Applying\u00a0this function to the output of a linear transformation yields a nonlinear transformation.\u00a0However, the function remains very close to linear, in the sense that is a piecewise linear\u00a0function with two linear pieces. Because rectified linear units are nearly linear, they\u00a0preserve many of the properties that make linear models easy to optimize with gradient-based methods. They also preserve many of the properties that make linear models\u00a0generalize well. A common principle throughout computer science is that we can build\u00a0complicated systems from minimal components. Much as a Turing machine\u2019s memory\u00a0needs only to be able to store 0 or 1 states, we can build a universal function approximator\u00a0from rectified linear functions.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1961",
    "text": "and b = 0.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1962",
    "text": "We can now walk through the way that the model processes a batch of inputs. Let X be the design matrix containing all four points in the binary input space,\u00a0with one example per row:",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1963",
    "text": "-6.7",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1964",
    "text": "X =",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1965",
    "text": "00 0 1\u00a01 0\u00a01 1",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1966",
    "text": "The first step in the neural network is to multiply the input matrix by the first layer\u2019s weight matrix:",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1967",
    "text": "XW",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1968",
    "text": "-1",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1969",
    "text": "O",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1970",
    "text": "0",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1971",
    "text": "1",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1972",
    "text": "1",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1973",
    "text": "1",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1974",
    "text": "1",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1975",
    "text": "to",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1976",
    "text": "to",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1977",
    "text": "-6.8",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1978",
    "text": "Next, we add the bias vector c, to obtain",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1979",
    "text": "-6.9",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1980",
    "text": "In this space, all of the examples lie along a line with slope 1. As we move along this line, the output needs to begin at 0, then rise to 1, then drop back down to 0.\u00a0A linear model cannot implement such a function. To finish computing the value\u00a0of h for each example, we apply the rectified linear transformation:",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1981",
    "text": " 0 0 1 0\u00a01 0\u00a021",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1982",
    "text": "-6.1",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1983",
    "text": "This transformation has changed the relationship between the examples. They no longer lie on a single line. As shown in Fig. 6.1, they now lie in a space where a\u00a0linear model can solve the problem.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1984",
    "text": "We finish by multiplying by the weight vector w:",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1985",
    "text": "0",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1986",
    "text": "1",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1987",
    "text": "1",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1988",
    "text": "0",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1989",
    "text": "-6.11",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1990",
    "text": "The neural network has obtained the correct answer for every example in the batch.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1991",
    "text": "In this example, we simply specified the solution, then showed that it obtained zero error. In a real situation, there might be billions of model parameters and\u00a0billions of training examples, so one cannot simply guess the solution as we did\u00a0here. Instead, a gradient-based optimization algorithm can find parameters that\u00a0produce very little error. The solution we described to the XOR problem is at a\u00a0global minimum of the loss function, so gradient descent could converge to this\u00a0point. There are other equivalent solutions to the XOR problem that gradient\u00a0descent could also find. The convergence point of gradient descent depends on the\u00a0initial values of the parameters. In practice, gradient descent would usually not\u00a0find clean, easily understood, integer-valued solutions like the one we presented\u00a0here.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1992",
    "text": "Designing and training a neural network is not much different from training any other machine learning model with gradient descent. In Sec. 5.10, we described\u00a0how to build a machine learning algorithm by specifying an optimization procedure,\u00a0a cost function, and a model family.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1993",
    "text": "The largest difference between the linear models we have seen so far and neural networks is that the nonlinearity of a neural network causes most interesting loss\u00a0functions to become non-convex. This means that neural networks are usually\u00a0trained by using iterative, gradient-based optimizers that merely drive the cost\u00a0function to a very low value, rather than the linear equation solvers used to train\u00a0linear regression models or the convex optimization algorithms with global convergence guarantees used to train logistic regression or SVMs. Convex optimization\u00a0converges starting from any initial parameters (in theory\u2014in practice it is very\u00a0robust but can encounter numerical problems). Stochastic gradient descent applied\u00a0to non-convex loss functions has no such convergence guarantee, and is sensitive\u00a0to the values of the initial parameters. For feedforward neural networks, it is\u00a0important to initialize all weights to small random values. The biases may be\u00a0initialized to zero or to small positive values. The iterative gradient-based optimization algorithms used to train feedforward networks and almost all other deep\u00a0models will be described in detail in Chapter 8, with parameter initialization in\u00a0particular discussed in Sec. 8.4. For the moment, it suffices to understand that\u00a0the training algorithm is almost always based on using the gradient to descend the\u00a0cost function in one way or another. The specific algorithms are improvements\u00a0and refinements on the ideas of gradient descent, introduced in Sec. 4.3, and,\u00a0more specifically, are most often improvements of the stochastic gradient descent\u00a0algorithm, introduced in Sec. 5.9.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1994",
    "text": "We can of course, train models such as linear regression and support vector machines with gradient descent too, and in fact this is common when the training\u00a0set is extremely large. From this point of view, training a neural network is not\u00a0much different from training any other model. Computing the gradient is slightly\u00a0more complicated for a neural network, but can still be done efficiently and exactly.\u00a0Sec. 6.5 will describe how to obtain the gradient using the back-propagation\u00a0algorithm and modern generalizations of the back-propagation algorithm.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1995",
    "text": "As with other machine learning models, to apply gradient-based learning we must choose a cost function, and we must choose how to represent the output of\u00a0the model. We now revisit these design considerations with special emphasis on\u00a0the neural networks scenario.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1996",
    "text": "An important aspect of the design of a deep neural network is the choice of the cost function. Fortunately, the cost functions for neural networks are more or less\u00a0the same as those for other parametric models, such as linear models.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1997",
    "text": "In most cases, our parametric model defines a distribution p( y | x; Q) and we simply use the principle of maximum likelihood. This means we use the\u00a0cross-entropy between the training data and the model\u2019s predictions as the cost\u00a0function.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1998",
    "text": "Sometimes, we take a simpler approach, where rather than predicting a complete probability distribution over y, we merely predict some statistic of y conditioned\u00a0on x. Specialized loss functions allow us to train a predictor of these estimates.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "1999",
    "text": "The total cost function used to train a neural network will often combine one of the primary cost functions described here with a regularization term. We have\u00a0already seen some simple examples of regularization applied to linear models in Sec.\u00a05.2.2. The weight decay approach used for linear models is also directly applicable\u00a0to deep neural networks and is among the most popular regularization strategies.\u00a0More advanced regularization strategies for neural networks will be described in\u00a0Chapter 7.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2000",
    "text": "6.2.1.1 \u00a0\u00a0\u00a0Learning Conditional Distributions with Maximum Likelihood",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2001",
    "text": "Most modern neural networks are trained using maximum likelihood. This means that the cost function is simply the negative log-likelihood, equivalently described",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2002",
    "text": "as the cross-entropy between the training data and the model distribution. This cost function is given by",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2003",
    "text": "J (6) \u00a0\u00a0\u00a0\u2014 Ex,y~p3data 10g pmode1(y 1 x)\u2022\u00a0\u00a0\u00a0\u00a0(6.12)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2004",
    "text": "The specific form of the cost function changes from model to model, depending on the specific form of logpmode1\u2022 The expansion of the above equation typically\u00a0yields some terms that do not depend on the model parameters and may be\u00a0discarded. For example, as we saw in Sec. 5.5.1, if pmode1 (y | x) = N(y; f (x; 6), I),\u00a0then we recover the mean squared error cost,",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2005",
    "text": "J (0) = ~E x,y~p3data\\\\y - f (X; 6 )|12 +COnSt \u00a0\u00a0\u00a0(6.13)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2006",
    "text": "up to a scaling factor of 2\u05be and a term that does not depend on 6. The discarded constant is based on the variance of the Gaussian distribution, which in this case\u00a0we chose not to parametrize. Previously, we saw that the equivalence between\u00a0maximum likelihood estimation with an output distribution and minimization of\u00a0mean squared error holds for a linear model, but in fact, the equivalence holds\u00a0regardless of the f (x; 6) used to predict the mean of the Gaussian.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2007",
    "text": "An advantage of this approach of deriving the cost function from maximum likelihood is that it removes the burden of designing cost functions for each model.\u00a0Specifying a model p(y \\ x) automatically determines a cost function logp(y \\ x).",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2008",
    "text": "One recurring theme throughout neural network design is that the gradient of the cost function must be large and predictable enough to serve as a good guide\u00a0for the learning algorithm. Functions that saturate (become very flat) undermine\u00a0this objective because they make the gradient become very small. In many cases\u00a0this happens because the activation functions used to produce the output of the\u00a0hidden units or the output units saturate. The negative log-likelihood helps to\u00a0avoid this problem for many models. Many output units involve an exp function\u00a0that can saturate when its argument is very negative. The log function in the\u00a0negative log-likelihood cost function undoes the exp of some output units. We will\u00a0discuss the interaction between the cost function and the choice of output unit in\u00a0Sec. 6.2.2.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2009",
    "text": "One unusual property of the cross-entropy cost used to perform maximum likelihood estimation is that it usually does not have a minimum value when applied\u00a0to the models commonly used in practice. For discrete output variables, most\u00a0models are parametrized in such a way that they cannot represent a probability\u00a0of zero or one, but can come arbitrarily close to doing so. Logistic regression\u00a0is an example of such a model. For real-valued output variables, if the model\u00a0can control the density of the output distribution (for example, by learning the\u00a0variance parameter of a Gaussian output distribution) then it becomes possible\u00a0to assign extremely high density to the correct training set outputs, resulting in\u00a0cross-entropy approaching negative infinity. Regularization techniques described\u00a0in Chapter 7 provide several different ways of modifying the learning problem so\u00a0that the model cannot reap unlimited reward in this way.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2010",
    "text": "6.2.1.2 Learning Conditional Statistics",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2011",
    "text": "Instead of learning a full probability distribution p(y | x; 6) we often want to learn just one conditional statistic of y given x.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2012",
    "text": "For example, we may have a predictor f (x; 6) that we wish to predict the mean of y.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2013",
    "text": "If we use a sufficiently powerful neural network, we can think of the neural network as being able to represent any function f from a wide class of functions,\u00a0with this class being limited only by features such as continuity and boundedness\u00a0rather than by having a specific parametric form. From this point of view, we\u00a0can view the cost function as being a functional rather than just a function. A\u00a0functional is a mapping from functions to real numbers. We can thus think of\u00a0learning as choosing a function rather than merely choosing a set of parameters.\u00a0We can design our cost functional to have its minimum occur at some specific\u00a0function we desire. For example, we can design the cost functional to have its\u00a0minimum lie on the function that maps x to the expected value of y given x.\u00a0Solving an optimization problem with respect to a function requires a mathematical\u00a0tool called calculus of variations, described in Sec. 19.4.2. It is not necessary to\u00a0understand calculus of variations to understand the content of this chapter. At\u00a0the moment, it is only necessary to understand that calculus of variations may be\u00a0used to derive the following two results.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2014",
    "text": "Our first result derived using calculus of variations is that solving the optimization problem",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2015",
    "text": "f = argmrn EX,y~Pdata||y - f (x)|!2 \u00a0\u00a0\u00a0(6.14)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2016",
    "text": "f",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2017",
    "text": "yields",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2018",
    "text": "f *(x) = Ey^pdata(y|x) [y], \u00a0\u00a0\u00a0(6.15)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2019",
    "text": "so long as this function lies within the class we optimize over. In other words, if we could train on infinitely many samples from the true data-generating distribution,\u00a0minimizing the mean squared error cost function gives a function that predicts the\u00a0mean of y for each value of x.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2020",
    "text": "Different cost functions give different statistics. A second result derived using calculus of variations is that",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2021",
    "text": "f = argmin EX,y~p data11 y - f (x)||1 \u00a0\u00a0\u00a0(6\u202216)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2022",
    "text": "f",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2023",
    "text": "yields a function that predicts the median value of y for each x, so long as such a function may be described by the family of functions we optimize over. This cost\u00a0function is commonly called mean absolute error.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2024",
    "text": "Unfortunately, mean squared error and mean absolute error often lead to poor results when used with gradient-based optimization. Some output units that\u00a0saturate produce very small gradients when combined with these cost functions.\u00a0This is one reason that the cross-entropy cost function is more popular than mean\u00a0squared error or mean absolute error, even when it is not necessary to estimate an\u00a0entire distribution p(y | x).",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2025",
    "text": "The choice of cost function is tightly coupled with the choice of output unit. Most of the time, we simply use the cross-entropy between the data distribution and the\u00a0model distribution. The choice of how to represent the output then determines\u00a0the form of the cross-entropy function.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2026",
    "text": "Any kind of neural network unit that may be used as an output can also be used as a hidden unit. Here, we focus on the use of these units as outputs of the\u00a0model, but in principle they can be used internally as well. We revisit these units\u00a0with additional detail about their use as hidden units in Sec. 6.3.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2027",
    "text": "Throughout this section, we suppose that the feedforward network provides a set of hidden features defined by h = f (x; 6). The role of the output layer is then\u00a0to provide some additional transformation from the features to complete the task\u00a0that the network must perform.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2028",
    "text": "6.2.2.1 Linear Units for Gaussian Output Distributions",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2029",
    "text": "One simple kind of output unit is an output unit based on an affine transformation with no nonlinearity. These are often just called linear units.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2030",
    "text": "Given features h, a layer of linear output units produces a vector y = WT h+ b. Linear output layers are often used to produce the mean of a conditional\u00a0Gaussian distribution:",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2031",
    "text": "p(y 1 x) = N(y; y, I). \u00a0\u00a0\u00a0(6.17)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2032",
    "text": "Maximizing the log-likelihood is then equivalent to minimizing the mean squared error.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2033",
    "text": "The maximum likelihood framework makes it straightforward to learn the covariance of the Gaussian too, or to make the covariance of the Gaussian be a\u00a0function of the input. However, the covariance must be constrained to be a positive\u00a0definite matrix for all inputs. It is difficult to satisfy such constraints with a linear\u00a0output layer, so typically other output units are used to parametrize the covariance.\u00a0Approaches to modeling the covariance are described shortly, in Sec. 6.2.2.4.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2034",
    "text": "Because linear units do not saturate, they pose little difficulty for gradient-based optimization algorithms and may be used with a wide variety of optimization algorithms.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2035",
    "text": "6.2.2.2 Sigmoid Units for Bernoulli Output Distributions",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2036",
    "text": "Many tasks require predicting the value of a binary variable y. Classification problems with two classes can be cast in this form.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2037",
    "text": "The maximum-likelihood approach is to define a Bernoulli distribution over y conditioned on x.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2038",
    "text": "A Bernoulli distribution is defined by just a single number. The neural net needs to predict only P(y = 1 | x). For this number to be a valid probability, it\u00a0must lie in the interval [0, 1].",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2039",
    "text": "Satisfying this constraint requires some careful design effort. Suppose we were to use a linear unit, and threshold its value to obtain a valid probability:",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2040",
    "text": "P(y = 1 | x) = max |0,min j 1, w h + b j j . \u00a0\u00a0\u00a0(6.18)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2041",
    "text": "This would indeed define a valid conditional distribution, but we would not be able to train it very effectively with gradient descent. Any time that wTh + b strayed\u00a0outside the unit interval, the gradient of the output of the model with respect to\u00a0its parameters would be 0. A gradient of 0 is typically problematic because the\u00a0learning algorithm no longer has a guide for how to improve the corresponding\u00a0parameters.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2042",
    "text": "Instead, it is better to use a different approach that ensures there is always a strong gradient whenever the model has the wrong answer. This approach is based\u00a0on using sigmoid output units combined with maximum likelihood.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2043",
    "text": "A sigmoid output unit is defined by",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2044",
    "text": "y = a (w h + b^ \u00a0\u00a0\u00a0(6.19)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2045",
    "text": "where a is the logistic sigmoid function described in Sec. 3.10.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2046",
    "text": "We can think of the sigmoid output unit as having two components. First, it uses a linear layer to compute z = wTh + b. Next, it uses the sigmoid activation\u00a0function to convert z into a probability.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2047",
    "text": "We omit the dependence on x for the moment to discuss how to define a probability distribution over y using the value z. The sigmoid can be motivated\u00a0by constructing an unnormalized probability distribution P(y), which does not\u00a0sum to 1. We can then divide by an appropriate constant to obtain a valid\u00a0probability distribution. If we begin with the assumption that the unnormalized log\u00a0probabilities are linear in y and z, we can exponentiate to obtain the unnormalized\u00a0probabilities. We then normalize to see that this yields a Bernoulli distribution\u00a0controlled by a sigmoidal transformation of z:",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2048",
    "text": "log P{y)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2049",
    "text": "P{y) p (y)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2050",
    "text": "-6.2",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2051",
    "text": "-6.21",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2052",
    "text": "-6.22",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2053",
    "text": "-6.23",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2054",
    "text": "yz",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2055",
    "text": "exp(yz) exp(yz)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2056",
    "text": "exp(y1 z) P (y) = a ((2y - 1)z) \u2022",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2057",
    "text": "Probability distributions based on exponentiation and normalization are common throughout the statistical modeling literature. The z variable defining such a\u00a0distribution over binary variables is called a logit.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2058",
    "text": "This approach to predicting the probabilities in log-space is natural to use with maximum likelihood learning. Because the cost function used with maximum\u00a0likelihood is \u2014 log P(y | x), the log in the cost function undoes the exp of the\u00a0sigmoid. Without this effect, the saturation of the sigmoid could prevent gradient-based learning from making good progress. The loss function for maximum\u00a0likelihood learning of a Bernoulli parametrized by a sigmoid is",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2059",
    "text": "J(0) = \u2014 log P(y | x) \u00a0\u00a0\u00a0(6.24)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2060",
    "text": "#ERROR!",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2061",
    "text": "#ERROR!",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2062",
    "text": "This derivation makes use of some properties from Sec. 3.10. By rewriting the loss in terms of the softplus function, we can see that it saturates only when\u00a0(1 \u2014 2y )z is very negative. Saturation thus occurs only when the model already\u00a0has the right answer\u2014when y = 1 and z is very positive, or y = 0 and z is very\u00a0negative. When z has the wrong sign, the argument to the softplus function,\u00a0(1 \u2014 2y)z, may be simplified to |z|. As |z| becomes large while z has the wrong sign,\u00a0the softplus function asymptotes toward simply returning its argument |z|. The\u00a0derivative with respect to z asymptotes to sign(z), so, in the limit of extremely\u00a0incorrect z, the softplus function does not shrink the gradient at all. This property\u00a0is very useful because it means that gradient-based learning can act to quickly\u00a0correct a mistaken z.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2063",
    "text": "When we use other loss functions, such as mean squared error, the loss can saturate anytime a(z) saturates. The sigmoid activation function saturates to 0\u00a0when z becomes very negative and saturates to 1 when z becomes very positive.\u00a0The gradient can shrink too small to be useful for learning whenever this happens,\u00a0whether the model has the correct answer or the incorrect answer. For this reason,\u00a0maximum likelihood is almost always the preferred approach to training sigmoid\u00a0output units.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2064",
    "text": "Analytically, the logarithm of the sigmoid is always defined and finite, because the sigmoid returns values restricted to the open interval (0,1), rather than using\u00a0the entire closed interval of valid probabilities [0, 1]. In software implementations,\u00a0to avoid numerical problems, it is best to write the negative log-likelihood as a\u00a0function of z, rather than as a function of y = a(z). If the sigmoid function\u00a0underflows to zero, then taking the logarithm of y yields negative infinity.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2065",
    "text": "6.2.2.3 Softmax Units for Multinoulli Output Distributions",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2066",
    "text": "Any time we wish to represent a probability distribution over a discrete variable with n possible values, we may use the softmax function. This can be seen as a\u00a0generalization of the sigmoid function which was used to represent a probability\u00a0distribution over a binary variable.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2067",
    "text": "Softmax functions are most often used as the output of a classifier, to represent the probability distribution over n different classes. More rarely, softmax functions\u00a0can be used inside the model itself, if we wish the model to choose between one of\u00a0n different options for some internal variable.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2068",
    "text": "In the case of binary variables, we wished to produce a single number",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2069",
    "text": "y = P(y = 1 | x). \u00a0\u00a0\u00a0(6.27)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2070",
    "text": "Because this number needed to lie between 0 and 1, and because we wanted the logarithm of the number to be well-behaved for gradient-based optimization of\u00a0the log-likelihood, we chose to instead predict a number z = logP(y = 1 | x).\u00a0Exponentiating and normalizing gave us a Bernoulli distribution controlled by the\u00a0sigmoid function.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2071",
    "text": "To generalize to the case of a discrete variable with n values, we now need to produce a vector y, with yi = P(y = i | x). We require not only that each\u00a0element of yi be between 0 and 1, but also that the entire vector sums to 1 so that\u00a0it represents a valid probability distribution. The same approach that worked for\u00a0the Bernoulli distribution generalizes to the multinoulli distribution. First, a linear\u00a0layer predicts unnormalized log probabilities:",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2072",
    "text": "z = WT h + b, \u00a0\u00a0\u00a0(6.28)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2073",
    "text": "where zi = log P(y = i | x). The softmax function can then exponentiate and normalize z to obtain the desired y. Formally, the softmax function is given by",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2074",
    "text": "softmax(z)i = \u00a0\u00a0\u00a06\u00a0\u00a0\u00a0\u00a0) .\u00a0\u00a0\u00a0\u00a0(6.29)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2075",
    "text": "j exP(zj)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2076",
    "text": "As with the logistic sigmoid, the use of the exp function works very well when training the softmax to output a target value y using maximum log-likelihood. In\u00a0this case, we wish to maximize log P (y = i; z) = logsoftmax(z)i. Defining the\u00a0softmax in terms of exp is natural because the log in the log-likelihood can undo\u00a0the exp of the softmax:",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2077",
    "text": "logsoftmax(z)i = z \u2014 log^^ exp(z;). \u00a0\u00a0\u00a0(6.30)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2078",
    "text": "j",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2079",
    "text": "The first term of Eq. 6.30 shows that the input z always has a direct contribution to the cost function. Because this term cannot saturate, we know that learning can proceed, even if the contribution of zi to the second term of Eq. 6.30\u00a0becomes very small. When maximizing the log-likelihood, the first term encourages\u00a0z to be pushed up, while the second term encourages all of z to be pushed down.\u00a0To gain some intuition for the second term, log^jexp(zj), observe that this term\u00a0can be roughly approximated by maxj zj. This approximation is based on the idea\u00a0that exp(zk) is insignificant for any zk that is noticeably less than maxj zj. The\u00a0intuition we can gain from this approximation is that the negative log-likelihood\u00a0cost function always strongly penalizes the most active incorrect prediction. If the\u00a0correct answer already has the largest input to the softmax, then the \u2014 zi term\u00a0and the log^j exp(zj) ~ maxj zj = zi terms will roughly cancel. This example\u00a0will then contribute little to the overall training cost, which will be dominated by\u00a0other examples that are not yet correctly classified.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2080",
    "text": "So far we have discussed only a single example. Overall, unregularized maximum likelihood will drive the model to learn parameters that drive the softmax to predict\u00a0the fraction of counts of each outcome observed in the training set:",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2081",
    "text": "m 1",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2082",
    "text": "softmax(z(x; 0)) ~ \u2014j=1m y 1 =i,x(J]~x . \u00a0\u00a0\u00a0(6.31)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2083",
    "text": "j=1 1x(j) =x",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2084",
    "text": "Because maximum likelihood is a consistent estimator, this is guaranteed to happen so long as the model family is capable of representing the training distribution. In\u00a0practice, limited model capacity and imperfect optimization will mean that the\u00a0model is only able to approximate these fractions.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2085",
    "text": "Many objective functions other than the log-likelihood do not work as well with the softmax function. Specifically, objective functions that do not use a log to\u00a0undo the exp of the softmax fail to learn when the argument to the exp becomes\u00a0very negative, causing the gradient to vanish. In particular, squared error is a\u00a0poor loss function for softmax units, and can fail to train the model to change its\u00a0output, even when the model makes highly confident incorrect predictions (Bridle,\u00a01990). To understand why these other loss functions can fail, we need to examine\u00a0the softmax function itself.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2086",
    "text": "Like the sigmoid, the softmax activation can saturate. The sigmoid function has a single output that saturates when its input is extremely negative or extremely\u00a0positive. In the case of the softmax, there are multiple output values. These\u00a0output values can saturate when the differences between input values become\u00a0extreme. When the softmax saturates, many cost functions based on the softmax\u00a0also saturate, unless they are able to invert the saturating activating function.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2087",
    "text": "To see that the softmax function responds to the difference between its inputs, observe that the softmax output is invariant to adding the same scalar to all of its\u00a0inputs:",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2088",
    "text": "softmax(z) = softmax(z + c). \u00a0\u00a0\u00a0(6.32)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2089",
    "text": "Using this property, we can derive a numerically stable variant of the softmax:",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2090",
    "text": "softmax(z) = softmax(z \u2014 max z). \u00a0\u00a0\u00a0(6.33)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2091",
    "text": "i",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2092",
    "text": "The reformulated version allows us to evaluate softmax with only small numerical errors even when z contains extremely large or extremely negative numbers. Examining the numerically stable variant, we see that the softmax function is driven\u00a0by the amount that its arguments deviate from maxi zi.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2093",
    "text": "An output softmax(z )i saturates to 1 when the corresponding input is maximal (zi = maxj zi) and zi is much greater than all of the other inputs. The output\u00a0softmax(z)i can also saturate to 0 when z is not maximal and the maximum is\u00a0much greater. This is a generalization of the way that sigmoid units saturate, and\u00a0can cause similar difficulties for learning if the loss function is not designed to\u00a0compensate for it.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2094",
    "text": "The argument z to the softmax function can be produced in two different ways. The most common is simply to have an earlier layer of the neural network output\u00a0every element of z, as described above using the linear layer z = WT h + b. While\u00a0straightforward, this approach actually overparametrizes the distribution. The\u00a0constraint that the n outputs must sum to 1 means that only n \u2014 1 parameters are\u00a0necessary; the probability of the n-th value may be obtained by subtracting the\u00a0first n \u2014 1 probabilities from 1. We can thus impose a requirement that one element\u00a0of z be fixed. For example, we can require that zn =0. Indeed, this is exactly\u00a0what the sigmoid unit does. Defining P(y = 1 | x) = a(z) is equivalent to defining\u00a0P(y = 1 | x) = softmax(z)1 with a two-dimensional z and z! = 0. Both the n \u2014 1\u00a0argument and the n argument approaches to the softmax can describe the same\u00a0set of probability distributions, but have different learning dynamics. In practice,\u00a0there is rarely much difference between using the overparametrized version or the\u00a0restricted version, and it is simpler to implement the overparametrized version.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2095",
    "text": "From a neuroscientific point of view, it is interesting to think of the softmax as a way to create a form of competition between the units that participate in it: the\u00a0softmax outputs always sum to 1 so an increase in the value of one unit necessarily\u00a0corresponds to a decrease in the value of others. This is analogous to the lateral\u00a0inhibition that is believed to exist between nearby neurons in the cortex. At the\u00a0extreme (when the difference between the maximal a and the others is large in\u00a0magnitude) it becomes a form of winner-take-all (one of the outputs is nearly 1\u00a0and the others are nearly 0).",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2096",
    "text": "The name \u201csoftmax\u201d can be somewhat confusing. The function is more closely related to the argmax function than the max function. The term \u201csoft\u201d derives\u00a0from the fact that the softmax function is continuous and differentiable. The\u00a0argmax function, with its result represented as a one-hot vector, is not continuous\u00a0or differentiable. The softmax function thus provides a \u201csoftened\u201d version of the\u00a0argmax. The corresponding soft version of the maximum function is softmax( z)Tz.\u00a0It would perhaps be better to call the softmax function \u201csoftargmax,\u201d but the\u00a0current name is an entrenched convention.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2097",
    "text": "6.2.2.4 Other Output Types",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2098",
    "text": "The linear, sigmoid, and softmax output units described above are the most common. Neural networks can generalize to almost any kind of output layer that\u00a0we wish. The principle of maximum likelihood provides a guide for how to design\u00a0a good cost function for nearly any kind of output layer.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2099",
    "text": "In general, if we define a conditional distribution p (y | x; 6), the principle of maximum likelihood suggests we use \u2014 logp(y | x; 6) as our cost function.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2100",
    "text": "In general, we can think of the neural network as representing a function f (x; 6). The outputs of this function are not direct predictions of the value y. Instead,\u00a0f (x;6) = u provides the parameters for a distribution over y. Our loss function\u00a0can then be interpreted as \u2014 logp(y; u(x)).",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2101",
    "text": "For example, we may wish to learn the variance of a conditional Gaussian for y, given x. In the simple case, where the variance a2 is a constant, there is a\u00a0closed form expression because the maximum likelihood estimator of variance is\u00a0simply the empirical mean of the squared difference between observations y and\u00a0their expected value. A computationally more expensive approach that does not\u00a0require writing special-case code is to simply include the variance as one of the\u00a0properties of the distribution p(y | x) that is controlled by u = f(x;6). The\u00a0negative log-likelihood \u2014 logp (y; u(x)) will then provide a cost function with the\u00a0appropriate terms necessary to make our optimization procedure incrementally\u00a0learn the variance. In the simple case where the standard deviation does not depend\u00a0on the input, we can make a new parameter in the network that is copied directly\u00a0into u. This new parameter might be a itself or could be a parameter v representing\u00a0a2 or it could be a parameter 3 representing , depending on how we choose to\u00a0parametrize the distribution. We may wish our model to predict a different amount\u00a0of variance in y for different values of x. This is called a heteroscedastic model.\u00a0In the heteroscedastic case, we simply make the specification of the variance be\u00a0one of the values output by f (x; 6). A typical way to do this is to formulate the\u00a0Gaussian distribution using precision, rather than variance, as described in Eq.\u00a03.22. In the multivariate case it is most common to use a diagonal precision matrix",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2102",
    "text": "diag(fl). \u00a0\u00a0\u00a0(6.34)",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2103",
    "text": "This formulation works well with gradient descent because the formula for the log-likelihood of the Gaussian distribution parametrized by involves only multiplication by (3% and addition of log . The gradient of multiplication, addition,\u00a0and logarithm operations is well-behaved. By comparison, if we parametrized the\u00a0output in terms of variance, we would need to use division. The division function\u00a0becomes arbitrarily steep near zero. While large gradients can help learning,\u00a0arbitrarily large gradients usually result in instability. If we parametrized the\u00a0output in terms of standard deviation, the log-likelihood would still involve division,\u00a0and would also involve squaring. The gradient through the squaring operation\u00a0can vanish near zero, making it difficult to learn parameters that are squared.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2104",
    "text": "Regardless of whether we use standard deviation, variance, or precision, we must ensure that the covariance matrix of the Gaussian is positive definite. Because\u00a0the eigenvalues of the precision matrix are the reciprocals of the eigenvalues of\u00a0the covariance matrix, this is equivalent to ensuring that the precision matrix is\u00a0positive definite. If we use a diagonal matrix, or a scalar times the diagonal matrix,\u00a0then the only condition we need to enforce on the output of the model is positivity.\u00a0If we suppose that a is the raw activation of the model used to determine the\u00a0diagonal precision, we can use the softplus function to obtain a positive precision\u00a0vector:\u00a0\u00a0\u00a0\u00a0= Z(a). This same strategy applies equally if using variance or standard",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2105",
    "text": "deviation rather than precision or if using a scalar times identity rather than diagonal matrix.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2106",
    "text": "It is rare to learn a covariance or precision matrix with richer structure than diagonal. If the covariance is full and conditional, then a parametrization must\u00a0be chosen that guarantees positive-definiteness of the predicted covariance matrix.\u00a0This can be achieved by writing \u00a3(x) = B(x )Bt (x), where B is an unconstrained\u00a0square matrix. One practical issue if the matrix is full rank is that computing the\u00a0likelihood is expensive, with a d x d matrix requiring O (d3) computation for the\u00a0determinant and inverse of \u00a3(x) (or equivalently, and more commonly done, its\u00a0eigendecomposition or that of B(x)).",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2107",
    "text": "We often want to perform multimodal regression, that is, to predict real values that come from a conditional distribution p(y | x) that can have several different\u00a0peaks in y space for the same value of x. In this case, a Gaussian mixture is\u00a0a natural representation for the output (Jacobs et al., 1991; Bishop, 1994).\u00a0Neural networks with Gaussian mixtures as their output are often called mixture\u00a0density networks. A Gaussian mixture output with n components is defined by the\u00a0conditional probability distribution",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2108",
    "text": "-6.35",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2109",
    "text": "p(y | x) = \u00a0\u00a0\u00a0p(c = i | x)N(y; MW(x), \u00a3 (i)(x)).",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2110",
    "text": "The neural network must have three outputs: a vector defining p(c = i | x), a matrix providing f1(i)(x) for all i, and a tensor providing \u00a3(i)(x) for all i. These\u00a0outputs must satisfy different constraints:",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2111",
    "text": "1. Mixture components p(c = i | x): these form a multinoulli distribution over the n different components associated with latent variable1 c, and can",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2112",
    "text": "1 We consider c to be latent because we do not observe it in the data: given input x and target y, it is not possible to know with certainty which Gaussian component was responsible for y, but\u00a0we can imagine that y was generated by picking one of them, and make that unobserved choice a\u00a0random variable.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2113",
    "text": "typically be obtained by a softmax over an n-dimensional vector, to guarantee that these outputs are positive and sum to 1.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2114",
    "text": "2. Means \u00a0\u00a0\u00a0x): these indicate the center or mean associated with the i-th",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2115",
    "text": "Gaussian component, and are unconstrained (typically with no nonlinearity at all for these output units). If y is a d-vector, then the network must output\u00a0an n x d matrix containing all n of these d-dimensional vectors. Learning\u00a0these means with maximum likelihood is slightly more complicated than\u00a0learning the means of a distribution with only one output mode. We only\u00a0want to update the mean for the component that actually produced the\u00a0observation. In practice, we do not know which component produced each\u00a0observation. The expression for the negative log-likelihood naturally weights\u00a0each example\u2019s contribution to the loss for each component by the probability\u00a0that the component produced the example.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2116",
    "text": "3. Covariances \u00a3 (i)(x): these specify the covariance matrix for each component\u00a0i. As when learning a single Gaussian component, we typically use a diagonal\u00a0matrix to avoid needing to compute determinants. As with learning the means\u00a0of the mixture, maximum likelihood is complicated by needing to assign\u00a0partial responsibility for each point to each mixture component. Gradient\u00a0descent will automatically follow the correct process if given the correct\u00a0specification of the negative log-likelihood under the mixture model.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2117",
    "text": "It has been reported that gradient-based optimization of conditional Gaussian mixtures (on the output of neural networks) can be unreliable, in part because one\u00a0gets divisions (by the variance) which can be numerically unstable (when some\u00a0variance gets to be small for a particular example, yielding very large gradients).\u00a0One solution is to clip gradients (see Sec. 10.11.1) while another is to scale the\u00a0gradients heuristically (Murray and Larochelle, 2014).",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2118",
    "text": "Gaussian mixture outputs are particularly effective in generative models of speech (Schuster, 1999) or movements of physical objects (Graves, 2013). The\u00a0mixture density strategy gives a way for the network to represent multiple output\u00a0modes and to control the variance of its output, which is crucial for obtaining\u00a0a high degree of quality in these real-valued domains. An example of a mixture\u00a0density network is shown in Fig. 6.4.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2119",
    "text": "In general, we may wish to continue to model larger vectors y containing more variables, and to impose richer and richer structures on these output variables. For\u00a0example, we may wish for our neural network to output a sequence of characters\u00a0that forms a sentence. In these cases, we may continue to use the principle\u00a0of maximum likelihood applied to our model p(y; w(x)), but the model we use",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2120",
    "text": "Figure 6.4: Samples drawn from a neural network with a mixture density output layer. The input x is sampled from a uniform distribution and the output y is sampled from\u00a0pmode1 (y | x). The neural network is able to learn nonlinear mappings from the input to\u00a0the parameters of the output distribution. These parameters include the probabilities\u00a0governing which of three mixture components will generate the output as well as the\u00a0parameters for each mixture component. Each mixture component is Gaussian with\u00a0predicted mean and variance. All of these aspects of the output distribution are able to\u00a0vary with respect to the input x, and to do so in nonlinear ways.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2121",
    "text": "to describe y becomes complex enough to be beyond the scope of this chapter. Chapter 10 describes how to use recurrent neural networks to define such models\u00a0over sequences, and Part III describes advanced techniques for modeling arbitrary\u00a0probability distributions.",
    "chapter": "Optimization for Training Deep Models",
    "chapter_id": "main-11.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2122",
    "text": "So far we have focused our discussion on design choices for neural networks that are common to most parametric machine learning models trained with gradient-based optimization. Now we turn to an issue that is unique to feedforward neural\u00a0networks: how to choose the type of hidden unit to use in the hidden layers of the\u00a0model.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2123",
    "text": "The design of hidden units is an extremely active area of research and does not yet have many definitive guiding theoretical principles.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2124",
    "text": "Rectified linear units are an excellent default choice of hidden unit. Many other types of hidden units are available. It can be difficult to determine when to use\u00a0which kind (though rectified linear units are usually an acceptable choice). We\u00a0describe here some of the basic intuitions motivating each type of hidden units.\u00a0These intuitions can be used to suggest when to try out each of these units. It is\u00a0usually impossible to predict in advance which will work best. The design process\u00a0consists of trial and error, intuiting that a kind of hidden unit may work well,\u00a0and then training a network with that kind of hidden unit and evaluating its\u00a0performance on a validation set.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2125",
    "text": "Some of the hidden units included in this list are not actually differentiable at all input points. For example, the rectified linear function g(z) = max{0 ,z} is not\u00a0differentiable at z = 0. This may seem like it invalidates g for use with a gradient-based learning algorithm. In practice, gradient descent still performs well enough\u00a0for these models to be used for machine learning tasks. This is in part because\u00a0neural network training algorithms do not usually arrive at a local minimum of\u00a0the cost function, but instead merely reduce its value significantly, as shown in\u00a0Fig. 4.3. These ideas will be described further in Chapter 8. Because we do not\u00a0expect training to actually reach a point where the gradient is 0, it is acceptable\u00a0for the minima of the cost function to correspond to points with undefined gradient.\u00a0Hidden units that are not differentiable are usually non-differentiable at only a\u00a0small number of points. In general, a function g(z) has a left derivative defined\u00a0by the slope of the function immediately to the left of z and a right derivative\u00a0defined by the slope of the function immediately to the right of z. A function\u00a0is differentiable at z only if both the left derivative and the right derivative are\u00a0defined and equal to each other. The functions used in the context of neural\u00a0networks usually have defined left derivatives and defined right derivatives. In the\u00a0case of g(z) = max{0, z}, the left derivative at z = 0 is 0 and the right derivative\u00a0is 1. Software implementations of neural network training usually return one of\u00a0the one-sided derivatives rather than reporting that the derivative is undefined or\u00a0raising an error. This may be heuristically justified by observing that gradient-based optimization on a digital computer is subject to numerical error anyway.\u00a0When a function is asked to evaluate g(0), it is very unlikely that the underlying\u00a0value truly was 0. Instead, it was likely to be some small value e that was rounded\u00a0to 0. In some contexts, more theoretically pleasing justifications are available, but\u00a0these usually do not apply to neural network training. The important point is that\u00a0in practice one can safely disregard the non-differentiability of the hidden unit\u00a0activation functions described below.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2126",
    "text": "Unless indicated otherwise, most hidden units can be described as accepting a vector of inputs x, computing an affine transformation z = WTx + b, and\u00a0then applying an element-wise nonlinear function g( z). Most hidden units are\u00a0distinguished from each other only by the choice of the form of the activation\u00a0function g(z).",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2127",
    "text": "Rectified linear units use the activation function g(z) = max{0, z}.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2128",
    "text": "Rectified linear units are easy to optimize because they are so similar to linear units. The only difference between a linear unit and a rectified linear unit is\u00a0that a rectified linear unit outputs zero across half its domain. This makes the\u00a0derivatives through a rectified linear unit remain large whenever the unit is active.\u00a0The gradients are not only large but also consistent. The second derivative of the\u00a0rectifying operation is 0 almost everywhere, and the derivative of the rectifying\u00a0operation is 1 everywhere that the unit is active. This means that the gradient\u00a0direction is far more useful for learning than it would be with activation functions\u00a0that introduce second-order effects.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2129",
    "text": "Rectified linear units are typically used on top of an affine transformation:",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2130",
    "text": "h = g(WTx + b). \u00a0\u00a0\u00a0(6.36)",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2131",
    "text": "When initializing the parameters of the affine transformation, it can be a good practice to set all elements of b to a small, positive value, such as 0.1. This makes\u00a0it very likely that the rectified linear units will be initially active for most inputs\u00a0in the training set and allow the derivatives to pass through.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2132",
    "text": "Several generalizations of rectified linear units exist. Most of these generalizations perform comparably to rectified linear units and occasionally perform better.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2133",
    "text": "One drawback to rectified linear units is that they cannot learn via gradient-based methods on examples for which their activation is zero. A variety of generalizations of rectified linear units guarantee that they receive gradient everywhere.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2134",
    "text": "Three generalizations of rectified linear units are based on using a non-zero slope a when Zi < 0: h = g(z, a) i = max(0, Zi) + aimin(0,zi). Absolute value\u00a0rectification fixes ai = \u2014 1 to obtain g(z) = |z|. It is used for object recognition\u00a0from images (Jarrett et al., 2009), where it makes sense to seek features that are\u00a0invariant under a polarity reversal of the input illumination. Other generalizations\u00a0of rectified linear units are more broadly applicable. A leaky ReLU (Maas et al.,\u00a02013) fixes ai to a small value like 0.01 while a parametric ReLU or PReLU treats\u00a0ai as a learnable parameter (He et al., 2015).",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2135",
    "text": "Maxout units (Goodfellow et al., 2013a) generalize rectified linear units further. Instead of applying an element-wise function g (z), maxout units divide z into\u00a0groups of k values. Each maxout unit then outputs the maximum element of one",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2136",
    "text": "-6.37",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2137",
    "text": "of these groups:",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2138",
    "text": "g(z)i = max zj",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2139",
    "text": "j&G",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2140",
    "text": "where G(i) is the indices of the inputs for group i, { (i \u2014 1) k + 1,..., ik}. This provides a way of learning a piecewise linear function that responds to multiple\u00a0directions in the input x space.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2141",
    "text": "A maxout unit can learn a piecewise linear, convex function with up to k pieces. Maxout units can thus be seen as learning the activation function itself rather\u00a0than just the relationship between units. With large enough k, a maxout unit can\u00a0learn to approximate any convex function with arbitrary fidelity. In particular,\u00a0a maxout layer with two pieces can learn to implement the same function of the\u00a0input x as a traditional layer using the rectified linear activation function, absolute\u00a0value rectification function, or the leaky or parametric ReLU, or can learn to\u00a0implement a totally different function altogether. The maxout layer will of course\u00a0be parametrized differently from any of these other layer types, so the learning\u00a0dynamics will be different even in the cases where maxout learns to implement the\u00a0same function of x as one of the other layer types.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2142",
    "text": "Each maxout unit is now parametrized by k weight vectors instead of just one, so maxout units typically need more regularization than rectified linear units. They\u00a0can work well without regularization if the training set is large and the number of\u00a0pieces per unit is kept low (Cai et al., 2013).",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2143",
    "text": "Maxout units have a few other benefits. In some cases, one can gain some statistical and computational advantages by requiring fewer parameters. Specifically, if the features captured by n different linear filters can be summarized without\u00a0losing information by taking the max over each group of k features, then the next\u00a0layer can get by with k times fewer weights.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2144",
    "text": "Because each unit is driven by multiple filters, maxout units have some redundancy that helps them to resist a phenomenon called catastrophic forgetting in which neural networks forget how to perform tasks that they were trained on in\u00a0the past (Goodfellow et al., 2014a).",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2145",
    "text": "Rectified linear units and all of these generalizations of them are based on the principle that models are easier to optimize if their behavior is closer to linear.\u00a0This same general principle of using linear behavior to obtain easier optimization\u00a0also applies in other contexts besides deep linear networks. Recurrent networks can\u00a0learn from sequences and produce a sequence of states and outputs. When training\u00a0them, one needs to propagate information through several time steps, which is much\u00a0easier when some linear computations (with some directional derivatives being of\u00a0magnitude near 1) are involved. One of the best-performing recurrent network\u00a0architectures, the LSTM, propagates information through time via summation\u2014a\u00a0particular straightforward kind of such linear activation. This is discussed further\u00a0in Sec. 10.10.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2146",
    "text": "Prior to the introduction of rectified linear units, most neural networks used the logistic sigmoid activation function",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2147",
    "text": "g(z) = a(z) \u00a0\u00a0\u00a0(6.38)",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2148",
    "text": "or the hyperbolic tangent activation function",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2149",
    "text": "g(z) = tanh(z). \u00a0\u00a0\u00a0(6.39)",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2150",
    "text": "These activation functions are closely related because tanh(z) = 2a(2z) \u2014 1.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2151",
    "text": "We have already seen sigmoid units as output units, used to predict the probability that a binary variable is 1. Unlike piecewise linear units, sigmoidal\u00a0units saturate across most of their domain\u2014they saturate to a high value when\u00a0z is very positive, saturate to a low value when z is very negative, and are only\u00a0strongly sensitive to their input when z is near 0. The widespread saturation of\u00a0sigmoidal units can make gradient-based learning very difficult. For this reason,\u00a0their use as hidden units in feedforward networks is now discouraged. Their use\u00a0as output units is compatible with the use of gradient-based learning when an\u00a0appropriate cost function can undo the saturation of the sigmoid in the output\u00a0layer.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2152",
    "text": "When a sigmoidal activation function must be used, the hyperbolic tangent activation function typically performs better than the logistic sigmoid. It resembles\u00a0the identity function more closely, in the sense that tanh (0) = 0 while a (0) = 2.\u00a0Because tanh is similar to identity near 0, training a deep neural network y =\u00a0wT tanh(UTtanh(VTx)) resembles training a linear model y = wTUTVTx so\u00a0long as the activations of the network can be kept small. This makes training the\u00a0tanh network easier.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2153",
    "text": "Sigmoidal activation functions are more common in settings other than feedforward networks. Recurrent networks, many probabilistic models, and some autoencoders have additional requirements that rule out the use of piecewise\u00a0linear activation functions and make sigmoidal units more appealing despite the\u00a0drawbacks of saturation.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2154",
    "text": "Many other types of hidden units are possible, but are used less frequently.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2155",
    "text": "In general, a wide variety of differentiable functions perform perfectly well. Many unpublished activation functions perform just as well as the popular ones.\u00a0To provide a concrete example, the authors tested a feedforward network using\u00a0h = cos(Wx + b) on the MNIST dataset and obtained an error rate of less than\u00a01%, which is competitive with results obtained using more conventional activation\u00a0functions. During research and development of new techniques, it is common\u00a0to test many different activation functions and find that several variations on\u00a0standard practice perform comparably. This means that usually new hidden unit\u00a0types are published only if they are clearly demonstrated to provide a significant\u00a0improvement. New hidden unit types that perform roughly comparably to known\u00a0types are so common as to be uninteresting.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2156",
    "text": "It would be impractical to list all of the hidden unit types that have appeared in the literature. We highlight a few especially useful and distinctive ones.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2157",
    "text": "One possibility is to not have an activation g(z) at all. One can also think of this as using the identity function as the activation function. We have already\u00a0seen that a linear unit can be useful as the output of a neural network. It may\u00a0also be used as a hidden unit. If every layer of the neural network consists of only\u00a0linear transformations, then the network as a whole will be linear. However, it\u00a0is acceptable for some layers of the neural network to be purely linear. Consider\u00a0a neural network layer with n inputs and p outputs, h = g( WTx + b). We may\u00a0replace this with two layers, with one layer using weight matrix U and the other\u00a0using weight matrix V. If the first layer has no activation function, then we have\u00a0essentially factored the weight matrix of the original layer based on W. The\u00a0factored approach is to compute h = g(VTUTx + b). If U produces q outputs,\u00a0then U and V together contain only (n + p)q parameters, while W contains np\u00a0parameters. For small q, this can be a considerable saving in parameters. It\u00a0comes at the cost of constraining the linear transformation to be low-rank, but\u00a0these low-rank relationships are often sufficient. Linear hidden units thus offer an\u00a0effective way of reducing the number of parameters in a network.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2158",
    "text": "Softmax units are another kind of unit that is usually used as an output (as described in Sec. 6.2.2.3) but may sometimes be used as a hidden unit. Softmax\u00a0units naturally represent a probability distribution over a discrete variable with k\u00a0possible values, so they may be used as a kind of switch. These kinds of hidden\u00a0units are usually only used in more advanced architectures that explicitly learn to\u00a0manipulate memory, described in Sec. 10.12.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2159",
    "text": "A few other reasonably common hidden unit types include:",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2160",
    "text": "\u2022 \u00a0\u00a0\u00a0Radial basis function or RBF unit: hi = exp ^\u2014^2 ||W\",i \u2014 x||2^. This\u00a0function becomes more active as x approaches a template W-7i. Because it\u00a0saturates to 0 for most x, it can be difficult to optimize.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2161",
    "text": "\u2022 Softplus: g(a) = Z(a) = log(1 + ea). This is a smooth version of the rectifier, introduced by Dugas et al. (2001) for function approximation and by Nair\u00a0and Hinton (2010) for the conditional distributions of undirected probabilistic\u00a0models. Glorot et al. (2011a) compared the softplus and rectifier and found\u00a0better results with the latter. The use of the softplus is generally discouraged.\u00a0The softplus demonstrates that the performance of hidden unit types can\u00a0be very counterintuitive\u2014one might expect it to have an advantage over\u00a0the rectifier due to being differentiable everywhere or due to saturating less\u00a0completely, but empirically it does not.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2162",
    "text": "\u2022 \u00a0\u00a0\u00a0Hard tanh: this is shaped similarly to the tanh and the rectifier but unlike\u00a0the latter, it is bounded, g(a) = max(\u2014 1,min(1 ,a)). It was introduced\u00a0by Collobert (2004).",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2163",
    "text": "Hidden unit design remains an active area of research and many useful hidden unit types remain to be discovered.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2164",
    "text": "Another key design consideration for neural networks is determining the architecture. The word architecture refers to the overall structure of the network: how many\u00a0units it should have and how these units should be connected to each other.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2165",
    "text": "Most neural networks are organized into groups of units called layers. Most neural network architectures arrange these layers in a chain structure, with each\u00a0layer being a function of the layer that preceded it. In this structure, the first layer\u00a0is given by",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2166",
    "text": "h(1) = g(1) (w(1)Tx + b(1)) , \u00a0\u00a0\u00a0(6.40)",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2167",
    "text": "the second layer is given by",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2168",
    "text": "h(2) = g(2) (w(2)Th(1) + b(2)) , \u00a0\u00a0\u00a0(6.41)",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2169",
    "text": "and so on.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2170",
    "text": "In these chain-based architectures, the main architectural considerations are to choose the depth of the network and the width of each layer. As we will see,\u00a0a network with even one hidden layer is sufficient to fit the training set. Deeper\u00a0networks often are able to use far fewer units per layer and far fewer parameters\u00a0and often generalize to the test set, but are also often harder to optimize. The\u00a0ideal network architecture for a task must be found via experimentation guided by\u00a0monitoring the validation set error.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2171",
    "text": "A linear model, mapping from features to outputs via matrix multiplication, can by definition represent only linear functions. It has the advantage of being easy to\u00a0train because many loss functions result in convex optimization problems when\u00a0applied to linear models. Unfortunately, we often want to learn nonlinear functions.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2172",
    "text": "At first glance, we might presume that learning a nonlinear function requires designing a specialized model family for the kind of nonlinearity we want to learn.\u00a0Fortunately, feedforward networks with hidden layers provide a universal approximation framework. Specifically, the universal approximation theorem (Hornik et al.,\u00a01989; Cybenko, 1989) states that a feedforward network with a linear output layer\u00a0and at least one hidden layer with any \u201csquashing\u201d activation function (such as\u00a0the logistic sigmoid activation function) can approximate any Borel measurable\u00a0function from one finite-dimensional space to another with any desired non-zero\u00a0amount of error, provided that the network is given enough hidden units. The\u00a0derivatives of the feedforward network can also approximate the derivatives of the\u00a0function arbitrarily well (Hornik et al., 1990). The concept of Borel measurability\u00a0is beyond the scope of this book; for our purposes it suffices to say that any\u00a0continuous function on a closed and bounded subset of Rn is Borel measurable\u00a0and therefore may be approximated by a neural network. A neural network may\u00a0also approximate any function mapping from any finite dimensional discrete space\u00a0to another. While the original theorems were first stated in terms of units with\u00a0activation functions that saturate both for very negative and for very positive\u00a0arguments, universal approximation theorems have also been proven for a wider\u00a0class of activation functions, which includes the now commonly used rectified linear\u00a0unit (Leshno et al., 1993).",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2173",
    "text": "The universal approximation theorem means that regardless of what function we are trying to learn, we know that a large MLP will be able to represent this\u00a0function. However, we are not guaranteed that the training algorithm will be able\u00a0to learn that function. Even if the MLP is able to represent the function, learning\u00a0can fail for two different reasons. First, the optimization algorithm used for training\u00a0may not be able to find the value of the parameters that corresponds to the desired\u00a0function. Second, the training algorithm might choose the wrong function due to\u00a0overfitting. Recall from Sec. 5.2.1 that the \u201cno free lunch\u201d theorem shows that\u00a0there is no universally superior machine learning algorithm. Feedforward networks\u00a0provide a universal system for representing functions, in the sense that, given a\u00a0function, there exists a feedforward network that approximates the function. There\u00a0is no universal procedure for examining a training set of specific examples and\u00a0choosing a function that will generalize to points not in the training set.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2174",
    "text": "The universal approximation theorem says that there exists a network large enough to achieve any degree of accuracy we desire, but the theorem does not\u00a0say how large this network will be. Barron (1993) provides some bounds on the\u00a0size of a single-layer network needed to approximate a broad class of functions.\u00a0Unfortunately, in the worse case, an exponential number of hidden units (possibly\u00a0with one hidden unit corresponding to each input configuration that needs to be\u00a0distinguished) may be required. This is easiest to see in the binary case: the\u00a0number of possible binary functions on vectors v <E {0, 1}n is 22 n and selecting\u00a0one such function requires 2\u2122 bits, which will in general require O(2n) degrees of\u00a0freedom.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2175",
    "text": "In summary, a feedforward network with a single layer is sufficient to represent any function, but the layer may be infeasibly large and may fail to learn and\u00a0generalize correctly. In many circumstances, using deeper models can reduce the\u00a0number of units required to represent the desired function and can reduce the\u00a0amount of generalization error.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2176",
    "text": "There exist families of functions which can be approximated efficiently by an architecture with depth greater than some value d, but which require a much larger\u00a0model if depth is restricted to be less than or equal to d. In many cases, the number\u00a0of hidden units required by the shallow model is exponential in n. Such results\u00a0were first proven for models that do not resemble the continuous, differentiable\u00a0neural networks used for machine learning, but have since been extended to these\u00a0models. The first results were for circuits of logic gates (Hastad, 1986). Later\u00a0work extended these results to linear threshold units with non-negative weights\u00a0(Hastad and Goldmann, 1991; Hajnal et al., 1993), and then to networks with\u00a0continuous-valued activations (Maass, 1992; Maass et al., 1994). Many modern\u00a0neural networks use rectified linear units. Leshno et al. (1993) demonstrated\u00a0that shallow networks with a broad family of non-polynomial activation functions,\u00a0including rectified linear units, have universal approximation properties, but these\u00a0results do not address the questions of depth or efficiency\u2014they specify only that\u00a0a sufficiently wide rectifier network could represent any function. Pascanu et al.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2177",
    "text": "(2013b) and Montufar et al. (2014) showed that functions representable with a deep rectifier net can require an exponential number of hidden units with a shallow\u00a0(one hidden layer) network. More precisely, they showed that piecewise linear\u00a0networks (which can be obtained from rectifier nonlinearities or maxout units) can\u00a0represent functions with a number of regions that is exponential in the depth of the\u00a0network. Fig. 6.5 illustrates how a network with absolute value rectification creates\u00a0mirror images of the function computed on top of some hidden unit, with respect\u00a0to the input of that hidden unit. Each hidden unit specifies where to fold the\u00a0input space in order to create mirror responses (on both sides of the absolute value\u00a0nonlinearity). By composing these folding operations, we obtain an exponentially\u00a0large number of piecewise linear regions which can capture all kinds of regular\u00a0(e.g., repeating) patterns.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2178",
    "text": "Figure 6.5: An intuitive, geometric explanation of the exponential advantage of deeper rectifier networks formally shown by Pascanu et al. (2014a) and by Montufar et al. (2014).\u00a0(Left) An absolute value rectification unit has the same output for every pair of mirror\u00a0points in its input. The mirror axis of symmetry is given by the hyperplane defined by the\u00a0weights and bias of the unit. A function computed on top of that unit (the green decision\u00a0surface) will be a mirror image of a simpler pattern across that axis of symmetry. (Center)\u00a0The function can be obtained by folding the space around the axis of symmetry. (Right)\u00a0Another repeating pattern can be folded on top of the first (by another downstream unit)\u00a0to obtain another symmetry (which is now repeated four times, with two hidden layers).",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2179",
    "text": "More precisely, the main theorem in Montufar et al. (2014) states that the number of linear regions carved out by a deep rectifier network with d inputs,\u00a0depth l, and n units per hidden layer, is",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2180",
    "text": "O ((n)\u201c-\u05f4n\u05be4.\u05be) . (\u05be,",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2181",
    "text": "i.e., exponential in the depth l. In the case of maxout networks with k filters per unit, the number of linear regions is",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2182",
    "text": "0[k(l-1)+d) . \u00a0\u00a0\u00a0(6.43)",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2183",
    "text": "Of course, there is no guarantee that the kinds of functions we want to learn in applications of machine learning (and in particular for AI) share such a property.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2184",
    "text": "We may also want to choose a deep model for statistical reasons. Any time we choose a specific machine learning algorithm, we are implicitly stating some\u00a0set of prior beliefs we have about what kind of function the algorithm should\u00a0learn. Choosing a deep model encodes a very general belief that the function we\u00a0want to learn should involve composition of several simpler functions. This can be\u00a0interpreted from a representation learning point of view as saying that we believe\u00a0the learning problem consists of discovering a set of underlying factors of variation\u00a0that can in turn be described in terms of other, simpler underlying factors of\u00a0variation. Alternately, we can interpret the use of a deep architecture as expressing\u00a0a belief that the function we want to learn is a computer program consisting of\u00a0multiple steps, where each step makes use of the previous step\u2019s output. These\u00a0intermediate outputs are not necessarily factors of variation, but can instead be\u00a0analogous to counters or pointers that the network uses to organize its internal\u00a0processing. Empirically, greater depth does seem to result in better generalization\u00a0for a wide variety of tasks (Bengio et al., 2007; Erhan et al., 2009; Bengio, 2009;\u00a0Mesnil et al., 2011; Ciresan et al., 2012; Krizhevsky et al., 2012; Sermanet et al.,\u00a02013; Farabet et al., 2013; Couprie et al., 2013; Kahou et al., 2013; Goodfellow\u00a0et al., 2014d; Szegedy et al., 2014a). See Fig. 6.6 and Fig. 6.7 for examples of some\u00a0of these empirical results. This suggests that using deep architectures does indeed\u00a0express a useful prior over the space of functions the model learns.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2185",
    "text": "So far we have described neural networks as being simple chains of layers, with the main considerations being the depth of the network and the width of each layer.\u00a0In practice, neural networks show considerably more diversity.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2186",
    "text": "Many neural network architectures have been developed for specific tasks. Specialized architectures for computer vision called convolutional networks are\u00a0described in Chapter 9. Feedforward networks may also be generalized to the\u00a0recurrent neural networks for sequence processing, described in Chapter 10, which\u00a0have their own architectural considerations.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2187",
    "text": "In general, the layers need not be connected in a chain, even though this is the most common practice. Many architectures build a main chain but then add extra\u00a0architectural features to it, such as skip connections going from layer i to layer\u00a0i + 2 or higher. These skip connections make it easier for the gradient to flow from\u00a0output layers to layers nearer the input.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2188",
    "text": "Number of hidden layers",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2189",
    "text": "Figure 6.6: Empirical results showing that deeper networks generalize better when used to transcribe multi-digit numbers from photographs of addresses. Data from Goodfellow\u00a0et al. (2014d). The test set accuracy consistently increases with increasing depth. See\u00a0Fig. 6.7 for a control experiment demonstrating that other increases to the model size do\u00a0not yield the same effect.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2190",
    "text": "Effect of Number of Parameters",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2191",
    "text": "kn",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2192",
    "text": "O",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2193",
    "text": "c3",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2194",
    "text": "S-l",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2195",
    "text": "\u05e7",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2196",
    "text": "O",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2197",
    "text": "o",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2198",
    "text": "c3",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2199",
    "text": "V)",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2200",
    "text": "\u00a3",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2201",
    "text": "Figure 6.7: Deeper models tend to perform better. This is not merely because the model is larger. This experiment from Goodfellow et al. (2014d) shows that increasing the number\u00a0of parameters in layers of convolutional networks without increasing their depth is not\u00a0nearly as effective at increasing test set performance. The legend indicates the depth of\u00a0network used to make each curve and whether the curve represents variation in the size of\u00a0the convolutional or the fully connected layers. We observe that shallow models in this\u00a0context overfit at around 20 million parameters while deep ones can benefit from having\u00a0over 60 million. This suggests that using a deep model expresses a useful preference over\u00a0the space of functions the model can learn. Specifically, it expresses a belief that the\u00a0function should consist of many simpler functions composed together. This could result\u00a0either in learning a representation that is composed in turn of simpler representations (e.g.,\u00a0corners defined in terms of edges) or in learning a program with sequentially dependent\u00a0steps (e.g., first locate a set of objects, then segment them from each other, then recognize\u00a0them).",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2202",
    "text": "Another key consideration of architecture design is exactly how to connect a pair of layers to each other. In the default neural network layer described by a linear\u00a0transformation via a matrix W, every input unit is connected to every output\u00a0unit. Many specialized networks in the chapters ahead have fewer connections, so\u00a0that each unit in the input layer is connected to only a small subset of units in\u00a0the output layer. These strategies for reducing the number of connections reduce\u00a0the number of parameters and the amount of computation required to evaluate\u00a0the network, but are often highly problem-dependent. For example, convolutional\u00a0networks, described in Chapter 9, use specialized patterns of sparse connections\u00a0that are very effective for computer vision problems. In this chapter, it is difficult\u00a0to give much more specific advice concerning the architecture of a generic neural\u00a0network. Subsequent chapters develop the particular architectural strategies that\u00a0have been found to work well for different application domains.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2203",
    "text": "When we use a feedforward neural network to accept an input x and produce an output y, information flows forward through the network. The inputs x provide\u00a0the initial information that then propagates up to the hidden units at each layer\u00a0and finally produces y. This is called forward propagation. During training,\u00a0forward propagation can continue onward until it produces a scalar cost J(6). The\u00a0back-propagation algorithm (Rumelhart et al., 1986a), often simply called backprop,\u00a0allows the information from the cost to then flow backwards through the network,\u00a0in order to compute the gradient.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2204",
    "text": "Computing an analytical expression for the gradient is straightforward, but numerically evaluating such an expression can be computationally expensive. The\u00a0back-propagation algorithm does so using a simple and inexpensive procedure.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2205",
    "text": "The term back-propagation is often misunderstood as meaning the whole learning algorithm for multi-layer neural networks. Actually, back-propagation\u00a0refers only to the method for computing the gradient, while another algorithm,\u00a0such as stochastic gradient descent, is used to perform learning using this gradient.\u00a0Furthermore, back-propagation is often misunderstood as being specific to multilayer neural networks, but in principle it can compute derivatives of any function\u00a0(for some functions, the correct response is to report that the derivative of the\u00a0function is undefined). Specifically, we will describe how to compute the gradient\u00a0Vx f (x, y) for an arbitrary function f, where x is a set of variables whose derivatives\u00a0are desired, and y is an additional set of variables that are inputs to the function\u00a0but whose derivatives are not required. In learning algorithms, the gradient we most\u00a0often require is the gradient of the cost function with respect to the parameters,\u00a0Vg J(0). Many machine learning tasks involve computing other derivatives, either\u00a0as part of the learning process, or to analyze the learned model. The back-propagation algorithm can be applied to these tasks as well, and is not restricted\u00a0to computing the gradient of the cost function with respect to the parameters. The\u00a0idea of computing derivatives by propagating information through a network is\u00a0very general, and can be used to compute values such as the Jacobian of a function\u00a0f with multiple outputs. We restrict our description here to the most commonly\u00a0used case where f has a single output.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2206",
    "text": "So far we have discussed neural networks with a relatively informal graph language. To describe the back-propagation algorithm more precisely, it is helpful to have a\u00a0more precise computational graph language.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2207",
    "text": "Many ways of formalizing computation as graphs are possible.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2208",
    "text": "Here, we use each node in the graph to indicate a variable. The variable may be a scalar, vector, matrix, tensor, or even a variable of another type.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2209",
    "text": "To formalize our graphs, we also need to introduce the idea of an operation. An operation is a simple function of one or more variables. Our graph language\u00a0is accompanied by a set of allowable operations. Functions more complicated\u00a0than the operations in this set may be described by composing many operations\u00a0together.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2210",
    "text": "Without loss of generality, we define an operation to return only a single output variable. This does not lose generality because the output variable can have\u00a0multiple entries, such as a vector. Software implementations of back-propagation\u00a0usually support operations with multiple outputs, but we avoid this case in our\u00a0description because it introduces many extra details that are not important to\u00a0conceptual understanding.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2211",
    "text": "If a variable y is computed by applying an operation to a variable x, then we draw a directed edge from x to y. We sometimes annotate the output node\u00a0with the name of the operation applied, and other times omit this label when the\u00a0operation is clear from context.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2212",
    "text": "Examples of computational graphs are shown in Fig. 6.8.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2213",
    "text": "(a) (b)",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2214",
    "text": "(c) \u00a0\u00a0\u00a0(d)",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2215",
    "text": "Figure 6.8: Examples of computational graphs. (a) The graph using thex operation to compute z = xy. (b) The graph for the logistic regression prediction y = a (xT w + 6).\u00a0Some of the intermediate expressions do not have names in the algebraic expression\u00a0but need names in the graph. We simply name the i-th such variable . (c) The\u00a0computational graph for the expression H = max{0, XW + b}, which computes a design\u00a0matrix of rectified linear unit activations H given a design matrix containing a minibatch\u00a0of inputs X. (d) Examples a-c applied at most one operation to each variable, but it\u00a0is possible to apply more than one operation. Here we show a computation graph that\u00a0applies more than one operation to the weights w of a linear regression model. The\u00a0weights are used to make the both the prediction y and the weight decay penalty A ^ i w2.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2216",
    "text": "The chain rule of calculus (not to be confused with the chain rule of probability) is used to compute the derivatives of functions formed by composing other functions\u00a0whose derivatives are known. Back-propagation is an algorithm that computes the\u00a0chain rule, with a specific order of operations that is highly efficient.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2217",
    "text": "Let x be a real number, and let f and g both be functions mapping from a real number to a real number. Suppose that y = g(x) and z = f (g(x)) = f (y). Then\u00a0the chain rule states that",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2218",
    "text": "-6.44",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2219",
    "text": "dz \u00a0\u00a0\u00a0dz dy",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2220",
    "text": "dx \u00a0\u00a0\u00a0dy dx",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2221",
    "text": "We can generalize this beyond the scalar case. Suppose that x G Rm, y G Rn, g maps from Rm to R\u2122, and f maps from Rn to R. If y = g (x) and z = f( y), then",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2222",
    "text": "dz",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2223",
    "text": "dx.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2224",
    "text": ". = \u00a3",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2225",
    "text": "dz dyj dyj dx i",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2226",
    "text": "-6.45",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2227",
    "text": "In vector notation, this may be equivalently written as",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2228",
    "text": "\u05be2\u05f4v \u00ae) =*\u05bev",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2229",
    "text": "T",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2230",
    "text": "-6.46",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2231",
    "text": "where is the n x m Jacobian matrix of g.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2232",
    "text": "From this we see that the gradient of a variable x can be obtained by multiplying a Jacobian matrix -gX by a gradient Vy z. The back-propagation algorithm consists\u00a0of performing such a Jacobian-gradient product for each operation in the graph.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2233",
    "text": "Usually we do not apply the back-propagation algorithm merely to vectors, but rather to tensors of arbitrary dimensionality. Conceptually, this is exactly the\u00a0same as back-propagation with vectors. The only difference is how the numbers\u00a0are arranged in a grid to form a tensor. We could imagine flattening each tensor\u00a0into a vector before we run back-propagation, computing a vector-valued gradient,\u00a0and then reshaping the gradient back into a tensor. In this rearranged view,\u00a0back-propagation is still just multiplying Jacobians by gradients.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2234",
    "text": "To denote the gradient of a value z with respect to a tensor X, we write Vxz, just as if X were a vector. The indices into X now have multiple coordinates\u2014for\u00a0example, a 3-D tensor is indexed by three coordinates. We can abstract this away\u00a0by using a single variable i to represent the complete tuple of indices. For all\u00a0possible index tuples i, (Vxz)i gives 4jXz. This is exactly the same as how for all",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2235",
    "text": "possible integer indicesi into a vector, (Vxz) gives q*. \u25a0 Using this notation, we can write the chain rule as it applies to tensors. If Y = g(X) and z = f (Y), then",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2236",
    "text": "Vx z = \u00a3(Vx Yj)",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2237",
    "text": "dz",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2238",
    "text": "-6.47",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2239",
    "text": "j",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2240",
    "text": "Using the chain rule, it is straightforward to write down an algebraic expression for the gradient of a scalar with respect to any node in the computational graph that\u00a0produced that scalar. However, actually evaluating that expression in a computer\u00a0introduces some extra considerations.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2241",
    "text": "Specifically, many subexpressions may be repeated several times within the overall expression for the gradient. Any procedure that computes the gradient\u00a0will need to choose whether to store these subexpressions or to recompute them\u00a0several times. An example of how these repeated subexpressions arise is given in\u00a0Fig. 6.9. In some cases, computing the same subexpression twice would simply\u00a0be wasteful. For complicated graphs, there can be exponentially many of these\u00a0wasted computations, making a naive implementation of the chain rule infeasible.\u00a0In other cases, computing the same subexpression twice could be a valid way to\u00a0reduce memory consumption at the cost of higher runtime.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2242",
    "text": "We first begin by a version of the back-propagation algorithm that specifies the actual gradient computation directly (Algorithm 6.2 along with Algorithm 6.1\u00a0for the associated forward computation), in the order it will actually be done and\u00a0according to the recursive application of chain rule. One could either directly\u00a0perform these computations or view the description of the algorithm as a symbolic\u00a0specification of the computational graph for computing the back-propagation. However, this formulation does not make explicit the manipulation and the construction\u00a0of the symbolic graph that performs the gradient computation. Such a formulation\u00a0is presented below in Sec. 6.5.6, with Algorithm 6.5, where we also generalize to\u00a0nodes that contain arbitrary tensors.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2243",
    "text": "First consider a computational graph describing how to compute a single scalar u(n) (say the loss on a training example). This scalar is the quantity whose\u00a0gradient we want to obtain, with respect to the n% input nodes u(1) to u(ni). In\u00a0other words we wish to compute dii) for all i G {1, 2,..., n}. In the application\u00a0of back-propagation to computing gradients for gradient descent over parameters,\u00a0u(n) will be the cost associated with an example or a minibatch, while u(1) to u(ni)\u00a0correspond to the parameters of the model.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2244",
    "text": "We will assume that the nodes of the graph have been ordered in such a way that we can compute their output one after the other, starting at u(ni+1) and\u00a0going up to u(n). As defined in Algorithm 6.1, each node u(i) is associated with an\u00a0operation f(i) and is computed by evaluating the function",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2245",
    "text": "u(i) = f (A(i)) \u00a0\u00a0\u00a0(6.48)",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2246",
    "text": "where A(i) is the set of all nodes that are parents of u(i).",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2247",
    "text": "Algorithm 6.1 A procedure that performs the computations mapping n% inputs u(1) to u(n^ to an output u(n). This defines a computational graph where each node\u00a0computes numerical value u(i) by applying a function f(i) to the set of arguments\u00a0A(i) that comprises the values of previous nodes u(j), j < i, with j G Pa(u(i)). The\u00a0input to the computational graph is the vector x, and is set into the first n% nodes\u00a0u(1) to u(n). The output of the computational graph is read off the last (output)",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2248",
    "text": "node u(n)._",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2249",
    "text": "for i = 1,...,n% do u(i) ^ x%\u00a0end for",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2250",
    "text": "for i = n% + 1,..., n do A(i) ^ {u(j) | j G Pa(u(i))}\u00a0u(i) ^ f (i)(A(i))\u00a0end for\u00a0return u(n)",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2251",
    "text": "That algorithm specifies the forward propagation computation, which we could put in a graph G. In order to perform back-propagation, we can construct a\u00a0computational graph that depends on G and adds to it an extra set of nodes. These\u00a0form a subgraph B with one node per node of G. Computation in B proceeds in\u00a0exactly the reverse of the order of computation in G, and each node of B computes\u00a0the derivative dujij associated with the forward graph node u(i). This is done\u00a0using the chain rule with respect to scalar output 1\u05f3in):",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2252",
    "text": "du(n)",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2253",
    "text": "du(j",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2254",
    "text": "#NAME?",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2255",
    "text": "i:jgPa(u(l))",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2256",
    "text": "du(n) du(i) du(i) du(j)",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2257",
    "text": "-6.49",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2258",
    "text": "as specified by Algorithm 6.2. The subgraph B contains exactly one edge for each edge from node u(j) to node u(i) of G. The edge from u(j) to u(i) is associated with\u00a0the computation of dj. In addition, a dot product is performed for each node,\u00a0between the gradient already computed with respect to nodes u(i) that are children\u00a0of u(j) and the vector containing the partial derivatives du(j) for the same children\u00a0nodes u(i). To summarize, the amount of computation required for performing\u00a0the back-propagation scales linearly with the number of edges in G, where the\u00a0computation for each edge corresponds to computing a partial derivative (of one\u00a0node with respect to one of its parents) as well as performing one multiplication\u00a0and one addition. Below, we generalize this analysis to tensor-valued nodes, which\u00a0is just a way to group multiple scalar values in the same node and enable more\u00a0efficient implementations.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2259",
    "text": "Algorithm 6.2 Simplified version of the back-propagation algorithm for computing the derivatives of u(n) with respect to the variables in the graph. This example is\u00a0intended to further understanding by showing a simplified case where all variables\u00a0are scalars, and we wish to compute the derivatives with respect to u(1),..., u(ni).\u00a0This simplified version computes the derivatives of all nodes in the graph. The\u00a0computational cost of this algorithm is proportional to the number of edges in\u00a0the graph, assuming that the partial derivative associated with each edge requires\u00a0a constant time. This is of the same order as the number of computations for\u00a0the forward propagation. Each dj is a function of the parents u(j) of u(i), thus\u00a0linking the nodes of the forward graph to those added for the back-propagation\u00a0graph.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2260",
    "text": "Run forward propagation (Algorithm 6.1 for this example) to obtain the activations of the network",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2261",
    "text": "Initialize grad_table, a data structure that will store the derivatives that have",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2262",
    "text": "been computed. The entry grad_table[u(i)] will store the computed value of",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2263",
    "text": "du(n) du(i) .",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2264",
    "text": "grad_table[du(n) ] ^ 1 for j = n \u2014 1 down to 1 do",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2265",
    "text": "Ei:jePa(u(0) fuS iuU) using stored values:",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2266",
    "text": "The next line computes dUu)",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2267",
    "text": "3u(i) du(j)",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2268",
    "text": "grad_ table [u(i)]",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2269",
    "text": "J i: jePa(u(i))",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2270",
    "text": "grad_table[u(j) ] ^ Ei -",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2271",
    "text": "end for return {grad_table [u(i)] | i = 1,..., ni}",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2272",
    "text": "The back-propagation algorithm is designed to reduce the number of common subexpressions without regard to memory. Specifically, it performs on the order\u00a0of one Jacobian product per node in the graph. This can be seen from the fact\u00a0in Algorithm 6.2 that backprop visits each edge from node u(j) to node u(i) of\u00a0the graph exactly once in order to obtain the associated partial derivative ^Up\u05be).\u00a0Back-propagation thus avoids the exponential explosion in repeated subexpressions.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2273",
    "text": "However, other algorithms may be able to avoid more subexpressions by performing simplifications on the computational graph, or may be able to conserve memory by\u00a0recomputing rather than storing some subexpressions. We will revisit these ideas\u00a0after describing the back-propagation algorithm itself.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2274",
    "text": "To clarify the above definition of the back-propagation computation, let us consider the specific graph associated with a fully-connected multi-layer MLP.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2275",
    "text": "Algorithm 6.3 first shows the forward propagation, which maps parameters to the supervised loss L(y, y) associated with a single (input,target) training example\u00a0(x, y), with y the output of the neural network when x is provided in input.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2276",
    "text": "Algorithm 6.4 then shows the corresponding computation to be done for applying the back-propagation algorithm to this graph.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2277",
    "text": "Algorithm 6.3 and Algorithm 6.4 are demonstrations that are chosen to be simple and straightforward to understand. However, they are specialized to one\u00a0specific problem.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2278",
    "text": "Modern software implementations are based on the generalized form of back-propagation described in Sec. 6.5.6 below, which can accommodate any computational graph by explicitly manipulating a data structure for representing symbolic computation.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2279",
    "text": "Algebraic expressions and computational graphs both operate on symbols, or variables that do not have specific values. These algebraic and graph-based\u00a0representations are called symbolic representations. When we actually use or\u00a0train a neural network, we must assign specific values to these symbols. We\u00a0replace a symbolic input to the network x with a specific numeric value, such as\u00a0[1.2,3.765, \u20141.8]t .",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2280",
    "text": "Some approaches to back-propagation take a computational graph and a set of numerical values for the inputs to the graph, then return a set of numerical\u00a0values describing the gradient at those input values. We call this approach \u201csymbol-to-number\u201d differentiation. This is the approach used by libraries such as Torch\u00a0(Collobert et al., 2011b) and Caffe (Jia, 2013).",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2281",
    "text": "Another approach is to take a computational graph and add additional nodes to the graph that provide a symbolic description of the desired derivatives. This",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2282",
    "text": "dz dw",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2283",
    "text": "-6.5",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2284",
    "text": "-6.51",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2285",
    "text": "dz dy dx dy dx dw",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2286",
    "text": "-6.52",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2287",
    "text": "-6.53",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2288",
    "text": "(x)f(w)",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2289",
    "text": "f /(f (f (w)))f/(f (w))f'(w)",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2290",
    "text": "Eq. 6.52 suggests an implementation in which we compute the value of f (w) only once and store it in the variable x. This is the approach taken by the back-propagation\u00a0algorithm. An alternative approach is suggested by Eq. 6.53, where the subexpression\u00a0f(w) appears more than once. In the alternative approach, f (w) is recomputed each time\u00a0it is needed. When the memory required to store the value of these expressions is low,\u00a0the back-propagation approach of Eq. 6.52 is clearly preferable because of its reduced\u00a0runtime. However, Eq. 6.53 is also a valid implementation of the chain rule, and is useful\u00a0when memory is limited.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2291",
    "text": "Algorithm 6.3 Forward propagation through a typical deep neural network and the computation of the cost function. The loss L(y, y) depends on the output y\u00a0and on the target y (see Sec. 6.2.1.1 for examples of loss functions). To obtain the\u00a0total cost J, the loss may be added to a regularizer 0(9), where 9 contains all the\u00a0parameters (weights and biases). Algorithm 6.4 shows how to compute gradients\u00a0of J with respect to parameters W and b. For simplicity, this demonstration uses\u00a0only a single input example x. Practical applications should use a minibatch. See\u00a0Sec. 6.5.7 for a more realistic demonstration.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2292",
    "text": "Require: Network depth, l",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2293",
    "text": "Require: W(i), i \u00a3 {1,..., l}, the weight matrices of the model Require: bW, i \u00a3 {1,..., l}, the bias parameters of the model\u00a0Require: x, the input to process\u00a0Require: y, the target output\u00a0h(0) = x",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2294",
    "text": "for k = 1,..., l do",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2295",
    "text": "a = b(k) + W(k) h(k-1) h(k) = f (a(k))\u00a0end for",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2296",
    "text": "y =",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2297",
    "text": "J = L(y, y) + A 0(9)",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2298",
    "text": "is the approach taken by Theano (Bergstra et al., 2010; Bastien et al., 2012) and TensorFlow (Abadi et al., 2015). An example of how this approach works\u00a0is illustrated in Fig. 6.10. The primary advantage of this approach is that\u00a0the derivatives are described in the same language as the original expression.\u00a0Because the derivatives are just another computational graph, it is possible to run\u00a0back-propagation again, differentiating the derivatives in order to obtain higher\u00a0derivatives. Computation of higher-order derivatives is described in Sec. 6.5.10.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2299",
    "text": "We will use the latter approach and describe the back-propagation algorithm in terms of constructing a computational graph for the derivatives. Any subset of the\u00a0graph may then be evaluated using specific numerical values at a later time. This\u00a0allows us to avoid specifying exactly when each operation should be computed.\u00a0Instead, a generic graph evaluation engine can evaluate every node as soon as its\u00a0parents\u2019 values are available.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2300",
    "text": "The description of the symbol-to-symbol based approach subsumes the symbol-to-number approach. The symbol-to-number approach can be understood as performing exactly the same computations as are done in the graph built by the\u00a0symbol-to-symbol approach. The key difference is that the symbol-to-number",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2301",
    "text": "Algorithm 6.4 Backward computation for the deep neural network of Algorithm 6.3, which uses in addition to the input x a target y. This computation yields the gradients on the activations a(k) for each layer k, starting from the\u00a0output layer and going backwards to the first hidden layer. From these gradients,\u00a0which can be interpreted as an indication of how each layer\u2019s output should change\u00a0to reduce error, one can obtain the gradient on the parameters of each layer. The\u00a0gradients on weights and biases can be immediately used as part of a stochastic gradient update (performing the update right after the gradients have been\u00a0computed) or used with other gradient-based optimization methods.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2302",
    "text": "y",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2303",
    "text": "X",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2304",
    "text": "w",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2305",
    "text": "Figure 6.10: An example of the symbol-to-symbol approach to computing derivatives. In this approach, the back-propagation algorithm does not need to ever access any actual\u00a0specific numeric values. Instead, it adds nodes to a computational graph describing how\u00a0to compute these derivatives. A generic graph evaluation engine can later compute the\u00a0derivatives for any specific numeric values. (Left) In this example, we begin with a graph\u00a0representing z = f(f (f(w))). (Right) We run the back-propagation algorithm, instructing\u00a0it to construct the graph for the expression corresponding to JW. In this example, we do\u00a0not explain how the back-propagation algorithm works. The purpose is only to illustrate\u00a0what the desired result is: a computational graph with a symbolic description of the\u00a0derivative.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2306",
    "text": "approach does not expose the graph.",
    "chapter": "Convolutional Networks",
    "chapter_id": "main-12.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2307",
    "text": "The back-propagation algorithm is very simple. To compute the gradient of some scalar z with respect to one of its ancestors x in the graph, we begin by observing\u00a0that the gradient with respect to z is given by = 1. We can then compute\u00a0the gradient with respect to each parent of z in the graph by multiplying the\u00a0current gradient by the Jacobian of the operation that produced z. We continue\u00a0multiplying by Jacobians traveling backwards through the graph in this way until\u00a0we reach x. For any node that may be reached by going backwards from z through\u00a0two or more paths, we simply sum the gradients arriving from different paths at\u00a0that node.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2308",
    "text": "More formally, each node in the graph G corresponds to a variable. To achieve maximum generality, we describe this variable as being a tensor V. Tensor can",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2309",
    "text": "in general have any number of dimensions, and subsume scalars, vectors, and matrices.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2310",
    "text": "We assume that each variable V is associated with the following subroutines:",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2311",
    "text": "\u2022 \u00a0\u00a0\u00a0get_operation(V): This returns the operation that computes V, represented by the edges coming into V in the computational graph. For example,\u00a0there may be a Python or C++ class representing the matrix multiplication\u00a0operation, and the get_operation function. Suppose we have a variable that\u00a0is created by matrix multiplication, C = AB. Then get_operation(V)\u00a0returns a pointer to an instance of the corresponding C+\u2014+ class.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2312",
    "text": "\u2022 \u00a0\u00a0\u00a0get_consumers(V, G): This returns the list of variables that are children of\u00a0V in the computational graph G.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2313",
    "text": "\u2022 \u00a0\u00a0\u00a0get_inputs(V, G): This returns the list of variables that are parents of V\u00a0in the computational graph G.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2314",
    "text": "Each operation op is also associated with a bprop operation. This bprop operation can compute a Jacobian-vector product as described by Eq. 6.47. This\u00a0is how the back-propagation algorithm is able to achieve great generality. Each\u00a0operation is responsible for knowing how to back-propagate through the edges in\u00a0the graph that it participates in. For example, we might use a matrix multiplication\u00a0operation to create a variable C = AB. Suppose that the gradient of a scalar z with\u00a0respect to C is given by G. The matrix multiplication operation is responsible for\u00a0defining two back-propagation rules, one for each of its input arguments. If we call\u00a0the bprop method to request the gradient with respect to A given that the gradient\u00a0on the output is G, then the bprop method of the matrix multiplication operation\u00a0must state that the gradient with respect to A is given by GBT. Likewise, if we\u00a0call the bprop method to request the gradient with respect to B, then the matrix\u00a0operation is responsible for implementing the bprop method and specifying that\u00a0the desired gradient is given by ATG. The back-propagation algorithm itself does\u00a0not need to know any differentiation rules. It only needs to call each operation\u2019s\u00a0bprop rules with the right arguments. Formally, op.bprop (inputs, X, G) must\u00a0return",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2315",
    "text": "^(Vxop.f (inputs)) Gi, \u00a0\u00a0\u00a0(6.54)",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2316",
    "text": "i",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2317",
    "text": "which is just an implementation of the chain rule as expressed in Eq. 6.47. Here, inputs is a list of inputs that are supplied to the operation, op.f is the\u00a0mathematical function that the operation implements, X is the input whose gradient\u00a0we wish to compute, and G is the gradient on the output of the operation.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2318",
    "text": "The op. bprop method should always pretend that all of its inputs are distinct from each other, even if they are not. For example, if the mul operator is passed",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2319",
    "text": "C\\",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2320",
    "text": "two copies of x to compute x , the op.bprop method should still return x as the derivative with respect to both inputs. The back-propagation algorithm will later\u00a0add both of these arguments together to obtain 2x, which is the correct total\u00a0derivative on x.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2321",
    "text": "Software implementations of back-propagation usually provide both the operations and their bprop methods, so that users of deep learning software libraries are able to back-propagate through graphs built using common operations like matrix\u00a0multiplication, exponents, logarithms, and so on. Software engineers who build a\u00a0new implementation of back-propagation or advanced users who need to add their\u00a0own operation to an existing library must usually derive the op. bprop method for\u00a0any new operations manually.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2322",
    "text": "The back-propagation algorithm is formally described in Algorithm 6.5.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2323",
    "text": "Algorithm 6.5 The outermost skeleton of the back-propagation algorithm. This portion does simple setup and cleanup work. Most of the important work happens\u00a0in the build_grad subroutine of Algorithm 6.6",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2324",
    "text": "Require: T, the target set of variables whose gradients must be computed. Require: G, the computational graph\u00a0Require: z, the variable to be differentiated",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2325",
    "text": "Let G' be G pruned to contain only nodes that are ancestors of z and descendents of nodes in T.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2326",
    "text": "Initialize grad_table, a data structure associating tensors to their gradients grad_table[z] ^ 1\u00a0for V in T do",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2327",
    "text": "build_grad(V, G, G', grad_table) end for",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2328",
    "text": "Return grad_table restricted to T",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2329",
    "text": "In Sec. 6.5.2, we motivated back-propagation as a strategy for avoiding computing the same subexpression in the chain rule multiple times. The naive algorithm could have exponential runtime due to these repeated subexpressions. Now that\u00a0we have specified the back-propagation algorithm, we can understand its computational cost. If we assume that each operation evaluation has roughly the\u00a0same cost, then we may analyze the computational cost in terms of the number\u00a0of operations executed. Keep in mind here that we refer to an operation as the\u00a0fundamental unit of our computational graph, which might actually consist of very",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2330",
    "text": "Algorithm 6.6 The inner loop subroutine build_grad(V, G, G, grad_table) of",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2331",
    "text": "the back-propagation algorithm, called by the back-propagation algorithm defined",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2332",
    "text": "in Algorithm 6.5.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2333",
    "text": "Require: V, the variable whose gradient should be added to G and grad_table.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2334",
    "text": "Require: G, the graph to modify.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2335",
    "text": "Require: G, the restriction of G to nodes that participate in the gradient.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2336",
    "text": "Require: grad_table, a data structure mapping nodes to their gradients if V is in grad_table then\u00a0Return grad_table [V]\u00a0end if\u00a0i ^ 1",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2337",
    "text": "for C in get_consumers(V, G) do op ^ get_operation(C)",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2338",
    "text": "D ^ build_grad(C, G, G', grad_table)",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2339",
    "text": "G(i) ^ op.bprop(get_inputs(C, G'), V, D) i ^ i + 1\u00a0end for",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2340",
    "text": "G ^ E\u05be G(\u05be)",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2341",
    "text": "grad_table[V] = G",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2342",
    "text": "Insert G and the operations creating it into G Return G",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2343",
    "text": "many arithmetic operations (for example, we might have a graph that treats matrix multiplication as a single operation). Computing a gradient in a graph with n nodes\u00a0will never execute more than O(n2) operations or store the output of more than\u00a0O(n2) operations. Here we are counting operations in the computational graph, not\u00a0individual operations executed by the underlying hardware, so it is important to\u00a0remember that the runtime of each operation may be highly variable. For example,\u00a0multiplying two matrices that each contain millions of entries might correspond to\u00a0a single operation in the graph. We can see that computing the gradient requires as\u00a0most O(n 2) operations because the forward propagation stage will at worst execute\u00a0all n nodes in the original graph (depending on which values we want to compute,\u00a0we may not need to execute the entire graph). The back-propagation algorithm\u00a0adds one Jacobian-vector product, which should be expressed with O( 1) nodes, per\u00a0edge in the original graph. Because the computational graph is a directed acyclic\u00a0graph it has at most O(n2) edges. For the kinds of graphs that are commonly used\u00a0in practice, the situation is even better. Most neural network cost functions are\u00a0roughly chain-structured, causing back-propagation to have O(n) cost. This is far",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2344",
    "text": "better than the naive approach, which might need to execute exponentially many nodes. This potentially exponential cost can be seen by expanding and rewriting\u00a0the recursive chain rule (Eq. 6.49) non-recursively:",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2345",
    "text": "du(n)",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2346",
    "text": "Qu^k )",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2347",
    "text": "path (u(n1 \\u (712) \u00a0\u00a0\u00a0)),",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2348",
    "text": "from n1=j to nt=n",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2349",
    "text": "k=2",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2350",
    "text": "-1)'",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2351",
    "text": "-6.55",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2352",
    "text": "Since the number of paths from node j to node n can grow up to exponentially in the length of these paths, the number of terms in the above sum, which is the number\u00a0of such paths, can grow exponentially with the depth of the forward propagation\u00a0graph. This large cost would be incurred because the same computation for\u00a0dU(j) would be redone many times. To avoid such recomputation, we can think\u00a0of back-propagation as a table-filling algorithm that takes advantage of storing\u00a0intermediate results . Each node in the graph has a corresponding slot in a\u00a0table to store the gradient for that node. By filling in these table entries in order,\u00a0back-propagation avoids repeating many common subexpressions. This table-filling\u00a0strategy is sometimes called dynamic programming.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2353",
    "text": "As an example, we walk through the back-propagation algorithm as it is used to train a multilayer perceptron.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2354",
    "text": "Here we develop a very simple multilayer perception with a single hidden layer. To train this model, we will use minibatch stochastic gradient descent.\u00a0The back-propagation algorithm is used to compute the gradient of the cost on a\u00a0single minibatch. Specifically, we use a minibatch of examples from the training\u00a0set formatted as a design matrix X and a vector of associated class labels y.\u00a0The network computes a layer of hidden features H = max{0, XW(1)}. To\u00a0simplify the presentation we do not use biases in this model. We assume that our\u00a0graph language includes a relu operation that can compute max{0, Z} elementwise. The predictions of the unnormalized log probabilities over classes are then\u00a0given by HW(2). We assume that our graph language includes a cross_entropy\u00a0operation that computes the cross-entropy between the targets y and the probability\u00a0distribution defined by these unnormalized log probabilities. The resulting crossentropy defines the cost Jmle . Minimizing this cross-entropy performs maximum\u00a0likelihood estimation of the classifier. However, to make this example more realistic,",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2355",
    "text": "Figure 6.11: The computational graph used to compute the cost used to train our example of a single-layer MLP using the cross-entropy loss and weight decay.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2356",
    "text": "we also include a regularization term. The total cost",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2357",
    "text": "J = Jmle + A fe \u00ab)2 + \u00a3 (wj)",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2358",
    "text": "2",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2359",
    "text": "-6.56",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2360",
    "text": "consists of the cross-entropy and a weight decay term with coefficient A. The computational graph is illustrated in Fig. 6.11.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2361",
    "text": "The computational graph for the gradient of this example is large enough that it would be tedious to draw or to read. This demonstrates one of the benefits\u00a0of the back-propagation algorithm, which is that it can automatically generate\u00a0gradients that would be straightforward but tedious for a software engineer to\u00a0derive manually.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2362",
    "text": "We can roughly trace out the behavior of the back-propagation algorithm by looking at the forward propagation graph in Fig. 6.11. To train, we wish\u00a0to compute both V W(1) J and\u00a0\u00a0\u00a0\u00a0(2)J. There are two different paths leading",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2363",
    "text": "backward from J to the weights: one through the cross-entropy cost, and one through the weight decay cost. The weight decay cost is relatively simple; it will\u00a0always contribute\u00a0\u00a0\u00a0\u00a0to the gradient on W(i).",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2364",
    "text": "The other path through the cross-entropy cost is slightly more complicated. Let G be the gradient on the unnormalized log probabilities U(2) provided by\u00a0the cross_entropy operation. The back-propagation algorithm now needs to\u00a0explore two different branches. On the shorter branch, it adds HTG to the\u00a0gradient on W(2), using the back-propagation rule for the second argument to\u00a0the matrix multiplication operation. The other branch corresponds to the longer\u00a0chain descending further along the network. First, the back-propagation algorithm\u00a0computes Vh J = GW(2)T using the back-propagation rule for the first argument\u00a0to the matrix multiplication operation. Next, the relu operation uses its back-propagation rule to zero out components of the gradient corresponding to entries\u00a0of U(1) that were less than 0. Let the result be called G'. The last step of the\u00a0back-propagation algorithm is to use the back-propagation rule for the second\u00a0argument of the matmul operation to add XTG' to the gradient on W(1).",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2365",
    "text": "After these gradients have been computed, it is the responsibility of the gradient descent algorithm, or another optimization algorithm, to use these gradients to\u00a0update the parameters.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2366",
    "text": "For the MLP, the computational cost is dominated by the cost of matrix multiplication. During the forward propagation stage, we multiply by each weight\u00a0matrix, resulting in O(w) multiply-adds, where w is the number of weights. During\u00a0the backward propagation stage, we multiply by the transpose of each weight\u00a0matrix, which has the same computational cost. The main memory cost of the\u00a0algorithm is that we need to store the input to the nonlinearity of the hidden layer.\u00a0This value is stored from the time it is computed until the backward pass has\u00a0returned to the same point. The memory cost is thus O(mn,), where m is the\u00a0number of examples in the minibatch and n, is the number of hidden units.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2367",
    "text": "Our description of the back-propagation algorithm here is simpler than the implementations actually used in practice.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2368",
    "text": "As noted above, we have restricted the definition of an operation to be a function that returns a single tensor. Most software implementations need to\u00a0support operations that can return more than one tensor. For example, if we wish\u00a0to compute both the maximum value in a tensor and the index of that value, it is\u00a0best to compute both in a single pass through memory, so it is most efficient to\u00a0implement this procedure as a single operation with two outputs.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2369",
    "text": "We have not described how to control the memory consumption of back-propagation. Back-propagation often involves summation of many tensors together.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2370",
    "text": "In the naive approach, each of these tensors would be computed separately, then all of them would be added in a second step. The naive approach has an overly\u00a0high memory bottleneck that can be avoided by maintaining a single buffer and\u00a0adding each value to that buffer as it is computed.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2371",
    "text": "Real-world implementations of back-propagation also need to handle various data types, such as 32-bit floating point, 64-bit floating point, and integer values.\u00a0The policy for handling each of these types takes special care to design.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2372",
    "text": "Some operations have undefined gradients, and it is important to track these cases and determine whether the gradient requested by the user is undefined.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2373",
    "text": "Various other technicalities make real-world differentiation more complicated. These technicalities are not insurmountable, and this chapter has described the key\u00a0intellectual tools needed to compute derivatives, but it is important to be aware\u00a0that many more subtleties exist.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2374",
    "text": "The deep learning community has been somewhat isolated from the broader computer science community and has largely developed its own cultural attitudes\u00a0concerning how to perform differentiation. More generally, the field of automatic\u00a0differentiation is concerned with how to compute derivatives algorithmically. The\u00a0back-propagation algorithm described here is only one approach to automatic\u00a0differentiation. It is a special case of a broader class of techniques called reverse\u00a0mode accumulation. Other approaches evaluate the subexpressions of the chain rule\u00a0in different orders. In general, determining the order of evaluation that results in\u00a0the lowest computational cost is a difficult problem. Finding the optimal sequence\u00a0of operations to compute the gradient is NP-complete (Naumann, 2008), in the\u00a0sense that it may require simplifying algebraic expressions into their least expensive\u00a0form.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2375",
    "text": "For example, suppose we have variables pi ,p2,... , pn representing probabilities and variables zi, z2 ,..., zn representing unnormalized log probabilities. Suppose\u00a0we define",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2376",
    "text": "_ exP(zi)",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2377",
    "text": "* \u00a0\u00a0\u00a0i exp(zi),\u00a0\u00a0\u00a0\u00a0(' \u05d9",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2378",
    "text": "where we build the softmax function out of exponentiation, summation and division operations, and construct a cross-entropy loss J = \u2014 ^ipi log qi. A human\u00a0mathematician can observe that the derivative of J with respect to z i takes a very\u00a0simple form: qi \u2014 pi. The back-propagation algorithm is not capable of simplifying\u00a0the gradient this way, and will instead explicitly propagate gradients through all of\u00a0the logarithm and exponentiation operations in the original graph. Some software\u00a0libraries such as Theano (Bergstra et al., 2010; Bastien et al., 2012) are able to\u00a0perform some kinds of algebraic substitution to improve over the graph proposed\u00a0by the pure back-propagation algorithm.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2379",
    "text": "When the forward graph G has a single output node and each partial derivative dU(j) can be computed with a constant amount of computation, back-propagation\u00a0guarantees that the number of computations for the gradient computation is of\u00a0the same order as the number of computations for the forward computation: this\u00a0can be seen in Algorithm 6.2 because each local partial derivative dujj) needs\u00a0to be computed only once along with an associated multiplication and addition\u00a0for the recursive chain-rule formulation (Eq. 6.49). The overall computation is\u00a0therefore O(# edges). However, it can potentially be reduced by simplifying the\u00a0computational graph constructed by back-propagation, and this is an NP-complete\u00a0task. Implementations such as Theano and TensorFlow use heuristics based on\u00a0matching known simplification patterns in order to iteratively attempt to simplify\u00a0the graph. We defined back-propagation only for the computation of a gradient of a\u00a0scalar output but back-propagation can be extended to compute a Jacobian (either\u00a0of k different scalar nodes in the graph, or of a tensor-valued node containing k\u00a0values). A naive implementation may then need k times more computation: for\u00a0each scalar internal node in the original forward graph, the naive implementation\u00a0computes k gradients instead of a single gradient. When the number of outputs\u00a0of the graph is larger than the number of inputs, it is sometimes preferable to\u00a0use another form of automatic differentiation called forward mode accumulation.\u00a0Forward mode computation has been proposed for obtaining real-time computation\u00a0of gradients in recurrent networks, for example (Williams and Zipser, 1989). This\u00a0also avoids the need to store the values and gradients for the whole graph, trading\u00a0off computational efficiency for memory. The relationship between forward mode\u00a0and backward mode is analogous to the relationship between left-multiplying versus\u00a0right-multiplying a sequence of matrices, such as",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2380",
    "text": "-6.58",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2381",
    "text": "ABCD,",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2382",
    "text": "where the matrices can be thought of as Jacobian matrices. For example, if D is a column vector while A has many rows, this corresponds to a graph with a\u00a0single output and many inputs, and starting the multiplications from the end\u00a0and going backwards only requires matrix-vector products. This corresponds to\u00a0the backward mode. Instead, starting to multiply from the left would involve a\u00a0series of matrix-matrix products, which makes the whole computation much more\u00a0expensive. However, if A has fewer rows than D has columns, it is cheaper to run\u00a0the multiplications left-to-right, corresponding to the forward mode.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2383",
    "text": "In many communities outside of machine learning, it is more common to implement differentiation software that acts directly on traditional programming\u00a0language code, such as Python or C code, and automatically generates programs\u00a0that different functions written in these languages. In the deep learning community,\u00a0computational graphs are usually represented by explicit data structures created by\u00a0specialized libraries. The specialized approach has the drawback of requiring the\u00a0library developer to define the bprop methods for every operation and limiting the\u00a0user of the library to only those operations that have been defined. However, the\u00a0specialized approach also has the benefit of allowing customized back-propagation\u00a0rules to be developed for each operation, allowing the developer to improve speed\u00a0or stability in non-obvious ways that an automatic procedure would presumably\u00a0be unable to replicate.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2384",
    "text": "Back-propagation is therefore not the only way or the optimal way of computing the gradient, but it is a very practical method that continues to serve the deep\u00a0learning community very well. In the future, differentiation technology for deep\u00a0networks may improve as deep learning practitioners become more aware of advances\u00a0in the broader field of automatic differentiation.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2385",
    "text": "Some software frameworks support the use of higher-order derivatives. Among the deep learning software frameworks, this includes at least Theano and TensorFlow.\u00a0These libraries use the same kind of data structure to describe the expressions for\u00a0derivatives as they use to describe the original function being differentiated. This\u00a0means that the symbolic differentiation machinery can be applied to derivatives.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2386",
    "text": "In the context of deep learning, it is rare to compute a single second derivative of a scalar function. Instead, we are usually interested in properties of the Hessian\u00a0matrix. If we have a function f : Rn ^ R, then the Hessian matrix is of size n x n.\u00a0In typical deep learning applications, n will be the number of parameters in the\u00a0model, which could easily number in the billions. The entire Hessian matrix is\u00a0thus infeasible to even represent.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2387",
    "text": "Instead of explicitly computing the Hessian, the typical deep learning approach is to use Krylov methods. Krylov methods are a set of iterative techniques for\u00a0performing various operations like approximately inverting a matrix or finding\u00a0approximations to its eigenvectors or eigenvalues, without using any operation\u00a0other than matrix-vector products.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2388",
    "text": "In order to use Krylov methods on the Hessian, we only need to be able to compute the product between the Hessian matrix H and an arbitrary vector v. A",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2389",
    "text": "straightforward technique (Christianson, 1992) for doing so is to compute",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2390",
    "text": "Hv = V x",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2391",
    "text": "(V*f (x))T v",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2392",
    "text": "-6.59",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2393",
    "text": "Both of the gradient computations in this expression may be computed automatically by the appropriate software library. Note that the outer gradient expression takes the gradient of a function of the inner gradient expression.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2394",
    "text": "If v is itself a vector produced by a computational graph, it is important to specify that the automatic differentiation software should not differentiate through\u00a0the graph that produced v.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2395",
    "text": "While computing the Hessian is usually not advisable, it is possible to do with Hessian vector products. One simply computes He(i) for all i = 1,..., n, where",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2396",
    "text": "e(i) is the one-hot vector with e(i) = 1 and all other entries equal to 0.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2397",
    "text": "Feedforward networks can be seen as efficient nonlinear function approximators based on using gradient descent to minimize the error in a function approximation.\u00a0From this point of view, the modern feedforward network is the culmination of\u00a0centuries of progress on the general function approximation task.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2398",
    "text": "The chain rule that underlies the back-propagation algorithm was invented in the 17th century (Leibniz, 1676; L\u2019Hopital, 1696). Calculus and algebra have\u00a0long been used to solve optimization problems in closed form, but gradient descent\u00a0was not introduced as a technique for iteratively approximating the solution to\u00a0optimization problems until the 19th century (Cauchy, 1847).",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2399",
    "text": "Beginning in the 1940s, these function approximation techniques were used to motivate machine learning models such as the perceptron. However, the earliest\u00a0models were based on linear models. Critics including Marvin Minsky pointed\u00a0out several of the flaws of the linear model family, such as it inability to learn the\u00a0XOR function, which led to a backlash against the entire neural network approach.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2400",
    "text": "Learning nonlinear functions required the development of a multilayer per-ceptron and a means of computing the gradient through such a model. Efficient applications of the chain rule based on dynamic programming began to appear in the\u00a01960s and 1970s, mostly for control applications (Kelley, 1960; Bryson and Denham,\u00a01961; Dreyfus, 1962; Bryson and Ho, 1969; Dreyfus, 1973) but also for sensitivity\u00a0analysis (Linnainmaa, 1976). Werbos (1981) proposed applying these techniques\u00a0to training artificial neural networks. The idea was finally developed in practice\u00a0after being independently rediscovered in different ways (LeCun, 1985; Parker,\u00a01985; Rumelhart et al1986a). The book Parallel Distributed Processing presented\u00a0the results of some of the first successful experiments with back-propagation in a\u00a0chapter (Rumelhart et al., 1986b) that contributed greatly to the popularization\u00a0of back-propagation and initiated a very active period of research in multi-layer\u00a0neural networks. However, the ideas put forward by the authors of that book\u00a0and in particular by Rumelhart and Hinton go much beyond back-propagation.\u00a0They include crucial ideas about the possible computational implementation of\u00a0several central aspects of cognition and learning, which came under the name of\u00a0\u201cconnectionism\u201d because of the importance given the connections between neurons\u00a0as the locus of learning and memory. In particular, these ideas include the notion\u00a0of distributed representation (Hinton et al., 1986).",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2401",
    "text": "Following the success of back-propagation, neural network research gained popularity and reached a peak in the early 1990s. Afterwards, other machine learning techniques became more popular until the modern deep learning renaissance that\u00a0began in 2006.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2402",
    "text": "The core ideas behind modern feedforward networks have not changed substantially since the 1980s. The same back-propagation algorithm and the same approaches to gradient descent are still in use. Most of the improvement in neural\u00a0network performance from 1986 to 2015 can be attributed to two factors. First,\u00a0larger datasets have reduced the degree to which statistical generalization is a\u00a0challenge for neural networks. Second, neural networks have become much larger,\u00a0due to more powerful computers, and better software infrastructure. However, a\u00a0small number of algorithmic changes have improved the performance of neural\u00a0networks noticeably.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2403",
    "text": "One of these algorithmic changes was the replacement of mean squared error with the cross-entropy family of loss functions. Mean squared error was popular in\u00a0the 1980s and 1990s, but was gradually replaced by cross-entropy losses and the\u00a0principle of maximum likelihood as ideas spread between the statistics community\u00a0and the machine learning community. The use of cross-entropy losses greatly\u00a0improved the performance of models with sigmoid and softmax outputs, which\u00a0had previously suffered from saturation and slow learning when using the mean\u00a0squared error loss.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2404",
    "text": "The other major algorithmic change that has greatly improved the performance of feedforward networks was the replacement of sigmoid hidden units with piecewise\u00a0linear hidden units, such as rectified linear units. Rectification using the max{0, z}\u00a0function was introduced in early neural network models and dates back at least\u00a0as far as the Cognitron and Neocognitron (Fukushima, 1975, 1980). These early\u00a0models did not use rectified linear units, but instead applied rectification to\u00a0nonlinear functions. Despite the early popularity of rectification, rectification was\u00a0largely replaced by sigmoids in the 1980s, perhaps because sigmoids perform better\u00a0when neural networks are very small. As of the early 2000s, rectified linear units\u00a0were avoided due to a somewhat superstitious belief that activation functions with\u00a0non-differentiable points must be avoided. This began to change in about 2009.\u00a0Jarrett et al. (2009) observed that \u201cusing a rectifying nonlinearity is the single most\u00a0important factor in improving the performance of a recognition system\u201d among\u00a0several different factors of neural network architecture design.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2405",
    "text": "For small datasets, Jarrett et al. (2009) observed that using rectifying nonlinearities is even more important than learning the weights of the hidden layers. Random weights are sufficient to propagate useful information through a rectified\u00a0linear network, allowing the classifier layer at the top to learn how to map different\u00a0feature vectors to class identities.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2406",
    "text": "When more data is available, learning begins to extract enough useful knowledge to exceed the performance of randomly chosen parameters. Glorot et al. (2011a)\u00a0showed that learning is far easier in deep rectified linear networks than in deep\u00a0networks that have curvature or two-sided saturation in their activation functions.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2407",
    "text": "Rectified linear units are also of historical interest because they show that neuroscience has continued to have an influence on the development of deep\u00a0learning algorithms. Glorot et al. (2011a) motivate rectified linear units from\u00a0biological considerations. The half-rectifying nonlinearity was intended to capture\u00a0these properties of biological neurons: 1) For some inputs, biological neurons are\u00a0completely inactive. 2) For some inputs, a biological neuron\u2019s output is proportional\u00a0to its input. 3) Most of the time, biological neurons operate in the regime where\u00a0they are inactive (i.e., they should have sparse activations).",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2408",
    "text": "When the modern resurgence of deep learning began in 2006, feedforward networks continued to have a bad reputation. From about 2006-2012, it was widely\u00a0believed that feedforward networks would not perform well unless they were assisted\u00a0by other models, such as probabilistic models. Today, it is now known that with the\u00a0right resources and engineering practices, feedforward networks perform very well.\u00a0Today, gradient-based learning in feedforward networks is used as a tool to develop\u00a0probabilistic models, such as the variational autoencoder and generative adversarial\u00a0networks, described in Chapter 20. Rather than being viewed as an unreliable\u00a0technology that must be supported by other techniques, gradient-based learning in\u00a0feedforward networks has been viewed since 2012 as a powerful technology that\u00a0may be applied to many other machine learning tasks. In 2006, the community\u00a0used unsupervised learning to support supervised learning, and now, ironically, it\u00a0is more common to use supervised learning to support unsupervised learning.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2409",
    "text": "Feedforward networks continue to have unfulfilled potential. In the future, we expect they will be applied to many more tasks, and that advances in optimization\u00a0algorithms and model design will improve their performance even further. This\u00a0chapter has primarily described the neural network family of models. In the\u00a0subsequent chapters, we turn to how to use these models\u2014how to regularize and\u00a0train them.",
    "chapter": "Sequence Modeling: Recurrent and Recursive Nets",
    "chapter_id": "main-13.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2410",
    "text": "A central problem in machine learning is how to make an algorithm that will perform well not just on the training data, but also on new inputs. Many strategies\u00a0used in machine learning are explicitly designed to reduce the test error, possibly\u00a0at the expense of increased training error. These strategies are known collectively\u00a0as regularization. As we will see there are a great many forms of regularization\u00a0available to the deep learning practitioner. In fact, developing more effective\u00a0regularization strategies has been one of the major research efforts in the field.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2411",
    "text": "Chapter 5 introduced the basic concepts of generalization, underfitting, overfitting, bias, variance and regularization. If you are not already familiar with these notions, please refer to that chapter before continuing with this one.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2412",
    "text": "In this chapter, we describe regularization in more detail, focusing on regularization strategies for deep models or models that may be used as building blocks to form deep models.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2413",
    "text": "Some sections of this chapter deal with standard concepts in machine learning. If you are already familiar with these concepts, feel free to skip the relevant\u00a0sections. However, most of this chapter is concerned with the extension of these\u00a0basic concepts to the particular case of neural networks.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2414",
    "text": "In Sec. 5.2.2, we defined regularization as \u201cany modification we make to a learning algorithm that is intended to reduce its generalization error but not\u00a0its training error.\u201d There are many regularization strategies. Some put extra\u00a0constraints on a machine learning model, such as adding restrictions on the\u00a0parameter values. Some add extra terms in the objective function that can be\u00a0thought of as corresponding to a soft constraint on the parameter values. If chosen\u00a0carefully, these extra constraints and penalties can lead to improved performance\u00a0on the test set. Sometimes these constraints and penalties are designed to encode\u00a0specific kinds of prior knowledge. Other times, these constraints and penalties\u00a0are designed to express a generic preference for a simpler model class in order to\u00a0promote generalization. Sometimes penalties and constraints are necessary to make\u00a0an underdetermined problem determined. Other forms of regularization, known as\u00a0ensemble methods, combine multiple hypotheses that explain the training data.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2415",
    "text": "In the context of deep learning, most regularization strategies are based on regularizing estimators. Regularization of an estimator works by trading increased\u00a0bias for reduced variance. An effective regularizer is one that makes a profitable\u00a0trade, reducing variance significantly while not overly increasing the bias. When\u00a0we discussed generalization and overfitting in Chapter 5, we focused on three\u00a0situations, where the model family being trained either (1) excluded the true\u00a0data generating process\u2014corresponding to underfitting and inducing bias, or (2)\u00a0matched the true data generating process, or (3) included the generating process\u00a0but also many other possible generating processes\u2014the overfitting regime where\u00a0variance rather than bias dominates the estimation error. The goal of regularization\u00a0is to take a model from the third regime into the second regime.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2416",
    "text": "In practice, an overly complex model family does not necessarily include the target function or the true data generating process, or even a close approximation\u00a0of either. We almost never have access to the true data generating process so\u00a0we can never know for sure if the model family being estimated includes the\u00a0generating process or not. However, most applications of deep learning algorithms\u00a0are to domains where the true data generating process is almost certainly outside\u00a0the model family. Deep learning algorithms are typically applied to extremely\u00a0complicated domains such as images, audio sequences and text, for which the true\u00a0generation process essentially involves simulating the entire universe. To some\u00a0extent, we are always trying to fit a square peg (the data generating process) into\u00a0a round hole (our model family).",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2417",
    "text": "What this means is that controlling the complexity of the model is not a simple matter of finding the model of the right size, with the right number of\u00a0parameters. Instead, we might find\u2014and indeed in practical deep learning scenarios,\u00a0we almost always do find\u2014that the best fitting model (in the sense of minimizing\u00a0generalization error) is a large model that has been regularized appropriately.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2418",
    "text": "We now review several strategies for how to create such a large, deep, regularized model.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2419",
    "text": "Regularization has been used for decades prior to the advent of deep learning. Linear models such as linear regression and logistic regression allow simple, straightforward,\u00a0and effective regularization strategies.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2420",
    "text": "Many regularization approaches are based on limiting the capacity of models, such as neural networks, linear regression, or logistic regression, by adding a parameter norm penalty 0,(0) to the objective function J. We denote the regularized\u00a0objective function by J:",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2421",
    "text": "J(0; X, y) = J(0; X, y) + afi(0) \u00a0\u00a0\u00a0(7.1)",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2422",
    "text": "where a E [0, to) is a hyperparameter that weights the relative contribution of the norm penalty term, 0, relative to the standard objective function J(x; 0).\u00a0Setting a to 0 results in no regularization. Larger values of a correspond to more\u00a0regularization.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2423",
    "text": "When our training algorithm minimizes the regularized objective function J it will decrease both the original objective J on the training data and some measure\u00a0of the size of the parameters 0 (or some subset of the parameters). Different\u00a0choices for the parameter norm 0 can result in different solutions being preferred.\u00a0In this section, we discuss the effects of the various norms when used as penalties\u00a0on the model parameters.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2424",
    "text": "Before delving into the regularization behavior of different norms, we note that for neural networks, we typically choose to use a parameter norm penalty 0 that\u00a0penalizes only the weights of the affine transformation at each layer and leaves\u00a0the biases unregularized. The biases typically require less data to fit accurately\u00a0than the weights. Each weight specifies how two variables interact. Fitting the\u00a0weight well requires observing both variables in a variety of conditions. Each\u00a0bias controls only a single variable. This means that we do not induce too much\u00a0variance by leaving the biases unregularized. Also, regularizing the bias parameters\u00a0can introduce a significant amount of underfitting. We therefore use the vector w\u00a0to indicate all of the weights that should be affected by a norm penalty, while the\u00a0vector 0 denotes all of the parameters, including both w and the unregularized\u00a0parameters.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2425",
    "text": "In the context of neural networks, it is sometimes desirable to use a separate penalty with a different a coefficient for each layer of the network. Because it can\u00a0be expensive to search for the correct value of multiple hyperparameters, it is still\u00a0reasonable to use the same weight decay at all layers just to reduce the size of\u00a0search space.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2426",
    "text": "We have already seen, in Sec. 5.2.2, one of the simplest and most common kinds of parameter norm penalty: the L2 parameter norm penalty commonly known as\u00a0weight decay. This regularization strategy drives the weights closer to the origin1\u00a0by adding a regularization term Q(6) = 2||w||2 to the objective function. In\u00a0other academic communities, L2 regularization is also known as ridge regression or\u00a0Tikhonov regularization.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2427",
    "text": "We can gain some insight into the behavior of weight decay regularization by studying the gradient of the regularized objective function. To simplify the\u00a0presentation, we assume no bias parameter, so 6 is just w. Such a model has the\u00a0following total objective function:",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2428",
    "text": "a",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2429",
    "text": "We can see that the addition of the weight decay term has modified the learning rule to multiplicatively shrink the weight vector by a constant factor on each step,\u00a0just before performing the usual gradient update. This describes what happens in\u00a0a single step. But what happens over the entire course of training?",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2430",
    "text": "We will further simplify the analysis by making a quadratic approximation to the objective function in the neighborhood of the value of the weights that\u00a0obtains minimal unregularized training cost, w* = argminw J(w). If the objective\u00a0function is truly quadratic, as in the case of fitting a linear regression model with",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2431",
    "text": "mean squared error, then the approximation is perfect. The approximation J is given by",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2432",
    "text": "1",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2433",
    "text": "J(e) = J(w*) + 2(w - w*) tH(w \u2014 w*),",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2434",
    "text": "2",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2435",
    "text": "-7.6",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2436",
    "text": "where H is the Hessian matrix of J with respect to w evaluated at w*. There is no first-order term in this quadratic approximation, because w* is defined to be a\u00a0minimum, where the gradient vanishes. Likewise, because w* is the location of a\u00a0minimum of J, we can conclude that H is positive semidefinite.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2437",
    "text": "The minimum of J occurs where its gradient",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2438",
    "text": "V w J(w) = H (w \u2014 w *)",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2439",
    "text": "-7.7",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2440",
    "text": "is equal to 0.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2441",
    "text": "To study the effect of weight decay, we modify Eq. 7.7 by adding the weight decay gradient. We can now solve for the minimum of the regularized version of J.\u00a0We use the variable w to represent the location of the minimum.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2442",
    "text": "aw + H (1!) \u2014 w*) =0 (H + al )w = Hw*",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2443",
    "text": "w",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2444",
    "text": "(H + al )-1 Hw *.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2445",
    "text": "-7.8",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2446",
    "text": "(7.9) (7.10)",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2447",
    "text": "As a approaches 0, the regularized solution w approaches w*. But what happens as a grows? Because H is real and symmetric, we can decompose it\u00a0into a diagonal matrix A and an orthonormal basis of eigenvectors, Q, such that\u00a0H = QAQt. Applying the decomposition to Eq.7.10, we obtain:",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2448",
    "text": "w =",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2449",
    "text": "....",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2450",
    "text": "(QAQt + al)-1QAQ 'w",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2451",
    "text": "1 \u05be \u05e8",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2452",
    "text": "\u25a0vr",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2453",
    "text": "Q(A + al )Q",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2454",
    "text": "#ERROR!",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2455",
    "text": "QAQt w*",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2456",
    "text": "-7.11",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2457",
    "text": "-7.12",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2458",
    "text": "-7.13",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2459",
    "text": "We see that the effect of weight decay is to rescale w * along the axes defined by the eigenvectors of H. Specifically, the component of w * that is aligned with the",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2460",
    "text": "i-th eigenvector of H is rescaled by a factor of",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2461",
    "text": "A.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2462",
    "text": "Ai *",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2463",
    "text": "(You may wish to review",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2464",
    "text": "how this kind of scaling works, first explained in Fig. 2.3).",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2465",
    "text": "Along the directions where the eigenvalues of H are relatively large, for example, where Ai ^ a, the effect of regularization is relatively small. However, components\u00a0with Ai ^ a will be shrunk to have nearly zero magnitude. This effect is illustrated\u00a0in Fig. 7.1.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2466",
    "text": "Figure 7.1: An illustration of the effect of L2 (or weight decay) regularization on the value of the optimal w. The solid ellipses represent contours of equal value of the unregularized\u00a0objective. The dotted circles represent contours of equal value of theL2 regularizer. At\u00a0the point W, these competing objectives reach an equilibrium. In the first dimension, the\u00a0eigenvalue of the Hessian of J is small. The objective function does not increase much\u00a0when moving horizontally away from w*. Because the objective function does not express\u00a0a strong preference along this direction, the regularizer has a strong effect on this axis.\u00a0The regularizer pulls w 1 close to zero. In the second dimension, the objective function\u00a0is very sensitive to movements away from w*. The corresponding eigenvalue is large,\u00a0indicating high curvature. As a result, weight decay affects the position ofw2 relatively\u00a0little.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2467",
    "text": "Only directions along which the parameters contribute significantly to reducing the objective function are preserved relatively intact. In directions that do not\u00a0contribute to reducing the objective function, a small eigenvalue of the Hessian\u00a0tells us that movement in this direction will not significantly increase the gradient.\u00a0Components of the weight vector corresponding to such unimportant directions\u00a0are decayed away through the use of the regularization throughout training.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2468",
    "text": "So far we have discussed weight decay in terms of its effect on the optimization of an abstract, general, quadratic cost function. How do these effects relate to\u00a0machine learning in particular? We can find out by studying linear regression, a\u00a0model for which the true cost function is quadratic and therefore amenable to the\u00a0same kind of analysis we have used so far. Applying the analysis again, we will\u00a0be able to obtain a special case of the same results, but with the solution now\u00a0phrased in terms of the training data. For linear regression, the cost function is",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2469",
    "text": "the sum of squared errors:",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2470",
    "text": "-7.14",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2471",
    "text": "(Xw \u2014 y)T(Xw \u2014 y).",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2472",
    "text": "When we add L2 regularization, the objective function changes to",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2473",
    "text": "\\T,",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2474",
    "text": "1",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2475",
    "text": "(Xw \u2014 y)1 (Xw \u2014 y) + awT w.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2476",
    "text": "2",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2477",
    "text": "This changes the normal equations for the solution from",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2478",
    "text": "w = (X TX)-1X y",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2479",
    "text": "-7.15",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2480",
    "text": "-7.16",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2481",
    "text": "to",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2482",
    "text": "-T",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2483",
    "text": "w = (X 1 X + al )-1X Ty.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2484",
    "text": "1",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2485",
    "text": "-7.17",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2486",
    "text": "The matrix X TX in Eq. 7.16 is proportional to the covariance matrix 1 XT X.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2487",
    "text": "Using L2 regularization replaces this matrix with (XTX + a/) 1 in Eq. 7.17. The new matrix is the same as the original one, but with the addition of a to the\u00a0diagonal. The diagonal entries of this matrix correspond to the variance of each\u00a0input feature. We can see that L2 regularization causes the learning algorithm\u00a0to \u201cperceive\u201d the input X as having higher variance, which makes it shrink the\u00a0weights on features whose covariance with the output target is low compared to\u00a0this added variance.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2488",
    "text": "7.1.2 L1 Regularization",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2489",
    "text": "C\\",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2490",
    "text": "While L2 weight decay is the most common form of weight decay, there are other ways to penalize the size of the model parameters. Another option is to use L1\u00a0regularization.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2491",
    "text": "Formally, L1 regularization on the model parameter w is defined as:",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2492",
    "text": "-7.18",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2493",
    "text": "fi(0) = ||w||1 = ^2 |w |,",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2494",
    "text": "that is, as the sum of absolute values of the individual parameters.2 We will now discuss the effect of L1 regularization on the simple linear regression model,\u00a0with no bias parameter, that we studied in our analysis of L2 regularization. In\u00a0particular, we are interested in delineating the differences between L1 and L2 forms\u00a0of regularization. As with L2 weight decay, L1 weight decay controls the strength\u00a0of the regularization by scaling the penalty Q using a positive hyperparameter a.\u00a0Thus, the regularized objective function J(w; X, y) is given by",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2495",
    "text": "J(w; X, y) = a|| w| |1 + J(w; X, y), \u00a0\u00a0\u00a0(7-19)",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2496",
    "text": "with the corresponding gradient (actually, sub-gradient):",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2497",
    "text": "VwJ(w; X, y) = asign(w) + VWJ(X, y; w) \u00a0\u00a0\u00a0(7.20)",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2498",
    "text": "where sign(w) is simply the sign of w applied element-wise.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2499",
    "text": "By inspecting Eq. 7.20, we can see immediately that the effect of L1 regu-",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2500",
    "text": "C\\",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2501",
    "text": "larization is quite different from that of L regularization. Specifically, we can see that the regularization contribution to the gradient no longer scales linearly\u00a0with each wi; instead it is a constant factor with a sign equal to sign(wi). One\u00a0consequence of this form of the gradient is that we will not necessarily see clean\u00a0algebraic solutions to quadratic approximations of J(X, y; w) as we did for L2\u00a0regularization.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2502",
    "text": "Our simple linear model has a quadratic cost function that we can represent via its Taylor series. Alternately, we could imagine that this is a truncated Taylor\u00a0series approximating the cost function of a more sophisticated model. The gradient\u00a0in this setting is given by",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2503",
    "text": "Vw J(w) = H (w \u2014 w*), \u00a0\u00a0\u00a0(7.21)",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2504",
    "text": "where, again, H is the Hessian matrix of J with respect to w evaluated at w*.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2505",
    "text": "Because the L1 penalty does not admit clean algebraic expressions in the case of a fully general Hessian, we will also make the further simplifying assumption\u00a0that the Hessian is diagonal, H = diag([H1;1,... , Hn,n]), where each H ,i > 0.\u00a0This assumption holds if the data for the linear regression problem has been\u00a0preprocessed to remove all correlation between the input features, which may be\u00a0accomplished using PCA.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2506",
    "text": "Our quadratic approximation of the L1 regularized objective function decomposes into a sum over the parameters:",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2507",
    "text": "j(w; X, y) = J (w*; X, y) + J2",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2508",
    "text": "1",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2509",
    "text": "Hi,i(wi \u2014 w* )2 + a|wi|",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2510",
    "text": "-7.22",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2511",
    "text": "The problem of minimizing this approximate cost function has an analytical solution (for each dimension i), with the following form:",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2512",
    "text": "-7.23",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2513",
    "text": "wi = sign(w*) max j|w * \u2014 -HL, 0 j .",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2514",
    "text": "Consider the situation where w* > 0 for all i. There are two possible outcomes:",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2515",
    "text": "1. The case where w* < H. \u2022 Here the optimal value of wi under the regularized objective is simply wi = 0\u2022 This occurs because the contribution of J(w; X, y)\u00a0to the regularized objective J(w; X, y) is overwhelmed\u2014in direction i\u2014by\u00a0the L1 regularization which pushes the value of wi to zero.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2516",
    "text": "2. The case where w* >",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2517",
    "text": "a",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2518",
    "text": "H i",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2519",
    "text": "In this case, the regularization does not move the",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2520",
    "text": "optimal value of wi to zero but instead it just shifts it in that direction by a distance equal to Ha .",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2521",
    "text": "A similar process happens when w * < 0, but with the L1 penalty making wi less negative by Ha , or 0.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2522",
    "text": "In comparison to L2 regularization, L1 regularization results in a solution that is more sparse. Sparsity in this context refers to the fact that some parameters\u00a0have an optimal value of zero. The sparsity of L1 regularization is a qualitatively\u00a0different behavior than arises with L2 regularization. Eq. 7.13 gave the solution\u00a0w for L2 regularization. If we revisit that equation using the assumption of a\u00a0diagonal and positive definite Hessian H that we introduced for our analysis of L1",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2523",
    "text": "regularization, we find that w = H.\"+a w*. If w* was nonzero, then wi remains",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2524",
    "text": "\u00ab 0 \u2019",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2525",
    "text": "nonzero. This demonstrates that L regularization does not cause the parameters to become sparse, while L1 regularization may do so for large enough a.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2526",
    "text": "The sparsity property induced by L1 regularization has been used extensively as a feature selection mechanism. Feature selection simplifies a machine learning\u00a0problem by choosing which subset of the available features should be used. In\u00a0particular, the well known LASSO (Tibshirani, 1995) (least absolute shrinkage and\u00a0selection operator) model integrates an L1 penalty with a linear model and a least\u00a0squares cost function. The L1 penalty causes a subset of the weights to become\u00a0zero, suggesting that the corresponding features may safely be discarded.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2527",
    "text": "In Sec. 5.6.1, we saw that many regularization strategies can be interpreted as MAP Bayesian inference, and that in particular, L2 regularization is equivalent\u00a0to MAP Bayesian inference with a Gaussian prior on the weights. For L1 regularization, the penalty aQ(w) = a^i |w,j | used to regularize a cost function is\u00a0equivalent to the log-prior term that is maximized by MAP Bayesian inference\u00a0when the prior is an isotropic Laplace distribution (Eq. 3.26) over w E Rn:",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2528",
    "text": "_ 1",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2529",
    "text": "logp(w) = \u00a0\u00a0\u00a0logLaplace(wi; 0, \u2014) = \u2014 aNwJL + n log a \u2014 n log 2.\u00a0\u00a0\u00a0\u00a0(7.24)",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2530",
    "text": "a",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2531",
    "text": "From the point of view of learning via maximization with respect to w, we can ignore the log a \u2014 log 2 terms because they do not depend on w.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2532",
    "text": "Consider the cost function regularized by a parameter norm penalty:",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2533",
    "text": "J>; X, y) = J(6; X, y) + a0(6). \u00a0\u00a0\u00a0(7.25)",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2534",
    "text": "Recall from Sec. 4.4 that we can minimize a function subject to constraints by constructing a generalized Lagrange function, consisting of the original objective\u00a0function plus a set of penalties. Each penalty is a product between a coefficient,\u00a0called a Karush-Kuhn-Tucker (KKT) multiplier, and a function representing\u00a0whether the constraint is satisfied. If we wanted to constrain 0,(6) to be less than\u00a0some constant k, we could construct a generalized Lagrange function",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2535",
    "text": "L(6, a; X, y) = J(6; X, y) + a(0(6) \u2014 k). \u00a0\u00a0\u00a0(7.26)",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2536",
    "text": "The solution to the constrained problem is given by",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2537",
    "text": "6* = argmin max L(6, a). \u00a0\u00a0\u00a0(7.27)",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2538",
    "text": "q \u00a0\u00a0\u00a0a,a> 0",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2539",
    "text": "As described in Sec. 4.4, solving this problem requires modifying both 6 and a. Sec. 4.5 provides a worked example of linear regression with an L2 constraint.\u00a0Many different procedures are possible\u2014some may use gradient descent, while\u00a0others may use analytical solutions for where the gradient is zero\u2014but in all\u00a0procedures a must increase whenever 0(6) > k and decrease whenever 0( 6) < k.\u00a0All positive a encourage 0(6) to shrink. The optimal value a* will encourage 0(6)\u00a0to shrink, but not so strongly to make 0(6) become less than k.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2540",
    "text": "To gain some insight into the effect of the constraint, we can fix a* and view the problem as just a function of 6:",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2541",
    "text": "6 * = argmin L(6, a*) = argmin J (6; X, y) + a *0(6). \u00a0\u00a0\u00a0(7.28)",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2542",
    "text": "q \u00a0\u00a0\u00a0q",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2543",
    "text": "This is exactly the same as the regularized training problem of minimizing J. We can thus think of a parameter norm penalty as imposing a constraint on the\u00a0weights. If 0 is the L norm, then the weights are constrained to lie in an L2\u00a0ball. If 0 is the L1 norm, then the weights are constrained to lie in a region of\u00a0limited L1 norm. Usually we do not know the size of the constraint region that we\u00a0impose by using weight decay with coefficient a* because the value of a* does not\u00a0directly tell us the value of k. In principle, one can solve for k, but the relationship\u00a0between k and a* depends on the form of J. While we do not know the exact size\u00a0of the constraint region, we can control it roughly by increasing or decreasing a\u00a0in order to grow or shrink the constraint region. Larger a will result in a smaller\u00a0constraint region. Smaller a will result in a larger constraint region.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2544",
    "text": "Sometimes we may wish to use explicit constraints rather than penalties. As described in Sec. 4.4, we can modify algorithms such as stochastic gradient descent\u00a0to take a step downhill on J(6) and then project 6 back to the nearest point\u00a0that satisfies 0,(6) < k. This can be useful if we have an idea of what value of k\u00a0is appropriate and do not want to spend time searching for the value of a that\u00a0corresponds to this k.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2545",
    "text": "Another reason to use explicit constraints and reprojection rather than enforcing constraints with penalties is that penalties can cause non-convex optimization\u00a0procedures to get stuck in local minima corresponding to small 6. When training\u00a0neural networks, this usually manifests as neural networks that train with several\u00a0\u201cdead units.\u201d These are units that do not contribute much to the behavior of the\u00a0function learned by the network because the weights going into or out of them are\u00a0all very small. When training with a penalty on the norm of the weights, these\u00a0configurations can be locally optimal, even if it is possible to significantly reduce\u00a0J by making the weights larger. Explicit constraints implemented by re-projection\u00a0can work much better in these cases because they do not encourage the weights\u00a0to approach the origin. Explicit constraints implemented by re-projection only\u00a0have an effect when the weights become large and attempt to leave the constraint\u00a0region.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2546",
    "text": "Finally, explicit constraints with reprojection can be useful because they impose some stability on the optimization procedure. When using high learning rates, it\u00a0is possible to encounter a positive feedback loop in which large weights induce\u00a0large gradients which then induce a large update to the weights. If these updates\u00a0consistently increase the size of the weights, then 6 rapidly moves away from\u00a0the origin until numerical overflow occurs. Explicit constraints with reprojection\u00a0prevent this feedback loop from continuing to increase the magnitude of the weights\u00a0without bound. Hinton et al. (2012c) recommend using constraints combined with\u00a0a high learning rate to allow rapid exploration of parameter space while maintaining\u00a0some stability.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2547",
    "text": "In particular, Hinton et al. (2012c) recommend a strategy introduced by Srebro and Shraibman (2005): constraining the norm of each column of the weight matrix\u00a0of a neural net layer, rather than constraining the Frobenius norm of the entire\u00a0weight matrix. Constraining the norm of each column separately prevents any one\u00a0hidden unit from having very large weights. If we converted this constraint into a",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2548",
    "text": "C\\",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2549",
    "text": "penalty in a Lagrange function, it would be similar to L weight decay but with a separate KKT multiplier for the weights of each hidden unit. Each of these KKT\u00a0multipliers would be dynamically updated separately to make each hidden unit\u00a0obey the constraint. In practice, column norm limitation is always implemented as\u00a0an explicit constraint with reprojection.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2550",
    "text": "In some cases, regularization is necessary for machine learning problems to be properly defined. Many linear models in machine learning, including linear regression and PCA, depend on inverting the matrix XTX. This is not possible whenever\u00a0XT X is singular. This matrix can be singular whenever the data generating distribution truly has no variance in some direction, or when no variance in observed\u00a0in some direction because there are fewer examples (rows of X) than input features\u00a0(columns of X). In this case, many forms of regularization correspond to inverting\u00a0XT X + aI instead. This regularized matrix is guaranteed to be invertible.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2551",
    "text": "These linear problems have closed form solutions when the relevant matrix is invertible. It is also possible for a problem with no closed form solution to be\u00a0underdetermined. An example is logistic regression applied to a problem where\u00a0the classes are linearly separable. If a weight vector w is able to achieve perfect\u00a0classification, then 2w will also achieve perfect classification and higher likelihood.\u00a0An iterative optimization procedure like stochastic gradient descent will continually\u00a0increase the magnitude of w and, in theory, will never halt. In practice, a numerical\u00a0implementation of gradient descent will eventually reach sufficiently large weights\u00a0to cause numerical overflow, at which point its behavior will depend on how the\u00a0programmer has decided to handle values that are not real numbers.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2552",
    "text": "Most forms of regularization are able to guarantee the convergence of iterative methods applied to underdetermined problems. For example, weight decay will\u00a0cause gradient descent to quit increasing the magnitude of the weights when the\u00a0slope of the likelihood is equal to the weight decay coefficient.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2553",
    "text": "The idea of using regularization to solve underdetermined problems extends beyond machine learning. The same idea is useful for several basic linear algebra\u00a0problems.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2554",
    "text": "As we saw in Sec. 2.9, we can solve underdetermined linear equations using the Moore-Penrose pseudoinverse. Recall that one definition of the pseudoinverse\u00a0X+ of a matrix X is",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2555",
    "text": "X+ = lim (XT X + aI)-lXT. \u00a0\u00a0\u00a0(7.29)",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2556",
    "text": "a\\0",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2557",
    "text": "We can now recognize Eq. 7.29 as performing linear regression with weight decay. Specifically, Eq. 7.29 is the limit of Eq. 7.17 as the regularization coefficient shrinks\u00a0to zero. We can thus interpret the pseudoinverse as stabilizing underdetermined\u00a0problems using regularization.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2558",
    "text": "The best way to make a machine learning model generalize better is to train it on more data. Of course, in practice, the amount of data we have is limited. One way\u00a0to get around this problem is to create fake data and add it to the training set.\u00a0For some machine learning tasks, it is reasonably straightforward to create new\u00a0fake data.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2559",
    "text": "This approach is easiest for classification. A classifier needs to take a complicated, high dimensional input x and summarize it with a single category identity y. This means that the main task facing a classifier is to be invariant to a wide variety\u00a0of transformations. We can generate new (x, y) pairs easily just by transforming\u00a0the x inputs in our training set.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2560",
    "text": "This approach is not as readily applicable to many other tasks. For example, it is difficult to generate new fake data for a density estimation task unless we have\u00a0already solved the density estimation problem.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2561",
    "text": "Dataset augmentation has been a particularly effective technique for a specific classification problem: object recognition. Images are high dimensional and include\u00a0an enormous variety of factors of variation, many of which can be easily simulated.\u00a0Operations like translating the training images a few pixels in each direction can\u00a0often greatly improve generalization, even if the model has already been designed to\u00a0be partially translation invariant by using the convolution and pooling techniques\u00a0described in Chapter 9. Many other operations such as rotating the image or\u00a0scaling the image have also proven quite effective.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2562",
    "text": "One must be careful not to apply transformations that would change the correct class. For example, optical character recognition tasks require recognizing the\u00a0difference between \u2018b\u2019 and \u2018d\u2019 and the difference between \u20186\u2019 and \u20189\u2019, so horizontal\u00a0flips and 180\u00b0 rotations are not appropriate ways of augmenting datasets for these\u00a0tasks.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2563",
    "text": "There are also transformations that we would like our classifiers to be invariant to, but which are not easy to perform. For example, out-of-plane rotation can not\u00a0be implemented as a simple geometric operation on the input pixels.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2564",
    "text": "Dataset augmentation is effective for speech recognition tasks as well (Jaitly and Hinton, 2013).",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2565",
    "text": "Injecting noise in the input to a neural network (Sietsma and Dow, 1991) can also be seen as a form of data augmentation. For many classification and\u00a0even some regression tasks, the task should still be possible to solve even if small\u00a0random noise is added to the input. Neural networks prove not to be very robust\u00a0to noise, however (Tang and Eliasmith, 2010). One way to improve the robustness\u00a0of neural networks is simply to train them with random noise applied to their\u00a0inputs. Input noise injection is part of some unsupervised learning algorithms such\u00a0as the denoising autoencoder (Vincent et al., 2008). Noise injection also works\u00a0when the noise is applied to the hidden units, which can be seen as doing dataset\u00a0augmentation at multiple levels of abstraction. Poole et al. (2014) recently showed\u00a0that this approach can be highly effective provided that the magnitude of the\u00a0noise is carefully tuned. Dropout, a powerful regularization strategy that will be\u00a0described in Sec. 7.12, can be seen as a process of constructing new inputs by\u00a0multiplying by noise.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2566",
    "text": "When comparing machine learning benchmark results, it is important to take the effect of dataset augmentation into account. Often, hand-designed dataset\u00a0augmentation schemes can dramatically reduce the generalization error of a machine\u00a0learning technique. To compare the performance of one machine learning algorithm\u00a0to another, it is necessary to perform controlled experiments. When comparing\u00a0machine learning algorithm A and machine learning algorithm B, it is necessary\u00a0to make sure that both algorithms were evaluated using the same hand-designed\u00a0dataset augmentation schemes. Suppose that algorithm A performs poorly with\u00a0no dataset augmentation and algorithm B performs well when combined with\u00a0numerous synthetic transformations of the input. In such a case it is likely the\u00a0synthetic transformations caused the improved performance, rather than the use\u00a0of machine learning algorithm B. Sometimes deciding whether an experiment\u00a0has been properly controlled requires subjective judgment. For example, machine\u00a0learning algorithms that inject noise into the input are performing a form of dataset\u00a0augmentation. Usually, operations that are generally applicable (such as adding\u00a0Gaussian noise to the input) are considered part of the machine learning algorithm,\u00a0while operations that are specific to one application domain (such as randomly\u00a0cropping an image) are considered to be separate pre-processing steps.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2567",
    "text": "Sec. 7.4 has motivated the use of noise applied to the inputs as a dataset augmentation strategy. For some models, the addition of noise with infinitesimal variance at the input of the model is equivalent to imposing a penalty on the\u00a0norm of the weights (Bishop, 1995a,b). In the general case, it is important to\u00a0remember that noise injection can be much more powerful than simply shrinking\u00a0the parameters, especially when the noise is added to the hidden units. Noise\u00a0applied to the hidden units is such an important topic as to merit its own separate\u00a0discussion; the dropout algorithm described in Sec. 7.12 is the main development\u00a0of that approach.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2568",
    "text": "Another way that noise has been used in the service of regularizing models is by adding it to the weights. This technique has been used primarily in the\u00a0context of recurrent neural networks (Jim et al., 1996; Graves, 2011). This can\u00a0be interpreted as a stochastic implementation of a Bayesian inference over the\u00a0weights. The Bayesian treatment of learning would consider the model weights\u00a0to be uncertain and representable via a probability distribution that reflects this\u00a0uncertainty. Adding noise to the weights is a practical, stochastic way to reflect\u00a0this uncertainty (Graves, 2011).",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2569",
    "text": "This can also be interpreted as equivalent (under some assumptions) to a more traditional form of regularization. Adding noise to the weights has been\u00a0shown to be an effective regularization strategy in the context of recurrent neural\u00a0networks (Jim et al., 1996; Graves, 2011). In the following, we will present an\u00a0analysis of the effect of weight noise on a standard feedforward neural network (as\u00a0introduced in Chapter 6).",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2570",
    "text": "We study the regression setting, where we wish to train a function y(x) that maps a set of features x to a scalar using the least-squares cost function between\u00a0the model predictions y(x) and the true values y:",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2571",
    "text": "J = Ep(x,y) [(y(x) - y)2] \u2022 \u00a0\u00a0\u00a0(7.30)",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2572",
    "text": "The training set consists of m labeled examples {(x(1), y(1)),..., (x(m), y(m))}.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2573",
    "text": "We now assume that with each input presentation we also include a random perturbation ew ~ N( e; 0,yl) of the network weights. Let us imagine that we\u00a0have a standard l-layer MLP. We denote the perturbed model as yew (x). Despite\u00a0the injection of noise, we are still interested in minimizing the squared error of the\u00a0output of the network. The objective function thus becomes:",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2574",
    "text": "JW",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2575",
    "text": "e",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2576",
    "text": "p(x,y,ew)",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2577",
    "text": "(j\u05f3\u00abw (x)- y)2",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2578",
    "text": "-7.31",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2579",
    "text": "#ERROR!",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2580",
    "text": "For small n, the minimization of J with added weight noise (with covariance nI) is equivalent to minimization of J with an additional regularization term:\u00a0nEp(x,y) [||VwV(x)||2]. This form of regularization encourages the parameters to\u00a0go to regions of parameter space where small perturbations of the weights have\u00a0a relatively small influence on the output. In other words, it pushes the model\u00a0into regions where the model is relatively insensitive to small variations in the\u00a0weights, finding points that are not merely minima, but minima surrounded by\u00a0flat regions (Hochreiter and Schmidhuber, 1995). In the simplified case of linear\u00a0regression (where, for instance, f(x) = wTx + b), this regularization term collapses\u00a0into nEp(x) [||x|| 2], which is not a function of parameters and therefore does not\u00a0contribute to the gradient of Jw with respect to the model parameters.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2581",
    "text": "7.5.1 Injecting Noise at the Output Targets",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2582",
    "text": "Most datasets have some amount of mistakes in the y labels. It can be harmful to maximize logp(y | x) when y is a mistake. One way to prevent this is to\u00a0explicitly model the noise on the labels. For example, we can assume that for some\u00a0small constant e, the training set label y is correct with probability 1 \u2014 e, and\u00a0otherwise any of the other possible labels might be correct. This assumption is\u00a0easy to incorporate into the cost function analytically, rather than by explicitly\u00a0drawing noise samples. For example, label smoothing regularizes a model based\u00a0on a softmax with k output values by replacing the hard 0 and 1 classification\u00a0targets with targets of \u05da and 1 \u2014 e, respectively. The standard cross-entropy\u00a0loss may then be used with these soft targets. Maximum likelihood learning with a\u00a0softmax classifier and hard targets may actually never converge\u2014the softmax can\u00a0never predict a probability of exactly 0 or exactly 1, so it will continue to learn\u00a0larger and larger weights, making more extreme predictions forever. It is possible\u00a0to prevent this scenario using other regularization strategies like weight decay.\u00a0Label smoothing has the advantage of preventing the pursuit of hard probabilities\u00a0without discouraging correct classification. This strategy has been used since\u00a0the 1980s and continues to be featured prominently in modern neural networks\u00a0(Szegedy et al., 2015).",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2583",
    "text": "In the paradigm of semi-supervised learning, both unlabeled examples from P(x) and labeled examples from P (x, y) are used to estimate P (y | x) or predict y from\u00a0x.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2584",
    "text": "In the context of deep learning, semi-supervised learning usually refers to learning a representation h = f (x). The goal is to learn a representation so\u00a0that examples from the same class have similar representations. Unsupervised\u00a0learning can provide useful cues for how to group examples in representation\u00a0space. Examples that cluster tightly in the input space should be mapped to\u00a0similar representations. A linear classifier in the new space may achieve better\u00a0generalization in many cases (Belkin and Niyogi, 2002; Chapelle et al., 2003). A\u00a0long-standing variant of this approach is the application of principal components\u00a0analysis as a pre-processing step before applying a classifier (on the projected\u00a0data).",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2585",
    "text": "Instead of having separate unsupervised and supervised components in the model, one can construct models in which a generative model of either P (x) or\u00a0P(x, y) shares parameters with a discriminative model of P(y | x). One can\u00a0then trade-off the supervised criterion \u2014 log P(y | x) with the unsupervised or\u00a0generative one (such as \u2014 log P(x) or \u2014 logP(x, y)). The generative criterion then\u00a0expresses a particular form of prior belief about the solution to the supervised\u00a0learning problem (Lasserre et al., 2006), namely that the structure of P(x) is\u00a0connected to the structure of P(y | x) in a way that is captured by the shared\u00a0parametrization. By controlling how much of the generative criterion is included\u00a0in the total criterion, one can find a better trade-off than with a purely generative\u00a0or a purely discriminative training criterion (Lasserre et al., 2006; Larochelle and\u00a0Bengio, 2008).",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2586",
    "text": "Salakhutdinov and Hinton (2008) describe a method for learning the kernel function of a kernel machine used for regression, in which the usage of unlabeled\u00a0examples for modeling P (x) improves P (y | x) quite significantly.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2587",
    "text": "See Chapelle et al. (2006) for more information about semi-supervised learning.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2588",
    "text": "Multi-task learning (Caruana, 1993) is a way to improve generalization by pooling the examples (which can be seen as soft constraints imposed on the parameters)\u00a0arising out of several tasks. In the same way that additional training examples\u00a0put more pressure on the parameters of the model towards values that generalize\u00a0well, when part of a model is shared across tasks, that part of the model is more\u00a0constrained towards good values (assuming the sharing is justified), often yielding\u00a0better generalization.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2589",
    "text": "Fig. 7.2 illustrates a very common form of multi-task learning, in which different supervised tasks (predicting y(i) given x) share the same input x, as well as some\u00a0intermediate-level representation h(shared) capturing a common pool of factors. The\u00a0model can generally be divided into two kinds of parts and associated parameters:",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2590",
    "text": "1. \u00a0\u00a0\u00a0Task-specific parameters (which only benefit from the examples of their task\u00a0to achieve good generalization). These are the upper layers of the neural\u00a0network in Fig. 7.2.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2591",
    "text": "2. \u00a0\u00a0\u00a0Generic parameters, shared across all the tasks (which benefit from the\u00a0pooled data of all the tasks). These are the lower layers of the neural network\u00a0in Fig. 7.2.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2592",
    "text": "Figure 7.2: Multi-task learning can be cast in several ways in deep learning frameworks and this figure illustrates the common situation where the tasks share a common input but\u00a0involve different target random variables. The lower layers of a deep network (whether it\u00a0is supervised and feedforward or includes a generative component with downward arrows)\u00a0can be shared across such tasks, while task-specific parameters (associated respectively\u00a0with the weights into and from h(1) and h(2)) can be learned on top of those yielding a\u00a0shared representation h(shared). The underlying assumption is that there exists a common\u00a0pool of factors that explain the variations in the input x, while each task is associated\u00a0with a subset of these factors. In this example, it is additionally assumed that top-level\u00a0hidden units h(1) and h(2) are specialized to each task (respectively predicting y(1) and\u00a0y(2)) while some intermediate-level representationh(shared) is shared across all tasks. In\u00a0the unsupervised learning context, it makes sense for some of the top-level factors to be\u00a0associated with none of the output tasks (h(3)): these are the factors that explain some of\u00a0the input variations but are not relevant for predicting y(1) or y(2).",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2593",
    "text": "Figure 7.3: Learning curves showing how the negative log-likelihood loss changes over time (indicated as number of training iterations over the dataset, or epochs). In this\u00a0example, we train a maxout network on MNIST. Observe that the training objective\u00a0decreases consistently over time, but the validation set average loss eventually begins to\u00a0increase again, forming an asymmetric U-shaped curve.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2594",
    "text": "Improved generalization and generalization error bounds (Baxter, 1995) can be achieved because of the shared parameters, for which statistical strength can be\u00a0greatly improved (in proportion with the increased number of examples for the\u00a0shared parameters, compared to the scenario of single-task models). Of course this\u00a0will happen only if some assumptions about the statistical relationship between\u00a0the different tasks are valid, meaning that there is something shared across some\u00a0of the tasks.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2595",
    "text": "From the point of view of deep learning, the underlying prior belief is the following: among the factors that explain the variations observed in the\u00a0data associated with the different tasks, some are shared across two or\u00a0more tasks.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2596",
    "text": "When training large models with sufficient representational capacity to overfit the task, we often observe that training error decreases steadily over time, but\u00a0validation set error begins to rise again. See Fig. 7.3 for an example of this behavior.\u00a0This behavior occurs very reliably.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2597",
    "text": "This means we can obtain a model with better validation set error (and thus, hopefully better test set error) by returning to the parameter setting at the point\u00a0in time with the lowest validation set error. Instead of running our optimization\u00a0algorithm until we reach a (local) minimum of validation error, we run it until the\u00a0error on the validation set has not improved for some amount of time. Every time\u00a0the error on the validation set improves, we store a copy of the model parameters.\u00a0When the training algorithm terminates, we return these parameters, rather than\u00a0the latest parameters. This procedure is specified more formally in Algorithm 7.1.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2598",
    "text": "Algorithm 7.1 The early stopping meta-algorithm for determining the best amount of time to train. This meta-algorithm is a general strategy that works\u00a0well with a variety of training algorithms and ways of quantifying error on the\u00a0validation set.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2599",
    "text": "Let n be the number of steps between evaluations.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2600",
    "text": "Let p be the \u201cpatience,\u201d the number of times to observe worsening validation set error before giving up.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2601",
    "text": "Let 0o be the initial parameters.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2602",
    "text": "0 \u00a0\u00a0\u00a0\u2014 Qo",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2603",
    "text": "1 \u00a0\u00a0\u00a0\u2014 0\u00a0j \u2014 0",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2604",
    "text": "V \u2014\u2014 X 0* \u2014 0",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2605",
    "text": "i* \u2014 i",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2606",
    "text": "while j < p do",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2607",
    "text": "Update 0 by running the training algorithm for n steps. i \u2014 i + n",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2608",
    "text": "V \u2014 ValidationSetError(Q) if V < v then",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2609",
    "text": "j \u2014 0 0* \u2014 0",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2610",
    "text": "i* \u2014 i v \u2014 v'\u00a0else",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2611",
    "text": "j \u2014 j + 1 end if\u00a0end while",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2612",
    "text": "Best parameters are 0*, best number of training steps is i*",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2613",
    "text": "This strategy is known as early stopping. It is probably the most commonly used form of regularization in deep learning. Its popularity is due both to its\u00a0effectiveness and its simplicity.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2614",
    "text": "One way to think of early stopping is as a very efficient hyperparameter selection algorithm. In this view, the number of training steps is just another hyperparameter.\u00a0We can see in Fig. 7.3 that this hyperparameter has a U-shaped validation set\u00a0performance curve. Most hyperparameters that control model capacity have such a\u00a0U-shaped validation set performance curve, as illustrated in Fig. 5.3. In the case of\u00a0early stopping, we are controlling the effective capacity of the model by determining\u00a0how many steps it can take to fit the training set. Most hyperparameters must be\u00a0chosen using an expensive guess and check process, where we set a hyperparameter\u00a0at the start of training, then run training for several steps to see its effect. The\u00a0\u201ctraining time\u201d hyperparameter is unique in that by definition a single run of\u00a0training tries out many values of the hyperparameter. The only significant cost\u00a0to choosing this hyperparameter automatically via early stopping is running the\u00a0validation set evaluation periodically during training. Ideally, this is done in\u00a0parallel to the training process on a separate machine, separate CPU, or separate\u00a0GPU from the main training process. If such resources are not available, then the\u00a0cost of these periodic evaluations may be reduced by using a validation set that is\u00a0small compared to the training set or by evaluating the validation set error less\u00a0frequently and obtaining a lower resolution estimate of the optimal training time.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2615",
    "text": "An additional cost to early stopping is the need to maintain a copy of the best parameters. This cost is generally negligible, because it is acceptable to store\u00a0these parameters in a slower and larger form of memory (for example, training in\u00a0GPU memory, but storing the optimal parameters in host memory or on a disk\u00a0drive). Since the best parameters are written to infrequently and never read during\u00a0training, these occasional slow writes have little effect on the total training time.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2616",
    "text": "Early stopping is a very unobtrusive form of regularization, in that it requires almost no change in the underlying training procedure, the objective function,\u00a0or the set of allowable parameter values. This means that it is easy to use early\u00a0stopping without damaging the learning dynamics. This is in contrast to weight\u00a0decay, where one must be careful not to use too much weight decay and trap the\u00a0network in a bad local minimum corresponding to a solution with pathologically\u00a0small weights.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2617",
    "text": "Early stopping may be used either alone or in conjunction with other regularization strategies. Even when using regularization strategies that modify the objective function to encourage better generalization, it is rare for the best generalization to\u00a0occur at a local minimum of the training objective.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2618",
    "text": "Early stopping requires a validation set, which means some training data is not fed to the model. To best exploit this extra data, one can perform extra training\u00a0after the initial training with early stopping has completed. In the second, extra\u00a0training step, all of the training data is included. There are two basic strategies\u00a0one can use for this second training procedure.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2619",
    "text": "One strategy (Algorithm 7.2) is to initialize the model again and retrain on all of the data. In this second training pass, we train for the same number of steps as\u00a0the early stopping procedure determined was optimal in the first pass. There are\u00a0some subtleties associated with this procedure. For example, there is not a good\u00a0way of knowing whether to retrain for the same number of parameter updates or\u00a0the same number of passes through the dataset. On the second round of training,\u00a0each pass through the dataset will require more parameter updates because the\u00a0training set is bigger.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2620",
    "text": "Algorithm 7.2 A meta-algorithm for using early stopping to determine how long to train, then retraining on all the data.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2621",
    "text": "Let X(tra1n) and y(tra1n) be the training set.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2622",
    "text": "Split X(tra1n) and y(tra1n) into (X(subtra1n), X(val1d)) and (y(subtra1n), y(val1d)) respectively.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2623",
    "text": "Run early stopping (Algorithm 7.1) starting from random 6 using X(subtra1n) and y(subtra1n) for training data and X(val1d) and y(val1d) for validation data. This\u00a0returns i*, the optimal number of steps.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2624",
    "text": "Set 6 to random values again.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2625",
    "text": "Train on X(tra1n) and y(tra1n) for i* steps.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2626",
    "text": "Another strategy for using all of the data is to keep the parameters obtained from the first round of training and then continue training but now using all of\u00a0the data. At this stage, we now no longer have a guide for when to stop in terms\u00a0of a number of steps. Instead, we can monitor the average loss function on the\u00a0validation set, and continue training until it falls below the value of the training\u00a0set objective at which the early stopping procedure halted. This strategy avoids\u00a0the high cost of retraining the model from scratch, but is not as well-behaved. For\u00a0example, there is not any guarantee that the objective on the validation set will\u00a0ever reach the target value, so this strategy is not even guaranteed to terminate.\u00a0This procedure is presented more formally in Algorithm 7.3.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2627",
    "text": "Early stopping is also useful because it reduces the computational cost of the training procedure. Besides the obvious reduction in cost due to limiting the number\u00a0of training iterations, it also has the benefit of providing regularization without\u00a0requiring the addition of penalty terms to the cost function or the computation of\u00a0the gradients of such additional terms.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2628",
    "text": "Algorithm 7.3 Meta-algorithm using early stopping to determine at what objective value we start to overfit, then continue training until that value is reached.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2629",
    "text": "Let X(tra1n) and y(tra1n) be the training set.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2630",
    "text": "Split X(tra1n) and y(tra1n) into (X(subtra1n), X(val1d)) and (y(subtra1n), y(val1d)) respectively.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2631",
    "text": "Run early stopping (Algorithm 7.1) starting from random 6 using X(subtra1n) and y(subtra1n) for training data and X(val1d) and y(val1d) for validation data. This\u00a0updates 6.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2632",
    "text": "^ __ j(6 X(subtra1n) y(subtra1n))",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2633",
    "text": "while J(6, X(val1d), y(val1d)) > e do",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2634",
    "text": "Train on X(tra1n) and y(tra1n) for n steps. end while",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2635",
    "text": "How early stopping acts as a regularizer: So far we have stated that early stopping is a regularization strategy, but we have supported this claim only by\u00a0showing learning curves where the validation set error has a U-shaped curve. What\u00a0is the actual mechanism by which early stopping regularizes the model? Bishop\u00a0(1995a) and Sjoberg and Ljung (1995) argued that early stopping has the effect of\u00a0restricting the optimization procedure to a relatively small volume of parameter\u00a0space in the neighborhood of the initial parameter value 6o. More specifically,\u00a0imagine taking t optimization steps (corresponding to t training iterations) and\u00a0with learning rate e. We can view the product et as a measure of effective capacity.\u00a0Assuming the gradient is bounded, restricting both the number of iterations and\u00a0the learning rate limits the volume of parameter space reachable from 6o. In this\u00a0sense, et behaves as if it were the reciprocal of the coefficient used for weight decay.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2636",
    "text": "Indeed, we can show how\u2014in the case of a simple linear model with a quadratic error function and simple gradient descent\u2014early stopping is equivalent to L2\u00a0regularization.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2637",
    "text": ". \u00a0\u00a0\u00a0\u2666O\u00a0\u00a0\u00a0\u00a0\u2666\u00a0\u00a0\u00a0\u00a0\u2666\u00a0\u00a0\u00a0\u00a0\u2666\u00a0\u00a0\u00a0\u00a0\u2666",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2638",
    "text": "In order to compare with classical L2 regularization, we examine a simple setting where the only parameters are linear weights (6 = w). We can model\u00a0the cost function J with a quadratic approximation in the neighborhood of the\u00a0empirically optimal value of the weights w*:",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2639",
    "text": "1",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2640",
    "text": "J(6) = J(w*) + 2(w - w*)TH(w - w*), 2",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2641",
    "text": "-7.33",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2642",
    "text": "where H is the Hessian matrix of J with respect to w evaluated at w*. Given the assumption that w* is a minimum of J(w), we know that H is positive semidefinite.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2643",
    "text": "Under a local Taylor series approximation, the gradient is given by:",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2644",
    "text": "Vw J(w) = H(w - w*). \u00a0\u00a0\u00a0(7.34)",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2645",
    "text": "We are going to study the trajectory followed by the parameter vector during training. For simplicity, let us set the initial parameter vector to the origin,3 that\u00a0is w(0) = 0. Let us suppose that we update the parameters via gradient descent:",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2646",
    "text": ";(r) = w(t-1) - eVw J(w(T-1))",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2647",
    "text": "-7.35",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2648",
    "text": "#ERROR!",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2649",
    "text": "-7.36",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2650",
    "text": "w* = (I - eH)(w (t-1) - w*)",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2651",
    "text": "-7.37",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2652",
    "text": "Figure 7.4: An illustration of the effect of early stopping. (Left) The solid contour lines indicate the contours of the negative log-likelihood. The dashed line indicates the\u00a0trajectory taken by SGD beginning from the origin. Rather than stopping at the point\u00a0w* that minimizes the cost, early stopping results in the trajectory stopping at an earlier\u00a0point W. (Right) An illustration of the effect of L2 regularization for comparison. The\u00a0dashed circles indicate the contours of the L2 penalty, which causes the minimum of the\u00a0total cost to lie nearer the origin than the minimum of the unregularized cost.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2653",
    "text": "w",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2654",
    "text": "Let us now rewrite this expression in the space of the eigenvectors of H, exploiting the eigendecomposition of H: H = QAQT, where A is a diagonal matrix and Q\u00a0is an orthonormal basis of eigenvectors.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2655",
    "text": "w",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2656",
    "text": "(t) - w* = (I - eQAQT)(w(T-1) - w*",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2657",
    "text": "w*)",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2658",
    "text": "-7.38",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2659",
    "text": "Qt(w(t) - w*) = (I - eA)QT (w(T-1) - w*) \u00a0\u00a0\u00a0(7.39)",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2660",
    "text": "Assuming that w(0) = 0 and that e is chosen to be small enough to guarantee |1 \u2014 e\\i | < 1, the parameter trajectory during training after t parameter updates\u00a0is as follows:",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2661",
    "text": "QTw(t) = [I - (I - eA)T]QTw*",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2662",
    "text": "w*",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2663",
    "text": "-7.4",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2664",
    "text": "1 \u00a0\u00a0\u00a0~\u00a0\u00a0\u00a0\u00a0o",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2665",
    "text": "Now, the expression for Q 1 w in Eq. 7.13 for L regularization can be rearranged as:",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2666",
    "text": "Qt w = (A + aI )-1A Q Tw *",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2667",
    "text": "\u00bbT,",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2668",
    "text": "\u00bbT",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2669",
    "text": "1",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2670",
    "text": "Q 1 w = [I - (A + al) 1a]QTw*",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2671",
    "text": "-7.41",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2672",
    "text": "-7.42",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2673",
    "text": "Comparing Eq. 7.40 and Eq. 7.42, we see that if the hyperparameters e, a, and t are chosen such that",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2674",
    "text": "(I - eA)T = (A + aI)-1 a, \u00a0\u00a0\u00a0(7.43)",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2675",
    "text": "then L2 regularization and early stopping can be seen to be equivalent (at least under the quadratic approximation of the objective function). Going even further,\u00a0by taking logarithms and using the series expansion for log(1 + x), we can conclude\u00a0that if all Ai are small (that is, eA ^ 1 and Ai/a ^ 1) then",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2676",
    "text": "1",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2677",
    "text": "t",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2678",
    "text": "ea",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2679",
    "text": "1",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2680",
    "text": "Te",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2681",
    "text": "-7.44",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2682",
    "text": "a",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2683",
    "text": "-7.45",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2684",
    "text": "That is, under these assumptions, the number of training iterations t plays a role",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2685",
    "text": "C\\",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2686",
    "text": "inversely proportional to the L regularization parameter, and the inverse of Te plays the role of the weight decay coefficient.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2687",
    "text": "Parameter values corresponding to directions of significant curvature (of the objective function) are regularized less than directions of less curvature. Of course,\u00a0in the context of early stopping, this really means that parameters that correspond\u00a0to directions of significant curvature tend to learn early relative to parameters\u00a0corresponding to directions of less curvature.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2688",
    "text": "The derivations in this section have shown that a trajectory of length t ends at a point that corresponds to a minimum of the L2-regularized objective. Early\u00a0stopping is of course more than the mere restriction of the trajectory length;\u00a0instead, early stopping typically involves monitoring the validation set error in\u00a0order to stop the trajectory at a particularly good point in space. Early stopping\u00a0therefore has the advantage over weight decay that early stopping automatically\u00a0determines the correct amount of regularization while weight decay requires many\u00a0training experiments with different values of its hyperparameter.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2689",
    "text": "1",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2690",
    "text": " More generally, we could regularize the parameters to be near any specific point in space and, surprisingly, still get a regularization effect, but better results will be obtained for a value\u00a0closer to the true one, with zero being a default value that makes sense when we do not know if\u00a0the correct value should be positive or negative. Since it is far more common to regularize the\u00a0model parameters towards zero, we will focus on this special case in our exposition.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2691",
    "text": "2",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2692",
    "text": " As with L2 regularization, we could regularize the parameters towards a value that is not zero, but instead towards some parameter value w(o). In that case the L1 regularization would\u00a0introduce the term Q(9) = || w \u2014 w(o) || 1 =\u00a0\u00a0\u00a0\u00a0|wj \u2014 w(o) |.",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2693",
    "text": "3",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2694",
    "text": " For neural networks, to obtain symmetry breaking between hidden units, we cannot initialize all the parameters to 0, as discussed in Sec. 6.2. However, the argument holds for any other\u00a0initial value w(0).",
    "chapter": "Practical Methodology",
    "chapter_id": "main-14.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2695",
    "text": "Thus far, in this chapter, when we have discussed adding constraints or penalties to the parameters, we have always done so with respect to a fixed region or point.\u00a0For example, L2 regularization (or weight decay) penalizes model parameters for\u00a0deviating from the fixed value of zero. However, sometimes we may need other\u00a0ways to express our prior knowledge about suitable values of the model parameters.\u00a0Sometimes we might not know precisely what values the parameters should take\u00a0but we know, from knowledge of the domain and model architecture, that there\u00a0should be some dependencies between the model parameters.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2696",
    "text": "A common type of dependency that we often want to express is that certain parameters should be close to one another. Consider the following scenario: we\u00a0have two models performing the same classification task (with the same set of\u00a0classes) but with somewhat different input distributions. Formally, we have model\u00a0A with parameters w(A) and model B with parameters w(B). The two models\u00a0map the input to two different, but related outputs: y(A) = f(w(A), x) and\u00a0y= g(w(B), x).",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2697",
    "text": "Let us imagine that the tasks are similar enough (perhaps with similar input and output distributions) that we believe the model parameters should be close\u00a0to each other: Vi,\u00a0\u00a0\u00a0\u00a0should be close to . We can leverage this information",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2698",
    "text": "through regularization. Specifically, we can use a parameter norm penalty of the form: 0,(w(A), w(B)) = || w(A) \u2014 w(B)||2. Here we used an L2 penalty, but other\u00a0choices are also possible.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2699",
    "text": "This kind of approach was proposed by Lasserre et al. (2006), who regularized the parameters of one model, trained as a classifier in a supervised paradigm, to\u00a0be close to the parameters of another model, trained in an unsupervised paradigm\u00a0(to capture the distribution of the observed input data). The architectures were\u00a0constructed such that many of the parameters in the classifier model could be\u00a0paired to corresponding parameters in the unsupervised model.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2700",
    "text": "While a parameter norm penalty is one way to regularize parameters to be close to one another, the more popular way is to use constraints: to force sets of\u00a0parameters to be equal. This method of regularization is often referred to as\u00a0parameter sharing, where we interpret the various models or model components as\u00a0sharing a unique set of parameters. A significant advantage of parameter sharing\u00a0over regularizing the parameters to be close (via a norm penalty) is that only a\u00a0subset of the parameters (the unique set) need to be stored in memory. In certain\u00a0models\u2014such as the convolutional neural network\u2014this can lead to significant\u00a0reduction in the memory footprint of the model.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2701",
    "text": "Convolutional Neural Networks By far the most popular and extensive use of parameter sharing occurs in convolutional neural networks (CNNs) applied to\u00a0computer vision.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2702",
    "text": "Natural images have many statistical properties that are invariant to translation. For example, a photo of a cat remains a photo of a cat if it is translated one pixel\u00a0to the right. CNNs take this property into account by sharing parameters across\u00a0multiple image locations. The same feature (a hidden unit with the same weights)\u00a0is computed over different locations in the input. This means that we can find a\u00a0cat with the same cat detector whether the cat appears at column i or column\u00a0i + 1 in the image.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2703",
    "text": "Parameter sharing has allowed CNNs to dramatically lower the number of unique model parameters and to significantly increase network sizes without requiring a\u00a0corresponding increase in training data. It remains one of the best examples of\u00a0how to effectively incorporate domain knowledge into the network architecture.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2704",
    "text": "CNNs will be discussed in more detail in Chapter 9.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2705",
    "text": "Weight decay acts by placing a penalty directly on the model parameters. Another strategy is to place a penalty on the activations of the units in a neural network,\u00a0encouraging their activations to be sparse. This indirectly imposes a complicated\u00a0penalty on the model parameters.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2706",
    "text": "We have already discussed (in Sec. 7.1.2) how L1 penalization induces a sparse parametrization\u2014meaning that many of the parameters become zero (or close to\u00a0zero). Representational sparsity, on the other hand, describes a representation\u00a0where many of the elements of the representation are zero (or close to zero).\u00a0A simplified view of this distinction can be illustrated in the context of linear\u00a0regression:",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2707",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2708",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2709",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2710",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2711",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2712",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2713",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2714",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2715",
    "text": "2",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2716",
    "text": " 18 \"",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2717",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2718",
    "text": "4",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2719",
    "text": "0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2720",
    "text": "0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2721",
    "text": "-2",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2722",
    "text": "0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2723",
    "text": "0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2724",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2725",
    "text": "3",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2726",
    "text": "5",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2727",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2728",
    "text": "0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2729",
    "text": "0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2730",
    "text": "-1",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2731",
    "text": "0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2732",
    "text": "3",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2733",
    "text": "0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2734",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2735",
    "text": "-2",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2736",
    "text": "15",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2737",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2738",
    "text": "0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2739",
    "text": "5",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2740",
    "text": "0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2741",
    "text": "0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2742",
    "text": "0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2743",
    "text": "0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2744",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2745",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2746",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2747",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2748",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2749",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2750",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2751",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2752",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2753",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2754",
    "text": "-5",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2755",
    "text": "-9",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2756",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2757",
    "text": "1",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2758",
    "text": "0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2759",
    "text": "0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2760",
    "text": "-1",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2761",
    "text": "0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2762",
    "text": "-4",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2763",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2764",
    "text": "1",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2765",
    "text": "-3 _",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2766",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2767",
    "text": "1",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2768",
    "text": "0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2769",
    "text": "0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2770",
    "text": "0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2771",
    "text": "-5",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2772",
    "text": "0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2773",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2774",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2775",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2776",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2777",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2778",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2779",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2780",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2781",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2782",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2783",
    "text": "4",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2784",
    "text": "y e Rm",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2785",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2786",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2787",
    "text": "A e R",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2788",
    "text": "mxn",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2789",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2790",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2791",
    "text": "x e R",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2792",
    "text": "-7.46",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2793",
    "text": "In the first expression, we have an example of a sparsely parametrized linear regression model. In the second, we have linear regression with a sparse representation h of the data x. That is, h is a function of x that, in some sense, represents\u00a0the information present in x, but does so with a sparse vector.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2794",
    "text": "Representational regularization is accomplished by the same sorts of mechanisms that we have used in parameter regularization.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2795",
    "text": "Norm penalty regularization of representations is performed by adding to the loss function J a norm penalty on the representation. This penalty is denoted\u00a0Q(h). As before, we denote the regularized loss function by J:",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2796",
    "text": "-7.48",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2797",
    "text": "-1",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2798",
    "text": "1",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2799",
    "text": "_1",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2800",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2801",
    "text": "3",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2802",
    "text": "\u20141",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2803",
    "text": "2",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2804",
    "text": "\u20145",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2805",
    "text": "4",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2806",
    "text": "1",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2807",
    "text": "1",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2808",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2809",
    "text": "4",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2810",
    "text": "2",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2811",
    "text": "\u20143",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2812",
    "text": "\u20141",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2813",
    "text": "1",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2814",
    "text": "3",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2815",
    "text": "19",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2816",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2817",
    "text": "\u2014 1",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2818",
    "text": "5",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2819",
    "text": "4",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2820",
    "text": "2",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2821",
    "text": "\u20143",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2822",
    "text": "\u20142",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2823",
    "text": "2",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2824",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2825",
    "text": "3",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2826",
    "text": "1",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2827",
    "text": "2",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2828",
    "text": "\u20143",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2829",
    "text": "0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2830",
    "text": "\u20143",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2831",
    "text": "23",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2832",
    "text": "",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2833",
    "text": "\u20145",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2834",
    "text": "4",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2835",
    "text": "\u20142",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2836",
    "text": "2",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2837",
    "text": "\u20145",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2838",
    "text": "\u20141",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2839",
    "text": "y e RT",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2840",
    "text": "Be Rr",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2841",
    "text": "0 2\u00a00\u00a00",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2842",
    "text": "-3 0",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2843",
    "text": "he R",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2844",
    "text": "-7.47",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2845",
    "text": "J(e; X, y) = J( h; X, y) + afi(h)",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2846",
    "text": "where a e [0, to) weights the relative contribution of the norm penalty term, with larger values of a corresponding to more regularization.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2847",
    "text": "Just as an L1 penalty on the parameters induces parameter sparsity, an L1 penalty on the elements of the representation induces representational sparsity:\u00a0Q(h) = ||h||1 = ^i |hi|. Of course, the L1 penalty is only one choice of penalty\u00a0that can result in a sparse representation. Others include the penalty derived from\u00a0a Student- prior on the representation (Olshausen and Field, 1996; Bergstra, 2011)\u00a0and KL divergence penalties (Larochelle and Bengio, 2008) that are especially\u00a0useful for representations with elements constrained to lie on the unit interval.\u00a0Lee et al. (2008) and Goodfellow et al. (2009) both provide examples of strategies\u00a0based on regularizing the average activation across several examples, A\u00a0\u00a0\u00a0\u00a0h(i), to",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2848",
    "text": "be near some target value, such as a vector with .01 for each entry.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2849",
    "text": "Other approaches obtain representational sparsity with a hard constraint on the activation values. For example, orthogonal matching pursuit (Pati et al.,\u00a01993) encodes an input x with the representation h that solves the constrained\u00a0optimization problem",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2850",
    "text": "argmin ||x \u2014 Wh||2, \u00a0\u00a0\u00a0(7.49)",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2851",
    "text": "h,||h||0 <k",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2852",
    "text": "where ||h||0 is the number of non-zero entries of h. This problem can be solved efficiently when W is constrained to be orthogonal. This method is often called",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2853",
    "text": "OMP-k with the value of k specified to indicate the number of non-zero features allowed. Coates and Ng (2011) demonstrated that OMP-1 can be a very effective\u00a0feature extractor for deep architectures.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2854",
    "text": "Essentially any model that has hidden units can be made sparse. Throughout this book, we will see many examples of sparsity regularization used in a variety of\u00a0contexts.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2855",
    "text": "Bagging (short for bootstrap aggregating) is a technique for reducing generalization error by combining several models (Breiman, 1994). The idea is to train several\u00a0different models separately, then have all of the models vote on the output for test\u00a0examples. This is an example of a general strategy in machine learning called model\u00a0averaging. Techniques employing this strategy are known as ensemble methods.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2856",
    "text": "The reason that model averaging works is that different models will usually not make all the same errors on the test set.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2857",
    "text": "Consider for example a set of k regression models. Suppose that each model makes an error ei on each example, with the errors drawn from a zero-mean\u00a0multivariate normal distribution with variances E[e 2] = v and covariances E[eie j =\u00a0c. Then the error made by the average prediction of all the ensemble models is\u00a0k Yli ei. The expected squared error of the ensemble predictor is",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2858",
    "text": "E",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2859",
    "text": "(k ? \u05f4)",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2860",
    "text": "1",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2861",
    "text": "5ZIe\u20222 + eiej",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2862",
    "text": "i \\ \u00a0\u00a0\u00a0j=i",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2863",
    "text": "1 k-1",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2864",
    "text": "k2 E",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2865",
    "text": "#ERROR!",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2866",
    "text": "-7.5",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2867",
    "text": "-7.51",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2868",
    "text": "In the case where the errors are perfectly correlated and c = v, the mean squared error reduces to v, so the model averaging does not help at all. In the case where\u00a0the errors are perfectly uncorrelated and c = 0, the expected squared error of the\u00a0ensemble is only -|,v. This means that the expected squared error of the ensemble\u00a0decreases linearly with the ensemble size. In other words, on average, the ensemble\u00a0will perform at least as well as any of its members, and if the members make\u00a0independent errors, the ensemble will perform significantly better than its members.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2869",
    "text": "Different ensemble methods construct the ensemble of models in different ways. For example, each member of the ensemble could be formed by training a completely\u00a0different kind of model using a different algorithm or objective function. Bagging",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2870",
    "text": "Original dataset",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2871",
    "text": "First resampled dataset",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2872",
    "text": "Second resampled dataset \u00a9@\u00ae",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2873",
    "text": "Figure 7.5: A cartoon depiction of how bagging works. Suppose we train an \u20188\u2019 detector on the dataset depicted above, containing an \u20188\u2019, a \u20186\u2019 and a \u20189\u2019. Suppose we make two\u00a0different resampled datasets. The bagging training procedure is to construct each of these\u00a0datasets by sampling with replacement. The first dataset omits the \u20189\u2019 and repeats the \u20188\u2019.\u00a0On this dataset, the detector learns that a loop on top of the digit corresponds to an \u20188\u2019.\u00a0On the second dataset, we repeat the \u20189\u2019 and omit the \u20186\u2019. In this case, the detector learns\u00a0that a loop on the bottom of the digit corresponds to an \u20188\u2019. Each of these individual\u00a0classification rules is brittle, but if we average their output then the detector is robust,\u00a0achieving maximal confidence only when both loops of the \u20188\u2019 are present.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2874",
    "text": "is a method that allows the same kind of model, training algorithm and objective function to be reused several times.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2875",
    "text": "Specifically, bagging involves constructing k different datasets. Each dataset has the same number of examples as the original dataset, but each dataset is\u00a0constructed by sampling with replacement from the original dataset. This means\u00a0that, with high probability, each dataset is missing some of the examples from the\u00a0original dataset and also contains several duplicate examples (on average around\u00a02/3 of the examples from the original dataset are found in the resulting training\u00a0set, if it has the same size as the original). Model i is then trained on dataset\u00a0i. The differences between which examples are included in each dataset result in\u00a0differences between the trained models. See Fig. 7.5 for an example.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2876",
    "text": "Neural networks reach a wide enough variety of solution points that they can often benefit from model averaging even if all of the models are trained on the same\u00a0dataset. Differences in random initialization, random selection of minibatches,\u00a0differences in hyperparameters, or different outcomes of non-deterministic implementations of neural networks are often enough to cause different members of the\u00a0ensemble to make partially independent errors.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2877",
    "text": "Model averaging is an extremely powerful and reliable method for reducing generalization error. Its use is usually discouraged when benchmarking algorithms\u00a0for scientific papers, because any machine learning algorithm can benefit substantially from model averaging at the price of increased computation and memory.\u00a0For this reason, benchmark comparisons are usually made using a single model.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2878",
    "text": "Machine learning contests are usually won by methods using model averaging over dozens of models. A recent prominent example is the Netflix Grand Prize (Koren, 2009).",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2879",
    "text": "Not all techniques for constructing ensembles are designed to make the ensemble more regularized than the individual models. For example, a technique called\u00a0boosting (Freund and Schapire, 1996b,a) constructs an ensemble with higher capacity\u00a0than the individual models. Boosting has been applied to build ensembles of neural\u00a0networks (Schwenk and Bengio, 1998) by incrementally adding neural networks to\u00a0the ensemble. Boosting has also been applied interpreting an individual neural\u00a0network as an ensemble (Bengio et al., 2006a), incrementally adding hidden units\u00a0to the neural network.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2880",
    "text": "Dropout (Srivastava et al., 2014) provides a computationally inexpensive but powerful method of regularizing a broad family of models. To a first approximation,\u00a0dropout can be thought of as a method of making bagging practical for ensembles\u00a0of very many large neural networks. Bagging involves training multiple models,\u00a0and evaluating multiple models on each test example. This seems impractical\u00a0when each model is a large neural network, since training and evaluating such\u00a0networks is costly in terms of runtime and memory. It is common to use ensembles\u00a0of five to ten neural networks\u2014Szegedy et al. (2014a) used six to win the ILSVRC\u2014\u00a0but more than this rapidly becomes unwieldy. Dropout provides an inexpensive\u00a0approximation to training and evaluating a bagged ensemble of exponentially many\u00a0neural networks.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2881",
    "text": "Specifically, dropout trains the ensemble consisting of all sub-networks that can be formed by removing non-output units from an underlying base network,\u00a0as illustrated in Fig. 7.6. In most modern neural networks, based on a series of\u00a0affine transformations and nonlinearities, we can effectively remove a unit from a\u00a0network by multiplying its output value by zero. This procedure requires some\u00a0slight modification for models such as radial basis function networks, which take\u00a0the difference between the unit\u2019s state and some reference value. Here, we present\u00a0the dropout algorithm in terms of multiplication by zero for simplicity, but it can\u00a0be trivially modified to work with other operations that remove a unit from the\u00a0network.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2882",
    "text": "Recall that to learn with bagging, we define k different models, construct k different datasets by sampling from the training set with replacement, and then\u00a0train model i on dataset i. Dropout aims to approximate this process, but with an\u00a0exponentially large number of neural networks. Specifically, to train with dropout,\u00a0we use a minibatch-based learning algorithm that makes small steps, such as\u00a0stochastic gradient descent. Each time we load an example into a minibatch, we\u00a0randomly sample a different binary mask to apply to all of the input and hidden\u00a0units in the network. The mask for each unit is sampled independently from all of\u00a0the others. The probability of sampling a mask value of one (causing a unit to be\u00a0included) is a hyperparameter fixed before training begins. It is not a function\u00a0of the current value of the model parameters or the input example. Typically,\u00a0an input unit is included with probability 0.8 and a hidden unit is included with\u00a0probability 0.5. We then run forward propagation, back-propagation, and the\u00a0learning update as usual. Fig. 7.7 illustrates how to run forward propagation with\u00a0dropout.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2883",
    "text": "More formally, suppose that a mask vector fi specifies which units to include, and J(6, i) defines the cost of the model defined by parameters 6 and mask !\u05f3.\u00a0Then dropout training consists in minimizing E^ J(6, i). The expectation contains\u00a0exponentially many terms but we can obtain an unbiased estimate of its gradient\u00a0by sampling values of !\u05f3.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2884",
    "text": "Dropout training is not quite the same as bagging training. In the case of bagging, the models are all independent. In the case of dropout, the models share\u00a0parameters, with each model inheriting a different subset of parameters from the\u00a0parent neural network. This parameter sharing makes it possible to represent an\u00a0exponential number of models with a tractable amount of memory. In the case of\u00a0bagging, each model is trained to convergence on its respective training set. In the\u00a0case of dropout, typically most models are not explicitly trained at all\u2014usually,\u00a0the model is large enough that it would be infeasible to sample all possible subnetworks within the lifetime of the universe. Instead, a tiny fraction of the possible\u00a0sub-networks are each trained for a single step, and the parameter sharing causes\u00a0the remaining sub-networks to arrive at good settings of the parameters. These\u00a0are the only differences. Beyond these, dropout follows the bagging algorithm. For\u00a0example, the training set encountered by each sub-network is indeed a subset of\u00a0the original training set sampled with replacement.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2885",
    "text": "To make a prediction, a bagged ensemble must accumulate votes from all of its members. We refer to this process as inference in this context. So far, our",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2886",
    "text": "description of bagging and dropout has not required that the model be explicitly probabilistic. Now, we assume that the model\u2019s role is to output a probability\u00a0distribution. In the case of bagging, each model i produces a probability distribution",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2887",
    "text": "pM",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2888",
    "text": "of these distributions,",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2889",
    "text": "x). The prediction of the ensemble is given by the arithmetic mean of all",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2890",
    "text": "-7.52",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2891",
    "text": "1x)\u05f3",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2892",
    "text": "In the case of dropout, each sub-model defined by mask vector i defines a probability distribution p(y | x, i). The arithmetic mean over all masks is given by",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2893",
    "text": "p(i)p(v 1 x, i) \u00a0\u00a0\u00a0(7.53)",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2894",
    "text": "M",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2895",
    "text": "where p(l) is the probability distribution that was used to sample i at training time.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2896",
    "text": "Because this sum includes an exponential number of terms, it is intractable to evaluate except in cases where the structure of the model permits some form\u00a0of simplification. So far, deep neural nets are not known to permit any tractable\u00a0simplification. Instead, we can approximate the inference with sampling, by\u00a0averaging together the output from many masks. Even 10-20 masks are often\u00a0sufficient to obtain good performance.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2897",
    "text": "However, there is an even better approach, that allows us to obtain a good approximation to the predictions of the entire ensemble, at the cost of only one\u00a0forward propagation. To do so, we change to using the geometric mean rather than\u00a0the arithmetic mean of the ensemble members\u2019 predicted distributions. Warde-Farley et al. (2014) present arguments and empirical evidence that the geometric\u00a0mean performs comparably to the arithmetic mean in this context.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2898",
    "text": "The geometric mean of multiple probability distributions is not guaranteed to be a probability distribution. To guarantee that the result is a probability distribution,\u00a0we impose the requirement that none of the sub-models assigns probability 0 to any\u00a0event, and we renormalize the resulting distribution. The unnormalized probability\u00a0distribution defined directly by the geometric mean is given by",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2899",
    "text": "-7.54",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2900",
    "text": "pensemble(v | x) = 2d \u00a0\u00a0\u00a0p(v | X, l)",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2901",
    "text": "M",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2902",
    "text": "where d is the number of units that may be dropped. Here we use a uniform distribution over i to simplify the presentation, but non-uniform distributions are",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2903",
    "text": "also possible. To make predictions we must re-normalize the ensemble:",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2904",
    "text": "-7.55",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2905",
    "text": "Pensemble(y 1 x) \u2014",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2906",
    "text": "Ttnsemble (y 1 x)",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2907",
    "text": "\u05f3 pensemb1e(y' 1 x)",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2908",
    "text": "A key insight (Hinton et al., 2012c) involved in dropout is that we can approximate pensemb1e by evaluating p(y | x) in one model: the model with all units, but with the weights going out of unit i multiplied by the probability of including unit\u00a0i. The motivation for this modification is to capture the right expected value of\u00a0the output from that unit. We call this approach the weight scaling inference rule.\u00a0There is not yet any theoretical argument for the accuracy of this approximate\u00a0inference rule in deep nonlinear networks, but empirically it performs very well.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2909",
    "text": "Because we usually use an inclusion probability of 2, the weight scaling rule usually amounts to dividing the weights by 2 at the end of training, and then using\u00a0the model as usual. Another way to achieve the same result is to multiply the\u00a0states of the units by 2 during training. Either way, the goal is to make sure that\u00a0the expected total input to a unit at test time is roughly the same as the expected\u00a0total input to that unit at train time, even though half the units at train time are\u00a0missing on average.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2910",
    "text": "For many classes of models that do not have nonlinear hidden units, the weight scaling inference rule is exact. For a simple example, consider a softmax regression\u00a0classifier with n input variables represented by the vector v:",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2911",
    "text": "-7.56",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2912",
    "text": "P(y \u2014 y | v) \u2014 softmax ^WTv + b \u00a0\u00a0\u00a0.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2913",
    "text": "We can index into the family of sub-models by element-wise multiplication of the input with a binary vector d:",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2914",
    "text": "-7.57",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2915",
    "text": "P(y \u2014 y | v; d) \u2014 softmax ^WT(d 0 v) + b .",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2916",
    "text": "The ensemble predictor is defined by re-normalizing the geometric mean over all ensemble members\u2019 predictions:",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2917",
    "text": "Pensemble(y \u2014 y | v) \u2014",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2918",
    "text": "P3nsemb1e(y \u2014 y 1 v)",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2919",
    "text": "Pensemb1e(y \u2014 y' | v)",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2920",
    "text": "-7.58",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2921",
    "text": "where",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2922",
    "text": "-7.59",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2923",
    "text": "Pensemb1e(y \u2014 V | v) \u2014 2? \u00a0\u00a0\u00a0P(y \u2014 V | v; d) .",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2924",
    "text": "de{0,1}n",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2925",
    "text": "To see that the weight scaling rule is exact, we can simplify Pensembie:",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2926",
    "text": "-7.6",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2927",
    "text": "-7.61",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2928",
    "text": "-Pensembie(y = V | v) = 2\"/ \u00a0\u00a0\u00a0P^ = V I v; d)",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2929",
    "text": "de{0,1}\"",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2930",
    "text": "2 \u00a0\u00a0\u00a0softmax (WT (d 0 v) + b)y",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2931",
    "text": "de{0,1} \u05f4",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2932",
    "text": "2",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2933",
    "text": "n",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2934",
    "text": "exp (WT:(d 0 v) + b",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2935",
    "text": "de{011}\u05f4 Ey\u05f3 exp (WJ. (d 0 v) + b)",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2936",
    "text": "-7.62",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2937",
    "text": "2",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2938",
    "text": "^{0,1}\u05f4 exp (wT(d 0 v)+b",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2939",
    "text": "2",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2940",
    "text": "dE{0.1f^y' eXP (WT,:(d 0 v) + b)",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2941",
    "text": "-7.63",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2942",
    "text": "Because P will be normalized, we can safely ignore multiplication by factors that are constant with respect to V:",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2943",
    "text": "\u25a0Pensembie(y = V I v) \u00ab 2\" \u00a0\u00a0\u00a0exp (WyT (d 0 v) + b)\u00a0\u00a0\u00a0\u00a0(7.64)",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2944",
    "text": "de{0,1}\"",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2945",
    "text": "-7.65",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2946",
    "text": "1",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2947",
    "text": "exP I 2n \u00a0\u00a0\u00a0WZ(d 0 v) + b I",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2948",
    "text": "de{0,1}\u05f4",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2949",
    "text": "12",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2950",
    "text": "exp ( rWy,: v + b",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2951",
    "text": "-7.66",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2952",
    "text": "Substituting this back into Eq. 7.58 we obtain a softmax classifier with weights 2w.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2953",
    "text": "The weight scaling rule is also exact in other settings, including regression networks with conditionally normal outputs, and deep networks that have hidden\u00a0layers without nonlinearities. However, the weight scaling rule is only an approximation for deep models that have nonlinearities. Though the approximation has\u00a0not been theoretically characterized, it often works well, empirically. Goodfellow\u00a0et al. (2013a) found experimentally that the weight scaling approximation can work\u00a0better (in terms of classification accuracy) than Monte Carlo approximations to the\u00a0ensemble predictor. This held true even when the Monte Carlo approximation was\u00a0allowed to sample up to 1,000 sub-networks. Gal and Ghahramani (2015) found\u00a0that some models obtain better classification accuracy using twenty samples and\u00a0the Monte Carlo approximation. It appears that the optimal choice of inference\u00a0approximation is problem-dependent.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2954",
    "text": "Srivastava et al. (2014) showed that dropout is more effective than other standard computationally inexpensive regularizers, such as weight decay, filter\u00a0norm constraints and sparse activity regularization. Dropout may also be combined\u00a0with other forms of regularization to yield a further improvement.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2955",
    "text": "One advantage of dropout is that it is very computationally cheap. Using dropout during training requires only O(n) computation per example per update,\u00a0to generate n random binary numbers and multiply them by the state. Depending\u00a0on the implementation, it may also require O (n) memory to store these binary\u00a0numbers until the back-propagation stage. Running inference in the trained model\u00a0has the same cost per-example as if dropout were not used, though we must pay\u00a0the cost of dividing the weights by 2 once before beginning to run inference on\u00a0examples.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2956",
    "text": "Another significant advantage of dropout is that it does not significantly limit the type of model or training procedure that can be used. It works well with nearly\u00a0any model that uses a distributed representation and can be trained with stochastic\u00a0gradient descent. This includes feedforward neural networks, probabilistic models\u00a0such as restricted Boltzmann machines (Srivastava et al., 2014), and recurrent\u00a0neural networks (Bayer and Osendorfer, 2014; Pascanu et al., 2014a). Many other\u00a0regularization strategies of comparable power impose more severe restrictions on\u00a0the architecture of the model.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2957",
    "text": "Though the cost per-step of applying dropout to a specific model is negligible, the cost of using dropout in a complete system can be significant. Because dropout\u00a0is a regularization technique, it reduces the effective capacity of a model. To offset\u00a0this effect, we must increase the size of the model. Typically the optimal validation\u00a0set error is much lower when using dropout, but this comes at the cost of a much\u00a0larger model and many more iterations of the training algorithm. For very large\u00a0datasets, regularization confers little reduction in generalization error. In these\u00a0cases, the computational cost of using dropout and larger models may outweigh\u00a0the benefit of regularization.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2958",
    "text": "When extremely few labeled training examples are available, dropout is less effective. Bayesian neural networks (Neal, 1996) outperform dropout on the\u00a0Alternative Splicing Dataset (Xiong et al., 2011) where fewer than 5,000 examples\u00a0are available (Srivastava et al., 2014). When additional unlabeled data is available,\u00a0unsupervised feature learning can gain an advantage over dropout.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2959",
    "text": "Wager et al. (2013) showed that, when applied to linear regression, dropout is equivalent to L2 weight decay, with a different weight decay coefficient for\u00a0each input feature. The magnitude of each feature\u2019s weight decay coefficient is\u00a0determined by its variance. Similar results hold for other linear models. For deep\u00a0models, dropout is not equivalent to weight decay.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2960",
    "text": "The stochasticity used while training with dropout is not necessary for the approach\u2019s success. It is just a means of approximating the sum over all submodels. Wang and Manning (2013) derived analytical approximations to this\u00a0marginalization. Their approximation, known as fast dropout resulted in faster\u00a0convergence time due to the reduced stochasticity in the computation of the\u00a0gradient. This method can also be applied at test time, as a more principled\u00a0(but also more computationally expensive) approximation to the average over all\u00a0sub-networks than the weight scaling approximation. Fast dropout has been used\u00a0to nearly match the performance of standard dropout on small neural network\u00a0problems, but has not yet yielded a significant improvement or been applied to a\u00a0large problem.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2961",
    "text": "Just as stochasticity is not necessary to achieve the regularizing effect of dropout, it is also not sufficient. To demonstrate this, Warde-Farley et al. (2014)\u00a0designed control experiments using a method called dropout boosting that they\u00a0designed to use exactly the same mask noise as traditional dropout but lack\u00a0its regularizing effect. Dropout boosting trains the entire ensemble to jointly\u00a0maximize the log-likelihood on the training set. In the same sense that traditional\u00a0dropout is analogous to bagging, this approach is analogous to boosting. As\u00a0intended, experiments with dropout boosting show almost no regularization effect\u00a0compared to training the entire network as a single model. This demonstrates that\u00a0the interpretation of dropout as bagging has value beyond the interpretation of\u00a0dropout as robustness to noise. The regularization effect of the bagged ensemble is\u00a0only achieved when the stochastically sampled ensemble members are trained to\u00a0perform well independently of each other.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2962",
    "text": "Dropout has inspired other stochastic approaches to training exponentially large ensembles of models that share weights. DropConnect is a special case of\u00a0dropout where each product between a single scalar weight and a single hidden\u00a0unit state is considered a unit that can be dropped (Wan et al., 2013). Stochastic\u00a0pooling is a form of randomized pooling (see Sec. 9.3) for building ensembles\u00a0of convolutional networks with each convolutional network attending to different\u00a0spatial locations of each feature map. So far, dropout remains the most widely\u00a0used implicit ensemble method.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2963",
    "text": "One of the key insights of dropout is that training a network with stochastic behavior and making predictions by averaging over multiple stochastic decisions\u00a0implements a form of bagging with parameter sharing. Earlier, we described\u00a0dropout as bagging an ensemble of models formed by including or excluding\u00a0units. However, there is no need for this model averaging strategy to be based on\u00a0inclusion and exclusion. In principle, any kind of random modification is admissible.\u00a0In practice, we must choose modification families that neural networks are able\u00a0to learn to resist. Ideally, we should also use model families that allow a fast\u00a0approximate inference rule. We can think of any form of modification parametrized\u00a0by a vector p as training an ensemble consisting of p(y | x, p) for all possible\u00a0values of p. There is no requirement that p have a finite number of values. For\u00a0example, p can be real-valued. Srivastava et al. (2014) showed that multiplying the\u00a0weights by p ~ N(1,1) can outperform dropout based on binary masks. Because\u00a0E[p] = 1 the standard network automatically implements approximate inference\u00a0in the ensemble, without needing any weight scaling.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2964",
    "text": "So far we have described dropout purely as a means of performing efficient, approximate bagging. However, there is another view of dropout that goes further\u00a0than this. Dropout trains not just a bagged ensemble of models, but an ensemble\u00a0of models that share hidden units. This means each hidden unit must be able to\u00a0perform well regardless of which other hidden units are in the model. Hidden units\u00a0must be prepared to be swapped and interchanged between models. Hinton et al.\u00a0(2012c) were inspired by an idea from biology: sexual reproduction, which involves\u00a0swapping genes between two different organisms, creates evolutionary pressure for\u00a0genes to become not just good, but to become readily swapped between different\u00a0organisms. Such genes and such features are very robust to changes in their\u00a0environment because they are not able to incorrectly adapt to unusual features\u00a0of any one organism or model. Dropout thus regularizes each hidden unit to be\u00a0not merely a good feature but a feature that is good in many contexts. Warde-Farley et al. (2014) compared dropout training to training of large ensembles and\u00a0concluded that dropout offers additional improvements to generalization error\u00a0beyond those obtained by ensembles of independent models.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2965",
    "text": "It is important to understand that a large portion of the power of dropout arises from the fact that the masking noise is applied to the hidden units. This\u00a0can be seen as a form of highly intelligent, adaptive destruction of the information\u00a0content of the input rather than destruction of the raw values of the input. For\u00a0example, if the model learns a hidden unit hi that detects a face by finding the nose,\u00a0then dropping hi corresponds to erasing the information that there is a nose in\u00a0the image. The model must learn another hi, either that redundantly encodes the\u00a0presence of a nose, or that detects the face by another feature, such as the mouth.\u00a0Traditional noise injection techniques that add unstructured noise at the input are\u00a0not able to randomly erase the information about a nose from an image of a face\u00a0unless the magnitude of the noise is so great that nearly all of the information in\u00a0the image is removed. Destroying extracted features rather than original values\u00a0allows the destruction process to make use of all of the knowledge about the input\u00a0distribution that the model has acquired so far.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2966",
    "text": "Another important aspect of dropout is that the noise is multiplicative. If the noise were additive with fixed scale, then a rectified linear hidden unit hi with\u00a0added noise e could simply learn to have hi become very large in order to make\u00a0the added noise e insignificant by comparison. Multiplicative noise does not allow\u00a0such a pathological solution to the noise robustness problem.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2967",
    "text": "Another deep learning algorithm, batch normalization, reparametrizes the model in a way that introduces both additive and multiplicative noise on the\u00a0hidden units at training time. The primary purpose of batch normalization is to\u00a0improve optimization, but the noise can have a regularizing effect, and sometimes\u00a0makes dropout unnecessary. Batch normalization is described further in Sec. 8.7.1.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2968",
    "text": "In many cases, neural networks have begun to reach human performance when evaluated on an i.i.d. test set. It is natural therefore to wonder whether these\u00a0models have obtained a true human-level understanding of these tasks. In order\u00a0to probe the level of understanding a network has of the underlying task, we can\u00a0search for examples that the model misclassifies. Szegedy et al. (2014b) found that\u00a0even neural networks that perform at human level accuracy have a nearly 100%\u00a0error rate on examples that are intentionally constructed by using an optimization\u00a0procedure to search for an input x' near a data point x such that the model output\u00a0is very different at x'. In many cases, x' can be so similar to x that a human\u00a0observer cannot tell the difference between the original example and the adversarial\u00a0example, but the network can make highly different predictions. See Fig. 7.8 for an\u00a0example.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2969",
    "text": "Adversarial examples have many implications, for example, in computer security, that are beyond the scope of this chapter. However, they are interesting in the\u00a0context of regularization because one can reduce the error rate on the original i.i.d.\u00a0test set via adversarial training\u2014training on adversarially perturbed examples\u00a0from the training set (Szegedy et al., 2014b; Goodfellow et al., 2014b).",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2970",
    "text": "Goodfellow et al. (2014b) showed that one of the primary causes of these adversarial examples is excessive linearity. Neural networks are built out of\u00a0primarily linear building blocks. In some experiments the overall function they\u00a0implement proves to be highly linear as a result. These linear functions are easy",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2971",
    "text": "x",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2972",
    "text": "y =\u201cpanda\u201d w/ 57.7%\u00a0confidence",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2973",
    "text": "sign(Vx J(6, x,y))",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2974",
    "text": "\u201cnematode\u201d w/ 8.2%\u00a0confidence",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2975",
    "text": "x +",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2976",
    "text": "e sign(V*J(6, x,y)) \u201cgibbon\u201d\u00a0w/ 99.3 %\u00a0confidence",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2977",
    "text": "Figure 7.8: A demonstration of adversarial example generation applied to GoogLeNet (Szegedy et al., 2014a) on ImageNet. By adding an imperceptibly small vector whose\u00a0elements are equal to the sign of the elements of the gradient of the cost function with\u00a0respect to the input, we can change GoogLeNet\u2019s classification of the image. Reproduced\u00a0with permission from Goodfellow et al. (2014b).",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2978",
    "text": "to optimize. Unfortunately, the value of a linear function can change very rapidly if it has numerous inputs. If we change each input by e, then a linear function\u00a0with weights w can change by as much as e||w|| 1, which can be a very large\u00a0amount if w is high-dimensional. Adversarial training discourages this highly\u00a0sensitive locally linear behavior by encouraging the network to be locally constant\u00a0in the neighborhood of the training data. This can be seen as a way of explicitly\u00a0introducing a local constancy prior into supervised neural nets.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2979",
    "text": "Adversarial training helps to illustrate the power of using a large function family in combination with aggressive regularization. Purely linear models, like\u00a0logistic regression, are not able to resist adversarial examples because they are\u00a0forced to be linear. Neural networks are able to represent functions that can range\u00a0from nearly linear to nearly locally constant and thus have the flexibility to capture\u00a0linear trends in the training data while still learning to resist local perturbation.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2980",
    "text": "Adversarial examples also provide a means of accomplishing semi-supervised learning. At a point x that is not associated with a label in the dataset, the\u00a0model itself assigns some label y. The model\u2019s label y may not be the true label,\u00a0but if the model is high quality, then y has a high probability of providing the\u00a0true label. We can seek an adversarial example x' that causes the classifier to\u00a0output a label y' with y' = y. Adversarial examples generated using not the\u00a0true label but a label provided by a trained model are called virtual adversarial\u00a0examples (Miyato et al., 2015). The classifier may then be trained to assign the\u00a0same label to x and x'. This encourages the classifier to learn a function that is\u00a0robust to small changes anywhere along the manifold where the unlabeled data\u00a0lies. The assumption motivating this approach is that different classes usually lie\u00a0on disconnected manifolds, and a small perturbation should not be able to jump\u00a0from one class manifold to another class manifold.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2981",
    "text": "Many machine learning algorithms aim to overcome the curse of dimensionality by assuming that the data lies near a low-dimensional manifold, as described in\u00a0Sec. 5.11.3.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2982",
    "text": "One of the early attempts to take advantage of the manifold hypothesis is the tangent distance algorithm (Simard et al., 1993, 1998). It is a non-parametric\u00a0nearest-neighbor algorithm in which the metric used is not the generic Euclidean\u00a0distance but one that is derived from knowledge of the manifolds near which\u00a0probability concentrates. It is assumed that we are trying to classify examples and\u00a0that examples on the same manifold share the same category. Since the classifier\u00a0should be invariant to the local factors of variation that correspond to movement\u00a0on the manifold, it would make sense to use as nearest-neighbor distance between\u00a0points x! and x2 the distance between the manifolds M! and M2 to which they\u00a0respectively belong. Although that may be computationally difficult (it would\u00a0require solving an optimization problem, to find the nearest pair of points on M!\u00a0and M2), a cheap alternative that makes sense locally is to approximate Mi by its\u00a0tangent plane at xi and measure the distance between the two tangents, or between\u00a0a tangent plane and a point. That can be achieved by solving a low-dimensional\u00a0linear system (in the dimension of the manifolds). Of course, this algorithm requires\u00a0one to specify the tangent vectors.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2983",
    "text": "In a related spirit, the tangent prop algorithm (Simard et al., 1992) (Fig. 7.9) trains a neural net classifier with an extra penalty to make each output f (x) of\u00a0the neural net locally invariant to known factors of variation. These factors of\u00a0variation correspond to movement along the manifold near which examples of the\u00a0same class concentrate. Local invariance is achieved by requiring Vxf (x) to be\u00a0orthogonal to the known manifold tangent vectors v(i) at x, or equivalently that\u00a0the directional derivative of f at x in the directions v(i) be small by adding a\u00a0regularization penalty 0:",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2984",
    "text": "2",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2985",
    "text": "0(f) = \u00a3((V.f(x))T v\u00ab \u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0(7.67)",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2986",
    "text": "i",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2987",
    "text": "This regularizer can of course by scaled by an appropriate hyperparameter, and, for most neural networks, we would need to sum over many outputs rather than the lone\u00a0output f (x) described here for simplicity. As with the tangent distance algorithm,\u00a0the tangent vectors are derived a priori, usually from the formal knowledge of\u00a0the effect of transformations such as translation, rotation, and scaling in images.\u00a0Tangent prop has been used not just for supervised learning (Simard et al., 1992)\u00a0but also in the context of reinforcement learning (Thrun, 1995).",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2988",
    "text": "Tangent propagation is closely related to dataset augmentation. In both cases, the user of the algorithm encodes his or her prior knowledge of the task\u00a0by specifying a set of transformations that should not alter the output of the\u00a0network. The difference is that in the case of dataset augmentation, the network is\u00a0explicitly trained to correctly classify distinct inputs that were created by applying\u00a0more than an infinitesimal amount of these transformations. Tangent propagation\u00a0does not require explicitly visiting a new input point. Instead, it analytically\u00a0regularizes the model to resist perturbation in the directions corresponding to\u00a0the specified transformation. While this analytical approach is intellectually\u00a0elegant, it has two major drawbacks. First, it only regularizes the model to resist\u00a0infinitesimal perturbation. Explicit dataset augmentation confers resistance to\u00a0larger perturbations. Second, the infinitesimal approach poses difficulties for models\u00a0based on rectified linear units. These models can only shrink their derivatives\u00a0by turning units off or shrinking their weights. They are not able to shrink their\u00a0derivatives by saturating at a high value with large weights, as sigmoid or tanh\u00a0units can. Dataset augmentation works well with rectified linear units because\u00a0different subsets of rectified units can activate for different transformed versions of\u00a0each original input.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2989",
    "text": "Tangent propagation is also related to double backprop (Drucker and LeCun, 1992) and adversarial training (Szegedy et al., 2014b; Goodfellow et al., 2014b).\u00a0Double backprop regularizes the Jacobian to be small, while adversarial training\u00a0finds inputs near the original inputs and trains the model to produce the same\u00a0output on these as on the original inputs. Tangent propagation and dataset\u00a0augmentation using manually specified transformations both require that the\u00a0model should be invariant to certain specified directions of change in the input.\u00a0Double backprop and adversarial training both require that the model should be\u00a0invariant to all directions of change in the input so long as the change is small. Just\u00a0as dataset augmentation is the non-infinitesimal version of tangent propagation,\u00a0adversarial training is the non-infinitesimal version of double backprop.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2990",
    "text": "The manifold tangent classifier (Rifai et al., 2011c), eliminates the need to know the tangent vectors a priori. As we will see in Chapter 14, autoencoders can",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2991",
    "text": "Figure 7.9: Illustration of the main idea of the tangent prop algorithm (Simard et al 1992) and manifold tangent classifier (Rifai et al., 2011c), which both regularize the\u00a0classifier output function f(x). Each curve represents the manifold for a different class,\u00a0illustrated here as a one-dimensional manifold embedded in a two-dimensional space.\u00a0On one curve, we have chosen a single point and drawn a vector that is tangent to the\u00a0class manifold (parallel to and touching the manifold) and a vector that is normal to the\u00a0class manifold (orthogonal to the manifold). In multiple dimensions there may be many\u00a0tangent directions and many normal directions. We expect the classification function to\u00a0change rapidly as it moves in the direction normal to the manifold, and not to change as\u00a0it moves along the class manifold. Both tangent propagation and the manifold tangent\u00a0classifier regularize f (x) to not change very much as x moves along the manifold. Tangent\u00a0propagation requires the user to manually specify functions that compute the tangent\u00a0directions (such as specifying that small translations of images remain in the same class\u00a0manifold) while the manifold tangent classifier estimates the manifold tangent directions\u00a0by training an autoencoder to fit the training data. The use of autoencoders to estimate\u00a0manifolds will be described in Chapter 14.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2992",
    "text": "estimate the manifold tangent vectors. The manifold tangent classifier makes use of this technique to avoid needing user-specified tangent vectors. As illustrated\u00a0in Fig. 14.10, these estimated tangent vectors go beyond the classical invariants\u00a0that arise out of the geometry of images (such as translation, rotation and scaling)\u00a0and include factors that must be learned because they are object-specific (such as\u00a0moving body parts). The algorithm proposed with the manifold tangent classifier\u00a0is therefore simple: (1) use an autoencoder to learn the manifold structure by\u00a0unsupervised learning, and (2) use these tangents to regularize a neural net classifier\u00a0as in tangent prop (Eq. 7.67).",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2993",
    "text": "This chapter has described most of the general strategies used to regularize neural networks. Regularization is a central theme of machine learning and as such",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2994",
    "text": "will be revisited periodically by most of the remaining chapters. theme of machine learning is optimization, described next.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2995",
    "text": "Another central",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2996",
    "text": "Ensemble of Sub-Networks",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2997",
    "text": "Figure 7.6: Dropout trains an ensemble consisting of all sub-networks that can be constructed by removing non-output units from an underlying base network. Here, we\u00a0begin with a base network with two visible units and two hidden units. There are sixteen\u00a0possible subsets of these four units. We show all sixteen subnetworks that may be formed\u00a0by dropping out different subsets of units from the original network. In this small example,\u00a0a large proportion of the resulting networks have no input units or no path connecting\u00a0the input to the output. This problem becomes insignificant for networks with wider\u00a0layers, where the probability of dropping all possible paths from inputs to outputs becomes\u00a0smaller.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2998",
    "text": "Figure 7.7: An example of forward propagation through a feedforward network using dropout. (Top) In this example, we use a feedforward network with two input units, one\u00a0hidden layer with two hidden units, and one output unit. (Bottom) To perform forward\u00a0propagation with dropout, we randomly sample a vector p with one entry for each input\u00a0or hidden unit in the network. The entries of p are binary and are sampled independently\u00a0from each other. The probability of each entry being 1 is a hyperparameter, usually 05\u00a0for the hidden layers and 0.8 for the input. Each unit in the network is multiplied by\u00a0the corresponding mask, and then forward propagation continues through the rest of the\u00a0network as usual. This is equivalent to randomly selecting one of the sub-networks from\u00a0Fig. 7.6 and running forward propagation through it.",
    "chapter": "Applications",
    "chapter_id": "main-15.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "2999",
    "text": "Deep learning algorithms involve optimization in many contexts. For example, performing inference in models such as PCA involves solving an optimization\u00a0problem. We often use analytical optimization to write proofs or design algorithms.\u00a0Of all of the many optimization problems involved in deep learning, the most\u00a0difficult is neural network training. It is quite common to invest days to months of\u00a0time on hundreds of machines in order to solve even a single instance of the neural\u00a0network training problem. Because this problem is so important and so expensive,\u00a0a specialized set of optimization techniques have been developed for solving it.\u00a0This chapter presents these optimization techniques for neural network training.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3000",
    "text": "If you are unfamiliar with the basic principles of gradient-based optimization, we suggest reviewing Chapter 4. That chapter includes a brief overview of numerical\u00a0optimization in general.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3001",
    "text": "This chapter focuses on one particular case of optimization: finding the parameters 0 of a neural network that significantly reduce a cost function J(0), which typically includes a performance measure evaluated on the entire training set as\u00a0well as additional regularization terms.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3002",
    "text": "We begin with a description of how optimization used as a training algorithm for a machine learning task differs from pure optimization. Next, we present several\u00a0of the concrete challenges that make optimization of neural networks difficult. We\u00a0then define several practical algorithms, including both optimization algorithms\u00a0themselves and strategies for initializing the parameters. More advanced algorithms\u00a0adapt their learning rates during training or leverage information contained in\u00a0the second derivatives of the cost function. Finally, we conclude with a review of\u00a0several optimization strategies that are formed by combining simple optimization\u00a0algorithms into higher-level procedures.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3003",
    "text": "Optimization algorithms used for training of deep models differ from traditional optimization algorithms in several ways. Machine learning usually acts indirectly.\u00a0In most machine learning scenarios, we care about some performance measure\u00a0P, that is defined with respect to the test set and may also be intractable. We\u00a0therefore optimize P only indirectly. We reduce a different cost function J(0) in\u00a0the hope that doing so will improve P. This is in contrast to pure optimization,\u00a0where minimizing J is a goal in and of itself. Optimization algorithms for training\u00a0deep models also typically include some specialization on the specific structure of\u00a0machine learning objective functions.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3004",
    "text": "Typically, the cost function can be written as an average over the training set, such as",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3005",
    "text": "J (0) = E(*,yWPdataL(f (Xi 0)^), \u00a0\u00a0\u00a0I8.1)",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3006",
    "text": "where L is the per-example loss function, f (x; 0) is the predicted output when the input is x, pdata is the empirical distribution. In the supervised learning case,\u00a0y is the target output. Throughout this chapter, we develop the unregularized\u00a0supervised case, where the arguments to L are f (x; 0) and y. However, it is trivial\u00a0to extend this development, for example, to include 0 or x as arguments, or to\u00a0exclude y as arguments, in order to develop various forms of regularization or\u00a0unsupervised learning.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3007",
    "text": "Eq. 8.1 defines an objective function with respect to the training set. We would usually prefer to minimize the corresponding objective function where the\u00a0expectation is taken across the data generating distribution pdata rather than\u00a0just over the finite training set:",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3008",
    "text": "J*(0) = E(x,y)~pdata L(f ^ 0),V)- \u00a0\u00a0\u00a0(8\u25a02)",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3009",
    "text": "The goal of a machine learning algorithm is to reduce the expected generalization error given by Eq. 8.2. This quantity is known as the risk. We emphasize here that\u00a0the expectation is taken over the true underlying distribution pdata. If we knew\u00a0the true distribution pdata(x,y), risk minimization would be an optimization task\u00a0solvable by an optimization algorithm. However, when we do not knowpdata(x,y)\u00a0but only have a training set of samples, we have a machine learning problem.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3010",
    "text": "The simplest way to convert a machine learning problem back into an optimization problem is to minimize the expected loss on the training set. This means replacing the true distribution p(x, y) with the empirical distribution p(x, y)\u00a0defined by the training set. We now minimize the empirical risk",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3011",
    "text": "m",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3012",
    "text": "Ex,y~Pdata(*,y)[L(/(x; \u00a0\u00a0\u00a0= -J2 L(/ (x(i); 0), y(i))\u00a0\u00a0\u00a0\u00a0(0)",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3013",
    "text": "m i=1",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3014",
    "text": "where m is the number of training examples.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3015",
    "text": "The training process based on minimizing this average training error is known as empirical risk minimization. In this setting, machine learning is still very similar\u00a0to straightforward optimization. Rather than optimizing the risk directly, we\u00a0optimize the empirical risk, and hope that the risk decreases significantly as well.\u00a0A variety of theoretical results establish conditions under which the true risk can\u00a0be expected to decrease by various amounts.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3016",
    "text": "However, empirical risk minimization is prone to overfitting. Models with high capacity can simply memorize the training set. In many cases, empirical\u00a0risk minimization is not really feasible. The most effective modern optimization\u00a0algorithms are based on gradient descent, but many useful loss functions, such\u00a0as 0-1 loss, have no useful derivatives (the derivative is either zero or undefined\u00a0everywhere). These two problems mean that, in the context of deep learning, we\u00a0rarely use empirical risk minimization. Instead, we must use a slightly different\u00a0approach, in which the quantity that we actually optimize is even more different\u00a0from the quantity that we truly want to optimize.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3017",
    "text": "Sometimes, the loss function we actually care about (say classification error) is not one that can be optimized efficiently. For example, exactly minimizing expected 0-1\u00a0loss is typically intractable (exponential in the input dimension), even for a linear\u00a0classifier (Marcotte and Savard, 1992). In such situations, one typically optimizes\u00a0a surrogate loss function instead, which acts as a proxy but has advantages. For\u00a0example, the negative log-likelihood of the correct class is typically used as a\u00a0surrogate for the 0-1 loss. The negative log-likelihood allows the model to estimate\u00a0the conditional probability of the classes, given the input, and if the model can\u00a0do that well, then it can pick the classes that yield the least classification error in\u00a0expectation.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3018",
    "text": "In some cases, a surrogate loss function actually results in being able to learn more. For example, the test set 0-1 loss often continues to decrease for a long\u00a0time after the training set 0-1 loss has reached zero, when training using the\u00a0log-likelihood surrogate. This is because even when the expected 0-1 loss is zero,\u00a0one can improve the robustness of the classifier by further pushing the classes apart\u00a0from each other, obtaining a more confident and reliable classifier, thus extracting\u00a0more information from the training data than would have been possible by simply\u00a0minimizing the average 0-1 loss on the training set.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3019",
    "text": "A very important difference between optimization in general and optimization as we use it for training algorithms is that training algorithms do not usually halt\u00a0at a local minimum. Instead, a machine learning algorithm usually minimizes\u00a0a surrogate loss function but halts when a convergence criterion based on early\u00a0stopping (Sec. 7.8) is satisfied. Typically the early stopping criterion is based on\u00a0the true underlying loss function, such as 0-1 loss measured on a validation set,\u00a0and is designed to cause the algorithm to halt whenever overfitting begins to occur.\u00a0Training often halts while the surrogate loss function still has large derivatives,\u00a0which is very different from the pure optimization setting, where an optimization\u00a0algorithm is considered to have converged when the gradient becomes very small.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3020",
    "text": "One aspect of machine learning algorithms that separates them from general optimization algorithms is that the objective function usually decomposes as a sum\u00a0over the training examples. Optimization algorithms for machine learning typically\u00a0compute each update to the parameters based on an expected value of the cost\u00a0function estimated using only a subset of the terms of the full cost function.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3021",
    "text": "For example, maximum likelihood estimation problems, when viewed in log space, decompose into a sum over each example:",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3022",
    "text": "-8.4",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3023",
    "text": "Oml = arg max ^ log Pmode!(*W, y(i); #)",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3024",
    "text": "i=1",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3025",
    "text": "Maximizing this sum is equivalent to maximizing the expectation over the empirical distribution defined by the training set:",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3026",
    "text": "J(^) \u00a0\u00a0\u00a0Ex,y~j5data 10gpmodel(x, y; \u2022\u00a0\u00a0\u00a0\u00a0(8.5)",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3027",
    "text": "Most of the properties of the objective function J used by most of our optimization algorithms are also expectations over the training set. For example, the",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3028",
    "text": "most commonly used property is the gradient:",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3029",
    "text": "V0 J(0) = Ex,y~j5dataV# 1ogpmodel (x,y; 0)\u2022 \u00a0\u00a0\u00a0(86\u05be)",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3030",
    "text": "Computing this expectation exactly is very expensive because it requires evaluating the model on every example in the entire dataset. In practice, we can\u00a0compute these expectations by randomly sampling a small number of examples\u00a0from the dataset, then taking the average over only those examples.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3031",
    "text": "Recall that the standard error of the mean (Eq. 5.46) estimated from n samples is given by a^Jn, where a is the true standard deviation of the value of the samples.\u00a0The denominator of \\/n shows that there are less than linear returns to using\u00a0more examples to estimate the gradient. Compare two hypothetical estimates of\u00a0the gradient, one based on 100 examples and another based on 10,000 examples.\u00a0The latter requires 100 times more computation than the former, but reduces the\u00a0standard error of the mean only by a factor of 10. Most optimization algorithms\u00a0converge much faster (in terms of total computation, not in terms of number of\u00a0updates) if they are allowed to rapidly compute approximate estimates of the\u00a0gradient rather than slowly computing the exact gradient.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3032",
    "text": "Another consideration motivating statistical estimation of the gradient from a small number of samples is redundancy in the training set. In the worst case, all\u00a0m samples in the training set could be identical copies of each other. A sampling-based estimate of the gradient could compute the correct gradient with a single\u00a0sample, using m times less computation than the naive approach. In practice, we\u00a0are unlikely to truly encounter this worst-case situation, but we may find large\u00a0numbers of examples that all make very similar contributions to the gradient.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3033",
    "text": "Optimization algorithms that use the entire training set are called batch or deterministic gradient methods, because they process all of the training examples\u00a0simultaneously in a large batch. This terminology can be somewhat confusing\u00a0because the word \u201cbatch\u201d is also often used to describe the minibatch used by\u00a0minibatch stochastic gradient descent. Typically the term \u201cbatch gradient descent\u201d\u00a0implies the use of the full training set, while the use of the term \u201cbatch\u201d to describe\u00a0a group of examples does not. For example, it is very common to use the term\u00a0\u201cbatch size\u201d to describe the size of a minibatch.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3034",
    "text": "Optimization algorithms that use only a single example at a time are sometimes called stochastic or sometimes online methods. The term online is usually reserved\u00a0for the case where the examples are drawn from a stream of continually created\u00a0examples rather than from a fixed-size training set over which several passes are\u00a0made.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3035",
    "text": "Most algorithms used for deep learning fall somewhere in between, using more than one but less than all of the training examples. These were traditionally called\u00a0minibatch or minibatch stochastic methods and it is now common to simply call\u00a0them stochastic methods.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3036",
    "text": "The canonical example of a stochastic method is stochastic gradient descent, presented in detail in Sec. 8.3.1.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3037",
    "text": "Minibatch sizes are generally driven by the following factors:",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3038",
    "text": "\u2022 \u00a0\u00a0\u00a0Larger batches provide a more accurate estimate of the gradient, but with\u00a0less than linear returns.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3039",
    "text": "\u2022 \u00a0\u00a0\u00a0Multicore architectures are usually underutilized by extremely small batches.\u00a0This motivates using some absolute minimum batch size, below which there\u00a0is no reduction in the time to process a minibatch.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3040",
    "text": "\u2022 \u00a0\u00a0\u00a0If all examples in the batch are to be processed in parallel (as is typically\u00a0the case), then the amount of memory scales with the batch size. For many\u00a0hardware setups this is the limiting factor in batch size.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3041",
    "text": "\u2022 \u00a0\u00a0\u00a0Some kinds of hardware achieve better runtime with specific sizes of arrays.\u00a0Especially when using GPUs, it is common for power of 2 batch sizes to offer\u00a0better runtime. Typical power of 2 batch sizes range from 32 to 256, with 16\u00a0sometimes being attempted for large models.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3042",
    "text": "\u2022 \u00a0\u00a0\u00a0Small batches can offer a regularizing effect (Wilson and Martinez, 2003),\u00a0perhaps due to the noise they add to the learning process. Generalization\u00a0error is often best for a batch size of 1. Training with such a small batch\u00a0size might require a small learning rate to maintain stability due to the high\u00a0variance in the estimate of the gradient. The total runtime can be very high\u00a0due to the need to make more steps, both because of the reduced learning\u00a0rate and because it takes more steps to observe the entire training set.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3043",
    "text": "Different kinds of algorithms use different kinds of information from the minibatch in different ways. Some algorithms are more sensitive to sampling error than others, either because they use information that is difficult to estimate accurately\u00a0with few samples, or because they use information in ways that amplify sampling\u00a0errors more. Methods that compute updates based only on the gradient g are\u00a0usually relatively robust and can handle smaller batch sizes like 100. Second-order\u00a0methods, which use also the Hessian matrix H and compute updates such as\u00a0H-1g, typically require much larger batch sizes like 10,000. These large batch\u00a0sizes are required to minimize fluctuations in the estimates of H-1g. Suppose\u00a0that H is estimated perfectly but has a poor condition number. Multiplication by",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3044",
    "text": "H or its inverse amplifies pre-existing errors, in this case, estimation errors in g. Very small changes in the estimate of g can thus cause large changes in the update\u00a0H-1g, even if H were estimated perfectly. Of course, H will be estimated only\u00a0approximately, so the update H-1g will contain even more error than we would\u00a0predict from applying a poorly conditioned operation to the estimate of g.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3045",
    "text": "It is also crucial that the minibatches be selected randomly. Computing an unbiased estimate of the expected gradient from a set of samples requires that those\u00a0samples be independent. We also wish for two subsequent gradient estimates to be\u00a0independent from each other, so two subsequent minibatches of examples should\u00a0also be independent from each other. Many datasets are most naturally arranged\u00a0in a way where successive examples are highly correlated. For example, we might\u00a0have a dataset of medical data with a long list of blood sample test results. This\u00a0list might be arranged so that first we have five blood samples taken at different\u00a0times from the first patient, then we have three blood samples taken from the\u00a0second patient, then the blood samples from the third patient, and so on. If we\u00a0were to draw examples in order from this list, then each of our minibatches would\u00a0be extremely biased, because it would represent primarily one patient out of the\u00a0many patients in the dataset. In cases such as these where the order of the dataset\u00a0holds some significance, it is necessary to shuffle the examples before selecting\u00a0minibatches. For very large datasets, for example datasets containing billions of\u00a0examples in a data center, it can be impractical to sample examples truly uniformly\u00a0at random every time we want to construct a minibatch. Fortunately, in practice\u00a0it is usually sufficient to shuffle the order of the dataset once and then store it in\u00a0shuffled fashion. This will impose a fixed set of possible minibatches of consecutive\u00a0examples that all models trained thereafter will use, and each individual model\u00a0will be forced to reuse this ordering every time it passes through the training\u00a0data. However, this deviation from true random selection does not seem to have a\u00a0significant detrimental effect. Failing to ever shuffle the examples in any way can\u00a0seriously reduce the effectiveness of the algorithm.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3046",
    "text": "Many optimization problems in machine learning decompose over examples well enough that we can compute entire separate updates over different examples\u00a0in parallel. In other words, we can compute the update that minimizes J(X) for\u00a0one minibatch of examples X at the same time that we compute the update for\u00a0several other minibatches. Such asynchronous parallel distributed approaches are\u00a0discussed further in Sec. 12.1.3.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3047",
    "text": "An interesting motivation for minibatch stochastic gradient descent is that it follows the gradient of the true generalization error (Eq. 8.2) so long as no\u00a0examples are repeated. Most implementations of minibatch stochastic gradient\u00a0descent shuffle the dataset once and then pass through it multiple times. On the\u00a0first pass, each minibatch is used to compute an unbiased estimate of the true\u00a0generalization error. On the second pass, the estimate becomes biased because it is\u00a0formed by re-sampling values that have already been used, rather than obtaining\u00a0new fair samples from the data generating distribution.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3048",
    "text": "The fact that stochastic gradient descent minimizes generalization error is easiest to see in the online learning case, where examples or minibatches are drawn\u00a0from a stream of data. In other words, instead of receiving a fixed-size training\u00a0set, the learner is similar to a living being who sees a new example at each instant,\u00a0with every example (x, y) coming from the data generating distributionpdata(x, y).\u00a0In this scenario, examples are never repeated; every experience is a fair sample\u00a0from pdata.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3049",
    "text": "The equivalence is easiest to derive when both x and y are discrete. In this case, the generalization error (Eq. 8.2) can be written as a sum",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3050",
    "text": "J*(Q) = ^ ^Pdata(X y)L(f (x; Q),y), \u00a0\u00a0\u00a0(8.7)",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3051",
    "text": "x y",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3052",
    "text": "with the exact gradient",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3053",
    "text": "g = V0 J*(Q) = \u00a0\u00a0\u00a0Pdata(x,y)VeL(f (x; Q), y).\u00a0\u00a0\u00a0\u00a0(8.8)",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3054",
    "text": "xy",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3055",
    "text": "We have already seen the same fact demonstrated for the log-likelihood in Eq. 8.5 and Eq. 8.6; we observe now that this holds for other functions L besides the\u00a0likelihood. A similar result can be derived when x and y are continuous, under\u00a0mild assumptions regarding pdata and L.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3056",
    "text": "Hence, we can obtain an unbiased estimator of the exact gradient of the generalization error by sampling a minibatch of examples {x(1),... x(m)} with corresponding targets y(i) from the data generating distribution pdata, and computing\u00a0the gradient of the loss with respect to the parameters for that minibatch:",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3057",
    "text": "1",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3058",
    "text": "g = -VeY, L(f(x\u00ab;Q),y\u00ab). \u00a0\u00a0\u00a0(8.9)",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3059",
    "text": "m",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3060",
    "text": "%",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3061",
    "text": "Updating Q in the direction of g performs SGD on the generalization error.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3062",
    "text": "Of course, this interpretation only applies when examples are not reused. Nonetheless, it is usually best to make several passes through the training set,\u00a0unless the training set is extremely large. When multiple such epochs are used,\u00a0only the first epoch follows the unbiased gradient of the generalization error, but\u00a0of course, the additional epochs usually provide enough benefit due to decreased\u00a0training error to offset the harm they cause by increasing the gap between training\u00a0error and test error.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3063",
    "text": "With some datasets growing rapidly in size, faster than computing power, it is becoming more common for machine learning applications to use each training\u00a0example only once or even to make an incomplete pass through the training\u00a0set. When using an extremely large training set, overfitting is not an issue, so\u00a0underfitting and computational efficiency become the predominant concerns. See\u00a0also Bottou and Bousquet (2008) for a discussion of the effect of computational\u00a0bottlenecks on generalization error, as the number of training examples grows.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3064",
    "text": "Optimization in general is an extremely difficult task. Traditionally, machine learning has avoided the difficulty of general optimization by carefully designing\u00a0the objective function and constraints to ensure that the optimization problem is\u00a0convex. When training neural networks, we must confront the general non-convex\u00a0case. Even convex optimization is not without its complications. In this section,\u00a0we summarize several of the most prominent challenges involved in optimization\u00a0for training deep models.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3065",
    "text": "Some challenges arise even when optimizing convex functions. Of these, the most prominent is ill-conditioning of the Hessian matrix H. This is a very general\u00a0problem in most numerical optimization, convex or otherwise, and is described in\u00a0more detail in Sec. 4.3.1.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3066",
    "text": "The ill-conditioning problem is generally believed to be present in neural network training problems. Ill-conditioning can manifest by causing SGD to get\u00a0\u201cstuck\u201d in the sense that even very small steps increase the cost function.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3067",
    "text": "Recall from Eq. 4.9 that a second-order Taylor series expansion of the cost function predicts that a gradient descent step of \u2014eg will add",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3068",
    "text": "2 e2gT Hg \u2014 eg g \u00a0\u00a0\u00a0(8.10)",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3069",
    "text": "to the cost. Ill-conditioning of the gradient becomes a problem when 1\u05be e2gTHg exceeds egTg. To determine whether ill-conditioning is detrimental to a neural\u00a0network training task, one can monitor the squared gradient norm g Tg and the",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3070",
    "text": "a",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3071",
    "text": "o",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3072",
    "text": "a",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3073",
    "text": "\u05db\u05d3",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3074",
    "text": "c6",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3075",
    "text": "u",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3076",
    "text": "O",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3077",
    "text": "Training time (epochs)",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3078",
    "text": "0 \u00a0\u00a0\u00a050\u00a0\u00a0\u00a0\u00a0100\u00a0\u00a0\u00a0\u00a0150\u00a0\u00a0\u00a0\u00a0200\u00a0\u00a0\u00a0\u00a0250",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3079",
    "text": "Training time (epochs)",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3080",
    "text": "Figure 8.1: Gradient descent often does not arrive at a critical point of any kind. In this example, the gradient norm increases throughout training of a convolutional network\u00a0used for object detection. (Left) A scatterplot showing how the norms of individual\u00a0gradient evaluations are distributed over time. To improve legibility, only one gradient\u00a0norm is plotted per epoch. The running average of all gradient norms is plotted as a solid\u00a0curve. The gradient norm clearly increases over time, rather than decreasing as we would\u00a0expect if the training process converged to a critical point. (Right) Despite the increasing\u00a0gradient, the training process is reasonably successful. The validation set classification\u00a0error decreases to a low level.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3081",
    "text": "gTHg term. In many cases, the gradient norm does not shrink significantly throughout learning, but the gTHg term grows by more than order of magnitude.\u00a0The result is that learning becomes very slow despite the presence of a strong\u00a0gradient because the learning rate must be shrunk to compensate for even stronger\u00a0curvature. Fig. 8.1 shows an example of the gradient increasing significantly during\u00a0the successful training of a neural network.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3082",
    "text": "Though ill-conditioning is present in other settings besides neural network training, some of the techniques used to combat it in other contexts are less\u00a0applicable to neural networks. For example, Newton\u2019s method is an excellent tool\u00a0for minimizing convex functions with poorly conditioned Hessian matrices, but in\u00a0the subsequent sections we will argue that Newton\u2019s method requires significant\u00a0modification before it can be applied to neural networks.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3083",
    "text": "One of the most prominent features of a convex optimization problem is that it can be reduced to the problem of finding a local minimum. Any local minimum is\u00a0guaranteed to be a global minimum. Some convex functions have a flat region at\u00a0the bottom rather than a single global minimum point, but any point within such\u00a0a flat region is an acceptable solution. When optimizing a convex function, we\u00a0know that we have reached a good solution if we find a critical point of any kind.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3084",
    "text": "With non-convex functions, such as neural nets, it is possible to have many local minima. Indeed, nearly any deep model is essentially guaranteed to have\u00a0an extremely large number of local minima. However, as we will see, this is not\u00a0necessarily a major problem.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3085",
    "text": "Neural networks and any models with multiple equivalently parametrized latent variables all have multiple local minima because of the model identifiability problem.\u00a0A model is said to be identifiable if a sufficiently large training set can rule out all\u00a0but one setting of the model\u2019s parameters. Models with latent variables are often\u00a0not identifiable because we can obtain equivalent models by exchanging latent\u00a0variables with each other. For example, we could take a neural network and modify\u00a0layer 1 by swapping the incoming weight vector for unit i with the incoming weight\u00a0vector for unit j, then doing the same for the outgoing weight vectors. If we have\u00a0m layers with n units each, then there are n!m ways of arranging the hidden units.\u00a0This kind of non-identifiability is known as weight space symmetry.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3086",
    "text": "In addition to weight space symmetry, many kinds of neural networks have additional causes of non-identifiability. For example, in any rectified linear or\u00a0maxout network, we can scale all of the incoming weights and biases of a unit by\u00a0a if we also scale all of its outgoing weights by \u05bea. This means that\u2014if the cost\u00a0function does not include terms such as weight decay that depend directly on the\u00a0weights rather than the models\u2019 outputs\u2014every local minimum of a rectified linear\u00a0or maxout network lies on an (m x n)-dimensional hyperbola of equivalent local\u00a0minima.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3087",
    "text": "These model identifiability issues mean that there can be an extremely large or even uncountably infinite amount of local minima in a neural network cost\u00a0function. However, all of these local minima arising from non-identifiability are\u00a0equivalent to each other in cost function value. As a result, these local minima are\u00a0not a problematic form of non-convexity.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3088",
    "text": "Local minima can be problematic if they have high cost in comparison to the global minimum. One can construct small neural networks, even without hidden\u00a0units, that have local minima with higher cost than the global minimum (Sontag\u00a0and Sussman, 1989; Brady et al., 1989; Gori and Tesi, 1992). If local minima\u00a0with high cost are common, this could pose a serious problem for gradient-based\u00a0optimization algorithms.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3089",
    "text": "It remains an open question whether there are many local minima of high cost for networks of practical interest and whether optimization algorithms encounter\u00a0them. For many years, most practitioners believed that local minima were a\u00a0common problem plaguing neural network optimization. Today, that does not\u00a0appear to be the case. The problem remains an active area of research, but experts\u00a0now suspect that, for sufficiently large neural networks, most local minima have a\u00a0low cost function value, and that it is not important to find a true global minimum\u00a0rather than to find a point in parameter space that has low but not minimal cost\u00a0(Saxe et al., 2013; Dauphin et al., 2014; Goodfellow et al., 2015; Choromanska\u00a0et al., 2014).",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3090",
    "text": "Many practitioners attribute nearly all difficulty with neural network optimization to local minima. We encourage practitioners to carefully test for specific problems. A test that can rule out local minima as the problem is to plot the\u00a0norm of the gradient over time. If the norm of the gradient does not shrink to\u00a0insignificant size, the problem is neither local minima nor any other kind of critical\u00a0point. This kind of negative test can rule out local minima. In high dimensional\u00a0spaces, it can be very difficult to positively establish that local minima are the\u00a0problem. Many structures other than local minima also have small gradients.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3091",
    "text": "For many high-dimensional non-convex functions, local minima (and maxima) are in fact rare compared to another kind of point with zero gradient: a saddle\u00a0point. Some points around a saddle point have greater cost than the saddle point,\u00a0while others have a lower cost. At a saddle point, the Hessian matrix has both\u00a0positive and negative eigenvalues. Points lying along eigenvectors associated with\u00a0positive eigenvalues have greater cost than the saddle point, while points lying\u00a0along negative eigenvalues have lower value. We can think of a saddle point as\u00a0being a local minimum along one cross-section of the cost function and a local\u00a0maximum along another cross-section. See Fig. 4.5 for an illustration.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3092",
    "text": "Many classes of random functions exhibit the following behavior: in lowdimensional spaces, local minima are common. In higher dimensional spaces, local minima are rare and saddle points are more common. For a function f : Rn ^ R of\u00a0this type, the expected ratio of the number of saddle points to local minima grows\u00a0exponentially with n. To understand the intuition behind this behavior, observe\u00a0that the Hessian matrix at a local minimum has only positive eigenvalues. The\u00a0Hessian matrix at a saddle point has a mixture of positive and negative eigenvalues.\u00a0Imagine that the sign of each eigenvalue is generated by flipping a coin. In a single\u00a0dimension, it is easy to obtain a local minimum by tossing a coin and getting heads\u00a0once. In n-dimensional space, it is exponentially unlikely that all n coin tosses will",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3093",
    "text": "be heads. See Dauphin et al. (2014) for a review of the relevant theoretical work.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3094",
    "text": "An amazing property of many random functions is that the eigenvalues of the Hessian become more likely to be positive as we reach regions of lower cost. In\u00a0our coin tossing analogy, this means we are more likely to have our coin come up\u00a0heads n times if we are at a critical point with low cost. This means that local\u00a0minima are much more likely to have low cost than high cost. Critical points with\u00a0high cost are far more likely to be saddle points. Critical points with extremely\u00a0high cost are more likely to be local maxima.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3095",
    "text": "This happens for many classes of random functions. Does it happen for neural networks? Baldi and Hornik (1989) showed theoretically that shallow autoencoders\u00a0(feedforward networks trained to copy their input to their output, described in\u00a0Chapter 14) with no nonlinearities have global minima and saddle points but no\u00a0local minima with higher cost than the global minimum. They observed without\u00a0proof that these results extend to deeper networks without nonlinearities. The\u00a0output of such networks is a linear function of their input, but they are useful\u00a0to study as a model of nonlinear neural networks because their loss function is\u00a0a non-convex function of their parameters. Such networks are essentially just\u00a0multiple matrices composed together. Saxe et al. (2013) provided exact solutions\u00a0to the complete learning dynamics in such networks and showed that learning in\u00a0these models captures many of the qualitative features observed in the training of\u00a0deep models with nonlinear activation functions. Dauphin et al. (2014) showed\u00a0experimentally that real neural networks also have loss functions that contain very\u00a0many high-cost saddle points. Choromanska et al. (2014) provided additional\u00a0theoretical arguments, showing that another class of high-dimensional random\u00a0functions related to neural networks does so as well.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3096",
    "text": "What are the implications of the proliferation of saddle points for training algorithms? For first-order optimization algorithms that use only gradient information, the situation is unclear. The gradient can often become very small near a saddle\u00a0point. On the other hand, gradient descent empirically seems to be able to escape\u00a0saddle points in many cases. Goodfellow et al. (2015) provided visualizations of\u00a0several learning trajectories of state-of-the-art neural networks, with an example\u00a0given in Fig. 8.2. These visualizations show a flattening of the cost function near\u00a0a prominent saddle point where the weights are all zero, but they also show the\u00a0gradient descent trajectory rapidly escaping this region. Goodfellow et al. (2015)\u00a0also argue that continuous-time gradient descent may be shown analytically to be\u00a0repelled from, rather than attracted to, a nearby saddle point, but the situation\u00a0may be different for more realistic uses of gradient descent.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3097",
    "text": "For Newton\u2019s method, it is clear that saddle points constitute a problem.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3098",
    "text": "Figure 8.2: A visualization of the cost function of a neural network. Image adapted with permission from Goodfellow et al. (2015). These visualizations appear similar for\u00a0feedforward neural networks, convolutional networks, and recurrent networks applied\u00a0to real object recognition and natural language processing tasks. Surprisingly, these\u00a0visualizations usually do not show many conspicuous obstacles. Prior to the success of\u00a0stochastic gradient descent for training very large models beginning in roughly 2012,\u00a0neural net cost function surfaces were generally believed to have much more non-convex\u00a0structure than is revealed by these projections. The primary obstacle revealed by this\u00a0projection is a saddle point of high cost near where the parameters are initialized, but, as\u00a0indicated by the blue path, the SGD training trajectory escapes this saddle point readily.\u00a0Most of training time is spent traversing the relatively flat valley of the cost function,\u00a0which may be due to high noise in the gradient, poor conditioning of the Hessian matrix\u00a0in this region, or simply the need to circumnavigate the tall \u201cmountain\u201d visible in the\u00a0figure via an indirect arcing path.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3099",
    "text": "Gradient descent is designed to move \u201cdownhill\u201d and is not explicitly designed to seek a critical point. Newton\u2019s method, however, is designed to solve for a\u00a0point where the gradient is zero. Without appropriate modification, it can jump\u00a0to a saddle point. The proliferation of saddle points in high dimensional spaces\u00a0presumably explains why second-order methods have not succeeded in replacing\u00a0gradient descent for neural network training. Dauphin et al. (2014) introduced\u00a0a saddle-free Newton method for second-order optimization and showed that it\u00a0improves significantly over the traditional version. Second-order methods remain\u00a0difficult to scale to large neural networks, but this saddle-free approach holds\u00a0promise if it could be scaled.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3100",
    "text": "There are other kinds of points with zero gradient besides minima and saddle points. There are also maxima, which are much like saddle points from the\u00a0perspective of optimization\u2014many algorithms are not attracted to them, but\u00a0unmodified Newton\u2019s method is. Maxima become exponentially rare in high\u00a0dimensional space, just like minima do.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3101",
    "text": "There may also be wide, flat regions of constant value. In these locations, the gradient and also the Hessian are all zero. Such degenerate locations pose major\u00a0problems for all numerical optimization algorithms. In a convex problem, a wide,\u00a0flat region must consist entirely of global minima, but in a general optimization\u00a0problem, such a region could correspond to a high value of the objective function.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3102",
    "text": "Neural networks with many layers often have extremely steep regions resembling cliffs, as illustrated in Fig. 8.3. These result from the multiplication of several large\u00a0weights together. On the face of an extremely steep cliff structure, the gradient\u00a0update step can move the parameters extremely far, usually jumping off of the\u00a0cliff structure altogether.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3103",
    "text": "b",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3104",
    "text": "Figure 8.3: The objective function for highly nonlinear deep neural networks or for recurrent neural networks often contains sharp nonlinearities in parameter space resulting\u00a0from the multiplication of several parameters. These nonlinearities give rise to very\u00a0high derivatives in some places. When the parameters get close to such a cliff region, a\u00a0gradient descent update can catapult the parameters very far, possibly losing most of the\u00a0optimization work that had been done. Figure adapted with permission from Pascanu\u00a0et al. (2013a).",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3105",
    "text": "The cliff can be dangerous whether we approach it from above or from below, but fortunately its most serious consequences can be avoided using the gradient\u00a0clipping heuristic described in Sec. 10.11.1. The basic idea is to recall that the\u00a0gradient does not specify the optimal step size, but only the optimal direction\u00a0within an infinitesimal region. When the traditional gradient descent algorithm\u00a0proposes to make a very large step, the gradient clipping heuristic intervenes to\u00a0reduce the step size to be small enough that it is less likely to go outside the region\u00a0where the gradient indicates the direction of approximately steepest descent. Cliff\u00a0structures are most common in the cost functions for recurrent neural networks,\u00a0because such models involve a multiplication of many factors, with one factor\u00a0for each time step. Long temporal sequences thus incur an extreme amount of\u00a0multiplication.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3106",
    "text": "Another difficulty that neural network optimization algorithms must overcome arises when the computational graph becomes extremely deep. Feedforward networks\u00a0with many layers have such deep computational graphs. So do recurrent networks,\u00a0described in Chapter 10, which construct very deep computational graphs by\u00a0repeatedly applying the same operation at each time step of a long temporal\u00a0sequence. Repeated application of the same parameters gives rise to especially\u00a0pronounced difficulties.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3107",
    "text": "For example, suppose that a computational graph contains a path that consists of repeatedly multiplying by a matrix W. After t steps, this is equivalent to multiplying by Wl. Suppose that W has an eigendecomposition W = Vdiag( A)V1\u05be.\u00a0In this simple case, it is straightforward to see that",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3108",
    "text": "Wt = (V diag( A) V 1\u05be^ = Vdiag(A) V -1. \u00a0\u00a0\u00a0(8.11)",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3109",
    "text": "Any eigenvalues Ai that are not near an absolute value of 1 will either explode if they are greater than 1 in magnitude or vanish if they are less than 1 in magnitude.\u00a0The vanishing and exploding gradient problem refers to the fact that gradients\u00a0through such a graph are also scaled according to diag( A) h Vanishing gradients\u00a0make it difficult to know which direction the parameters should move to improve\u00a0the cost function, while exploding gradients can make learning unstable. The cliff\u00a0structures described earlier that motivate gradient clipping are an example of the\u00a0exploding gradient phenomenon.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3110",
    "text": "The repeated multiplication by W at each time step described here is very similar to the power method algorithm used to find the largest eigenvalue of a matrix\u00a0W and the corresponding eigenvector. From this point of view it is not surprising\u00a0that x TWt will eventually discard all components of x that are orthogonal to the\u00a0principal eigenvector of W.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3111",
    "text": "Recurrent networks use the same matrix W at each time step, but feedforward networks do not, so even very deep feedforward networks can largely avoid the\u00a0vanishing and exploding gradient problem (Sussillo, 2014).",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3112",
    "text": "We defer a further discussion of the challenges of training recurrent networks until Sec. 10.7, after recurrent networks have been described in more detail.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3113",
    "text": "Most optimization algorithms are primarily motivated by the case where we have exact knowledge of the gradient or Hessian matrix. In practice, we usually only\u00a0have a noisy or even biased estimate of these quantities. Nearly every deep learning\u00a0algorithm relies on sampling-based estimates at least insofar as using a minibatch\u00a0of training examples to compute the gradient.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3114",
    "text": "In other cases, the objective function we want to minimize is actually intractable. When the objective function is intractable, typically its gradient is intractable as\u00a0well. In such cases we can only approximate the gradient. These issues mostly arise\u00a0with the more advanced models in Part III. For example, contrastive divergence\u00a0gives a technique for approximating the gradient of the intractable log-likelihood\u00a0of a Boltzmann machine.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3115",
    "text": "Various neural network optimization algorithms are designed to account for imperfections in the gradient estimate. One can also avoid the problem by choosing\u00a0a surrogate loss function that is easier to approximate than the true loss.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3116",
    "text": "Many of the problems we have discussed so far correspond to properties of the loss function at a single point\u2014it can be difficult to make a single step if J(0) is\u00a0poorly conditioned at the current point 0, or if 0 lies on a cliff, or if 0 is a saddle\u00a0point hiding the opportunity to make progress downhill from the gradient.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3117",
    "text": "It is possible to overcome all of these problems at a single point and still perform poorly if the direction that results in the most improvement locally does\u00a0not point toward distant regions of much lower cost.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3118",
    "text": "Goodfellow et al. (2015) argue that much of the runtime of training is due to the length of the trajectory needed to arrive at the solution. Fig. 8.2 shows that\u00a0the learning trajectory spends most of its time tracing out a wide arc around a\u00a0mountain-shaped structure.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3119",
    "text": "Much of research into the difficulties of optimization has focused on whether training arrives at a global minimum, a local minimum, or a saddle point, but in\u00a0practice neural networks do not arrive at a critical point of any kind. Fig. 8.1\u00a0shows that neural networks often do not arrive at a region of small gradient. Indeed,\u00a0such critical points do not even necessarily exist. For example, the loss function\u00a0\u2014 log p( y | x; 0) can lack a global minimum point and instead asymptotically\u00a0approach some value as the model becomes more confident. For a classifier with\u00a0discrete y and p (y | x) provided by a softmax, the negative log-likelihood can\u00a0become arbitrarily close to zero if the model is able to correctly classify every\u00a0example in the training set, but it is impossible to actually reach the value of\u00a0zero. Likewise, a model of real values p(y | x) = N(y;f (0),3-1) can have negative\u00a0log-likelihood that asymptotes to negative infinity\u2014if f (0) is able to correctly\u00a0predict the value of all training set y targets, the learning algorithm will increase\u00a03 without bound. See Fig. 8.4 for an example of a failure of local optimization to\u00a0find a good cost function value even in the absence of any local minima or saddle\u00a0points.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3120",
    "text": "Future research will need to develop further understanding of the factors that influence the length of the learning trajectory and better characterize the outcome",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3121",
    "text": "Figure 8.4: Optimization based on local downhill moves can fail if the local surface does not point toward the global solution. Here we provide an example of how this can occur,\u00a0even if there are no saddle points and no local minima. This example cost function\u00a0contains only asymptotes toward low values, not minima. The main cause of difficulty in\u00a0this case is being initialized on the wrong side of the \u201cmountain\u201d and not being able to\u00a0traverse it. In higher dimensional space, learning algorithms can often circumnavigate\u00a0such mountains but the trajectory associated with doing so may be long and result in\u00a0excessive training time, as illustrated in Fig. 8.2.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3122",
    "text": "of the process.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3123",
    "text": "Many existing research directions are aimed at finding good initial points for problems that have difficult global structure, rather than developing algorithms\u00a0that use non-local moves.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3124",
    "text": "Gradient descent and essentially all learning algorithms that are effective for training neural networks are based on making small, local moves. The previous\u00a0sections have primarily focused on how the correct direction of these local moves\u00a0can be difficult to compute. We may be able to compute some properties of the\u00a0objective function, such as its gradient, only approximately, with bias or variance\u00a0in our estimate of the correct direction. In these cases, local descent may or may\u00a0not define a reasonably short path to a valid solution, but we are not actually\u00a0able to follow the local descent path. The objective function may have issues\u00a0such as poor conditioning or discontinuous gradients, causing the region where\u00a0the gradient provides a good model of the objective function to be very small. In\u00a0these cases, local descent with steps of size e may define a reasonably short path\u00a0to the solution, but we are only able to compute the local descent direction with\u00a0steps of size 5 ^ e. In these cases, local descent may or may not define a path\u00a0to the solution, but the path contains many steps, so following the path incurs a\u00a0high computational cost. Sometimes local information provides us no guide, when\u00a0the function has a wide flat region, or if we manage to land exactly on a critical\u00a0point (usually this latter scenario only happens to methods that solve explicitly\u00a0for critical points, such as Newton\u2019s method). In these cases, local descent does\u00a0not define a path to a solution at all. In other cases, local moves can be too greedy\u00a0and lead us along a path that moves downhill but away from any solution, as in\u00a0Fig. 8.4, or along an unnecessarily long trajectory to the solution, as in Fig. 8.2.\u00a0Currently, we do not understand which of these problems are most relevant to\u00a0making neural network optimization difficult, and this is an active area of research.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3125",
    "text": "Regardless of which of these problems are most significant, all of them might be avoided if there exists a region of space connected reasonably directly to a solution\u00a0by a path that local descent can follow, and if we are able to initialize learning\u00a0within that well-behaved region. This last view suggests research into choosing\u00a0good initial points for traditional optimization algorithms to use.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3126",
    "text": "Several theoretical results show that there are limits on the performance of any optimization algorithm we might design for neural networks (Blum and Rivest,\u00a01992; Judd, 1989; Wolpert and MacReady, 1997). Typically these results have\u00a0little bearing on the use of neural networks in practice.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3127",
    "text": "Some theoretical results apply only to the case where the units of a neural network output discrete values. However, most neural network units output\u00a0smoothly increasing values that make optimization via local search feasible. Some\u00a0theoretical results show that there exist problem classes that are intractable, but\u00a0it can be difficult to tell whether a particular problem falls into that class. Other\u00a0results show that finding a solution for a network of a given size is intractable, but\u00a0in practice we can find a solution easily by using a larger network for which many\u00a0more parameter settings correspond to an acceptable solution. Moreover, in the\u00a0context of neural network training, we usually do not care about finding the exact\u00a0minimum of a function, but only in reducing its value sufficiently to obtain good\u00a0generalization error. Theoretical analysis of whether an optimization algorithm\u00a0can accomplish this goal is extremely difficult. Developing more realistic bounds\u00a0on the performance of optimization algorithms therefore remains an important\u00a0goal for machine learning research.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3128",
    "text": "We have previously introduced the gradient descent (Sec. 4.3) algorithm that follows the gradient of an entire training set downhill. This may be accelerated\u00a0considerably by using stochastic gradient descent to follow the gradient of randomly\u00a0selected minibatches downhill, as discussed in Sec. 5.9 and Sec. 8.1.3.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3129",
    "text": "Stochastic gradient descent (SGD) and its variants are probably the most used optimization algorithms for machine learning in general and for deep learning in\u00a0particular. As discussed in Sec. 8.1.3, it is possible to obtain an unbiased estimate\u00a0of the gradient by taking the average gradient on a minibatch of m examples drawn",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3130",
    "text": "i.i.d from the data generating distribution.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3131",
    "text": "Algorithm 8.1 shows how to follow this estimate of the gradient downhill.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3132",
    "text": "Algorithm 8.1 Stochastic gradient descent (SGD) update at training iteration k",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3133",
    "text": "Require: Learning rate ek.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3134",
    "text": "Require: Initial parameter 6",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3135",
    "text": "while stopping criterion not met do",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3136",
    "text": "Sample a minibatch of m examples from the training set {x(1),..., x with corresponding targets y(i).",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3137",
    "text": "Compute gradient estimate: g <\u2014+ ^Vi L(f (x(i); 6), y(i))",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3138",
    "text": "Apply update: 6 ^ 6 \u2014 eg end while",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3139",
    "text": "A crucial parameter for the SGD algorithm is the learning rate. Previously, we have described SGD as using a fixed learning rate e. In practice, it is necessary to\u00a0gradually decrease the learning rate over time, so we now denote the learning rate\u00a0at iteration k as ek.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3140",
    "text": "This is because the SGD gradient estimator introduces a source of noise (the random sampling of m training examples) that does not vanish even when we arrive\u00a0at a minimum. By comparison, the true gradient of the total cost function becomes\u00a0small and then 0 when we approach and reach a minimum using batch gradient\u00a0descent, so batch gradient descent can use a fixed learning rate. A sufficient\u00a0condition to guarantee convergence of SGD is that",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3141",
    "text": "ek = ro, \u00a0\u00a0\u00a0and\u00a0\u00a0\u00a0\u00a0(8.12)",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3142",
    "text": "J24 < \u00a0\u00a0\u00a0(s\u202213)",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3143",
    "text": "k= 1",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3144",
    "text": "In practice, it is common to decay the learning rate linearly until iteration t:",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3145",
    "text": "\u00a3k = (1 - a)e0 + aeT \u00a0\u00a0\u00a0(8.14)",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3146",
    "text": "with a = k. After iteration t, it is common to leave e constant.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3147",
    "text": "T \u00a0\u00a0\u00a05",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3148",
    "text": "The learning rate may be chosen by trial and error, but it is usually best to choose it by monitoring learning curves that plot the objective function as a\u00a0function of time. This is more of an art than a science, and most guidance on this\u00a0subject should be regarded with some skepticism. When using the linear schedule,\u00a0the parameters to choose are eo, eT, and t. Usually t may be set to the number of\u00a0iterations required to make a few hundred passes through the training set. Usually\u00a0eT should be set to roughly 1% the value of eo. The main question is how to set eo.\u00a0If it is too large, the learning curve will show violent oscillations, with the cost\u00a0function often increasing significantly. Gentle oscillations are fine, especially if\u00a0training with a stochastic cost function such as the cost function arising from the\u00a0use of dropout. If the learning rate is too low, learning proceeds slowly, and if the\u00a0initial learning rate is too low, learning may become stuck with a high cost value.\u00a0Typically, the optimal initial learning rate, in terms of total training time and the\u00a0final cost value, is higher than the learning rate that yields the best performance\u00a0after the first 100 iterations or so. Therefore, it is usually best to monitor the first\u00a0several iterations and use a learning rate that is higher than the best-performing\u00a0learning rate at this time, but not so high that it causes severe instability.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3149",
    "text": "The most important property of SGD and related minibatch or online gradient-based optimization is that computation time per update does not grow with the number of training examples. This allows convergence even when the number\u00a0of training examples becomes very large. For a large enough dataset, SGD may\u00a0converge to within some fixed tolerance of its final test set error before it has\u00a0processed the entire training set.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3150",
    "text": "To study the convergence rate of an optimization algorithm it is common to measure the excess error J(6) \u2014 min# J(6), which is the amount that the current\u00a0cost function exceeds the minimum possible cost. When SGD is applied to a convex\u00a0problem, the excess error is O () after k iterations, while in the strongly convex",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3151",
    "text": "case it is O( 1). These bounds cannot be improved unless extra conditions are assumed. Batch gradient descent enjoys better convergence rates than stochastic\u00a0gradient descent in theory. However, the Cramer-Rao bound (Cramer, 1946; Rao,\u00a01945) states that generalization error cannot decrease faster than O (\u05be!). Bottou\u00a0and Bousquet (2008) argue that it therefore may not be worthwhile to pursue\u00a0an optimization algorithm that converges faster than O( -j) for machine learning\u00a0tasks\u2014faster convergence presumably corresponds to overfitting. Moreover, the\u00a0asymptotic analysis obscures many advantages that stochastic gradient descent\u00a0has after a small number of steps. With large datasets, the ability of SGD to make\u00a0rapid initial progress while evaluating the gradient for only very few examples\u00a0outweighs its slow asymptotic convergence. Most of the algorithms described in\u00a0the remainder of this chapter achieve benefits that matter in practice but are lost\u00a0in the constant factors obscured by the O(-j) asymptotic analysis. One can also\u00a0trade off the benefits of both batch and stochastic gradient descent by gradually\u00a0increasing the minibatch size during the course of learning.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3152",
    "text": "For more information on SGD, see Bottou (1998).",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3153",
    "text": "While stochastic gradient descent remains a very popular optimization strategy, learning with it can sometimes be slow. The method of momentum (Polyak, 1964)\u00a0is designed to accelerate learning, especially in the face of high curvature, small but\u00a0consistent gradients, or noisy gradients. The momentum algorithm accumulates\u00a0an exponentially decaying moving average of past gradients and continues to move\u00a0in their direction. The effect of momentum is illustrated in Fig. 8.5.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3154",
    "text": "Formally, the momentum algorithm introduces a variable v that plays the role of velocity\u2014it is the direction and speed at which the parameters move through\u00a0parameter space. The velocity is set to an exponentially decaying average of\u00a0the negative gradient. The name momentum derives from a physical analogy, in\u00a0which the negative gradient is a force moving a particle through parameter space,\u00a0according to Newton\u2019s laws of motion. Momentum in physics is mass times velocity.\u00a0In the momentum learning algorithm, we assume unit mass, so the velocity vector v\u00a0may also be regarded as the momentum of the particle. A hyperparameter a E [0,1)\u00a0determines how quickly the contributions of previous gradients exponentially decay.\u00a0The update rule is given by:",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3155",
    "text": ",",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3156",
    "text": "-8.15",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3157",
    "text": "1 m",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3158",
    "text": "v ^ av - eV0 \u00a0\u00a0\u00a0L(f (x(i); 6), y(i))",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3159",
    "text": "m",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3160",
    "text": "1=1",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3161",
    "text": "6 ^ 6 + v. \u00a0\u00a0\u00a0(8.16)",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3162",
    "text": "The velocity v accumulates the gradient elements V0 (m Y^m=1 L(f (x(i); 6), y(i))). The larger a is relative to e, the more previous gradients affect the current direction.\u00a0The SGD algorithm with momentum is given in Algorithm 8.2.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3163",
    "text": "Figure 8.5: Momentum aims primarily to solve two problems: poor conditioning of the Hessian matrix and variance in the stochastic gradient. Here, we illustrate how momentum\u00a0overcomes the first of these two problems. The contour lines depict a quadratic loss\u00a0function with a poorly conditioned Hessian matrix. The red path cutting across the\u00a0contours indicates the path followed by the momentum learning rule as it minimizes this\u00a0function. At each step along the way, we draw an arrow indicating the step that gradient\u00a0descent would take at that point. We can see that a poorly conditioned quadratic objective\u00a0looks like a long, narrow valley or canyon with steep sides. Momentum correctly traverses\u00a0the canyon lengthwise, while gradient steps waste time moving back and forth across the\u00a0narrow axis of the canyon. Compare also Fig. 4.6, which shows the behavior of gradient\u00a0descent without momentum.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3164",
    "text": "Previously, the size of the step was simply the norm of the gradient multiplied by the learning rate. Now, the size of the step depends on how large and how\u00a0aligned a sequence of gradients are. The step size is largest when many successive\u00a0gradients point in exactly the same direction. If the momentum algorithm always\u00a0observes gradient g, then it will accelerate in the direction of \u2014 g, until reaching a\u00a0terminal velocity where the size of each step is",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3165",
    "text": "-8.17",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3166",
    "text": "e||g||",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3167",
    "text": "1 a",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3168",
    "text": "It is thus helpful to think of the momentum hyperparameter in terms of . For example, a = .9 corresponds to multiplying the maximum speed by 10 relative to\u00a0the gradient descent algorithm.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3169",
    "text": "Common values of a used in practice include .5, .9, and .99. Like the learning rate, a may also be adapted over time. Typically it begins with a small value and\u00a0is later raised. It is less important to adapt a over time than to shrink e over time.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3170",
    "text": "Algorithm 8.2 Stochastic gradient descent (SGD) with momentum",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3171",
    "text": "Require: Learning rate e, momentum parameter a.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3172",
    "text": "Require: Initial parameter 6, initial velocity v. while stopping criterion not met do",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3173",
    "text": "Sample a minibatch of m examples from the training set {x(1),..., x(m)} with corresponding targets y(i).",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3174",
    "text": "Compute gradient estimate: g ^ m V0 ^ L(f (x(i); 6), \u00a0\u00a0\u00a0)",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3175",
    "text": "Compute velocity update: v ^ av \u2014 eg Apply update: 6 ^ 6 + v\u00a0end while",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3176",
    "text": "We can view the momentum algorithm as simulating a particle subject to continuous-time Newtonian dynamics. The physical analogy can help to build\u00a0intuition for how the momentum and gradient descent algorithms behave.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3177",
    "text": "The position of the particle at any point in time is given by 6 (t). The particle experiences net force f (t). This force causes the particle to accelerate:",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3178",
    "text": "-8.18",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3179",
    "text": "f (t) = lt2 6(t).",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3180",
    "text": "Rather than viewing this as a second-order differential equation of the position, we can introduce the variable v (t) representing the velocity of the particle at time\u00a0t and rewrite the Newtonian dynamics as a first-order differential equation:",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3181",
    "text": "d",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3182",
    "text": "v(t) = dt 6(t) \u00a0\u00a0\u00a0(8A9)",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3183",
    "text": "d",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3184",
    "text": "f (t) = \u00a0\u00a0\u00a0v(t).\u00a0\u00a0\u00a0\u00a0(8.20)",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3185",
    "text": "The momentum algorithm then consists of solving the differential equations via numerical simulation. A simple numerical method for solving differential equations\u00a0is Euler\u2019s method, which simply consists of simulating the dynamics defined by\u00a0the equation by taking small, finite steps in the direction of each gradient.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3186",
    "text": "This explains the basic form of the momentum update, but what specifically are the forces? One force is proportional to the negative gradient of the cost function:\u00a0\u2014V# J (6). This force pushes the particle downhill along the cost function surface.\u00a0The gradient descent algorithm would simply take a single step based on each\u00a0gradient, but the Newtonian scenario used by the momentum algorithm instead\u00a0uses this force to alter the velocity of the particle. We can think of the particle\u00a0as being like a hockey puck sliding down an icy surface. Whenever it descends a\u00a0steep part of the surface, it gathers speed and continues sliding in that direction\u00a0until it begins to go uphill again.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3187",
    "text": "One other force is necessary. If the only force is the gradient of the cost function, then the particle might never come to rest. Imagine a hockey puck sliding down\u00a0one side of a valley and straight up the other side, oscillating back and forth forever,\u00a0assuming the ice is perfectly frictionless. To resolve this problem, we add one\u00a0other force, proportional to \u2014v(t). In physics terminology, this force corresponds\u00a0to viscous drag, as if the particle must push through a resistant medium such as\u00a0syrup. This causes the particle to gradually lose energy over time and eventually\u00a0converge to a local minimum.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3188",
    "text": "Why do we use \u2014 v (t) and viscous drag in particular? Part of the reason to use \u2014 v (t) is mathematical convenience\u2014an integer power of the velocity is easy\u00a0to work with. However, other physical systems have other kinds of drag based\u00a0on other integer powers of the velocity. For example, a particle traveling through\u00a0the air experiences turbulent drag, with force proportional to the square of the\u00a0velocity, while a particle moving along the ground experiences dry friction, with a\u00a0force of constant magnitude. We can reject each of these options. Turbulent drag,\u00a0proportional to the square of the velocity, becomes very weak when the velocity is\u00a0small. It is not powerful enough to force the particle to come to rest. A particle\u00a0with a non-zero initial velocity that experiences only the force of turbulent drag\u00a0will move away from its initial position forever, with the distance from the starting\u00a0point growing like O(log t). We must therefore use a lower power of the velocity.\u00a0If we use a power of zero, representing dry friction, then the force is too strong.\u00a0When the force due to the gradient of the cost function is small but non-zero, the\u00a0constant force due to friction can cause the particle to come to rest before reaching\u00a0a local minimum. Viscous drag avoids both of these problems\u2014it is weak enough\u00a0that the gradient can continue to cause motion until a minimum is reached, but\u00a0strong enough to prevent motion if the gradient does not justify moving.",
    "chapter": "Linear Factor Models",
    "chapter_id": "main-16.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3189",
    "text": "Sutskever et al. (2013) introduced a variant of the momentum algorithm that was inspired by Nesterov\u2019s accelerated gradient method (Nesterov, 1983, 2004). The\u00a0update rules in this case are given by:",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3190",
    "text": "v ^ av \u2014 eVi 0 ^ 0 + v,",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3191",
    "text": "1",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3192",
    "text": "m",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3193",
    "text": "m",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3194",
    "text": "Y L (f (x(i); 0 + av), y(i>)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3195",
    "text": "i=1",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3196",
    "text": "-8.21",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3197",
    "text": "-8.22",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3198",
    "text": "where the parameters a and e play a similar role as in the standard momentum method. The difference between Nesterov momentum and standard momentum is\u00a0where the gradient is evaluated. With Nesterov momentum the gradient is evaluated\u00a0after the current velocity is applied. Thus one can interpret Nesterov momentum\u00a0as attempting to add a correction factor to the standard method of momentum.\u00a0The complete Nesterov momentum algorithm is presented in Algorithm 8.3.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3199",
    "text": "In the convex batch gradient case, Nesterov momentum brings the rate of convergence of the excess error from O(1/k) (after k steps) to O(1 /k2) as shown\u00a0by Nesterov (1983). Unfortunately, in the stochastic gradient case, Nesterov\u00a0momentum does not improve the rate of convergence.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3200",
    "text": "Algorithm 8.3 Stochastic gradient descent (SGD) with Nesterov momentum",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3201",
    "text": "Require: Learning rate e, momentum parameter a.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3202",
    "text": "Require: Initial parameter 0, initial velocity v. while stopping criterion not met do",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3203",
    "text": "Sample a minibatch of m examples from the training set {x(1>,..., x(m>} with",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3204",
    "text": "corresponding labels y(i>.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3205",
    "text": "Apply interim update: 0 ^ 0 + av Compute gradient (at interim point): g\u00a0Compute velocity update: v ^ av \u2014 eg\u00a0Apply update: 0 ^ 0 + v\u00a0end while",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3206",
    "text": "1",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3207",
    "text": "m",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3208",
    "text": "viEi L(f(x(i>; 0),y(i>)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3209",
    "text": "Some optimization algorithms are not iterative by nature and simply solve for a solution point. Other optimization algorithms are iterative by nature but, when\u00a0applied to the right class of optimization problems, converge to acceptable solutions\u00a0in an acceptable amount of time regardless of initialization. Deep learning training\u00a0algorithms usually do not have either of these luxuries. Training algorithms for deep\u00a0learning models are usually iterative in nature and thus require the user to specify\u00a0some initial point from which to begin the iterations. Moreover, training deep\u00a0models is a sufficiently difficult task that most algorithms are strongly affected by\u00a0the choice of initialization. The initial point can determine whether the algorithm\u00a0converges at all, with some initial points being so unstable that the algorithm\u00a0encounters numerical difficulties and fails altogether. When learning does converge,\u00a0the initial point can determine how quickly learning converges and whether it\u00a0converges to a point with high or low cost. Also, points of comparable cost\u00a0can have wildly varying generalization error, and the initial point can affect the\u00a0generalization as well.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3210",
    "text": "Modern initialization strategies are simple and heuristic. Designing improved initialization strategies is a difficult task because neural network optimization is\u00a0not yet well understood. Most initialization strategies are based on achieving some\u00a0nice properties when the network is initialized. However, we do not have a good\u00a0understanding of which of these properties are preserved under which circumstances\u00a0after learning begins to proceed. A further difficulty is that some initial points\u00a0may be beneficial from the viewpoint of optimization but detrimental from the\u00a0viewpoint of generalization. Our understanding of how the initial point affects\u00a0generalization is especially primitive, offering little to no guidance for how to select\u00a0the initial point.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3211",
    "text": "Perhaps the only property known with complete certainty is that the initial parameters need to \u201cbreak symmetry\u201d between different units. If two hidden\u00a0units with the same activation function are connected to the same inputs, then\u00a0these units must have different initial parameters. If they have the same initial\u00a0parameters, then a deterministic learning algorithm applied to a deterministic cost\u00a0and model will constantly update both of these units in the same way. Even if the\u00a0model or training algorithm is capable of using stochasticity to compute different\u00a0updates for different units (for example, if one trains with dropout), it is usually\u00a0best to initialize each unit to compute a different function from all of the other\u00a0units. This may help to make sure that no input patterns are lost in the null\u00a0space of forward propagation and no gradient patterns are lost in the null space\u00a0of back-propagation. The goal of having each unit compute a different function\u00a0motivates random initialization of the parameters. We could explicitly search\u00a0for a large set of basis functions that are all mutually different from each other,\u00a0but this often incurs a noticeable computational cost. For example, if we have at\u00a0most as many outputs as inputs, we could use Gram-Schmidt orthogonalization\u00a0on an initial weight matrix, and be guaranteed that each unit computes a very\u00a0different function from each other unit. Random initialization from a high-entropy\u00a0distribution over a high-dimensional space is computationally cheaper and unlikely\u00a0to assign any units to compute the same function as each other.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3212",
    "text": "Typically, we set the biases for each unit to heuristically chosen constants, and initialize only the weights randomly. Extra parameters, for example, parameters\u00a0encoding the conditional variance of a prediction, are usually set to heuristically\u00a0chosen constants much like the biases are.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3213",
    "text": "We almost always initialize all the weights in the model to values drawn randomly from a Gaussian or uniform distribution. The choice of Gaussian\u00a0or uniform distribution does not seem to matter very much, but has not been\u00a0exhaustively studied. The scale of the initial distribution, however, does have a\u00a0large effect on both the outcome of the optimization procedure and on the ability\u00a0of the network to generalize.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3214",
    "text": "Larger initial weights will yield a stronger symmetry breaking effect, helping to avoid redundant units. They also help to avoid losing signal during forward or\u00a0back-propagation through the linear component of each layer\u2014larger values in the\u00a0matrix result in larger outputs of matrix multiplication. Initial weights that are\u00a0too large may, however, result in exploding values during forward propagation or\u00a0back-propagation. In recurrent networks, large weights can also result in chaos\u00a0(such extreme sensitivity to small perturbations of the input that the behavior\u00a0of the deterministic forward propagation procedure appears random). To some\u00a0extent, the exploding gradient problem can be mitigated by gradient clipping\u00a0(thresholding the values of the gradients before performing a gradient descent step).\u00a0Large weights may also result in extreme values that cause the activation function\u00a0to saturate, causing complete loss of gradient through saturated units. These\u00a0competing factors determine the ideal initial scale of the weights.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3215",
    "text": "The perspectives of regularization and optimization can give very different insights into how we should initialize a network. The optimization perspective\u00a0suggests that the weights should be large enough to propagate information successfully, but some regularization concerns encourage making them smaller. The use\u00a0of an optimization algorithm such as stochastic gradient descent that makes small\u00a0incremental changes to the weights and tends to halt in areas that are nearer to\u00a0the initial parameters (whether due to getting stuck in a region of low gradient, or\u00a0due to triggering some early stopping criterion based on overfitting) expresses a\u00a0prior that the final parameters should be close to the initial parameters. Recall\u00a0from Sec. 7.8 that gradient descent with early stopping is equivalent to weight\u00a0decay for some models. In the general case, gradient descent with early stopping is\u00a0not the same as weight decay, but does provide a loose analogy for thinking about\u00a0the effect of initialization. We can think of initializing the parameters 0 to 00 as\u00a0being similar to imposing a Gaussian prior p(0) with mean 00. From this point\u00a0of view, it makes sense to choose 00 to be near 0. This prior says that it is more\u00a0likely that units do not interact with each other than that they do interact. Units\u00a0interact only if the likelihood term of the objective function expresses a strong\u00a0preference for them to interact. On the other hand, if we initialize 00 to large\u00a0values, then our prior specifies which units should interact with each other, and\u00a0how they should interact.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3216",
    "text": "Some heuristics are available for choosing the initial scale of the weights. One heuristic is to initialize the weights of a fully connected layer with m inputs and\u00a0n outputs by sampling each weight from U (\u2014 -\u05e7-, =\u05e7= ), while Glorot and Bengio\u00a0(2010) suggest using the normalized initialization",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3217",
    "text": "-8.23",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3218",
    "text": ")\u2022",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3219",
    "text": "Wij - U(-",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3220",
    "text": "6 6",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3221",
    "text": "\\Jm + n y/m + n",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3222",
    "text": "This latter heuristic is designed to compromise between the goal of initializing all layers to have the same activation variance and the goal of initializing all\u00a0layers to have the same gradient variance. The formula is derived using the\u00a0assumption that the network consists only of a chain of matrix multiplications,\u00a0with no nonlinearities. Real neural networks obviously violate this assumption,\u00a0but many strategies designed for the linear model perform reasonably well on its\u00a0nonlinear counterparts.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3223",
    "text": "Saxe et al. (2013) recommend initializing to random orthogonal matrices, with a carefully chosen scaling or gain factor g that accounts for the nonlinearity applied\u00a0at each layer. They derive specific values of the scaling factor for different types of\u00a0nonlinear activation functions. This initialization scheme is also motivated by a\u00a0model of a deep network as a sequence of matrix multiplies without nonlinearities.\u00a0Under such a model, this initialization scheme guarantees that the total number of\u00a0training iterations required to reach convergence is independent of depth.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3224",
    "text": "Increasing the scaling factor g pushes the network toward the regime where activations increase in norm as they propagate forward through the network and\u00a0gradients increase in norm as they propagate backward. Sussillo (2014) showed\u00a0that setting the gain factor correctly is sufficient to train networks as deep as\u00a01,000 layers, without needing to use orthogonal initializations. A key insight of\u00a0this approach is that in feedforward networks, activations and gradients can grow\u00a0or shrink on each step of forward or back-propagation, following a random walk\u00a0behavior. This is because feedforward networks use a different weight matrix at\u00a0each layer. If this random walk is tuned to preserve norms, then feedforward\u00a0networks can mostly avoid the vanishing and exploding gradients problem that\u00a0arises when the same weight matrix is used at each step, described in Sec. 8.2.5.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3225",
    "text": "Unfortunately, these optimal criteria for initial weights often do not lead to optimal performance. This may be for three different reasons. First, we may\u00a0be using the wrong criteria\u2014it may not actually be beneficial to preserve the\u00a0norm of a signal throughout the entire network. Second, the properties imposed\u00a0at initialization may not persist after learning has begun to proceed. Third, the\u00a0criteria might succeed at improving the speed of optimization but inadvertently\u00a0increase generalization error. In practice, we usually need to treat the scale of the\u00a0weights as a hyperparameter whose optimal value lies somewhere roughly near but\u00a0not exactly equal to the theoretical predictions.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3226",
    "text": "One drawback to scaling rules that set all of the initial weights to have the same standard deviation, such as Jm, is that every individual weight becomes extremely\u00a0small when the layers become large. Martens (2010) introduced an alternative\u00a0initialization scheme called sparse initialization in which each unit is initialized to\u00a0have exactly k non-zero weights. The idea is to keep the total amount of input to\u00a0the unit independent from the number of inputs m without making the magnitude\u00a0of individual weight elements shrink with m. Sparse initialization helps to achieve\u00a0more diversity among the units at initialization time. However, it also imposes\u00a0a very strong prior on the weights that are chosen to have large Gaussian values.\u00a0Because it takes a long time for gradient descent to shrink \u201cincorrect\u201d large values,\u00a0this initialization scheme can cause problems for units such as maxout units that\u00a0have several filters that must be carefully coordinated with each other.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3227",
    "text": "When computational resources allow it, it is usually a good idea to treat the initial scale of the weights for each layer as a hyperparameter, and to choose these\u00a0scales using a hyperparameter search algorithm described in Sec. 11.4.2, such\u00a0as random search. The choice of whether to use dense or sparse initialization\u00a0can also be made a hyperparameter. Alternately, one can manually search for\u00a0the best initial scales. A good rule of thumb for choosing the initial scales is to\u00a0look at the range or standard deviation of activations or gradients on a single\u00a0minibatch of data. If the weights are too small, the range of activations across the\u00a0minibatch will shrink as the activations propagate forward through the network.\u00a0By repeatedly identifying the first layer with unacceptably small activations and\u00a0increasing its weights, it is possible to eventually obtain a network with reasonable\u00a0initial activations throughout. If learning is still too slow at this point, it can be\u00a0useful to look at the range or standard deviation of the gradients as well as the\u00a0activations. This procedure can in principle be automated and is generally less\u00a0computationally costly than hyperparameter optimization based on validation set\u00a0error because it is based on feedback from the behavior of the initial model on a\u00a0single batch of data, rather than on feedback from a trained model on the validation\u00a0set. While long used heuristically, this protocol has recently been specified more\u00a0formally and studied by Mishkin and Matas (2015).",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3228",
    "text": "So far we have focused on the initialization of the weights. Fortunately, initialization of other parameters is typically easier.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3229",
    "text": "The approach for setting the biases must be coordinated with the approach for settings the weights. Setting the biases to zero is compatible with most weight\u00a0initialization schemes. There are a few situations where we may set some biases to\u00a0non-zero values:",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3230",
    "text": "\u2022 \u00a0\u00a0\u00a0If a bias is for an output unit, then it is often beneficial to initialize the bias to\u00a0obtain the right marginal statistics of the output. To do this, we assume that\u00a0the initial weights are small enough that the output of the unit is determined\u00a0only by the bias. This justifies setting the bias to the inverse of the activation\u00a0function applied to the marginal statistics of the output in the training set.\u00a0For example, if the output is a distribution over classes and this distribution\u00a0is a highly skewed distribution with the marginal probability of class i given\u00a0by element c of some vector c, then we can set the bias vector b by solving\u00a0the equation softmax(b) = c. This applies not only to classifiers but also to\u00a0models we will encounter in Part III, such as autoencoders and Boltzmann\u00a0machines. These models have layers whose output should resemble the input\u00a0data x, and it can be very helpful to initialize the biases of such layers to\u00a0match the marginal distribution over x.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3231",
    "text": "\u2022 \u00a0\u00a0\u00a0Sometimes we may want to choose the bias to avoid causing too much\u00a0saturation at initialization. For example, we may set the bias of a ReLU\u00a0hidden unit to 0.1 rather than 0 to avoid saturating the ReLU at initialization.\u00a0This approach is not compatible with weight initialization schemes that do\u00a0not expect strong input from the biases though. For example, it is not\u00a0recommended for use with random walk initialization (Sussillo, 2014).",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3232",
    "text": "\u2022 \u00a0\u00a0\u00a0Sometimes a unit controls whether other units are able to participate in a\u00a0function. In such situations, we have a unit with output u and another unit\u00a0h G [0,1], then we can view h as a gate that determines whether uh ~ 1 or\u00a0uh ~ 0. In these situations, we want to set the bias for h so that h ~ 1 most",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3233",
    "text": "of the time at initialization. Otherwise u does not have a chance to learn. For example, Jozefowicz et al. (2015) advocate setting the bias to 1 for the\u00a0forget gate of the LSTM model, described in Sec. 10.10.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3234",
    "text": "Another common type of parameter is a variance or precision parameter. For example, we can perform linear regression with a conditional variance estimate\u00a0using the model",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3235",
    "text": "p(y | x) = N(y | wTx + b, l/fi) \u00a0\u00a0\u00a0(8.24)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3236",
    "text": "where (3 is a precision parameter. We can usually initialize variance or precision parameters to 1 safely. Another approach is to assume the initial weights are close\u00a0enough to zero that the biases may be set while ignoring the effect of the weights,\u00a0then set the biases to produce the correct marginal mean of the output, and set\u00a0the variance parameters to the marginal variance of the output in the training set.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3237",
    "text": "Besides these simple constant or random methods of initializing model parameters, it is possible to initialize model parameters using machine learning. A common strategy discussed in Part III of this book is to initialize a supervised model with\u00a0the parameters learned by an unsupervised model trained on the same inputs.\u00a0One can also perform supervised training on a related task. Even performing\u00a0supervised training on an unrelated task can sometimes yield an initialization that\u00a0offers faster convergence than a random initialization. Some of these initialization\u00a0strategies may yield faster convergence and better generalization because they\u00a0encode information about the distribution in the initial parameters of the model.\u00a0Others apparently perform well primarily because they set the parameters to have\u00a0the right scale or set different units to compute different functions from each other.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3238",
    "text": "Neural network researchers have long realized that the learning rate was reliably one of the hyperparameters that is the most difficult to set because it has a significant\u00a0impact on model performance. As we have discussed in Sec. 4.3 and Sec. 8.2, the\u00a0cost is often highly sensitive to some directions in parameter space and insensitive\u00a0to others. The momentum algorithm can mitigate these issues somewhat, but\u00a0does so at the expense of introducing another hyperparameter. In the face of this,\u00a0it is natural to ask if there is another way. If we believe that the directions of\u00a0sensitivity are somewhat axis-aligned, it can make sense to use a separate learning\u00a0rate for each parameter, and automatically adapt these learning rates throughout\u00a0the course of learning.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3239",
    "text": "The delta-bar-delta algorithm (Jacobs, 1988) is an early heuristic approach to adapting individual learning rates for model parameters during training. The\u00a0approach is based on a simple idea: if the partial derivative of the loss, with respect\u00a0to a given model parameter, remains the same sign, then the learning rate should\u00a0increase. If the partial derivative with respect to that parameter changes sign,\u00a0then the learning rate should decrease. Of course, this kind of rule can only be\u00a0applied to full batch optimization.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3240",
    "text": "More recently, a number of incremental (or mini-batch-based) methods have been introduced that adapt the learning rates of model parameters. This section\u00a0will briefly review a few of these algorithms.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3241",
    "text": "The AdaGrad algorithm, shown in Algorithm 8.4, individually adapts the learning rates of all model parameters by scaling them inversely proportional to the square\u00a0root of the sum of all of their historical squared values (Duchi et al., 2011). The\u00a0parameters with the largest partial derivative of the loss have a correspondingly\u00a0rapid decrease in their learning rate, while parameters with small partial derivatives\u00a0have a relatively small decrease in their learning rate. The net effect is greater\u00a0progress in the more gently sloped directions of parameter space.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3242",
    "text": "In the context of convex optimization, the AdaGrad algorithm enjoys some desirable theoretical properties. However, empirically it has been found that\u2014for\u00a0training deep neural network models\u2014the accumulation of squared gradients from\u00a0the beginning of training can result in a premature and excessive decrease\u00a0in the effective learning rate. AdaGrad performs well for some but not all deep\u00a0learning models.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3243",
    "text": "The RMSProp algorithm (Hinton, 2012) modifies AdaGrad to perform better in the non-convex setting by changing the gradient accumulation into an exponentially\u00a0weighted moving average. AdaGrad is designed to converge rapidly when applied\u00a0to a convex function. When applied to a non-convex function to train a neural\u00a0network, the learning trajectory may pass through many different structures and\u00a0eventually arrive at a region that is a locally convex bowl. AdaGrad shrinks the\u00a0learning rate according to the entire history of the squared gradient and may\u00a0have made the learning rate too small before arriving at such a convex structure.\u00a0RMSProp uses an exponentially decaying average to discard history from the",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3244",
    "text": "Algorithm 8.4 The AdaGrad algorithm Require: Global learning rate e\u00a0Require: Initial parameter 6",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3245",
    "text": "Require: Small constant 5, perhaps 10-7, for numerical stability Initialize gradient accumulation variable r = 0\u00a0while stopping criterion not met do",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3246",
    "text": "Sample a minibatch of m examples from the training set {x(1),..., \u00a0\u00a0\u00a0} with",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3247",
    "text": "corresponding targets",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3248",
    "text": "Compute gradient: g ^ ^V0YU L(f (*W; 6), y(i))",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3249",
    "text": "Accumulate squared gradient: r ^ r + g 0 g",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3250",
    "text": "Compute update: A6 ^ \u2014 s_+^r 0 g\u25a0 \u00a0\u00a0\u00a0(Division and square root applied",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3251",
    "text": "element-wise)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3252",
    "text": "Apply update: 6 ^ 6 + A6 end while",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3253",
    "text": "extreme past so that it can converge rapidly after finding a convex bowl, as if it were an instance of the AdaGrad algorithm initialized within that bowl.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3254",
    "text": "RMSProp is shown in its standard form in Algorithm 8.5 and combined with Nesterov momentum in Algorithm 8.6. Compared to AdaGrad, the use of the\u00a0moving average introduces a new hyperparameter, p, that controls the length scale\u00a0of the moving average.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3255",
    "text": "Empirically, RMSProp has been shown to be an effective and practical optimization algorithm for deep neural networks. It is currently one of the go-to optimization methods being employed routinely by deep learning practitioners.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3256",
    "text": "Adam (Kingma and Ba, 2014) is yet another adaptive learning rate optimization algorithm and is presented in Algorithm 8.7. The name \u201cAdam\u201d derives from\u00a0the phrase \u201cadaptive moments.\u201d In the context of the earlier algorithms, it is\u00a0perhaps best seen as a variant on the combination of RMSProp and momentum\u00a0with a few important distinctions. First, in Adam, momentum is incorporated\u00a0directly as an estimate of the first order moment (with exponential weighting) of\u00a0the gradient. The most straightforward way to add momentum to RMSProp is to\u00a0apply momentum to the rescaled gradients. The use of momentum in combination\u00a0with rescaling does not have a clear theoretical motivation. Second, Adam includes\u00a0bias corrections to the estimates of both the first-order moments (the momentum\u00a0term) and the (uncentered) second-order moments to account for their initialization",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3257",
    "text": "Algorithm 8.5 The RMSProp algorithm",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3258",
    "text": "Require: Global learning rate e, decay rate p.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3259",
    "text": "Require: Initial parameter 6 Require: Small constant S, usually 10-6, used to stabilize division by small\u00a0numbers.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3260",
    "text": "Initialize accumulation variables r = 0 while stopping criterion not met do",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3261",
    "text": "Sample a minibatch of m examples from the training set {x(1),..., \u00a0\u00a0\u00a0} with",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3262",
    "text": "corresponding targets y(i).",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3263",
    "text": "Compute gradient: g ^ ^V0 La L(f (x(i); 6), y(i))",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3264",
    "text": "Accumulate squared gradient: r ^ pr + (1 \u2014 p)g 0 g",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3265",
    "text": "Compute parameter update: A6 = \u2014 \u00a0\u00a0\u00a00 g. (^\u00a7+r applied element-wise)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3266",
    "text": "Apply update: 6 ^ 6 + A6 end while",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3267",
    "text": "at the origin (see Algorithm 8.7). RMSProp also incorporates an estimate of the (uncentered) second-order moment, however it lacks the correction factor. Thus,\u00a0unlike in Adam, the RMSProp second-order moment estimate may have high bias\u00a0early in training. Adam is generally regarded as being fairly robust to the choice\u00a0of hyperparameters, though the learning rate sometimes needs to be changed from\u00a0the suggested default.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3268",
    "text": "In this section, we discussed a series of related algorithms that each seek to address the challenge of optimizing deep models by adapting the learning rate for each\u00a0model parameter. At this point, a natural question is: which algorithm should one\u00a0choose?",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3269",
    "text": "Unfortunately, there is currently no consensus on this point. Schaul et al. (2014) presented a valuable comparison of a large number of optimization algorithms\u00a0across a wide range of learning tasks. While the results suggest that the family of\u00a0algorithms with adaptive learning rates (represented by RMSProp and AdaDelta)\u00a0performed fairly robustly, no single best algorithm has emerged.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3270",
    "text": "Currently, the most popular optimization algorithms actively in use include SGD, SGD with momentum, RMSProp, RMSProp with momentum, AdaDelta\u00a0and Adam. The choice of which algorithm to use, at this point, seems to depend\u00a0largely on the user\u2019s familiarity with the algorithm (for ease of hyperparameter\u00a0tuning).",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3271",
    "text": "Algorithm 8.6 RMSProp algorithm with Nesterov momentum Require: Global learning rate e, decay rate p, momentum coefficient a.\u00a0Require: Initial parameter 6, initial velocity v.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3272",
    "text": "Initialize accumulation variable r = 0 while stopping criterion not met do",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3273",
    "text": "Sample a minibatch of m examples from the training set {x(1),..., x(m)} with corresponding targets y(i).",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3274",
    "text": "Compute interim update: 6 ^ 6 + av Compute gradient: g ^ my - ^. L(f (x(i);6), y(i))",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3275",
    "text": "Accumulate gradient: r ^ pr + (1 \u2014 p)g 0 g",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3276",
    "text": "Compute velocity update: v ^ av \u2014 \u00a0\u00a0\u00a00 g \u2022 (yr applied element-wise)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3277",
    "text": "Apply update: 6 ^ 6 + v end while",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3278",
    "text": "In this section we discuss the application of second-order methods to the training of deep networks. See LeCun et al. (1998a) for an earlier treatment of this subject.\u00a0For simplicity of exposition, the only objective function we examine is the empirical\u00a0risk:",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3279",
    "text": "J (6) = Ex,",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3280",
    "text": "y~pdata (x,y",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3281",
    "text": ")[L(f(x; 6), y)] = m^ L(f (x(i); 6),y(i)).",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3282",
    "text": "-8.25",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3283",
    "text": "i= 1",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3284",
    "text": "However the methods we discuss here extend readily to more general objective functions that, for instance, include parameter regularization terms such as those\u00a0discussed in Chapter 7.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3285",
    "text": "In Sec. 4.3, we introduced second-order gradient methods. In contrast to first-order methods, second-order methods make use of second derivatives to improve optimization. The most widely used second-order method is Newton\u2019s method. We\u00a0now describe Newton\u2019s method in more detail, with emphasis on its application to\u00a0neural network training.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3286",
    "text": "Newton\u2019s method is an optimization scheme based on using a second-order Taylor series expansion to approximate J(6) near some point 60, ignoring derivatives",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3287",
    "text": "Algorithm 8.7 The Adam algorithm",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3288",
    "text": "Require: Step size e (Suggested default: 0.001)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3289",
    "text": "Require: Exponential decay rates for moment estimates, p! and p2 in [0, 1).",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3290",
    "text": "(Suggested defaults: 0.9 and 0.999 respectively)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3291",
    "text": "Require: Small constant S used for numerical stabilization. (Suggested default: 10-8)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3292",
    "text": "Require: Initial parameters 6",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3293",
    "text": "Initialize 1st and 2nd moment variables s = 0, r = 0",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3294",
    "text": "Initialize time step t = 0",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3295",
    "text": "while stopping criterion not met do",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3296",
    "text": "Sample a minibatch of m examples from the training set {x(!),..., \u00a0\u00a0\u00a0} with",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3297",
    "text": "corresponding targets y(i).",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3298",
    "text": "Compute gradient: g \u2014 ^V0 Xa L(f (x(i); 6), y(i)) t i\u2014 t + 1",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3299",
    "text": "Update biased first moment estimate: s \u2014 p!s + (1 \u2014 p! )g Update biased second moment estimate: r \u2014 p2r + (1 \u2014 p2)g 0 g\u00a0Correct bias in first moment: S",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3300",
    "text": "Correct bias in second moment: r Compute update: A6 = \u2014 e-",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3301",
    "text": "!-pi",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3302",
    "text": "r",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3303",
    "text": "!-p2",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3304",
    "text": "Apply update: 6 \u2014 6 + A6 end while",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3305",
    "text": "r+S",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3306",
    "text": "(operations applied element-wise)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3307",
    "text": "of higher order:",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3308",
    "text": "1",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3309",
    "text": "J(6) \u00ab J(60) + (6 \u2014 60)' VeJ(6)) + 2(6 \u2014 60)1 H(6 \u2014 60),",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3310",
    "text": "-8.26",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3311",
    "text": "where H is the Hessian of J with respect to 6 evaluated at 60. If we then solve for the critical point of this function, we obtain the Newton parameter update rule:",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3312",
    "text": "-8.27",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3313",
    "text": "6* = 60 \u2014 H-!V eJ (6 0)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3314",
    "text": "Thus for a locally quadratic function (with positive definite H), by rescaling the gradient by H-!, Newton\u2019s method jumps directly to the minimum. If the\u00a0objective function is convex but not quadratic (there are higher-order terms), this\u00a0update can be iterated, yielding the training algorithm associated with Newton\u2019s\u00a0method, given in Algorithm 8.8.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3315",
    "text": "For surfaces that are not quadratic, as long as the Hessian remains positive definite, Newton\u2019s method can be applied iteratively. This implies a two-step",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3316",
    "text": "Algorithm 8.8 Newton\u2019s method with objective \u00a0\u00a0\u00a0J (0)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3317",
    "text": "i \"1 L(f (*\u00bb; 0)^)._",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3318",
    "text": "Require: Initial parameter 03 Require: Training set of m examples\u00a0while stopping criterion not met do",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3319",
    "text": "Compute gradient: g ^ \"Ve , L(f (x(i); 0), y(i))",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3320",
    "text": "Compute Hessian: H ^ \" Ve i L(f (x(i); 0), y(i))",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3321",
    "text": "Compute Hessian inverse: H-1 Compute update: A0 = \u2014H-1g\u00a0Apply update: 0 = 0 + A0\u00a0end while",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3322",
    "text": "iterative procedure. First, update or compute the inverse Hessian (i.e. by updating the quadratic approximation). Second, update the parameters according to Eq.\u00a08.27.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3323",
    "text": "In Sec. 8.2.3, we discussed how Newton\u2019s method is appropriate only when the Hessian is positive definite. In deep learning, the surface of the objective\u00a0function is typically non-convex with many features, such as saddle points, that\u00a0are problematic for Newton\u2019s method. If the eigenvalues of the Hessian are not\u00a0all positive, for example, near a saddle point, then Newton\u2019s method can actually\u00a0cause updates to move in the wrong direction. This situation can be avoided\u00a0by regularizing the Hessian. Common regularization strategies include adding a\u00a0constant, a, along the diagonal of the Hessian. The regularized update becomes",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3324",
    "text": "0* = 00 \u2014 [H (f (00)) + all1\u05be Ve f (00). \u00a0\u00a0\u00a0(8.28)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3325",
    "text": "This regularization strategy is used in approximations to Newton\u2019s method, such as the Levenberg-Marquardt algorithm (Levenberg, 1944; Marquardt, 1963), and\u00a0works fairly well as long as the negative eigenvalues of the Hessian are still relatively\u00a0close to zero. In cases where there are more extreme directions of curvature, the\u00a0value of a would have to be sufficiently large to offset the negative eigenvalues.\u00a0However, as a increases in size, the Hessian becomes dominated by the al diagonal\u00a0and the direction chosen by Newton\u2019s method converges to the standard gradient\u00a0divided by a. When strong negative curvature is present, a may need to be so\u00a0large that Newton\u2019s method would make smaller steps than gradient descent with\u00a0a properly chosen learning rate.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3326",
    "text": "Beyond the challenges created by certain features of the objective function, such as saddle points, the application of Newton\u2019s method for training large neural\u00a0networks is limited by the significant computational burden it imposes. The\u00a0number of elements in the Hessian is squared in the number of parameters, so with\u00a0k parameters (and for even very small neural networks the number of parameters\u00a0k can be in the millions), Newton\u2019s method would require the inversion of a k x k\u00a0matrix\u2014with computational complexity of O(k3). Also, since the parameters\u00a0will change with every update, the inverse Hessian has to be computed at every\u00a0training iteration. As a consequence, only networks with a very small number\u00a0of parameters can be practically trained via Newton\u2019s method. In the remainder\u00a0of this section, we will discuss alternatives that attempt to gain some of the\u00a0advantages of Newton\u2019s method while side-stepping the computational hurdles.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3327",
    "text": "Conjugate gradients is a method to efficiently avoid the calculation of the inverse Hessian by iteratively descending conjugate directions. The inspiration for this\u00a0approach follows from a careful study of the weakness of the method of steepest\u00a0descent (see Sec. 4.3 for details), where line searches are applied iteratively in\u00a0the direction associated with the gradient. Fig. 8.6 illustrates how the method of\u00a0steepest descent, when applied in a quadratic bowl, progresses in a rather ineffective\u00a0back-and-forth, zig-zag pattern. This happens because each line search direction,\u00a0when given by the gradient, is guaranteed to be orthogonal to the previous line\u00a0search direction.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3328",
    "text": "Let the previous search direction be dt_1. At the minimum, where the line search terminates, the directional derivative is zero in direction dt_ 1: V0 J(0) \u2022\u00a0dt_ 1 = 0. Since the gradient at this point defines the current search direction,\u00a0dt = V0J(0) will have no contribution in the direction dt_ 1. Thus dt is orthogonal\u00a0to dt-1. This relationship between dt-1 and dt is illustrated in Fig. 8.6 for\u00a0multiple iterations of steepest descent. As demonstrated in the figure, the choice of\u00a0orthogonal directions of descent do not preserve the minimum along the previous\u00a0search directions. This gives rise to the zig-zag pattern of progress, where by\u00a0descending to the minimum in the current gradient direction, we must re-minimize\u00a0the objective in the previous gradient direction. Thus, by following the gradient at\u00a0the end of each line search we are, in a sense, undoing progress we have already\u00a0made in the direction of the previous line search. The method of conjugate gradients\u00a0seeks to address this problem.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3329",
    "text": "In the method of conjugate gradients, we seek to find a search direction that is conjugate to the previous line search direction, i.e. it will not undo progress made\u00a0in that direction. At training iteration t, the next search direction dt takes the\u00a0form:",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3330",
    "text": "dt = V 0J (0) + f3td t_ 1 \u00a0\u00a0\u00a0(8.29)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3331",
    "text": "Figure 8.6: The method of steepest descent applied to a quadratic cost surface. The method of steepest descent involves jumping to the point of lowest cost along the line\u00a0defined by the gradient at the initial point on each step. This resolves some of the problems\u00a0seen with using a fixed learning rate in Fig. 4.6, but even with the optimal step size the\u00a0algorithm still makes back-and-forth progress toward the optimum. By definition, at\u00a0the minimum of the objective along a given direction, the gradient at the final point is\u00a0orthogonal to that direction.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3332",
    "text": "were fit is a coefficient whose magnitude controls how much of the direction, dt-1, we should add back to the current search direction.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3333",
    "text": "Two directions, d and dt-1, are defined as conjugate if dJH(J)dt-1 = 0.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3334",
    "text": "dj Hdt-1 = 0 \u00a0\u00a0\u00a0(8.30)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3335",
    "text": "The straightforward way to impose conjugacy would involve calculation of the eigenvectors of H to choose fit, which would not satisfy our goal of developing\u00a0a method that is more computationally viable than Newton\u2019s method for large\u00a0problems. Can we calculate the conjugate directions without resorting to these\u00a0calculations? Fortunately the answer to that is yes.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3336",
    "text": "Two popular methods for computing the fit are:",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3337",
    "text": "1. Fletcher-Reeves:",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3338",
    "text": "fi t =",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3339",
    "text": "_Ve J (ft )T VeJ (O t)_ VeJ (Ot-1 )T VJ (O t-1)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3340",
    "text": "-8.31",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3341",
    "text": "For a quadratic surface, the conjugate directions ensure that the gradient along the previous direction does not increase in magnitude. We therefore stay at the\u00a0minimum along the previous directions. As a consequence, in a k-dimensional\u00a0parameter space, conjugate gradients only requires k line searches to achieve the\u00a0minimum. The conjugate gradient algorithm is given in Algorithm 8.9.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3342",
    "text": "Algorithm 8.9 Conjugate gradient method",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3343",
    "text": "Require: Initial parameters 60 Require: Training set of m examples\u00a0Initialize po = 0\u00a0Initialize go = 0\u00a0Initialize t = 1",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3344",
    "text": "while stopping criterion not met do Initialize the gradient gt = 0",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3345",
    "text": "Compute gradient: gt \u2014 ^iL(f (x(i); 6), y(i))",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3346",
    "text": "Compute fy = gf\u2014 ^ 1 * (Polak-Ribiere)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3347",
    "text": "(Nonlinear conjugate gradient: optionally reset fy to zero, for example if t is a multiple of some constant k, such as k = 5)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3348",
    "text": "Compute search direction: pt = \u2014gt + fytpt_1",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3349",
    "text": "Perform line search to find: e* = argmin e \u00a0\u00a0\u00a0L(f (x (i); 6t + ept), y(i))",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3350",
    "text": "(On a truly quadratic cost function, analytically solve for e* rather than explicitly searching for it)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3351",
    "text": "Apply update: 6t+! = 6t + e *pt t \u2014\u2014 t + 1\u00a0end while",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3352",
    "text": "Nonlinear Conjugate Gradients: So far we have discussed the method of conjugate gradients as it is applied to quadratic objective functions. Of course,\u00a0our primary interest in this chapter is to explore optimization methods for training\u00a0neural networks and other related deep learning models where the corresponding\u00a0objective function is far from quadratic. Perhaps surprisingly, the method of\u00a0conjugate gradients is still applicable in this setting, though with some modification.\u00a0Without any assurance that the objective is quadratic, the conjugate directions are\u00a0no longer assured to remain at the minimum of the objective for previous directions.\u00a0As a result, the nonlinear conjugate gradients algorithm includes occasional resets\u00a0where the method of conjugate gradients is restarted with line search along the\u00a0unaltered gradient.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3353",
    "text": "Practitioners report reasonable results in applications of the nonlinear conjugate",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3354",
    "text": "gradients algorithm to training neural networks, though it is often beneficial to initialize the optimization with a few iterations of stochastic gradient descent before\u00a0commencing nonlinear conjugate gradients. Also, while the (nonlinear) conjugate\u00a0gradients algorithm has traditionally been cast as a batch method, minibatch\u00a0versions have been used successfully for the training of neural networks (Le et al.,\u00a02011). Adaptations of conjugate gradients specifically for neural networks have\u00a0been proposed earlier, such as the scaled conjugate gradients algorithm (Moller,\u00a01993).",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3355",
    "text": "The Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm attempts to bring some of the advantages of Newton\u2019s method without the computational burden. In that\u00a0respect, BFGS is similar to CG. However, BFGS takes a more direct approach to\u00a0the approximation of Newton\u2019s update. Recall that Newton\u2019s update is given by",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3356",
    "text": "9* = 00 - H-'Vg J(6b), \u00a0\u00a0\u00a0(8.33)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3357",
    "text": "where H is the Hessian of J with respect to 9 evaluated at 90. The primary computational difficulty in applying Newton\u2019s update is the calculation of the\u00a0inverse Hessian H-1. The approach adopted by quasi-Newton methods (of which\u00a0the BFGS algorithm is the most prominent) is to approximate the inverse with\u00a0a matrix Mt that is iteratively refined by low rank updates to become a better\u00a0approximation of H-1.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3358",
    "text": "The specification and derivation of the BFGS approximation is given in many textbooks on optimization, including Luenberger (1984).",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3359",
    "text": "Once the inverse Hessian approximation Mt is updated, the direction of descent P is determined by pt = Mtgt. A line search is performed in this direction to\u00a0determine the size of the step, e*, taken in this direction. The final update to the\u00a0parameters is given by:",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3360",
    "text": "9t+1 = 9t + e* pt. \u00a0\u00a0\u00a0(8.34)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3361",
    "text": "Like the method of conjugate gradients, the BFGS algorithm iterates a series of line searches with the direction incorporating second-order information. However\u00a0unlike conjugate gradients, the success of the approach is not heavily dependent\u00a0on the line search finding a point very close to the true minimum along the line.\u00a0Thus, relative to conjugate gradients, BFGS has the advantage that it can spend\u00a0less time refining each line search. On the other hand, the BFGS algorithm must\u00a0store the inverse Hessian matrix, M, that requires O(n2) memory, making BFGS\u00a0impractical for most modern deep learning models that typically have millions of\u00a0parameters.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3362",
    "text": "Limited Memory BFGS (or L-BFGS) The memory costs of the BFGS algorithm can be significantly decreased by avoiding storing the complete inverse\u00a0Hessian approximation M. The L-BFGS algorithm computes the approximation M\u00a0using the same method as the BFGS algorithm, but beginning with the assumption\u00a0that M(t-1) is the identity matrix, rather than storing the approximation from one\u00a0step to the next. If used with exact line searches, the directions defined by L-BFGS\u00a0are mutually conjugate. However, unlike the method of conjugate gradients, this\u00a0procedure remains well behaved when the minimum of the line search is reached\u00a0only approximately. Th L-BFGS strategy with no storage described here can be\u00a0generalized to include more information about the Hessian by storing some of the\u00a0vectors used to update M at each time step, which costs only O(n) per step.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3363",
    "text": "Many optimization techniques are not exactly algorithms, but rather general templates that can be specialized to yield algorithms, or subroutines that can be\u00a0incorporated into many different algorithms.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3364",
    "text": "Batch normalization (Ioffe and Szegedy, 2015) is one of the most exciting recent innovations in optimizing deep neural networks and it is actually not an optimization\u00a0algorithm at all. Instead, it is a method of adaptive reparametrization, motivated\u00a0by the difficulty of training very deep models.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3365",
    "text": "Very deep models involve the composition of several functions or layers. The gradient tells how to update each parameter, under the assumption that the other\u00a0layers do not change. In practice, we update all of the layers simultaneously.\u00a0When we make the update, unexpected results can happen because many functions\u00a0composed together are changed simultaneously, using updates that were computed\u00a0under the assumption that the other functions remain constant. As a simple\u00a0example, suppose we have a deep neural network that has only one unit per layer\u00a0and does not use an activation function at each hidden layer: y = xw 1 w2 w3 ... wi.\u00a0Here, wi provides the weight used by layer i. The output of layer i is hi = h,_ 1 w^.\u00a0The output y is a linear function of the input x, but a nonlinear function of the\u00a0weights wi. Suppose our cost function has put a gradient of 1 on y, so we wish to\u00a0decrease y slightly. The back-propagation algorithm can then compute a gradient\u00a0g = Vwy. Consider what happens when we make an update w ^ w \u2014 eg. The\u00a0first-order Taylor series approximation of y predicts that the value of y will decrease\u00a0by egTg. If we wanted to decrease y by .1, this first-order information available in\u00a0the gradient suggests we could set the learning rate e to . However, the actual\u00a0update will include second-order and third-order effects, on up to effects of order l.\u00a0The new value of y is given by",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3366",
    "text": "x(w1 \u2014 egi )(w2 \u2014 eg2)... (wi \u2014 egi). \u00a0\u00a0\u00a0(8.35)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3367",
    "text": "An example of one second-order term arising from this update is e2gi g2 ni=3 wi. This term might be negligible if ni=3 wi is small, or might be exponentially large\u00a0if the weights on layers 3 through l are greater than 1. This makes it very hard\u00a0to choose an appropriate learning rate, because the effects of an update to the\u00a0parameters for one layer depends so strongly on all of the other layers. Second-order\u00a0optimization algorithms address this issue by computing an update that takes these\u00a0second-order interactions into account, but we can see that in very deep networks,\u00a0even higher-order interactions can be significant. Even second-order optimization\u00a0algorithms are expensive and usually require numerous approximations that prevent\u00a0them from truly accounting for all significant second-order interactions. Building\u00a0an n-th order optimization algorithm for n > 2 thus seems hopeless. What can we\u00a0do instead?",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3368",
    "text": "Batch normalization provides an elegant way of reparametrizing almost any deep network. The reparametrization significantly reduces the problem of coordinating\u00a0updates across many layers. Batch normalization can be applied to any input\u00a0or hidden layer in a network. Let H be a minibatch of activations of the layer\u00a0to normalize, arranged as a design matrix, with the activations for each example\u00a0appearing in a row of the matrix. To normalize H, we replace it with",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3369",
    "text": "H = \u00a0\u00a0\u00a0,\u00a0\u00a0\u00a0\u00a0(8.36)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3370",
    "text": "G",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3371",
    "text": "where 1 is a vector containing the mean of each unit and g is a vector containing the standard deviation of each unit. The arithmetic here is based on broadcasting\u00a0the vector 1 and the vector g to be applied to every row of the matrix H. Within\u00a0each row, the arithmetic is element-wise, so Hij is normalized by subtracting gj\u00a0and dividing by aj. The rest of the network then operates on H' in exactly the\u00a0same way that the original network operated on H.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3372",
    "text": "At training time,",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3373",
    "text": "1",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3374",
    "text": "1 = - \u00a0\u00a0\u00a0Hi,:\u00a0\u00a0\u00a0\u00a0(8.37)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3375",
    "text": "m",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3376",
    "text": "and",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3377",
    "text": "a = ^J5 + ^J2(h - vt, \u00a0\u00a0\u00a0(8-38)",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3378",
    "text": "where 5 is a small positive value such as 10-8 imposed to avoid encountering the undefined gradient of y/z at z = 0. Crucially, we back-propagate through\u00a0these operations for computing the mean and the standard deviation, and for\u00a0applying them to normalize H. This means that the gradient will never propose\u00a0an operation that acts simply to increase the standard deviation or mean of\u00a0hi; the normalization operations remove the effect of such an action and zero\u00a0out its component in the gradient. This was a major innovation of the batch\u00a0normalization approach. Previous approaches had involved adding penalties to\u00a0the cost function to encourage units to have normalized activation statistics or\u00a0involved intervening to renormalize unit statistics after each gradient descent step.\u00a0The former approach usually resulted in imperfect normalization and the latter\u00a0usually resulted in significant wasted time as the learning algorithm repeatedly\u00a0proposed changing the mean and variance and the normalization step repeatedly\u00a0undid this change. Batch normalization reparametrizes the model to make some\u00a0units always be standardized by definition, deftly sidestepping both problems.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3379",
    "text": "At test time, fi and a may be replaced by running averages that were collected during training time. This allows the model to be evaluated on a single example,\u00a0without needing to use definitions of i and a that depend on an entire minibatch.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3380",
    "text": "Revisiting the y = xw!w2 ... wi example, we see that we can mostly resolve the difficulties in learning this model by normalizing h-1. Suppose that x is drawn\u00a0from a unit Gaussian. Then hi\u2014 will also come from a Gaussian, because the\u00a0transformation from x to hi is linear. However, h 1-1 will no longer have zero mean\u00a0and unit variance. After applying batch normalization, we obtain the normalized\u00a0hi-! that restores the zero mean and unit variance properties. For almost any\u00a0update to the lower layers, hi\u2014 will remain a unit Gaussian. The output y may\u00a0then be learned as a simple linear function y = uih i\u2014. Learning in this model is\u00a0now very simple because the parameters at the lower layers simply do not have an\u00a0effect in most cases; their output is always renormalized to a unit Gaussian. In\u00a0some corner cases, the lower layers can have an effect. Changing one of the lower\u00a0layer weights to 0 can make the output become degenerate, and changing the sign\u00a0of one of the lower weights can flip the relationship between hi\u2014 and y. These\u00a0situations are very rare. Without normalization, nearly every update would have\u00a0an extreme effect on the statistics of h1_!. Batch normalization has thus made\u00a0this model significantly easier to learn. In this example, the ease of learning of\u00a0course came at the cost of making the lower layers useless. In our linear example,\u00a0the lower layers no longer have any harmful effect, but they also no longer have\u00a0any beneficial effect. This is because we have normalized out the first and second\u00a0order statistics, which is all that a linear network can influence. In a deep neural\u00a0network with nonlinear activation functions, the lower layers can perform nonlinear\u00a0transformations of the data, so they remain useful. Batch normalization acts to\u00a0standardize only the mean and variance of each unit in order to stabilize learning,\u00a0but allows the relationships between units and the nonlinear statistics of a single\u00a0unit to change.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3381",
    "text": "Because the final layer of the network is able to learn a linear transformation, we may actually wish to remove all linear relationships between units within a\u00a0layer. Indeed, this is the approach taken by Desjardins et al. (2015), who provided\u00a0the inspiration for batch normalization. Unfortunately, eliminating all linear\u00a0interactions is much more expensive than standardizing the mean and standard\u00a0deviation of each individual unit, and so far batch normalization remains the most\u00a0practical approach.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3382",
    "text": "Normalizing the mean and standard deviation of a unit can reduce the expressive power of the neural network containing that unit. In order to maintain the\u00a0expressive power of the network, it is common to replace the batch of hidden unit\u00a0activations H with 7H' + fl rather than simply the normalized H'. The variables\u00a07 and fl are learned parameters that allow the new variable to have any mean\u00a0and standard deviation. At first glance, this may seem useless\u2014why did we set\u00a0the mean to 0, and then introduce a parameter that allows it to be set back to\u00a0any arbitrary value fl ? The answer is that the new parametrization can represent\u00a0the same family of functions of the input as the old parametrization, but the new\u00a0parametrization has different learning dynamics. In the old parametrization, the\u00a0mean of H was determined by a complicated interaction between the parameters\u00a0in the layers below H. In the new parametrization, the mean of 7H' + fl is\u00a0determined solely by fl. The new parametrization is much easier to learn with\u00a0gradient descent.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3383",
    "text": "Most neural network layers take the form of ^(XW + b) where ^ is some fixed nonlinear activation function such as the rectified linear transformation. It\u00a0is natural to wonder whether we should apply batch normalization to the input\u00a0X, or to the transformed value XW + b. Ioffe and Szegedy ( 2015) recommend\u00a0the latter. More specifically, XW + b should be replaced by a normalized version\u00a0of XW. The bias term should be omitted because it becomes redundant with\u00a0the f3 parameter applied by the batch normalization reparametrization. The input\u00a0to a layer is usually the output of a nonlinear activation function such as the\u00a0rectified linear function in a previous layer. The statistics of the input are thus\u00a0more non-Gaussian and less amenable to standardization by linear operations.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3384",
    "text": "In convolutional networks, described in Chapter 9, it is important to apply the same normalizing /a and a at every spatial location within a feature map, so that\u00a0the statistics of the feature map remain the same regardless of spatial location.",
    "chapter": "Autoencoders",
    "chapter_id": "main-17.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3385",
    "text": "In some cases, it may be possible to solve an optimization problem quickly by breaking it into separate pieces. If we minimize f (x) with respect to a single variable\u00a0xi, then minimize it with respect to another variable xj and so on, repeatedly\u00a0cycling through all variables, we are guaranteed to arrive at a (local) minimum.\u00a0This practice is known as coordinate descent, because we optimize one coordinate\u00a0at a time. More generally, block coordinate descent refers to minimizing with\u00a0respect to a subset of the variables simultaneously. The term \u201ccoordinate descent\u201d\u00a0is often used to refer to block coordinate descent as well as the strictly individual\u00a0coordinate descent.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3386",
    "text": "Coordinate descent makes the most sense when the different variables in the optimization problem can be clearly separated into groups that play relatively\u00a0isolated roles, or when optimization with respect to one group of variables is\u00a0significantly more efficient than optimization with respect to all of the variables.\u00a0For example, consider the cost function",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3387",
    "text": "2",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3388",
    "text": "J(H, W) = \u00a3 |Hi,j| + \u00a3 (x - WT H) ij. \u00a0\u00a0\u00a0(8.39)",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3389",
    "text": "i,j i,j i,j",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3390",
    "text": "This function describes a learning problem called sparse coding, where the goal is to find a weight matrix W that can linearly decode a matrix of activation values\u00a0H to reconstruct the training set X. Most applications of sparse coding also\u00a0involve weight decay or a constraint on the norms of the columns of W, in order\u00a0to prevent the pathological solution with extremely small H and large W.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3391",
    "text": "The function J is not convex. However, we can divide the inputs to the training algorithm into two sets: the dictionary parameters W and the code\u00a0representations H. Minimizing the objective function with respect to either one of\u00a0these sets of variables is a convex problem. Block coordinate descent thus gives\u00a0us an optimization strategy that allows us to use efficient convex optimization\u00a0algorithms, by alternating between optimizing W with H fixed, then optimizing\u00a0H with W fixed.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3392",
    "text": "Coordinate descent is not a very good strategy when the value of one variable strongly influences the optimal value of another variable, as in the function f (x) =\u00a0(x1 \u2014 x2)2 + a (x2 + x2) where a is a positive constant. The first term encourages\u00a0the two variables to have similar value, while the second term encourages them\u00a0to be near zero. The solution is to set both to zero. Newton\u2019s method can solve\u00a0the problem in a single step because it is a positive definite quadratic problem.\u00a0However, for small a, coordinate descent will make very slow progress because the\u00a0first term does not allow a single variable to be changed to a value that differs\u00a0significantly from the current value of the other variable.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3393",
    "text": "Polyak averaging (Polyak and Juditsky, 1992) consists of averaging together several points in the trajectory through parameter space visited by an optimization\u00a0algorithm. If t iterations of gradient descent visit points 6(1),..., 6(t), then the\u00a0output of the Polyak averaging algorithm is 6'(t) = -1 ^ ^ 6(i). On some problem\u00a0classes, such as gradient descent applied to convex problems, this approach has\u00a0strong convergence guarantees. When applied to neural networks, its justification\u00a0is more heuristic, but it performs well in practice. The basic idea is that the\u00a0optimization algorithm may leap back and forth across a valley several times\u00a0without ever visiting a point near the bottom of the valley. The average of all of\u00a0the locations on either side should be close to the bottom of the valley though.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3394",
    "text": "In non-convex problems, the path taken by the optimization trajectory can be very complicated and visit many different regions. Including points in parameter\u00a0space from the distant past that may be separated from the current point by large\u00a0barriers in the cost function does not seem like a useful behavior. As a result,\u00a0when applying Polyak averaging to non-convex problems, it is typical to use an\u00a0exponentially decaying running average:",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3395",
    "text": "6(t) = a6(t-1) + (1 \u2014 a)6(t). \u00a0\u00a0\u00a0(8.40)",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3396",
    "text": "The running average approach is used in numerous applications. See Szegedy et al. (2015) for a recent example.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3397",
    "text": "Sometimes, directly training a model to solve a specific task can be too ambitious if the model is complex and hard to optimize or if the task is very difficult. It is\u00a0sometimes more effective to train a simpler model to solve the task, then make the\u00a0model more complex. It can also be more effective to train the model to solve a\u00a0simpler task, then move on to confront the final task. These strategies that involve\u00a0training simple models on simple tasks before confronting the challenge of training\u00a0the desired model to perform the desired task are collectively known as pretraining.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3398",
    "text": "Greedy algorithms break a problem into many components, then solve for the optimal version of each component in isolation. Unfortunately, combining the\u00a0individually optimal components is not guaranteed to yield an optimal complete\u00a0solution. However, greedy algorithms can be computationally much cheaper than\u00a0algorithms that solve for the best joint solution, and the quality of a greedy solution\u00a0is often acceptable if not optimal. Greedy algorithms may also be followed by a\u00a0fine-tuning stage in which a joint optimization algorithm searches for an optimal\u00a0solution to the full problem. Initializing the joint optimization algorithm with a\u00a0greedy solution can greatly speed it up and improve the quality of the solution it\u00a0finds.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3399",
    "text": "Pretraining, and especially greedy pretraining, algorithms are ubiquitous in deep learning. In this section, we describe specifically those pretraining algorithms\u00a0that break supervised learning problems into other simpler supervised learning\u00a0problems. This approach is known as greedy supervised pretraining.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3400",
    "text": "In the original (Bengio et al., 2007) version of greedy supervised pretraining, each stage consists of a supervised learning training task involving only a subset of\u00a0the layers in the final neural network. An example of greedy supervised pretraining\u00a0is illustrated in Fig. 8.7, in which each added hidden layer is pretrained as part of\u00a0a shallow supervised MLP, taking as input the output of the previously trained\u00a0hidden layer. Instead of pretraining one layer at a time, Simonyan and Zisserman\u00a0(2015) pretrain a deep convolutional network (eleven weight layers) and then use\u00a0the first four and last three layers from this network to initialize even deeper\u00a0networks (with up to nineteen layers of weights). The middle layers of the new,\u00a0very deep network are initialized randomly. The new network is then jointly trained.\u00a0Another option, explored by Yu et al. (2010) is to use the outputs of the previously\u00a0trained MLPs, as well as the raw input, as inputs for each added stage.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3401",
    "text": "Why would greedy supervised pretraining help? The hypothesis initially discussed by Bengio et al. (2007) is that it helps to provide better guidance to the\u00a0intermediate levels of a deep hierarchy. In general, pretraining may help both in\u00a0terms of optimization and in terms of generalization.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3402",
    "text": "An approach related to supervised pretraining extends the idea to the context of transfer learning: Yosinski et al. (2014) pretrain a deep convolutional net with 8\u00a0layers of weights on a set of tasks (a subset of the 1000 ImageNet object categories)\u00a0and then initialize a same-size network with the first k layers of the first net. All\u00a0the layers of the second network (with the upper layers initialized randomly) are",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3403",
    "text": "fit =",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3404",
    "text": "(VJ (Ot) - Ve J (O t-1))T Ve J (Ot) VJ (Ot-1 )T VeJ (O t-1)",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3405",
    "text": "-8.32",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3406",
    "text": "(a)",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3407",
    "text": "Figure 8.7: Illustration of one form of greedy supervised pretraining (Bengio et al2007). (a) We start by training a sufficiently shallow architecture. (b) Another drawing of the\u00a0same architecture. (c) We keep only the input-to-hidden layer of the original network and\u00a0discard the hidden-to-output layer. We send the output of the first hidden layer as input\u00a0to another supervised single hidden layer MLP that is trained with the same objective\u00a0as the first network was, thus adding a second hidden layer. This can be repeated for\u00a0as many layers as desired. (d) Another drawing of the result, viewed as a feedforward\u00a0network. To further improve the optimization, we can jointly fine-tune all the layers,\u00a0either only at the end or at each stage of this process.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3408",
    "text": "then jointly trained to perform a different set of tasks (another subset of the 1000 ImageNet object categories), with fewer training examples than for the first set of\u00a0tasks. Other approaches to transfer learning with neural networks are discussed in\u00a0Sec. 15.2.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3409",
    "text": "Another related line of work is the FitNets (Romero et al., 2015) approach. This approach begins by training a network that has low enough depth and great enough\u00a0width (number of units per layer) to be easy to train. This network then becomes\u00a0a teacher for a second network, designated the student. The student network is\u00a0much deeper and thinner (eleven to nineteen layers) and would be difficult to train\u00a0with SGD under normal circumstances. The training of the student network is\u00a0made easier by training the student network not only to predict the output for\u00a0the original task, but also to predict the value of the middle layer of the teacher\u00a0network. This extra task provides a set of hints about how the hidden layers\u00a0should be used and can simplify the optimization problem. Additional parameters\u00a0are introduced to regress the middle layer of the 5-layer teacher network from\u00a0the middle layer of the deeper student network. However, instead of predicting\u00a0the final classification target, the objective is to predict the middle hidden layer\u00a0of the teacher network. The lower layers of the student networks thus have two\u00a0objectives: to help the outputs of the student network accomplish their task, as\u00a0well as to predict the intermediate layer of the teacher network. Although a thin\u00a0and deep network appears to be more difficult to train than a wide and shallow\u00a0network, the thin and deep network may generalize better and certainly has lower\u00a0computational cost if it is thin enough to have far fewer parameters. Without\u00a0the hints on the hidden layer, the student network performs very poorly in the\u00a0experiments, both on the training and test set. Hints on middle layers may thus\u00a0be one of the tools to help train neural networks that otherwise seem difficult to\u00a0train, but other optimization techniques or changes in the architecture may also\u00a0solve the problem.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3410",
    "text": "To improve optimization, the best strategy is not always to improve the optimization algorithm. Instead, many improvements in the optimization of deep models have\u00a0come from designing the models to be easier to optimize.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3411",
    "text": "In principle, we could use activation functions that increase and decrease in jagged non-monotonic patterns. However, this would make optimization extremely\u00a0difficult. In practice, it is more important to choose a model family that\u00a0is easy to optimize than to use a powerful optimization algorithm. Most\u00a0of the advances in neural network learning over the past 30 years have been\u00a0obtained by changing the model family rather than changing the optimization\u00a0procedure. Stochastic gradient descent with momentum, which was used to train\u00a0neural networks in the 1980s, remains in use in modern state of the art neural\u00a0network applications.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3412",
    "text": "Specifically, modern neural networks reflect a design choice to use linear transformations between layers and activation functions that are differentiable almost everywhere and have significant slope in large portions of their domain. In particular, model innovations like the LSTM, rectified linear units and maxout units\u00a0have all moved toward using more linear functions than previous models like deep\u00a0networks based on sigmoidal units. These models have nice properties that make\u00a0optimization easier. The gradient flows through many layers provided that the\u00a0Jacobian of the linear transformation has reasonable singular values. Moreover,\u00a0linear functions consistently increase in a single direction, so even if the model\u2019s\u00a0output is very far from correct, it is clear simply from computing the gradient\u00a0which direction its output should move to reduce the loss function. In other words,\u00a0modern neural nets have been designed so that their local gradient information\u00a0corresponds reasonably well to moving toward a distant solution.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3413",
    "text": "Other model design strategies can help to make optimization easier. For example, linear paths or skip connections between layers reduce the length of\u00a0the shortest path from the lower layer\u2019s parameters to the output, and thus\u00a0mitigate the vanishing gradient problem (Srivastava et al., 2015). A related idea\u00a0to skip connections is adding extra copies of the output that are attached to the\u00a0intermediate hidden layers of the network, as in GoogLeNet (Szegedy et al., 2014a)\u00a0and deeply-supervised nets (Lee et al., 2014). These \u201cauxiliary heads\u201d are trained\u00a0to perform the same task as the primary output at the top of the network in order\u00a0to ensure that the lower layers receive a large gradient. When training is complete\u00a0the auxiliary heads may be discarded. This is an alternative to the pretraining\u00a0strategies, which were introduced in the previous section. In this way, one can\u00a0train jointly all the layers in a single phase but change the architecture, so that\u00a0intermediate layers (especially the lower ones) can get some hints about what they\u00a0should do, via a shorter path. These hints provide an error signal to lower layers.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3414",
    "text": "As argued in Sec. 8.2.7, many of the challenges in optimization arise from the global structure of the cost function and cannot be resolved merely by making better\u00a0estimates of local update directions. The predominant strategy for overcoming this\u00a0problem is to attempt to initialize the parameters in a region that is connected\u00a0to the solution by a short path through parameter space that local descent can\u00a0discover.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3415",
    "text": "Continuation methods are a family of strategies that can make optimization easier by choosing initial points to ensure that local optimization spends most of\u00a0its time in well-behaved regions of space. The idea behind continuation methods is\u00a0to construct a series of objective functions over the same parameters. In order to\u00a0minimize a cost function J (6), we will construct new cost functions { J(0),..., J(n)}.\u00a0These cost functions are designed to be increasingly difficult, with J(0) being fairly\u00a0easy to minimize, and J(n), the most difficult, being J(6), the true cost function\u00a0motivating the entire process. When we say that J(i) is easier than J (i+x), we\u00a0mean that it is well behaved over more of 6 space. A random initialization is more\u00a0likely to land in the region where local descent can minimize the cost function\u00a0successfully because this region is larger. The series of cost functions are designed\u00a0so that a solution to one is a good initial point of the next. We thus begin by\u00a0solving an easy problem then refine the solution to solve incrementally harder\u00a0problems until we arrive at a solution to the true underlying problem.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3416",
    "text": "Traditional continuation methods (predating the use of continuation methods for neural network training) are usually based on smoothing the objective function.\u00a0See Wu (1997) for an example of such a method and a review of some related\u00a0methods. Continuation methods are also closely related to simulated annealing,\u00a0which adds noise to the parameters (Kirkpatrick et al., 1983). Continuation\u00a0methods have been extremely successful in recent years. See Mobahi and Fisher\u00a0(2015) for an overview of recent literature, especially for AI applications.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3417",
    "text": "Continuation methods traditionally were mostly designed with the goal of overcoming the challenge of local minima. Specifically, they were designed to\u00a0reach a global minimum despite the presence of many local minima. To do so,\u00a0these continuation methods would construct easier cost functions by \u201cblurring\u201d the\u00a0original cost function. This blurring operation can be done by approximating",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3418",
    "text": "J(6)<\u05be) = Ee, \u00a0\u00a0\u00a0;8,02>\u05f4 )J (6 8.41)\u00a0\u00a0\u00a0\u00a0(\u05f3)",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3419",
    "text": "via sampling. The intuition for this approach is that some non-convex functions become approximately convex when blurred. In many cases, this blurring preserves\u00a0enough information about the location of a global minimum that we can find the\u00a0global minimum by solving progressively less blurred versions of the problem. This\u00a0approach can break down in three different ways. First, it might successfully define\u00a0a series of cost functions where the first is convex and the optimum tracks from\u00a0one function to the next arriving at the global minimum, but it might require so\u00a0many incremental cost functions that the cost of the entire procedure remains high.\u00a0NP-hard optimization problems remain NP-hard, even when continuation methods\u00a0are applicable. The other two ways that continuation methods fail both correspond\u00a0to the method not being applicable. First, the function might not become convex,\u00a0no matter how much it is blurred. Consider for example the function J( ff) = -9Tff.\u00a0Second, the function may become convex as a result of blurring, but the minimum\u00a0of this blurred function may track to a local rather than a global minimum of the\u00a0original cost function.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3420",
    "text": "Though continuation methods were mostly originally designed to deal with the problem of local minima, local minima are no longer believed to be the primary\u00a0problem for neural network optimization. Fortunately, continuation methods can\u00a0still help. The easier objective functions introduced by the continuation method can\u00a0eliminate flat regions, decrease variance in gradient estimates, improve conditioning\u00a0of the Hessian matrix, or do anything else that will either make local updates\u00a0easier to compute or improve the correspondence between local update directions\u00a0and progress toward a global solution.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3421",
    "text": "Bengio et al. (2009) observed that an approach called curriculum learning or shaping can be interpreted as a continuation method. Curriculum learning is based\u00a0on the idea of planning a learning process to begin by learning simple concepts\u00a0and progress to learning more complex concepts that depend on these simpler\u00a0concepts. This basic strategy was previously known to accelerate progress in animal\u00a0training (Skinner, 1958; Peterson, 2004; Krueger and Dayan, 2009) and machine\u00a0learning (Solomonoff, 1989; Elman, 1993; Sanger, 1994). Bengio et al. (2009)\u00a0justified this strategy as a continuation method, where earlier J(i) are made easier by\u00a0increasing the influence of simpler examples (either by assigning their contributions\u00a0to the cost function larger coefficients, or by sampling them more frequently), and\u00a0experimentally demonstrated that better results could be obtained by following a\u00a0curriculum on a large-scale neural language modeling task. Curriculum learning\u00a0has been successful on a wide range of natural language (Spitkovsky et al., 2010;\u00a0Collobert et al., 2011a; Mikolov et al., 2011b; Tu and Honavar, 2011) and computer\u00a0vision (Kumar et al., 2010; Lee and Grauman, 2011; Supancic and Ramanan, 2013)\u00a0tasks. Curriculum learning was also verified as being consistent with the way in\u00a0which humans teach (Khan et al., 2011): teachers start by showing easier and\u00a0more prototypical examples and then help the learner refine the decision surface\u00a0with the less obvious cases. Curriculum-based strategies are more effective for\u00a0teaching humans than strategies based on uniform sampling of examples, and can\u00a0also increase the effectiveness of other teaching strategies (Basu and Christensen,\u00a02013).",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3422",
    "text": "Another important contribution to research on curriculum learning arose in the context of training recurrent neural networks to capture long-term dependencies:",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3423",
    "text": "Zaremba and Sutskever (2014) found that much better results were obtained with a stochastic curriculum, in which a random mix of easy and difficult examples is always\u00a0presented to the learner, but where the average proportion of the more difficult\u00a0examples (here, those with longer-term dependencies) is gradually increased. With\u00a0a deterministic curriculum, no improvement over the baseline (ordinary training\u00a0from the full training set) was observed.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3424",
    "text": "We have now described the basic family of neural network models and how to regularize and optimize them. In the chapters ahead, we turn to specializations of\u00a0the neural network family, that allow neural networks to scale to very large sizes and\u00a0process input data that has special structure. The optimization methods discussed\u00a0in this chapter are often directly applicable to these specialized architectures with\u00a0little or no modification.",
    "chapter": "Representation Learning",
    "chapter_id": "main-18.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3425",
    "text": "Convolutional networks (LeCun, 1989), also known as convolutional neural networks or CNNs, are a specialized kind of neural network for processing data that has\u00a0a known, grid-like topology. Examples include time-series data, which can be\u00a0thought of as a 1D grid taking samples at regular time intervals, and image data,\u00a0which can be thought of as a 2D grid of pixels. Convolutional networks have been\u00a0tremendously successful in practical applications. The name \u201cconvolutional neural\u00a0network\u201d indicates that the network employs a mathematical operation called\u00a0convolution. Convolution is a specialized kind of linear operation. Convolutional\u00a0networks are simply neural networks that use convolution in place of\u00a0general matrix multiplication in at least one of their layers.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3426",
    "text": "In this chapter, we will first describe what convolution is. Next, we will explain the motivation behind using convolution in a neural network. We will\u00a0then describe an operation called pooling, which almost all convolutional networks\u00a0employ. Usually, the operation used in a convolutional neural network does not\u00a0correspond precisely to the definition of convolution as used in other fields such\u00a0as engineering or pure mathematics. We will describe several variants on the\u00a0convolution function that are widely used in practice for neural networks. We\u00a0will also show how convolution may be applied to many kinds of data, with\u00a0different numbers of dimensions. We then discuss means of making convolution\u00a0more efficient. Convolutional networks stand out as an example of neuroscientific\u00a0principles influencing deep learning. We will discuss these neuroscientific principles,\u00a0then conclude with comments about the role convolutional networks have played\u00a0in the history of deep learning. One topic this chapter does not address is how to\u00a0choose the architecture of your convolutional network. The goal of this chapter is\u00a0to describe the kinds of tools that convolutional networks provide, while Chapter 11\u00a0describes general guidelines for choosing which tools to use in which circumstances.\u00a0Research into convolutional network architectures proceeds so rapidly that a new\u00a0best architecture for a given benchmark is announced every few weeks to months,\u00a0rendering it impractical to describe the best architecture in print. However, the\u00a0best architectures have consistently been composed of the building blocks described\u00a0here.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3427",
    "text": "In its most general form, convolution is an operation on two functions of a realvalued argument. To motivate the definition of convolution, we start with examples of two functions we might use.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3428",
    "text": "Suppose we are tracking the location of a spaceship with a laser sensor. Our laser sensor provides a single output x(t), the position of the spaceship at time\u00a0t. Both x and t are real-valued, i.e., we can get a different reading from the laser\u00a0sensor at any instant in time.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3429",
    "text": "Now suppose that our laser sensor is somewhat noisy. To obtain a less noisy estimate of the spaceship\u2019s position, we would like to average together several\u00a0measurements. Of course, more recent measurements are more relevant, so we will\u00a0want this to be a weighted average that gives more weight to recent measurements.\u00a0We can do this with a weighting function w(a), where a is the age of a measurement.\u00a0If we apply such a weighted average operation at every moment, we obtain a new\u00a0function s providing a smoothed estimate of the position of the spaceship:",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3430",
    "text": "-9.1",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3431",
    "text": "s(t) = /x(a)w(t - a)da",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3432",
    "text": "This operation is called convolution. The convolution operation is typically denoted with an asterisk:",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3433",
    "text": "s(t) = (x * w)(t) \u00a0\u00a0\u00a0(9.2)",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3434",
    "text": "In our example, w needs to be a valid probability density function, or the output is not a weighted average. Also, w needs to be 0 for all negative arguments,\u00a0or it will look into the future, which is presumably beyond our capabilities. These\u00a0limitations are particular to our example though. In general, convolution is defined\u00a0for any functions for which the above integral is defined, and may be used for other\u00a0purposes besides taking weighted averages.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3435",
    "text": "In convolutional network terminology, the first argument (in this example, the function x )to the convolution is often referred to as the input and the second",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3436",
    "text": "argument (in this example, the function w) as the kernel. The output is sometimes referred to as the feature map.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3437",
    "text": "In our example, the idea of a laser sensor that can provide measurements at every instant in time is not realistic. Usually, when we work with data on a\u00a0computer, time will be discretized, and our sensor will provide data at regular\u00a0intervals. In our example, it might be more realistic to assume that our laser\u00a0provides a measurement once per second. The time index t can then take on only\u00a0integer values. If we now assume that x and w are defined only on integer t, we\u00a0can define the discrete convolution:",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3438",
    "text": "s(t) = (x * w)(t) = \u00a0\u00a0\u00a0x(a)w(t \u2014 a)\u00a0\u00a0\u00a0\u00a0(9.3)",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3439",
    "text": "a=\u2014oo",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3440",
    "text": "In machine learning applications, the input is usually a multidimensional array of data and the kernel is usually a multidimensional array of parameters that are\u00a0adapted by the learning algorithm. We will refer to these multidimensional arrays\u00a0as tensors. Because each element of the input and kernel must be explicitly stored\u00a0separately, we usually assume that these functions are zero everywhere but the\u00a0finite set of points for which we store the values. This means that in practice we\u00a0can implement the infinite summation as a summation over a finite number of\u00a0array elements.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3441",
    "text": "Finally, we often use convolutions over more than one axis at a time. For example, if we use a two-dimensional image I as our input, we probably also want\u00a0to use a two-dimensional kernel K:",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3442",
    "text": "S(i,j) = (I * K)(i,j) = \u00a0\u00a0\u00a01(m,n)K(i \u2014 m,j \u2014 n).\u00a0\u00a0\u00a0\u00a0(9.4)",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3443",
    "text": "m n",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3444",
    "text": "Convolution is commutative, meaning we can equivalently write:",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3445",
    "text": "S(i, j) = (K * I)(i, j) = \u00a0\u00a0\u00a0I(i \u2014 m, j \u2014 n)K(m, n).\u00a0\u00a0\u00a0\u00a0(9.5)",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3446",
    "text": "mn",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3447",
    "text": "Usually the latter formula is more straightforward to implement in a machine learning library, because there is less variation in the range of valid values of m\u00a0and n.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3448",
    "text": "The commutative property of convolution arises because we have flipped the kernel relative to the input, in the sense that as m increases, the index into the\u00a0input increases, but the index into the kernel decreases. The only reason to flip\u00a0the kernel is to obtain the commutative property. While the commutative property\u00a0is useful for writing proofs, it is not usually an important property of a neural\u00a0network implementation. Instead, many neural network libraries implement a\u00a0related function called the cross-correlation, which is the same as convolution but\u00a0without flipping the kernel:",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3449",
    "text": "S(i,j) = (I * K)(i,j) = ^2^2 I+ m\u2019 j + n)K(m,n). \u00a0\u00a0\u00a0(9.6)",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3450",
    "text": "m n",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3451",
    "text": "Many machine learning libraries implement cross-correlation but call it convolution. In this text we will follow this convention of calling both operations convolution,\u00a0and specify whether we mean to flip the kernel or not in contexts where kernel\u00a0flipping is relevant. In the context of machine learning, the learning algorithm will\u00a0learn the appropriate values of the kernel in the appropriate place, so an algorithm\u00a0based on convolution with kernel flipping will learn a kernel that is flipped relative\u00a0to the kernel learned by an algorithm without the flipping. It is also rare for\u00a0convolution to be used alone in machine learning; instead convolution is used\u00a0simultaneously with other functions, and the combination of these functions does\u00a0not commute regardless of whether the convolution operation flips its kernel or\u00a0not.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3452",
    "text": "See Fig. 9.1 for an example of convolution (without kernel flipping) applied to a 2-D tensor.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3453",
    "text": "Discrete convolution can be viewed as multiplication by a matrix. However, the matrix has several entries constrained to be equal to other entries. For example,\u00a0for univariate discrete convolution, each row of the matrix is constrained to be\u00a0equal to the row above shifted by one element. This is known as a Toeplitz matrix.\u00a0In two dimensions, a doubly block circulant matrix corresponds to convolution.\u00a0In addition to these constraints that several elements be equal to each other,\u00a0convolution usually corresponds to a very sparse matrix (a matrix whose entries are\u00a0mostly equal to zero). This is because the kernel is usually much smaller than the\u00a0input image. Any neural network algorithm that works with matrix multiplication\u00a0and does not depend on specific properties of the matrix structure should work\u00a0with convolution, without requiring any further changes to the neural network.\u00a0Typical convolutional neural networks do make use of further specializations in\u00a0order to deal with large inputs efficiently, but these are not strictly necessary from\u00a0a theoretical perspective.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3454",
    "text": "Input",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3455",
    "text": "a",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3456",
    "text": "b",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3457",
    "text": "c",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3458",
    "text": "d",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3459",
    "text": "e",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3460",
    "text": "j",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3461",
    "text": "g",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3462",
    "text": "h",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3463",
    "text": "",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3464",
    "text": "",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3465",
    "text": "k",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3466",
    "text": "1",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3467",
    "text": "Output",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3468",
    "text": "Kernel",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3469",
    "text": "w",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3470",
    "text": "x",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3471",
    "text": "y",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3472",
    "text": "z",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3473",
    "text": "aw + bx +",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3474",
    "text": "ey + fz",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3475",
    "text": "bw + cx +",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3476",
    "text": "fy + 9z",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3477",
    "text": "cw + dx + gy + hz",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3478",
    "text": "ew + fx + iy + jz",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3479",
    "text": "fw + gx + jy + kz",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3480",
    "text": "gw",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3481",
    "text": "+",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3482",
    "text": "hx +",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3483",
    "text": "ky",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3484",
    "text": "+",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3485",
    "text": "Iz",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3486",
    "text": "Figure 9.1: An example of 2-D convolution without kernel-flipping. In this case we restrict the output to only positions where the kernel lies entirely within the image, called \u201cvalid\u201d\u00a0convolution in some contexts. We draw boxes with arrows to indicate how the upper-left\u00a0element of the output tensor is formed by applying the kernel to the corresponding\u00a0upper-left region of the input tensor.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3487",
    "text": "Convolution leverages three important ideas that can help improve a machine learning system: sparse interactions, parameter sharing and equivariant representations. Moreover, convolution provides a means for working with inputs of variable\u00a0size. We now describe each of these ideas in turn.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3488",
    "text": "Traditional neural network layers use matrix multiplication by a matrix of parameters with a separate parameter describing the interaction between each\u00a0input unit and each output unit. This means every output unit interacts with every\u00a0input unit. Convolutional networks, however, typically have sparse interactions\u00a0(also referred to as sparse connectivity or sparse weights). This is accomplished by\u00a0making the kernel smaller than the input. For example, when processing an image,\u00a0the input image might have thousands or millions of pixels, but we can detect small,\u00a0meaningful features such as edges with kernels that occupy only tens or hundreds of\u00a0pixels. This means that we need to store fewer parameters, which both reduces the\u00a0memory requirements of the model and improves its statistical efficiency. It also\u00a0means that computing the output requires fewer operations. These improvements\u00a0in efficiency are usually quite large. If there are m inputs and n outputs, then\u00a0matrix multiplication requires m x n parameters and the algorithms used in practice\u00a0have O(m x n) runtime (per example). If we limit the number of connections\u00a0each output may have to k, then the sparsely connected approach requires only\u00a0k x n parameters and O(k x n) runtime. For many practical applications, it is\u00a0possible to obtain good performance on the machine learning task while keeping\u00a0k several orders of magnitude smaller than m. For graphical demonstrations of\u00a0sparse connectivity, see Fig. 9.2 and Fig. 9.3. In a deep convolutional network,\u00a0units in the deeper layers may indirectly interact with a larger portion of the input,\u00a0as shown in Fig. 9.4. This allows the network to efficiently describe complicated\u00a0interactions between many variables by constructing such interactions from simple\u00a0building blocks that each describe only sparse interactions.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3489",
    "text": "Parameter sharing refers to using the same parameter for more than one function in a model. In a traditional neural net, each element of the weight matrix\u00a0is used exactly once when computing the output of a layer. It is multiplied by one\u00a0element of the input and then never revisited. As a synonym for parameter sharing,\u00a0one can say that a network has tied weights, because the value of the weight applied\u00a0to one input is tied to the value of a weight applied elsewhere. In a convolutional\u00a0neural net, each member of the kernel is used at every position of the input (except\u00a0perhaps some of the boundary pixels, depending on the design decisions regarding\u00a0the boundary). The parameter sharing used by the convolution operation means\u00a0that rather than learning a separate set of parameters for every location, we learn",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3490",
    "text": "Figure 9.2: Sparse connectivity, viewed from below: We highlight one input unit,x3, and also highlight the output units in s that are affected by this unit. (Top) When s is formed\u00a0by convolution with a kernel of width 3, only three outputs are affected by x. (Bottom)\u00a0When s is formed by matrix multiplication, connectivity is no longer sparse, so all of the\u00a0outputs are affected by x3.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3491",
    "text": "Figure 9.5: Parameter sharing: Black arrows indicate the connections that use a particular parameter in two different models. (Top) The black arrows indicate uses of the central\u00a0element of a 3-element kernel in a convolutional model. Due to parameter sharing, this\u00a0single parameter is used at all input locations. (Bottom) The single black arrow indicates\u00a0the use of the central element of the weight matrix in a fully connected model. This model\u00a0has no parameter sharing so the parameter is used only once.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3492",
    "text": "only one set. This does not affect the runtime of forward propagation\u2014it is still O(k x n)\u2014but it does further reduce the storage requirements of the model to\u00a0k parameters. Recall that k is usually several orders of magnitude less than m.\u00a0Since m and n are usually roughly the same size, k is practically insignificant\u00a0compared to m x n. Convolution is thus dramatically more efficient than dense\u00a0matrix multiplication in terms of the memory requirements and statistical efficiency.\u00a0For a graphical depiction of how parameter sharing works, see Fig. 9.5.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3493",
    "text": "As an example of both of these first two principles in action, Fig. 9.6 shows how sparse connectivity and parameter sharing can dramatically improve the efficiency\u00a0of a linear function for detecting edges in an image.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3494",
    "text": "In the case of convolution, the particular form of parameter sharing causes the layer to have a property called equivariance to translation. To say a function is\u00a0equivariant means that if the input changes, the output changes in the same way.\u00a0Specifically, a function f(x) is equivariant to a function g if f (g(x)) = g(f(x)).\u00a0In the case of convolution, if we let g be any function that translates the input,\u00a0i.e., shifts it, then the convolution function is equivariant to g. For example, let I\u00a0be a function giving image brightness at integer coordinates. Let g be a function\u00a0mapping one image function to another image function, such that I' = g (I) is\u00a0the image function with I'(x,y) = I(x \u2014 1,y). This shifts every pixel of I one\u00a0unit to the right. If we apply this transformation to I, then apply convolution,\u00a0the result will be the same as if we applied convolution to I', then applied the\u00a0transformation g to the output. When processing time series data, this means\u00a0that convolution produces a sort of timeline that shows when different features\u00a0appear in the input. If we move an event later in time in the input, the exact\u00a0same representation of it will appear in the output, just later in time. Similarly\u00a0with images, convolution creates a 2-D map of where certain features appear in\u00a0the input. If we move the object in the input, its representation will move the\u00a0same amount in the output. This is useful for when we know that some function\u00a0of a small number of neighboring pixels is useful when applied to multiple input\u00a0locations. For example, when processing images, it is useful to detect edges in\u00a0the first layer of a convolutional network. The same edges appear more or less\u00a0everywhere in the image, so it is practical to share parameters across the entire\u00a0image. In some cases, we may not wish to share parameters across the entire\u00a0image. For example, if we are processing images that are cropped to be centered\u00a0on an individual\u2019s face, we probably want to extract different features at different\u00a0locations\u2014the part of the network processing the top of the face needs to look for\u00a0eyebrows, while the part of the network processing the bottom of the face needs to\u00a0look for a chin.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3495",
    "text": "Convolution is not naturally equivariant to some other transformations, such as changes in the scale or rotation of an image. Other mechanisms are necessary\u00a0for handling these kinds of transformations.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3496",
    "text": "Finally, some kinds of data cannot be processed by neural networks defined by matrix multiplication with a fixed-shape matrix. Convolution enables processing\u00a0of some of these kinds of data. We discuss this further in Sec. 9.7.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3497",
    "text": "A typical layer of a convolutional network consists of three stages (see Fig. 9.7). In the first stage, the layer performs several convolutions in parallel to produce a set\u00a0of linear activations. In the second stage, each linear activation is run through a\u00a0nonlinear activation function, such as the rectified linear activation function. This\u00a0stage is sometimes called the detector stage. In the third stage, we use a pooling\u00a0function to modify the output of the layer further.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3498",
    "text": "A pooling function replaces the output of the net at a certain location with a summary statistic of the nearby outputs. For example, the max pooling (Zhou\u00a0and Chellappa, 1988) operation reports the maximum output within a rectangular",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3499",
    "text": "Figure 9.6: Efficiency of edge detection. The image on the right was formed by taking each pixel in the original image and subtracting the value of its neighboring pixel on the\u00a0left. This shows the strength of all of the vertically oriented edges in the input image,\u00a0which can be a useful operation for object detection. Both images are 280 pixels tall.\u00a0The input image is 320 pixels wide while the output image is 319 pixels wide. This\u00a0transformation can be described by a convolution kernel containing two elements, and\u00a0requires 319 x 280 x 3 = 267, 960 floating point operations (two multiplications and\u00a0one addition per output pixel) to compute using convolution. To describe the same\u00a0transformation with a matrix multiplication would take 320 x 280 x 319 x 280, or over\u00a0eight billion, entries in the matrix, making convolution four billion times more efficient for\u00a0representing this transformation. The straightforward matrix multiplication algorithm\u00a0performs over sixteen billion floating point operations, making convolution roughly 60,000\u00a0times more efficient computationally. Of course, most of the entries of the matrix would be\u00a0zero. If we stored only the nonzero entries of the matrix, then both matrix multiplication\u00a0and convolution would require the same number of floating point operations to compute.\u00a0The matrix would still need to contain 2 x 319 x 280 = 178, 640 entries. Convolution\u00a0is an extremely efficient way of describing transformations that apply the same linear\u00a0transformation of a small, local region across the entire input. (Photo credit: Paula\u00a0Goodfellow)",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3500",
    "text": "Figure 9.3: Sparse connectivity, viewed from above: We highlight one output unit,s3, and also highlight the input units in x that affect this unit. These units are known as the\u00a0receptive field of s3. (Top) When s is formed by convolution with a kernel of width 3, only\u00a0three inputs affect S3. (Bottom) When s is formed by matrix multiplication, connectivity\u00a0is no longer sparse, so all of the inputs affect S3.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3501",
    "text": "Figure 9.4: The receptive field of the units in the deeper layers of a convolutional network is larger than the receptive field of the units in the shallow layers. This effect increases if\u00a0the network includes architectural features like strided convolution (Fig. 9.12) or pooling\u00a0(Sec. 9.3). This means that even though direct connections in a convolutional net are very\u00a0sparse, units in the deeper layers can be indirectly connected to all or most of the input\u00a0image.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3502",
    "text": "Figure 9.7: The components of a typical convolutional neural network layer. There are two commonly used sets of terminology for describing these layers. (Left) In this terminology,\u00a0the convolutional net is viewed as a small number of relatively complex layers, with each\u00a0layer having many \u201cstages.\u201d In this terminology, there is a one-to-one mapping between\u00a0kernel tensors and network layers. In this book we generally use this terminology. (Right)\u00a0In this terminology, the convolutional net is viewed as a larger number of simple layers;\u00a0every step of processing is regarded as a layer in its own right. This means that not every\u00a0\u201clayer\u201d has parameters.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3503",
    "text": "neighborhood. Other popular pooling functions include the average of a rectangular neighborhood, the L2 norm of a rectangular neighborhood, or a weighted average\u00a0based on the distance from the central pixel.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3504",
    "text": "In all cases, pooling helps to make the representation become approximately invariant to small translations of the input. Invariance to translation means that if\u00a0we translate the input by a small amount, the values of most of the pooled outputs\u00a0do not change. See Fig. 9.8 for an example of how this works. Invariance to\u00a0local translation can be a very useful property if we care more about\u00a0whether some feature is present than exactly where it is. For example,\u00a0when determining whether an image contains a face, we need not know the location\u00a0of the eyes with pixel-perfect accuracy, we just need to know that there is an eye on\u00a0the left side of the face and an eye on the right side of the face. In other contexts,\u00a0it is more important to preserve the location of a feature. For example, if we want\u00a0to find a corner defined by two edges meeting at a specific orientation, we need to\u00a0preserve the location of the edges well enough to test whether they meet.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3505",
    "text": "The use of pooling can be viewed as adding an infinitely strong prior that the function the layer learns must be invariant to small translations. When this\u00a0assumption is correct, it can greatly improve the statistical efficiency of the network.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3506",
    "text": "Pooling over spatial regions produces invariance to translation, but if we pool over the outputs of separately parametrized convolutions, the features can learn\u00a0which transformations to become invariant to (see Fig. 9.9).",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3507",
    "text": "Because pooling summarizes the responses over a whole neighborhood, it is possible to use fewer pooling units than detector units, by reporting summary\u00a0statistics for pooling regions spaced k pixels apart rather than 1 pixel apart. See\u00a0Fig. 9.10 for an example. This improves the computational efficiency of the network\u00a0because the next layer has roughly k times fewer inputs to process. When the\u00a0number of parameters in the next layer is a function of its input size (such as\u00a0when the next layer is fully connected and based on matrix multiplication) this\u00a0reduction in the input size can also result in improved statistical efficiency and\u00a0reduced memory requirements for storing the parameters.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3508",
    "text": "For many tasks, pooling is essential for handling inputs of varying size. For example, if we want to classify images of variable size, the input to the classification\u00a0layer must have a fixed size. This is usually accomplished by varying the size of an\u00a0offset between pooling regions so that the classification layer always receives the\u00a0same number of summary statistics regardless of the input size. For example, the\u00a0final pooling layer of the network may be defined to output four sets of summary\u00a0statistics, one for each quadrant of an image, regardless of the image size.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3509",
    "text": "Some theoretical work gives guidance as to which kinds of pooling one should",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3510",
    "text": "POOLING STAGE",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3511",
    "text": "POOLING STAGE",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3512",
    "text": "Figure 9.8: Max pooling introduces invariance. (Top) A view of the middle of the output of a convolutional layer. The bottom row shows outputs of the nonlinearity. The top\u00a0row shows the outputs of max pooling, with a stride of one pixel between pooling regions\u00a0and a pooling region width of three pixels. (Bottom) A view of the same network, after\u00a0the input has been shifted to the right by one pixel. Every value in the bottom row has\u00a0changed, but only half of the values in the top row have changed, because the max pooling\u00a0units are only sensitive to the maximum value in the neighborhood, not its exact location.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3513",
    "text": "Figure 9.9: Example of learned invariances: A pooling unit that pools over multiple features that are learned with separate parameters can learn to be invariant to transformations of\u00a0the input. Here we show how a set of three learned filters and a max pooling unit can learn\u00a0to become invariant to rotation. All three filters are intended to detect a hand-written 5.\u00a0Each filter attempts to match a slightly different orientation of the 5. When a 5 appears in\u00a0the input, the corresponding filter will match it and cause a large activation in a detector\u00a0unit. The max pooling unit then has a large activation regardless of which pooling unit\u00a0was activated. We show here how the network processes two different inputs, resulting\u00a0in two different detector units being activated. The effect on the pooling unit is roughly\u00a0the same either way. This principle is leveraged by maxout networks (Goodfellow et al.,\u00a02013a) and other convolutional networks. Max pooling over spatial positions is naturally\u00a0invariant to translation; this multi-channel approach is only necessary for learning other\u00a0transformations.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3514",
    "text": "Figure 9.10: Pooling with downsampling. Here we use max-pooling with a pool width of three and a stride between pools of two. This reduces the representation size by a factor\u00a0of two, which reduces the computational and statistical burden on the next layer. Note\u00a0that the rightmost pooling region has a smaller size, but must be included if we do not\u00a0want to ignore some of the detector units.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3515",
    "text": "use in various situations (Boureau et al2010). It is also possible to dynamically pool features together, for example, by running a clustering algorithm on the\u00a0locations of interesting features (Boureau et al., 2011). This approach yields a\u00a0different set of pooling regions for each image. Another approach is to learn a\u00a0single pooling structure that is then applied to all images (Jia et al., 2012).",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3516",
    "text": "Pooling can complicate some kinds of neural network architectures that use top-down information, such as Boltzmann machines and autoencoders. These\u00a0issues will be discussed further when we present these types of networks in Part\u00a0III. Pooling in convolutional Boltzmann machines is presented in Sec. 20.6. The\u00a0inverse-like operations on pooling units needed in some differentiable networks will\u00a0be covered in Sec. 20.10.6.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3517",
    "text": "Some examples of complete convolutional network architectures for classification using convolution and pooling are shown in Fig. 9.11.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3518",
    "text": "Recall the concept of a prior probability distribution from Sec. 5.2. This is a probability distribution over the parameters of a model that encodes our beliefs\u00a0about what models are reasonable, before we have seen any data.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3519",
    "text": "Priors can be considered weak or strong depending on how concentrated the probability density in the prior is. A weak prior is a prior distribution with high\u00a0entropy, such as a Gaussian distribution with high variance. Such a prior allows\u00a0the data to move the parameters more or less freely. A strong prior has very low\u00a0entropy, such as a Gaussian distribution with low variance. Such a prior plays a\u00a0more active role in determining where the parameters end up.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3520",
    "text": "An infinitely strong prior places zero probability on some parameters and says that these parameter values are completely forbidden, regardless of how much\u00a0support the data gives to those values.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3521",
    "text": "We can imagine a convolutional net as being similar to a fully connected net, but with an infinitely strong prior over its weights. This infinitely strong prior\u00a0says that the weights for one hidden unit must be identical to the weights of its\u00a0neighbor, but shifted in space. The prior also says that the weights must be zero,\u00a0except for in the small, spatially contiguous receptive field assigned to that hidden\u00a0unit. Overall, we can think of the use of convolution as introducing an infinitely\u00a0strong prior probability distribution over the parameters of a layer. This prior\u00a0says that the function the layer should learn contains only local interactions and is",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3522",
    "text": "Figure 9.11: Examples of architectures for classification with convolutional networks. The specific strides and depths used in this figure are not advisable for real use; they are\u00a0designed to be very shallow in order to fit onto the page. Real convolutional networks\u00a0also often involve significant amounts of branching, unlike the chain structures used\u00a0here for simplicity. (Left) A convolutional network that processes a fixed image size.\u00a0After alternating between convolution and pooling for a few layers, the tensor for the\u00a0convolutional feature map is reshaped to flatten out the spatial dimensions. The rest\u00a0of the network is an ordinary feedforward network classifier, as described in Chapter 6.\u00a0(Center) A convolutional network that processes a variable-sized image, but still maintains\u00a0a fully connected section. This network uses a pooling operation with variably-sized pools\u00a0but a fixed number of pools, in order to provide a fixed-size vector of 576 units to the\u00a0fully connected portion of the network. (Right) A convolutional network that does not\u00a0have any fully connected weight layer. Instead, the last convolutional layer outputs one\u00a0feature map per class. The model presumably learns a map of how likely each class is to\u00a0occur at each spatial location. Averaging a feature map down to a single value provides\u00a0the argument to the softmax classifier at the top.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3523",
    "text": "equivariant to translation. Likewise, the use of pooling is an infinitely strong prior that each unit should be invariant to small translations.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3524",
    "text": "Of course, implementing a convolutional net as a fully connected net with an infinitely strong prior would be extremely computationally wasteful. But thinking\u00a0of a convolutional net as a fully connected net with an infinitely strong prior can\u00a0give us some insights into how convolutional nets work.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3525",
    "text": "One key insight is that convolution and pooling can cause underfitting. Like any prior, convolution and pooling are only useful when the assumptions made\u00a0by the prior are reasonably accurate. If a task relies on preserving precise spatial\u00a0information, then using pooling on all features can increase the training error.\u00a0Some convolutional network architectures (Szegedy et al., 2014a) are designed to\u00a0use pooling on some channels but not on other channels, in order to get both\u00a0highly invariant features and features that will not underfit when the translation\u00a0invariance prior is incorrect. When a task involves incorporating information from\u00a0very distant locations in the input, then the prior imposed by convolution may be\u00a0inappropriate.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3526",
    "text": "Another key insight from this view is that we should only compare convolutional models to other convolutional models in benchmarks of statistical learning performance. Models that do not use convolution would be able to learn even if\u00a0we permuted all of the pixels in the image. For many image datasets, there are\u00a0separate benchmarks for models that are permutation invariant and must discover\u00a0the concept of topology via learning, and models that have the knowledge of spatial\u00a0relationships hard-coded into them by their designer.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3527",
    "text": "When discussing convolution in the context of neural networks, we usually do not refer exactly to the standard discrete convolution operation as it is usually\u00a0understood in the mathematical literature. The functions used in practice differ\u00a0slightly. Here we describe these differences in detail, and highlight some useful\u00a0properties of the functions used in neural networks.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3528",
    "text": "First, when we refer to convolution in the context of neural networks, we usually actually mean an operation that consists of many applications of convolution in\u00a0parallel. This is because convolution with a single kernel can only extract one kind\u00a0of feature, albeit at many spatial locations. Usually we want each layer of our\u00a0network to extract many kinds of features, at many locations.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3529",
    "text": "Additionally, the input is usually not just a grid of real values. Rather, it is a grid of vector-valued observations. For example, a color image has a red, green\u00a0and blue intensity at each pixel. In a multilayer convolutional network, the input\u00a0to the second layer is the output of the first layer, which usually has the output\u00a0of many different convolutions at each position. When working with images, we\u00a0usually think of the input and output of the convolution as being 3-D tensors, with\u00a0one index into the different channels and two indices into the spatial coordinates\u00a0of each channel. Software implementations usually work in batch mode, so they\u00a0will actually use 4-D tensors, with the fourth axis indexing different examples in\u00a0the batch, but we will omit the batch axis in our description here for simplicity.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3530",
    "text": "Because convolutional networks usually use multi-channel convolution, the linear operations they are based on are not guaranteed to be commutative, even if\u00a0kernel-flipping is used. These multi-channel operations are only commutative if\u00a0each operation has the same number of output channels as input channels.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3531",
    "text": "Assume we have a 4-D kernel tensor K with element Ki,j,k,l giving the connection strength between a unit in channel i of the output and a unit in channel j of the\u00a0input, with an offset of k rows and l columns between the output unit and the\u00a0input unit. Assume our input consists of observed data V with element Vi,j,k giving\u00a0the value of the input unit within channel i at row j and column k. Assume our\u00a0output consists of Z with the same format as V. If Z is produced by convolving K\u00a0across V without flipping K, then",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3532",
    "text": "Zi,j,k \u2014 ^ ' Vlj+m\u2014l,k+n\u2014lKi,l,m,n \u00a0\u00a0\u00a0(9.7)",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3533",
    "text": "l,m,n",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3534",
    "text": "where the summation over l, m and n is over all values for which the tensor indexing operations inside the summation is valid. In linear algebra notation, we index into\u00a0arrays using a 1 for the first entry. This necessitates the \u2014 1 in the above formula.\u00a0Programming languages such as C and Python index starting from 0, rendering\u00a0the above expression even simpler.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3535",
    "text": "We may want to skip over some positions of the kernel in order to reduce the computational cost (at the expense of not extracting our features as finely). We\u00a0can think of this as downsampling the output of the full convolution function. If\u00a0we want to sample only every s pixels in each direction in the output, then we can\u00a0define a downsampled convolution function c such that",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3536",
    "text": "Zi,j,k \u00a0\u00a0\u00a0c(K, V, s)i,j,k\u00a0\u00a0\u00a0\u00a0^ ' \\_Vl,(j-l)xs+m,(k \u2014 l)xs+nKi,l,m,n '\u00a0\u00a0\u00a0\u00a0(9.8)",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3537",
    "text": "l,m,n",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3538",
    "text": "We refer to s as the stride of this downsampled convolution. It is also possible to define a separate stride for each direction of motion. See Fig. 9.12 for an\u00a0illustration.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3539",
    "text": "Figure 9.12: Convolution with a stride. In this example, we use a stride of two. (Top) Convolution with a stride length of two implemented in a single operation. (Bottom)\u00a0Convolution with a stride greater than one pixel is mathematically equivalent to convolution\u00a0with unit stride followed by downsampling. Obviously, the two-step approach involving\u00a0downsampling is computationally wasteful, because it computes many values that are\u00a0then discarded.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3540",
    "text": "One essential feature of any convolutional network implementation is the ability to implicitly zero-pad the input V in order to make it wider. Without this feature,\u00a0the width of the representation shrinks by one pixel less than the kernel width\u00a0at each layer. Zero padding the input allows us to control the kernel width and\u00a0the size of the output independently. Without zero padding, we are forced to\u00a0choose between shrinking the spatial extent of the network rapidly and using small\u00a0kernels\u2014both scenarios that significantly limit the expressive power of the network.\u00a0See Fig. 9.13 for an example.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3541",
    "text": "Three special cases of the zero-padding setting are worth mentioning. One is the extreme case in which no zero-padding is used whatsoever, and the convolution\u00a0kernel is only allowed to visit positions where the entire kernel is contained entirely\u00a0within the image. In MATLAB terminology, this is called valid convolution. In\u00a0this case, all pixels in the output are a function of the same number of pixels in\u00a0the input, so the behavior of an output pixel is somewhat more regular. However,\u00a0the size of the output shrinks at each layer. If the input image has width m and\u00a0the kernel has width k, the output will be of width m \u2014 k + 1. The rate of this\u00a0shrinkage can be dramatic if the kernels used are large. Since the shrinkage is\u00a0greater than 0, it limits the number of convolutional layers that can be included\u00a0in the network. As layers are added, the spatial dimension of the network will\u00a0eventually drop to 1 x 1, at which point additional layers cannot meaningfully\u00a0be considered convolutional. Another special case of the zero-padding setting is\u00a0when just enough zero-padding is added to keep the size of the output equal to the\u00a0size of the input. MATLAB calls this same convolution. In this case, the network\u00a0can contain as many convolutional layers as the available hardware can support,\u00a0since the operation of convolution does not modify the architectural possibilities\u00a0available to the next layer. However, the input pixels near the border influence\u00a0fewer output pixels than the input pixels near the center. This can make the\u00a0border pixels somewhat underrepresented in the model. This motivates the other\u00a0extreme case, which MATLAB refers to as full convolution, in which enough zeroes\u00a0are added for every pixel to be visited k times in each direction, resulting in an\u00a0output image of width m + k \u2014 1. In this case, the output pixels near the border\u00a0are a function of fewer pixels than the output pixels near the center. This can\u00a0make it difficult to learn a single kernel that performs well at all positions in\u00a0the convolutional feature map. Usually the optimal amount of zero padding (in\u00a0terms of test set classification accuracy) lies somewhere between \u201cvalid\u201d and \u201csame\u201d\u00a0convolution.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3542",
    "text": "In some cases, we do not actually want to use convolution, but rather locally connected layers (LeCun, 1986, 1989). In this case, the adjacency matrix in the\u00a0graph of our MLP is the same, but every connection has its own weight, specified",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3543",
    "text": "Figure 9.13: The effect of zero padding on network size: Consider a convolutional network with a kernel of width six at every layer. In this example, we do not use any pooling, so\u00a0only the convolution operation itself shrinks the network size. (Top) In this convolutional\u00a0network, we do not use any implicit zero padding. This causes the representation to\u00a0shrink by five pixels at each layer. Starting from an input of sixteen pixels, we are only\u00a0able to have three convolutional layers, and the last layer does not ever move the kernel,\u00a0so arguably only two of the layers are truly convolutional. The rate of shrinking can\u00a0be mitigated by using smaller kernels, but smaller kernels are less expressive and some\u00a0shrinking is inevitable in this kind of architecture. (Bottom) By adding five implicit zeroes\u00a0to each layer, we prevent the representation from shrinking with depth. This allows us to\u00a0make an arbitrarily deep convolutional network.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3544",
    "text": "by a 6-D tensor W. The indices into W are respectively: i, the output channel, j, the output row, k, the output column, l, the input channel, m, the row offset\u00a0within the input, and n, the column offset within the input. The linear part of a\u00a0locally connected layer is then given by",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3545",
    "text": "Zi,j,k ~ ^ ^ [Vl,j+m- 1,k+n- 1'wi,j,k,l,m,n] \u2022 \u00a0\u00a0\u00a0(99\u05d9)",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3546",
    "text": "l,m,n",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3547",
    "text": "This is sometimes also called unshared convolution, because it is a similar operation to discrete convolution with a small kernel, but without sharing parameters across\u00a0locations. Fig. 9.14 compares local connections, convolution, and full connections.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3548",
    "text": "Locally connected layers are useful when we know that each feature should be a function of a small part of space, but there is no reason to think that the same\u00a0feature should occur across all of space. For example, if we want to tell if an image\u00a0is a picture of a face, we only need to look for the mouth in the bottom half of the\u00a0image.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3549",
    "text": "It can also be useful to make versions of convolution or locally connected layers in which the connectivity is further restricted, for example to constrain that each\u00a0output channel i be a function of only a subset of the input channels l. A common\u00a0way to do this is to make the first m output channels connect to only the first\u00a0n input channels, the second m output channels connect to only the second n\u00a0input channels, and so on. See Fig. 9.15 for an example. Modeling interactions\u00a0between few channels allows the network to have fewer parameters in order to\u00a0reduce memory consumption and increase statistical efficiency, and also reduces\u00a0the amount of computation needed to perform forward and back-propagation. It\u00a0accomplishes these goals without reducing the number of hidden units.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3550",
    "text": "Tiled convolution (Gregor and LeCun, 2010a; Le et al., 2010) offers a compromise between a convolutional layer and a locally connected layer. Rather than learning\u00a0a separate set of weights at every spatial location, we learn a set of kernels that\u00a0we rotate through as we move through space. This means that immediately\u00a0neighboring locations will have different filters, like in a locally connected layer, but\u00a0the memory requirements for storing the parameters will increase only by a factor\u00a0of the size of this set of kernels, rather than the size of the entire output feature\u00a0map. See Fig. 9.16 for a comparison of locally connected layers, tiled convolution,\u00a0and standard convolution.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3551",
    "text": "To define tiled convolution algebraically, let k be a 6-D tensor, where two of the dimensions correspond to different locations in the output map. Rather than\u00a0having a separate index for each location in the output map, output locations cycle\u00a0through a set of t different choices of kernel stack in each direction. If t is equal to",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3552",
    "text": "m",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3553",
    "text": "a;",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3554",
    "text": "<d",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3555",
    "text": "Pi",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3556",
    "text": "\u2022H",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3557",
    "text": "U",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3558",
    "text": "o",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3559",
    "text": "o",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3560",
    "text": "o",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3561",
    "text": "CD",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3562",
    "text": "Pi",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3563",
    "text": "fd",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3564",
    "text": "<d",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3565",
    "text": "o",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3566",
    "text": "Figure 9.15: A convolutional network with the first two output channels connected to only the first two input channels, and the second two output channels connected to only\u00a0the second two input channels.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3567",
    "text": "Figure 9.14: Comparison of local connections, convolution, and full connections.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3568",
    "text": "(Top) A locally connected layer with a patch size of two pixels. Each edge is labeled with a unique letter to show that each edge is associated with its own weight parameter.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3569",
    "text": "(Center) A convolutional layer with a kernel width of two pixels. This model has exactly the same connectivity as the locally connected layer. The difference lies not in which units\u00a0interact with each other, but in how the parameters are shared. The locally connected layer\u00a0has no parameter sharing. The convolutional layer uses the same two weights repeatedly\u00a0across the entire input, as indicated by the repetition of the letters labeling each edge.\u00a0(Bottom) A fully connected layer resembles a locally connected layer in the sense that\u00a0each edge has its own parameter (there are too many to label explicitly with letters in this\u00a0diagram). However, it does not have the restricted connectivity of the locally connected\u00a0layer.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3570",
    "text": "the output width, this is the same as a locally connected layer.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3571",
    "text": "Z,j,k = ^ ' Vl,j+m-1,k+n-1Ki,l,m,n,j%t+1,k%t+1 9.10) \u00a0\u00a0\u00a0\u05d9)",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3572",
    "text": "l,m,n",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3573",
    "text": "where % is the modulo operation, with t%t =0, (t + 1)%t = 1, etc. It is straightforward to generalize this equation to use a different tiling range for each\u00a0dimension.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3574",
    "text": "Both locally connected layers and tiled convolutional layers have an interesting interaction with max-pooling: the detector units of these layers are driven by\u00a0different filters. If these filters learn to detect different transformed versions of\u00a0the same underlying features, then the max-pooled units become invariant to the\u00a0learned transformation (see Fig. 9.9). Convolutional layers are hard-coded to be\u00a0invariant specifically to translation.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3575",
    "text": "Other operations besides convolution are usually necessary to implement a convolutional network. To perform learning, one must be able to compute the\u00a0gradient with respect to the kernel, given the gradient with respect to the outputs.\u00a0In some simple cases, this operation can be performed using the convolution\u00a0operation, but many cases of interest, including the case of stride greater than 1,\u00a0do not have this property.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3576",
    "text": "Recall that convolution is a linear operation and can thus be described as a matrix multiplication (if we first reshape the input tensor into a flat vector). The\u00a0matrix involved is a function of the convolution kernel. The matrix is sparse and\u00a0each element of the kernel is copied to several elements of the matrix. This view\u00a0helps us to derive some of the other operations needed to implement a convolutional\u00a0network.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3577",
    "text": "Multiplication by the transpose of the matrix defined by convolution is one such operation. This is the operation needed to back-propagate error derivatives\u00a0through a convolutional layer, so it is needed to train convolutional networks\u00a0that have more than one hidden layer. This same operation is also needed if we\u00a0wish to reconstruct the visible units from the hidden units (Simard et al., 1992).\u00a0Reconstructing the visible units is an operation commonly used in the models\u00a0described in Part III of this book, such as autoencoders, RBMs, and sparse coding.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3578",
    "text": "Transpose convolution is necessary to construct convolutional versions of those models. Like the kernel gradient operation, this input gradient operation can be\u00a0implemented using a convolution in some cases, but in the general case requires\u00a0a third operation to be implemented. Care must be taken to coordinate this\u00a0transpose operation with the forward propagation. The size of the output that the\u00a0transpose operation should return depends on the zero padding policy and stride of\u00a0the forward propagation operation, as well as the size of the forward propagation\u2019s\u00a0output map. In some cases, multiple sizes of input to forward propagation can\u00a0result in the same size of output map, so the transpose operation must be explicitly\u00a0told what the size of the original input was.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3579",
    "text": "These three operations\u2014convolution, backprop from output to weights, and backprop from output to inputs\u2014are sufficient to compute all of the gradients\u00a0needed to train any depth of feedforward convolutional network, as well as to train\u00a0convolutional networks with reconstruction functions based on the transpose of\u00a0convolution. See Goodfellow (2010) for a full derivation of the equations in the\u00a0fully general multi-dimensional, multi-example case. To give a sense of how these\u00a0equations work, we present the two dimensional, single example version here.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3580",
    "text": "Suppose we want to train a convolutional network that incorporates strided convolution of kernel stack K applied to multi-channel image V with stride s as\u00a0defined by c(K, V, s) as in Eq. 9.8. Suppose we want to minimize some loss function\u00a0J(V, K). During forward propagation, we will need to use c itself to output Z,\u00a0which is then propagated through the rest of the network and used to compute\u00a0the cost function J. During back-propagation, we will receive a tensor G such that",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3581",
    "text": "Gi,j,k ~ 3Z\u05be~k J(V, K)\u2022",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3582",
    "text": "To train the network, we need to compute the derivatives with respect to the weights in the kernel. To do so, we can use a function",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3583",
    "text": "g(G, V, s)i,j,k,l ~",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3584",
    "text": "d",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3585",
    "text": "J(V, K) ~ ^ ' Gi,m,n Vj,(m-1)xs+k,(n-1)xs+l\u2022 \u00a0\u00a0\u00a0(9.11)",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3586",
    "text": "If this layer is not the bottom layer of the network, we will need to compute the gradient with respect to V in order to back-propagate the error farther down.\u00a0To do so, we can use a function",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3587",
    "text": "h(K, G, s)i,j,k",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3588",
    "text": "d",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3589",
    "text": "dVi,j,k = \u00a3",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3590",
    "text": "-9.12",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3591",
    "text": "-9.13",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3592",
    "text": "l,m",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3593",
    "text": "s.t.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3594",
    "text": "n,p",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3595",
    "text": "s.t.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3596",
    "text": "(l-l)xs+m=j (n-l)xs+p=k",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3597",
    "text": "Autoencoder networks, described in Chapter 14, are feedforward networks trained to copy their input to their output. A simple example is the PCA algorithm,\u00a0that copies its input x to an approximate reconstruction r using the function\u00a0WT Wx. It is common for more general autoencoders to use multiplication\u00a0by the transpose of the weight matrix just as PCA does. To make such models\u00a0convolutional, we can use the function h to perform the transpose of the convolution\u00a0operation. Suppose we have hidden units H in the same format as Z and we define\u00a0a reconstruction",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3598",
    "text": "R = h(K, H,s). \u00a0\u00a0\u00a0(9.14)",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3599",
    "text": "In order to train the autoencoder, we will receive the gradient with respect to R as a tensor E. To train the decoder, we need to obtain the gradient with\u00a0respect to K. This is given by g (H, E , s). To train the encoder, we need to obtain\u00a0the gradient with respect to H. This is given by c(K, E, s). It is also possible to\u00a0differentiate through g using c and h, but these operations are not needed for the\u00a0back-propagation algorithm on any standard network architectures.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3600",
    "text": "Generally, we do not use only a linear operation in order to transform from the inputs to the outputs in a convolutional layer. We generally also add some\u00a0bias term to each output before applying the nonlinearity. This raises the question\u00a0of how to share parameters among the biases. For locally connected layers it is\u00a0natural to give each unit its own bias, and for tiled convolution, it is natural to\u00a0share the biases with the same tiling pattern as the kernels. For convolutional\u00a0layers, it is typical to have one bias per channel of the output and share it across\u00a0all locations within each convolution map. However, if the input is of known, fixed\u00a0size, it is also possible to learn a separate bias at each location of the output map.\u00a0Separating the biases may slightly reduce the statistical efficiency of the model, but\u00a0also allows the model to correct for differences in the image statistics at different\u00a0locations. For example, when using implicit zero padding, detector units at the\u00a0edge of the image receive less total input and may need larger biases.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3601",
    "text": "Convolutional networks can be used to output a high-dimensional, structured object, rather than just predicting a class label for a classification task or a real\u00a0value for a regression task. Typically this object is just a tensor, emitted by a\u00a0standard convolutional layer. For example, the model might emit a tensor S, where\u00a0is the probability that pixel (j, k) of the input to the network belongs to class\u00a0i. This allows the model to label every pixel in an image and draw precise masks\u00a0that follow the outlines of individual objects.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3602",
    "text": "One issue that often comes up is that the output plane can be smaller than the input plane, as shown in Fig. 9.13. In the kinds of architectures typically used for\u00a0classification of a single object in an image, the greatest reduction in the spatial\u00a0dimensions of the network comes from using pooling layers with large stride. In",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3603",
    "text": "",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3604",
    "text": "Y (1A",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3605",
    "text": "( Y(2) '",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3606",
    "text": "(15",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3607",
    "text": "V",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3608",
    "text": "",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3609",
    "text": ". V w\\",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3610",
    "text": "V",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3611",
    "text": "(",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3612",
    "text": "H(1))",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3613",
    "text": "f H(2) '",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3614",
    "text": "( h(3) J",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3615",
    "text": "U",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3616",
    "text": "U",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3617",
    "text": "U",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3618",
    "text": "",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3619",
    "text": "",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3620",
    "text": "X \\",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3621",
    "text": "",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3622",
    "text": "",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3623",
    "text": "Figure 9.17: An example of a recurrent convolutional network for pixel labeling. The input is an image tensor X, with axes corresponding to image rows, image columns, and\u00a0channels (red, green, blue). The goal is to output a tensor of labelsY, with a probability\u00a0distribution over labels for each pixel. This tensor has axes corresponding to image rows,\u00a0image columns, and the different classes. Rather than outputtingY in a single shot, the\u00a0recurrent network iteratively refines its estimate Y by using a previous estimate of Y\u00a0as input for creating a new estimate. The same parameters are used for each updated\u00a0estimate, and the estimate can be refined as many times as we wish. The tensor of\u00a0convolution kernels U is used on each step to compute the hidden representation given the\u00a0input image. The kernel tensor V is used to produce an estimate of the labels given the\u00a0hidden values. On all but the first step, the kernels W are convolved over Y to provide\u00a0input to the hidden layer. On the first time step, this term is replaced by zero. Because\u00a0the same parameters are used on each step, this is an example of a recurrent network, as\u00a0described in Chapter 10.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3624",
    "text": "order to produce an output map of similar size as the input, one can avoid pooling altogether (Jain et al., 2007). Another strategy is to simply emit a lower-resolution\u00a0grid of labels (Pinheiro and Collobert, 2014, 2015). Finally, in principle, one could\u00a0use a pooling operator with unit stride.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3625",
    "text": "One strategy for pixel-wise labeling of images is to produce an initial guess of the image labels, then refine this initial guess using the interactions between\u00a0neighboring pixels. Repeating this refinement step several times corresponds to\u00a0using the same convolutions at each stage, sharing weights between the last layers\u00a0of the deep net (Jain et al., 2007). This makes the sequence of computations\u00a0performed by the successive convolutional layers with weights shared across layers\u00a0a particular kind of recurrent network (Pinheiro and Collobert, 2014, 2015). Fig.\u00a09.17 shows the architecture of such a recurrent convolutional network.",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3626",
    "text": "Once a prediction for each pixel is made, various methods can be used to further process these predictions in order to obtain a segmentation of the image\u00a0into regions (Briggman et al., 2009; Turaga et al., 2010; Farabet et al., 2013).",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3627",
    "text": "The general idea is to assume that large groups of contiguous pixels tend to be associated with the same label. Graphical models can describe the probabilistic\u00a0relationships between neighboring pixels. Alternatively, the convolutional network\u00a0can be trained to maximize an approximation of the graphical model training\u00a0objective (Ning et al., 2005; Thompson et al., 2014).",
    "chapter": "Structured Probabilistic Models for Deep Learning",
    "chapter_id": "main-19.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3628",
    "text": "The data used with a convolutional network usually consists of several channels, each channel being the observation of a different quantity at some point in space\u00a0or time. See Table 9.1 for examples of data types with different dimensionalities\u00a0and number of channels.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3629",
    "text": "For an example of convolutional networks applied to video, see Chen et al. (2010).",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3630",
    "text": "So far we have discussed only the case where every example in the train and test data has the same spatial dimensions. One advantage to convolutional networks\u00a0is that they can also process inputs with varying spatial extents. These kinds of\u00a0input simply cannot be represented by traditional, matrix multiplication-based\u00a0neural networks. This provides a compelling reason to use convolutional networks\u00a0even when computational cost and overfitting are not significant issues.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3631",
    "text": "For example, consider a collection of images, where each image has a different width and height. It is unclear how to model such inputs with a weight matrix of\u00a0fixed size. Convolution is straightforward to apply; the kernel is simply applied a\u00a0different number of times depending on the size of the input, and the output of the\u00a0convolution operation scales accordingly. Convolution may be viewed as matrix\u00a0multiplication; the same convolution kernel induces a different size of doubly block\u00a0circulant matrix for each size of input. Sometimes the output of the network is\u00a0allowed to have variable size as well as the input, for example if we want to assign\u00a0a class label to each pixel of the input. In this case, no further design work is\u00a0necessary. In other cases, the network must produce some fixed-size output, for\u00a0example if we want to assign a single class label to the entire image. In this case\u00a0we must make some additional design steps, like inserting a pooling layer whose\u00a0pooling regions scale in size proportional to the size of the input, in order to\u00a0maintain a fixed number of pooled outputs. Some examples of this kind of strategy\u00a0are shown in Fig. 9.11.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3632",
    "text": "Note that the use of convolution for processing variable sized inputs only makes sense for inputs that have variable size because they contain varying amounts",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3633",
    "text": "",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3634",
    "text": "Single channel",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3635",
    "text": "Multi-channel",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3636",
    "text": "1-D",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3637",
    "text": "Audio waveform: The axis we convolve over corresponds to\u00a0time. We discretize time and\u00a0measure the amplitude of the\u00a0waveform once per time step.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3638",
    "text": "Skeleton animation data: Animations of 3-D computer-rendered characters are generated by altering the pose of a \u201cskeleton\u201d over\u00a0time. At each point in time, the\u00a0pose of the character is described\u00a0by a specification of the angles of\u00a0each of the joints in the character\u2019s skeleton. Each channel in\u00a0the data we feed to the convolutional model represents the angle\u00a0about one axis of one joint.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3639",
    "text": "2-D",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3640",
    "text": "Audio data that has been preprocessed with a Fourier transform: We can transform the audio waveform into a 2D tensor with different rows corresponding to different frequencies and different\u00a0columns corresponding to different points in time. Using convolution in the time makes the model\u00a0equivariant to shifts in time. Using convolution across the frequency axis makes the model\u00a0equivariant to frequency, so that\u00a0the same melody played in a different octave produces the same\u00a0representation but at a different\u00a0height in the network\u2019s output.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3641",
    "text": "Color image data: One channel contains the red pixels, one the\u00a0green pixels, and one the blue\u00a0pixels. The convolution kernel\u00a0moves over both the horizontal\u00a0and vertical axes of the image,\u00a0conferring translation equivari-ance in both directions.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3642",
    "text": "3-D",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3643",
    "text": "Volumetric data: A common source of this kind of data is medical imaging technology, such as\u00a0CT scans.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3644",
    "text": "Color video data: One axis corresponds to time, one to the height of the video frame, and one to\u00a0the width of the video frame.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3645",
    "text": "Table 9.1: Examples of different formats of data that can be used with convolutional networks.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3646",
    "text": "of observation of the same kind of thing\u2014different lengths of recordings over time, different widths of observations over space, etc. Convolution does not make\u00a0sense if the input has variable size because it can optionally include different\u00a0kinds of observations. For example, if we are processing college applications, and\u00a0our features consist of both grades and standardized test scores, but not every\u00a0applicant took the standardized test, then it does not make sense to convolve the\u00a0same weights over both the features corresponding to the grades and the features\u00a0corresponding to the test scores.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3647",
    "text": "Modern convolutional network applications often involve networks containing more than one million units. Powerful implementations exploiting parallel computation\u00a0resources, as discussed in Sec. 12.1, are essential. However, in many cases it is also\u00a0possible to speed up convolution by selecting an appropriate convolution algorithm.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3648",
    "text": "Convolution is equivalent to converting both the input and the kernel to the frequency domain using a Fourier transform, performing point-wise multiplication\u00a0of the two signals, and converting back to the time domain using an inverse\u00a0Fourier transform. For some problem sizes, this can be faster than the naive\u00a0implementation of discrete convolution.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3649",
    "text": "When a d-dimensional kernel can be expressed as the outer product of d vectors, one vector per dimension, the kernel is called separable. When the kernel\u00a0is separable, naive convolution is inefficient. It is equivalent to compose d onedimensional convolutions with each of these vectors. The composed approach\u00a0is significantly faster than performing one d-dimensional convolution with their\u00a0outer product. The kernel also takes fewer parameters to represent as vectors.\u00a0If the kernel is w elements wide in each dimension, then naive multidimensional\u00a0convolution requires O (wd) runtime and parameter storage space, while separable\u00a0convolution requires O(w x d) runtime and parameter storage space. Of course,\u00a0not every convolution can be represented in this way.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3650",
    "text": "Devising faster ways of performing convolution or approximate convolution without harming the accuracy of the model is an active area of research. Even techniques that improve the efficiency of only forward propagation are useful because\u00a0in the commercial setting, it is typical to devote more resources to deployment of\u00a0a network than to its training.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3651",
    "text": "Typically, the most expensive part of convolutional network training is learning the features. The output layer is usually relatively inexpensive due to the small number\u00a0of features provided as input to this layer after passing through several layers of\u00a0pooling. When performing supervised training with gradient descent, every gradient\u00a0step requires a complete run of forward propagation and backward propagation\u00a0through the entire network. One way to reduce the cost of convolutional network\u00a0training is to use features that are not trained in a supervised fashion.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3652",
    "text": "There are three basic strategies for obtaining convolution kernels without supervised training. One is to simply initialize them randomly. Another is to\u00a0design them by hand, for example by setting each kernel to detect edges at a\u00a0certain orientation or scale. Finally, one can learn the kernels with an unsupervised\u00a0criterion. For example, Coates et al. (2011) apply k-means clustering to small\u00a0image patches, then use each learned centroid as a convolution kernel. Part III\u00a0describes many more unsupervised learning approaches. Learning the features\u00a0with an unsupervised criterion allows them to be determined separately from the\u00a0classifier layer at the top of the architecture. One can then extract the features for\u00a0the entire training set just once, essentially constructing a new training set for the\u00a0last layer. Learning the last layer is then typically a convex optimization problem,\u00a0assuming the last layer is something like logistic regression or an SVM.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3653",
    "text": "Random filters often work surprisingly well in convolutional networks (Jarrett et al., 2009; Saxe et al., 2011; Pinto et al., 2011; Cox and Pinto, 2011). Saxe et al.\u00a0(2011) showed that layers consisting of convolution following by pooling naturally\u00a0become frequency selective and translation invariant when assigned random weights.\u00a0They argue that this provides an inexpensive way to choose the architecture of\u00a0a convolutional network: first evaluate the performance of several convolutional\u00a0network architectures by training only the last layer, then take the best of these\u00a0architectures and train the entire architecture using a more expensive approach.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3654",
    "text": "An intermediate approach is to learn the features, but using methods that do not require full forward and back-propagation at every gradient step. As with\u00a0multilayer perceptrons, we use greedy layer-wise pretraining, to train the first layer\u00a0in isolation, then extract all features from the first layer only once, then train the\u00a0second layer in isolation given those features, and so on. Chapter 8 has described\u00a0how to perform supervised greedy layer-wise pretraining, and Part III extends this\u00a0to greedy layer-wise pretraining using an unsupervised criterion at each layer. The\u00a0canonical example of greedy layer-wise pretraining of a convolutional model is the\u00a0convolutional deep belief network (Lee et al., 2009). Convolutional networks offer\u00a0us the opportunity to take the pretraining strategy one step further than is possible\u00a0with multilayer perceptrons. Instead of training an entire convolutional layer at a\u00a0time, we can train a model of a small patch, as Coates et al. (2011) do with k-means.\u00a0We can then use the parameters from this patch-based model to define the kernels\u00a0of a convolutional layer. This means that it is possible to use unsupervised learning\u00a0to train a convolutional network without ever using convolution during the\u00a0training process. Using this approach, we can train very large models and incur a\u00a0high computational cost only at inference time (Ranzato et al., 2007b; Jarrett et al.,\u00a02009; Kavukcuoglu et al., 2010; Coates et al., 2013). This approach was popular\u00a0from roughly 2007-2013, when labeled datasets were small and computational\u00a0power was more limited. Today, most convolutional networks are trained in a\u00a0purely supervised fashion, using full forward and back-propagation through the\u00a0entire network on each training iteration.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3655",
    "text": "As with other approaches to unsupervised pretraining, it remains difficult to tease apart the cause of some of the benefits seen with this approach. Unsupervised\u00a0pretraining may offer some regularization relative to supervised training, or it may\u00a0simply allow us to train much larger architectures due to the reduced computational\u00a0cost of the learning rule.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3656",
    "text": "Convolutional networks are perhaps the greatest success story of biologically inspired artificial intelligence. Though convolutional networks have been guided\u00a0by many other fields, some of the key design principles of neural networks were\u00a0drawn from neuroscience.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3657",
    "text": "The history of convolutional networks begins with neuroscientific experiments long before the relevant computational models were developed. Neurophysiologists\u00a0David Hubel and Torsten Wiesel collaborated for several years to determine many\u00a0of the most basic facts about how the mammalian vision system works (Hubel and\u00a0Wiesel, 1959, 1962, 1968). Their accomplishments were eventually recognized with\u00a0a Nobel prize. Their findings that have had the greatest influence on contemporary\u00a0deep learning models were based on recording the activity of individual neurons in\u00a0cats. They observed how neurons in the cat\u2019s brain responded to images projected\u00a0in precise locations on a screen in front of the cat. Their great discovery was\u00a0that neurons in the early visual system responded most strongly to very specific\u00a0patterns of light, such as precisely oriented bars, but responded hardly at all to\u00a0other patterns.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3658",
    "text": "Their work helped to characterize many aspects of brain function that are beyond the scope of this book. From the point of view of deep learning, we can\u00a0focus on a simplified, cartoon view of brain function.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3659",
    "text": "In this simplified view, we focus on a part of the brain called V1, also known as the primary visual cortex. V1 is the first area of the brain that begins to perform\u00a0significantly advanced processing of visual input. In this cartoon view, images are\u00a0formed by light arriving in the eye and stimulating the retina, the light-sensitive\u00a0tissue in the back of the eye. The neurons in the retina perform some simple\u00a0preprocessing of the image but do not substantially alter the way it is represented.\u00a0The image then passes through the optic nerve and a brain region called the lateral\u00a0geniculate nucleus. The main role, as far as we are concerned here, of both of these\u00a0anatomical regions is primarily just to carry the signal from the eye to V1, which\u00a0is located at the back of the head.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3660",
    "text": "A convolutional network layer is designed to capture three properties of V1:",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3661",
    "text": "1. \u00a0\u00a0\u00a0V1 is arranged in a spatial map. It actually has a two-dimensional structure\u00a0mirroring the structure of the image in the retina. For example, light\u00a0arriving at the lower half of the retina affects only the corresponding half of\u00a0V1. Convolutional networks capture this property by having their features\u00a0defined in terms of two dimensional maps.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3662",
    "text": "2. \u00a0\u00a0\u00a0V1 contains many simple cells. A simple cell\u2019s activity can to some extent be\u00a0characterized by a linear function of the image in a small, spatially localized\u00a0receptive field. The detector units of a convolutional network are designed\u00a0to emulate these properties of simple cells.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3663",
    "text": "3. \u00a0\u00a0\u00a0V1 also contains many complex cells. These cells respond to features that\u00a0are similar to those detected by simple cells, but complex cells are invariant\u00a0to small shifts in the position of the feature. This inspires the pooling units\u00a0of convolutional networks. Complex cells are also invariant to some changes\u00a0in lighting that cannot be captured simply by pooling over spatial locations.\u00a0These invariances have inspired some of the cross-channel pooling strategies\u00a0in convolutional networks, such as maxout units (Goodfellow et al., 2013a).",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3664",
    "text": "Though we know the most about V1, it is generally believed that the same basic principles apply to other areas of the visual system. In our cartoon view of\u00a0the visual system, the basic strategy of detection followed by pooling is repeatedly\u00a0applied as we move deeper into the brain. As we pass through multiple anatomical\u00a0layers of the brain, we eventually find cells that respond to some specific concept\u00a0and are invariant to many transformations of the input. These cells have been\u00a0nicknamed \u201cgrandmother cells\u201d\u2014the idea is that a person could have a neuron that\u00a0activates when seeing an image of their grandmother, regardless of whether she\u00a0appears in the left or right side of the image, whether the image is a close-up of\u00a0her face or zoomed out shot of her entire body, whether she is brightly lit, or in\u00a0shadow, etc.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3665",
    "text": "These grandmother cells have been shown to actually exist in the human brain, in a region called the medial temporal lobe (Quiroga et al., 2005). Researchers\u00a0tested whether individual neurons would respond to photos of famous individuals.\u00a0They found what has come to be called the \u201cHalle Berry neuron\u201d: an individual\u00a0neuron that is activated by the concept of Halle Berry. This neuron fires when a\u00a0person sees a photo of Halle Berry, a drawing of Halle Berry, or even text containing\u00a0the words \u201cHalle Berry.\u201d Of course, this has nothing to do with Halle Berry herself;\u00a0other neurons responded to the presence of Bill Clinton, Jennifer Aniston, etc.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3666",
    "text": "These medial temporal lobe neurons are somewhat more general than modern convolutional networks, which would not automatically generalize to identifying\u00a0a person or object when reading its name. The closest analog to a convolutional\u00a0network\u2019s last layer of features is a brain area called the inferotemporal cortex\u00a0(IT). When viewing an object, information flows from the retina, through the\u00a0LGN, to V1, then onward to V2, then V4, then IT. This happens within the first\u00a0100ms of glimpsing an object. If a person is allowed to continue looking at the\u00a0object for more time, then information will begin to flow backwards as the brain\u00a0uses top-down feedback to update the activations in the lower level brain areas.\u00a0However, if we interrupt the person\u2019s gaze, and observe only the firing rates that\u00a0result from the first 100ms of mostly feedforward activation, then IT proves to be\u00a0very similar to a convolutional network. Convolutional networks can predict IT\u00a0firing rates, and also perform very similarly to (time limited) humans on object\u00a0recognition tasks (DiCarlo, 2013).",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3667",
    "text": "That being said, there are many differences between convolutional networks and the mammalian vision system. Some of these differences are well known\u00a0to computational neuroscientists, but outside the scope of this book. Some of\u00a0these differences are not yet known, because many basic questions about how the\u00a0mammalian vision system works remain unanswered. As a brief list:",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3668",
    "text": "\u2022 The human eye is mostly very low resolution, except for a tiny patch called the fovea. The fovea only observes an area about the size of a thumbnail held at\u00a0arms length. Though we feel as if we can see an entire scene in high resolution,\u00a0this is an illusion created by the subconscious part of our brain, as it stitches\u00a0together several glimpses of small areas. Most convolutional networks actually\u00a0receive large full resolution photographs as input. The human brain makes\u00a0several eye movements called saccades to glimpse the most visually salient or\u00a0task-relevant parts of a scene. Incorporating similar attention mechanisms\u00a0into deep learning models is an active research direction. In the context of\u00a0deep learning, attention mechanisms have been most successful for natural\u00a0language processing, as described in Sec. 12.4.5.1. Several visual models\u00a0with foveation mechanisms have been developed but so far have not become\u00a0the dominant approach (Larochelle and Hinton, 2010; Denil et al., 2012).",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3669",
    "text": "\u2022 \u00a0\u00a0\u00a0The human visual system is integrated with many other senses, such as\u00a0hearing, and factors like our moods and thoughts. Convolutional networks\u00a0so far are purely visual.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3670",
    "text": "\u2022 \u00a0\u00a0\u00a0The human visual system does much more than just recognize objects. It is\u00a0able to understand entire scenes including many objects and relationships\u00a0between objects, and processes rich 3-D geometric information needed for\u00a0our bodies to interface with the world. Convolutional networks have been\u00a0applied to some of these problems but these applications are in their infancy.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3671",
    "text": "\u2022 \u00a0\u00a0\u00a0Even simple brain areas like V1 are heavily impacted by feedback from higher\u00a0levels. Feedback has been explored extensively in neural network models but\u00a0has not yet been shown to offer a compelling improvement.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3672",
    "text": "\u2022 \u00a0\u00a0\u00a0While feedforward IT firing rates capture much of the same information as\u00a0convolutional network features, it is not clear how similar the intermediate\u00a0computations are. The brain probably uses very different activation and\u00a0pooling functions. An individual neuron\u2019s activation probably is not well-characterized by a single linear filter response. A recent model of V1 involves\u00a0multiple quadratic filters for each neuron (Rust et al., 2005). Indeed our\u00a0cartoon picture of \u201csimple cells\u201d and \u201ccomplex cells\u201d might create a nonexistent distinction; simple cells and complex cells might both be the same\u00a0kind of cell but with their \u201cparameters\u201d enabling a continuum of behaviors\u00a0ranging from what we call \u201csimple\u201d to what we call \u201ccomplex.\u201d",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3673",
    "text": "It is also worth mentioning that neuroscience has told us relatively little about how to train convolutional networks. Model structures with parameter\u00a0sharing across multiple spatial locations date back to early connectionist models\u00a0of vision (Marr and Poggio, 1976), but these models did not use the modern\u00a0back-propagation algorithm and gradient descent. For example, the Neocognitron\u00a0(Fukushima, 1980) incorporated most of the model architecture design elements of\u00a0the modern convolutional network but relied on a layer-wise unsupervised clustering\u00a0algorithm.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3674",
    "text": "Lang and Hinton (1988) introduced the use of back-propagation to train time-delay neural networks (TDNNs). To use contemporary terminology, TDNNs are one-dimensional convolutional networks applied to time series. Back-propagation\u00a0applied to these models was not inspired by any neuroscientific observation and\u00a0is considered by some to be biologically implausible. Following the success of\u00a0back-propagation-based training of TDNNs, (LeCun et al., 1989) developed the\u00a0modern convolutional network by applying the same training algorithm to 2-D\u00a0convolution applied to images.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3675",
    "text": "So far we have described how simple cells are roughly linear and selective for certain features, complex cells are more nonlinear and become invariant to some\u00a0transformations of these simple cell features, and stacks of layers that alternate\u00a0between selectivity and invariance can yield grandmother cells for very specific\u00a0phenomena. We have not yet described precisely what these individual cells detect.\u00a0In a deep, nonlinear network, it can be difficult to understand the function of\u00a0individual cells. Simple cells in the first layer are easier to analyze, because their\u00a0responses are driven by a linear function. In an artificial neural network, we can\u00a0just display an image of the convolution kernel to see what the corresponding\u00a0channel of a convolutional layer responds to. In a biological neural network, we\u00a0do not have access to the weights themselves. Instead, we put an electrode in the\u00a0neuron itself, display several samples of white noise images in front of the animal\u2019s\u00a0retina, and record how each of these samples causes the neuron to activate. We\u00a0can then fit a linear model to these responses in order to obtain an approximation\u00a0of the neuron\u2019s weights. This approach is known as reverse correlation (Ringach\u00a0and Shapley, 2004).",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3676",
    "text": "Reverse correlation shows us that most V1 cells have weights that are described by Gabor functions. The Gabor function describes the weight at a 2-D point in the\u00a0image. We can think of an image as being a function of 2-D coordinates, I(x, y).\u00a0Likewise, we can think of a simple cell as sampling the image at a set of locations,\u00a0defined by a set of x coordinates X and a set of y coordinates, Y, and applying\u00a0weights that are also a function of the location, w(x, y). From this point of view,\u00a0the response of a simple cell to an image is given by",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3677",
    "text": "s(I) = \u00a0\u00a0\u00a0w(x,y)I (x,y)\u2022\u00a0\u00a0\u00a0\u00a0(9.15)",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3678",
    "text": "x\u00a3Xy\u00a3Y",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3679",
    "text": "Specifically, w(x, y) takes the form of a Gabor function:",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3680",
    "text": "w(x, y; a,fix,Py,f,0,xo,y0, t) = a exp (\u05beArX/2 - \u00a3yy'2) cos(fx/ + ^), \u00a0\u00a0\u00a0(9.16)",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3681",
    "text": "where",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3682",
    "text": "x/ = (x - xo) cos(t) + (y - yo) sin(T) \u00a0\u00a0\u00a0(9.17)",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3683",
    "text": "and",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3684",
    "text": "y' = - (x - x0) sin(r) + (y - y0) cos(r). \u00a0\u00a0\u00a0(9.18)",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3685",
    "text": "Here, a, 3x, 3y, f, 3, x0, y0, and t are parameters that control the properties of the Gabor function. Fig. 9.18 shows some examples of Gabor functions with\u00a0different settings of these parameters.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3686",
    "text": "The parameters x0, yo, and t define a coordinate system. We translate and rotate x and y to form x! and y'. Specifically, the simple cell will respond to image\u00a0features centered at the point (x 0, y 0), and it will respond to changes in brightness\u00a0as we move along a line rotated t radians from the horizontal.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3687",
    "text": "Viewed as a function of x' and y', the function w then responds to changes in brightness as we move along the x' axis. It has two important factors: one is a\u00a0Gaussian function and the other is a cosine function.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3688",
    "text": "The Gaussian factor a exp (\u20143x x'2 \u2014 3y32) can be seen as a gating term that ensures the simple cell will only respond to values near where x' and y are both\u00a0zero, in other words, near the center of the cell\u2019s receptive field. The scaling factor\u00a0a adjusts the total magnitude of the simple cell\u2019s response, while 3x and 3y control\u00a0how quickly its receptive field falls off.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3689",
    "text": "The cosine factor cos (fx' + 3) controls how the simple cell responds to changing brightness along the x' axis. The parameter f controls the frequency of the cosine\u00a0and 3 controls its phase offset.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3690",
    "text": "Altogether, this cartoon view of simple cells means that a simple cell responds to a specific spatial frequency of brightness in a specific direction at a specific\u00a0location. Simple cells are most excited when the wave of brightness in the image\u00a0has the same phase as the weights. This occurs when the image is bright where the\u00a0weights are positive and dark where the weights are negative. Simple cells are most\u00a0inhibited when the wave of brightness is fully out of phase with the weights\u2014when\u00a0the image is dark where the weights are positive and bright where the weights are\u00a0negative.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3691",
    "text": "The cartoon view of a complex cell is that it computes the L norm of the 2-D vector containing two simple cells\u2019 responses: c(I) = y/s0(I)2 + s1(I) 2. An\u00a0important special case occurs when s 1 has all of the same parameters as s0 except\u00a0for 3, and 3 is set such that si is one quarter cycle out of phase with s0. In\u00a0this case, s0 and s! form a quadrature pair. A complex cell defined in this way\u00a0responds when the Gaussian reweighted image I(x, y) exp(\u20143xx2 \u2014 3yy'2) contains\u00a0a high amplitude sinusoidal wave with frequency f in direction t near (x0, y0),\u00a0regardless of the phase offset of this wave. In other words, the complex cell\u00a0is invariant to small translations of the image in direction t , or to negating the",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3692",
    "text": "aaSBBBBB nnODDDDDD DDDDDDDin",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3693",
    "text": "Figure 9.18: Gabor functions with a variety of parameter settings. White indicates large positive weight, black indicates large negative weight, and the background gray\u00a0corresponds to zero weight. (Left) Gabor functions with different values of the parameters\u00a0that control the coordinate system: x 0, y0, and t. Each Gabor function in this grid is\u00a0assigned a value of X0 and y0 proportional to its position in its grid, and t is chosen so\u00a0that each Gabor filter is sensitive to the direction radiating out from the center of the grid.\u00a0For the other two plots, X0, yo, and t are fixed to zero. (Center) Gabor functions with\u00a0different Gaussian scale parameters flx and fly. Gabor functions are arranged in increasing\u00a0width (decreasing flx) as we move left to right through the grid, and increasing height\u00a0(decreasing fly) as we move top to bottom. For the other two plots, the values are fixed\u00a0to 1.5x the image width. (Right) Gabor functions with different sinusoid parameters f\u00a0and As we move top to bottom, f increases, and as we move left to right, $ increases.\u00a0For the other two plots, $ is fixed to 0 and f is fixed to 5x the image width.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3694",
    "text": "image (replacing black with white and vice versa).",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3695",
    "text": "Some of the most striking correspondences between neuroscience and machine learning come from visually comparing the features learned by machine learning\u00a0models with those employed by V1. Olshausen and Field (1996) showed that\u00a0a simple unsupervised learning algorithm, sparse coding, learns features with\u00a0receptive fields similar to those of simple cells. Since then, we have found that\u00a0an extremely wide variety of statistical learning algorithms learn features with\u00a0Gabor-like functions when applied to natural images. This includes most deep\u00a0learning algorithms, which learn these features in their first layer. Fig. 9.19 shows\u00a0some examples. Because so many different learning algorithms learn edge detectors,\u00a0it is difficult to conclude that any specific learning algorithm is the \u201cright\u201d model\u00a0of the brain just based on the features that it learns (though it can certainly be a\u00a0bad sign if an algorithm does not learn some sort of edge detector when applied to\u00a0natural images). These features are an important part of the statistical structure\u00a0of natural images and can be recovered by many different approaches to statistical\u00a0modeling. See Hyvarinen et al. (2009) for a review of the field of natural image\u00a0statistics.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3696",
    "text": "#ERROR!",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3697",
    "text": "V I",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3698",
    "text": "Figure 9.19: Many machine learning algorithms learn features that detect edges or specific colors of edges when applied to natural images. These feature detectors are reminiscent of\u00a0the Gabor functions known to be present in primary visual cortex. (Left) Weights learned\u00a0by an unsupervised learning algorithm (spike and slab sparse coding) applied to small\u00a0image patches. (Right) Convolution kernels learned by the first layer of a fully supervised\u00a0convolutional maxout network. Neighboring pairs of filters drive the same maxout unit.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3699",
    "text": "Convolutional networks have played an important role in the history of deep learning. They are a key example of a successful application of insights obtained\u00a0by studying the brain to machine learning applications. They were also some of\u00a0the first deep models to perform well, long before arbitrary deep models were\u00a0considered viable. Convolutional networks were also some of the first neural\u00a0networks to solve important commercial applications and remain at the forefront\u00a0of commercial applications of deep learning today. For example, in the 1990s, the\u00a0neural network research group at AT&T developed a convolutional network for\u00a0reading checks (LeCun et al., 1998b). By the end of the 1990s, this system deployed\u00a0by NEC was reading over 10% of all the checks in the US. Later, several OCR\u00a0and handwriting recognition systems based on convolutional nets were deployed\u00a0by Microsoft (Simard et al., 2003). See Chapter 12 for more details on such\u00a0applications and more modern applications of convolutional networks. See LeCun\u00a0et al. (2010) for a more in-depth history of convolutional networks up to 2010.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3700",
    "text": "Convolutional networks were also used to win many contests. The current intensity of commercial interest in deep learning began when Krizhevsky et al.\u00a0(2012) won the ImageNet object recognition challenge, but convolutional networks\u00a0had been used to win other machine learning and computer vision contests with\u00a0less impact for years earlier.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3701",
    "text": "Convolutional nets were some of the first working deep networks trained with back-propagation. It is not entirely clear why convolutional networks succeeded\u00a0when general back-propagation networks were considered to have failed. It may\u00a0simply be that convolutional networks were more computationally efficient than\u00a0fully connected networks, so it was easier to run multiple experiments with them\u00a0and tune their implementation and hyperparameters. Larger networks also seem\u00a0to be easier to train. With modern hardware, large fully connected networks\u00a0appear to perform reasonably on many tasks, even when using datasets that were\u00a0available and activation functions that were popular during the times when fully\u00a0connected networks were believed not to work well. It may be that the primary\u00a0barriers to the success of neural networks were psychological (practitioners did\u00a0not expect neural networks to work, so they did not make a serious effort to use\u00a0neural networks). Whatever the case, it is fortunate that convolutional networks\u00a0performed well decades ago. In many ways, they carried the torch for the rest of\u00a0deep learning and paved the way to the acceptance of neural networks in general.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3702",
    "text": "Convolutional networks provide a way to specialize neural networks to work with data that has a clear grid-structured topology and to scale such models to\u00a0very large size. This approach has been the most successful on a two-dimensional,\u00a0image topology. To process one-dimensional, sequential data, we turn next to\u00a0another powerful specialization of the neural networks framework: recurrent neural\u00a0networks.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3703",
    "text": "Figure 9.16: A comparison of locally connected layers, tiled convolution, and standard convolution. All three have the same sets of connections between units, when the same\u00a0size of kernel is used. This diagram illustrates the use of a kernel that is two pixels wide.\u00a0The differences between the methods lies in how they share parameters. (Top) A locally\u00a0connected layer has no sharing at all. We indicate that each connection has its own weight\u00a0by labeling each connection with a unique letter. (Center) Tiled convolution has a set of\u00a0t different kernels. Here we illustrate the case of t = 2. One of these kernels has edges\u00a0labeled \u201ca\u201d and \u201cb,\u201d while the other has edges labeled \u201cc\u201d and \u201cd.\u201d Each time we move one\u00a0pixel to the right in the output, we move on to using a different kernel. This means that,\u00a0like the locally connected layer, neighboring units in the output have different parameters.\u00a0Unlike the locally connected layer, after we have gone through all t available kernels,\u00a0we cycle back to the first kernel. If two output units are separated by a multiple oft\u00a0steps, then they share parameters. (Bottom) Traditional convolution is equivalent to tiled\u00a0convolution with t = 1. There is only one kernel and it is applied everywhere, as indicated\u00a0in the diagram by using the kernel with weights labeled \u201ca\u201d and \u201cb\u201d everywhere.",
    "chapter": "Monte Carlo Methods",
    "chapter_id": "main-20.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3704",
    "text": "Recurrent neural networks or RNNs (Rumelhart et al., 1986a) are a family of neural networks for processing sequential data. Much as a convolutional network\u00a0is a neural network that is specialized for processing a grid of values X such as\u00a0an image, a recurrent neural network is a neural network that is specialized for\u00a0processing a sequence of values x(1),...,x(t). Just as convolutional networks\u00a0can readily scale to images with large width and height, and some convolutional\u00a0networks can process images of variable size, recurrent networks can scale to much\u00a0longer sequences than would be practical for networks without sequence-based\u00a0specialization. Most recurrent networks can also process sequences of variable\u00a0length.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3705",
    "text": "To go from multi-layer networks to recurrent networks, we need to take advantage of one of the early ideas found in machine learning and statistical models of the 1980s: sharing parameters across different parts of a model. Parameter sharing\u00a0makes it possible to extend and apply the model to examples of different forms\u00a0(different lengths, here) and generalize across them. If we had separate parameters\u00a0for each value of the time index, we could not generalize to sequence lengths not\u00a0seen during training, nor share statistical strength across different sequence lengths\u00a0and across different positions in time. Such sharing is particularly important when\u00a0a specific piece of information can occur at multiple positions within the sequence.\u00a0For example, consider the two sentences \u201cI went to Nepal in 2009\u201d and \u201cIn 2009,\u00a0I went to Nepal.\u201d If we ask a machine learning model to read each sentence and\u00a0extract the year in which the narrator went to Nepal, we would like it to recognize\u00a0the year 2009 as the relevant piece of information, whether it appears in the sixth\u00a0word or the second word of the sentence. Suppose that we trained a feedforward\u00a0network that processes sentences of fixed length. A traditional fully connected\u00a0feedforward network would have separate parameters for each input feature, so it\u00a0would need to learn all of the rules of the language separately at each position in\u00a0the sentence. By comparison, a recurrent neural network shares the same weights\u00a0across several time steps.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3706",
    "text": "A related idea is the use of convolution across a 1-D temporal sequence. This convolutional approach is the basis for time-delay neural networks (Lang and\u00a0Hinton, 1988; Waibel et al., 1989; Lang et al., 1990). The convolution operation\u00a0allows a network to share parameters across time, but is shallow. The output\u00a0of convolution is a sequence where each member of the output is a function of\u00a0a small number of neighboring members of the input. The idea of parameter\u00a0sharing manifests in the application of the same convolution kernel at each time\u00a0step. Recurrent networks share parameters in a different way. Each member of the\u00a0output is a function of the previous members of the output. Each member of the\u00a0output is produced using the same update rule applied to the previous outputs.\u00a0This recurrent formulation results in the sharing of parameters through a very\u00a0deep computational graph.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3707",
    "text": "For the simplicity of exposition, we refer to RNNs as operating on a sequence that contains vectors with the time step index t ranging from 1 to t. In\u00a0practice, recurrent networks usually operate on minibatches of such sequences,\u00a0with a different sequence length t for each member of the minibatch. We have\u00a0omitted the minibatch indices to simplify notation. Moreover, the time step index\u00a0need not literally refer to the passage of time in the real world, but only to the\u00a0position in the sequence. RNNs may also be applied in two dimensions across\u00a0spatial data such as images, and even when applied to data involving time, the\u00a0network may have connections that go backwards in time, provided that the entire\u00a0sequence is observed before it is provided to the network.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3708",
    "text": "This chapter extends the idea of a computational graph to include cycles. These cycles represent the influence of the present value of a variable on its own value\u00a0at a future time step. Such computational graphs allow us to define recurrent\u00a0neural networks. We then describe many different ways to construct, train, and\u00a0use recurrent neural networks.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3709",
    "text": "For more information on recurrent neural networks than is available in this chapter, we refer the reader to the textbook of Graves (2012).",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3710",
    "text": "A computational graph is a way to formalize the structure of a set of computations, such as those involved in mapping inputs and parameters to outputs and loss.\u00a0Please refer to Sec. 6.5.1 for a general introduction. In this section we explain\u00a0the idea of unfolding a recursive or recurrent computation into a computational\u00a0graph that has a repetitive structure, typically corresponding to a chain of events.\u00a0Unfolding this graph results in the sharing of parameters across a deep network\u00a0structure.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3711",
    "text": "For example, consider the classical form of a dynamical system:",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3712",
    "text": "s(t) = f (s(t-1); e), \u00a0\u00a0\u00a0(10.1)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3713",
    "text": "where s(t) is called the state of the system.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3714",
    "text": "Eq. 10.1 is recurrent because the definition of s at time t refers back to the same definition at time t \u2014 1.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3715",
    "text": "For a finite number of time steps t, the graph can be unfolded by applying the definition t \u2014 1 times. For example, if we unfold Eq. 10.1 for t = 3 time steps, we\u00a0obtain",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3716",
    "text": "s",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3717",
    "text": "(3) =f (s(2); e)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3718",
    "text": "#NAME?",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3719",
    "text": "-10.2",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3720",
    "text": "-10.3",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3721",
    "text": "Unfolding the equation by repeatedly applying the definition in this way has yielded an expression that does not involve recurrence. Such an expression can\u00a0now be represented by a traditional directed acyclic computational graph. The\u00a0unfolded computational graph of Eq. 10.1 and Eq. 10.3 is illustrated in Fig. 10.1.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3722",
    "text": "\u2022\u2022\u2022)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3723",
    "text": "f",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3724",
    "text": "Figure 10.1: The classical dynamical system described by Eq. 10.1, illustrated as an unfolded computational graph. Each node represents the state at some time t and the\u00a0function f maps the state at t to the state at t +1. The same parameters (the same value\u00a0of e used to parametrize f) are used for all time steps.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3725",
    "text": "As another example, let us consider a dynamical system driven by an external signal x(t),",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3726",
    "text": "s(t) = f (s(t-1), x(t); e), \u00a0\u00a0\u00a0(10.4)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3727",
    "text": "where we see that the state now contains information about the whole past sequence.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3728",
    "text": "Recurrent neural networks can be built in many different ways. Much as almost any function can be considered a feedforward neural network, essentially\u00a0any function involving recurrence can be considered a recurrent neural network.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3729",
    "text": "Many recurrent neural networks use Eq. 10.5 or a similar equation to define the values of their hidden units. To indicate that the state is the hidden units of\u00a0the network, we now rewrite Eq. 10.4 using the variable h to represent the state:",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3730",
    "text": "-10.5",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3731",
    "text": "h(t) = f (h(t-1), x(t); 0),",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3732",
    "text": "illustrated in Fig. 10.2, typical RNNs will add extra architectural features such as output layers that read information out of the state h to make predictions.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3733",
    "text": "When the recurrent network is trained to perform a task that requires predicting the future from the past, the network typically learns to use h(t) as a kind of lossy\u00a0summary of the task-relevant aspects of the past sequence of inputs up to t. This\u00a0summary is in general necessarily lossy, since it maps an arbitrary length sequence\u00a0(x(t), x(t-1), x(t-2),..., x(2), x(1)) to a fixed length vector h(t). Depending on the\u00a0training criterion, this summary might selectively keep some aspects of the past\u00a0sequence with more precision than other aspects. For example, if the RNN is used\u00a0in statistical language modeling, typically to predict the next word given previous\u00a0words, it may not be necessary to store all of the information in the input sequence\u00a0up to time t, but rather only enough information to predict the rest of the sentence.\u00a0The most demanding situation is when we ask h(t) to be rich enough to allow\u00a0one to approximately recover the input sequence, as in autoencoder frameworks\u00a0(Chapter 14).",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3734",
    "text": "h(\u25a0\u25a0\u25a0) L",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3735",
    "text": "h (t+x",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3736",
    "text": "I h(\u25a0\u25a0\u25a0) '",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3737",
    "text": "f",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3738",
    "text": "Unfold",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3739",
    "text": "x",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3740",
    "text": "x",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3741",
    "text": "(t-1)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3742",
    "text": "x",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3743",
    "text": "(t)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3744",
    "text": "x",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3745",
    "text": "(t+1)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3746",
    "text": "Figure 10.2: A recurrent network with no outputs. This recurrent network just processes information from the input x by incorporating it into the state h that is passed forward\u00a0through time. (Left) Circuit diagram. The black square indicates a delay of 1 time step.\u00a0(Right) The same network seen as an unfolded computational graph, where each node is\u00a0now associated with one particular time instance.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3747",
    "text": "Eq. 10.5 can be drawn in two different ways. One way to draw the RNN is with a diagram containing one node for every component that might exist in a",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3748",
    "text": "physical implementation of the model, such as a biological neural network. In this view, the network defines a circuit that operates in real time, with physical\u00a0parts whose current state can influence their future state, as in the left of Fig. 10.2.\u00a0Throughout this chapter, we use a black square in a circuit diagram to indicate\u00a0that an interaction takes place with a delay of 1 time step, from the state at time\u00a0t to the state at time t +1. The other way to draw the RNN is as an unfolded\u00a0computational graph, in which each component is represented by many different\u00a0variables, with one variable per time step, representing the state of the component\u00a0at that point in time. Each variable for each time step is drawn as a separate node\u00a0of the computational graph, as in the right of Fig. 10.2. What we call unfolding is\u00a0the operation that maps a circuit as in the left side of the figure to a computational\u00a0graph with repeated pieces as in the right side. The unfolded graph now has a size\u00a0that depends on the sequence length.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3749",
    "text": "We can represent the unfolded recurrence after t steps with a function g(t):",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3750",
    "text": "#ERROR!",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3751",
    "text": "#N/A",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3752",
    "text": "The function g(t) takes the whole past sequence (x(t), x(t-1), x(t-2),..., x(2), x(1)) as input and produces the current state, but the unfolded recurrent structure\u00a0allows us to factorize g(t) into repeated application of a function f. The unfolding\u00a0process thus introduces two major advantages:",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3753",
    "text": "1. \u00a0\u00a0\u00a0Regardless of the sequence length, the learned model always has the same\u00a0input size, because it is specified in terms of transition from one state to\u00a0another state, rather than specified in terms of a variable-length history of\u00a0states.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3754",
    "text": "2. \u00a0\u00a0\u00a0It is possible to use the same transition function f with the same parameters\u00a0at every time step.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3755",
    "text": "These two factors make it possible to learn a single model f that operates on all time steps and all sequence lengths, rather than needing to learn a separate\u00a0model g(t) for all possible time steps. Learning a single, shared model allows\u00a0generalization to sequence lengths that did not appear in the training set, and\u00a0allows the model to be estimated with far fewer training examples than would be\u00a0required without parameter sharing.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3756",
    "text": "Both the recurrent graph and the unrolled graph have their uses. The recurrent graph is succinct. The unfolded graph provides an explicit description of which\u00a0computations to perform. The unfolded graph also helps to illustrate the idea of\u00a0information flow forward in time (computing outputs and losses) and backward\u00a0in time (computing gradients) by explicitly showing the path along which this\u00a0information flows.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3757",
    "text": "Armed with the graph unrolling and parameter sharing ideas of Sec. 10.1, we can design a wide variety of recurrent neural networks.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3758",
    "text": "Figure 10.3: The computational graph to compute the training loss of a recurrent network that maps an input sequence of x values to a corresponding sequence of output o values.\u00a0A loss L measures how far each o is from the corresponding training target y. When using\u00a0softmax outputs, we assume o is the unnormalized log probabilities. The loss L internally\u00a0computes y = softmax(o) and compares this to the target y. The RNN has input to hidden\u00a0connections parametrized by a weight matrix U, hidden-to-hidden recurrent connections\u00a0parametrized by a weight matrix W, and hidden-to-output connections parametrized by\u00a0a weight matrix V. Eq. 10.8 defines forward propagation in this model. (Left) The RNN\u00a0and its loss drawn with recurrent connections. (Right) The same seen as an time-unfolded\u00a0computational graph, where each node is now associated with one particular time instance.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3759",
    "text": "Some examples of important design patterns for recurrent neural networks include the following:",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3760",
    "text": "\u2022 Recurrent networks that produce an output at each time step and have",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3761",
    "text": "recurrent connections between hidden units, illustrated in Fig. 10.3.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3762",
    "text": "\u2022 \u00a0\u00a0\u00a0Recurrent networks that produce an output at each time step and have\u00a0recurrent connections only from the output at one time step to the hidden\u00a0units at the next time step, illustrated in Fig. 10.4",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3763",
    "text": "\u2022 \u00a0\u00a0\u00a0Recurrent networks with recurrent connections between hidden units, that\u00a0read an entire sequence and then produce a single output, illustrated in Fig.\u00a010.5.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3764",
    "text": "Fig. 10.3 is a reasonably representative example that we return to throughout most of the chapter.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3765",
    "text": "The recurrent neural network of Fig. 10.3 and Eq. 10.8 is universal in the sense that any function computable by a Turing machine can be computed by such\u00a0a recurrent network of a finite size. The output can be read from the RNN after\u00a0a number of time steps that is asymptotically linear in the number of time steps\u00a0used by the Turing machine and asymptotically linear in the length of the input\u00a0(Siegelmann and Sontag, 1991; Siegelmann, 1995; Siegelmann and Sontag, 1995;\u00a0Hyotyniemi, 1996). The functions computable by a Turing machine are discrete,\u00a0so these results regard exact implementation of the function, not approximations.\u00a0The RNN, when used as a Turing machine, takes a binary sequence as input and its\u00a0outputs must be discretized to provide a binary output. It is possible to compute all\u00a0functions in this setting using a single specific RNN of finite size (Siegelmann and\u00a0Sontag (1995) use 886 units). The \u201cinput\u201d of the Turing machine is a specification\u00a0of the function to be computed, so the same network that simulates this Turing\u00a0machine is sufficient for all problems. The theoretical RNN used for the proof\u00a0can simulate an unbounded stack by representing its activations and weights with\u00a0rational numbers of unbounded precision.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3766",
    "text": "We now develop the forward propagation equations for the RNN depicted in Fig. 10.3. The figure does not specify the choice of activation function for the\u00a0hidden units. Here we assume the hyperbolic tangent activation function. Also,\u00a0the figure does not specify exactly what form the output and loss function take.\u00a0Here we assume that the output is discrete, as if the RNN is used to predict words\u00a0or characters. A natural way to represent discrete variables is to regard the output\u00a0o as giving the unnormalized log probabilities of each possible value of the discrete\u00a0variable. We can then apply the softmax operation as a post-processing step to\u00a0obtain a vector y of normalized probabilities over the output. Forward propagation\u00a0begins with a specification of the initial state h(0). Then, for each time step from\u00a0t = 1 to t = t, we apply the following update equations:",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3767",
    "text": "a(t) = b + Wh(t-1) + Ux(t) \u00a0\u00a0\u00a0(10.8)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3768",
    "text": "Figure 10.4: An RNN whose only recurrence is the feedback connection from the output to the hidden layer. At each time step t, the input is x t, the hidden layer activations are\u00a0h(t), the outputs are o(t), the targets are yand the loss is . (Left) Circuit diagram.\u00a0(Right) Unfolded computational graph. Such an RNN is less powerful (can express a\u00a0smaller set of functions) than those in the family represented by Fig. 10.3. The RNN\u00a0in Fig. 10.3 can choose to put any information it wants about the past into its hidden\u00a0representation h and transmit h to the future. The RNN in this figure is trained to\u00a0put a specific output value into o, and o is the only information it is allowed to send\u00a0to the future. There are no direct connections from h going forward. The previous h\u00a0is connected to the present only indirectly, via the predictions it was used to produce.\u00a0Unless o is very high-dimensional and rich, it will usually lack important information\u00a0from the past. This makes the RNN in this figure less powerful, but it may be easier to\u00a0train because each time step can be trained in isolation from the others, allowing greater\u00a0parallelization during training, as described in Sec. 10.2.1.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3769",
    "text": "h(t) \u00a0\u00a0\u00a0=\u00a0\u00a0\u00a0\u00a0tanh(a(t))\u00a0\u00a0\u00a0\u00a0(10.9)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3770",
    "text": "o(t) \u00a0\u00a0\u00a0=\u00a0\u00a0\u00a0\u00a0c + Vh(t)\u00a0\u00a0\u00a0\u00a0(10.10)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3771",
    "text": "y(t) \u00a0\u00a0\u00a0=\u00a0\u00a0\u00a0\u00a0s0ftmax(o(t))\u00a0\u00a0\u00a0\u00a0(10.11)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3772",
    "text": "where the parameters are the \u00a0\u00a0\u00a0bias vectors b and c along with the weight matrices",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3773",
    "text": "U, V and W, respectively for input-to-hidden, hidden-to-output and hidden-to-hidden connections. This is an example of a recurrent network that maps an input sequence to an output sequence of the same length. The total loss for a\u00a0given sequence of x values paired with a sequence of y values would then be just\u00a0the sum of the losses over all the time steps. For example, if L(t) is the negative\u00a0log-likelihood of y(t) given x(1),..., x(t), then",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3774",
    "text": "L ({x<1)...., x(T)}, {y(1),..., y(T)})",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3775",
    "text": "E L(t) t",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3776",
    "text": "-10.12",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3777",
    "text": "-10.13",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3778",
    "text": "- E 10gPmodel (y(t) | {x(1\\ . . . , x (t)}) ,",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3779",
    "text": "-10.14",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3780",
    "text": "t",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3781",
    "text": "where pmodei (y(t) | \u00a0\u00a0\u00a0is given by reading the entry for y(t) from the",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3782",
    "text": "model\u2019s output vector y(t). Computing the gradient of this loss function with respect to the parameters is an expensive operation. The gradient computation\u00a0involves performing a forward propagation pass moving left to right through our\u00a0illustration of the unrolled graph in Fig. 10.3, followed by a backward propagation\u00a0pass moving right to left through the graph. The runtime is O ( t) and cannot be\u00a0reduced by parallelization because the forward propagation graph is inherently\u00a0sequential; each time step may only be computed after the previous one. States\u00a0computed in the forward pass must be stored until they are reused during the\u00a0backward pass, so the memory cost is also O(t). The back-propagation algorithm\u00a0applied to the unrolled graph with O (t) cost is called back-propagation through\u00a0time or BPTT and is discussed further Sec. 10.2.2. The network with recurrence\u00a0between hidden units is thus very powerful but also expensive to train. Is there an\u00a0alternative?",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3783",
    "text": "The network with recurrent connections only from the output at one time step to the hidden units at the next time step (shown in Fig. 10.4) is strictly less powerful\u00a0because it lacks hidden-to-hidden recurrent connections. For example, it cannot\u00a0simulate a universal Turing machine. Because this network lacks hidden-to-hidden\u00a0recurrence, it requires that the output units capture all of the information about\u00a0the past that the network will use to predict the future. Because the output units\u00a0are explicitly trained to match the training set targets, they are unlikely to capture\u00a0the necessary information about the past history of the input, unless the user\u00a0knows how to describe the full state of the system and provides it as part of the\u00a0training set targets. The advantage of eliminating hidden-to-hidden recurrence\u00a0is that, for any loss function based on comparing the prediction at time t to the\u00a0training target at time t, all the time steps are decoupled. Training can thus be\u00a0parallelized, with the gradient for each step t computed in isolation. There is no\u00a0need to compute the output for the previous time step first, because the training\u00a0set provides the ideal value of that output.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3784",
    "text": "Figure 10.5: Time-unfolded recurrent neural network with a single output at the end of the sequence. Such a network can be used to summarize a sequence and produce a\u00a0fixed-size representation used as input for further processing. There might be a target\u00a0right at the end (as depicted here) or the gradient on the output can be obtained by\u00a0back-propagating from further downstream modules.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3785",
    "text": "Models that have recurrent connections from their outputs leading back into the model may be trained with teacher forcing. Teacher forcing is a procedure\u00a0that emerges from the maximum likelihood criterion, in which during training the\u00a0model receives the ground truth output as input at time t + 1. We can see\u00a0this by examining a sequence with two time steps. The conditional maximum\u00a0likelihood criterion is",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3786",
    "text": "logp(^y(1),y(2) | x(1),x(10.15)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3787",
    "text": "Figure 10.6: Illustration of teacher forcing. Teacher forcing is a training technique that is applicable to RNNs that have connections from their output to their hidden states at the\u00a0next time step. (Left) At train time, we feed the correct outputy(t) drawn from the train\u00a0set as input to h(t+1). (Right) When the model is deployed, the true output is generally\u00a0not known. In this case, we approximate the correct output y(t) with the model\u2019s output\u00a0o(t), and feed the output back into the model.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3788",
    "text": "#ERROR!",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3789",
    "text": "In this example, we see that at time t = 2, the model is trained to maximize the conditional probability of y(2) given both the x sequence so far and the previous y\u00a0value from the training set. Maximum likelihood thus specifies that during training,\u00a0rather than feeding the model\u2019s own output back into itself, these connections\u00a0should be fed with the target values specifying what the correct output should be.\u00a0This is illustrated in Fig. 10.6.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3790",
    "text": "We originally motivated teacher forcing as allowing us to avoid back-propagation through time in models that lack hidden-to-hidden connections. Teacher forcing\u00a0may still be applied to models that have hidden-to-hidden connections so long as\u00a0they have connections from the output at one time step to values computed in the\u00a0next time step. However, as soon as the hidden units become a function of earlier\u00a0time steps, the BPTT algorithm is necessary. Some models may thus be trained\u00a0with both teacher forcing and BPTT.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3791",
    "text": "The disadvantage of strict teacher forcing arises if the network is going to be later used in an open-loop mode, with the network outputs (or samples from the\u00a0output distribution) fed back as input. In this case, the kind of inputs that the\u00a0network sees during training could be quite different from the kind of inputs that\u00a0it will see at test time. One way to mitigate this problem is to train with both\u00a0teacher-forced inputs and with free-running inputs, for example by predicting the\u00a0correct target a number of steps in the future through the unfolded recurrent\u00a0output-to-input paths. In this way, the network can learn to take into account\u00a0input conditions (such as those it generates itself in the free-running mode) not\u00a0seen during training and how to map the state back towards one that will make\u00a0the network generate proper outputs after a few steps. Another approach (Bengio\u00a0et al., 2015b) to mitigate the gap between the inputs seen at train time and the\u00a0inputs seen at test time randomly chooses to use generated values or actual data\u00a0values as input. This approach exploits a curriculum learning strategy to gradually\u00a0use more of the generated values as input.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3792",
    "text": "Computing the gradient through a recurrent neural network is straightforward. One simply applies the generalized back-propagation algorithm of Sec. 6.5.6 to the\u00a0unrolled computational graph. No specialized algorithms are necessary. The use\u00a0of back-propagation on the unrolled graph is called the back-propagation through\u00a0time (BPTT) algorithm. Gradients obtained by back-propagation may then be\u00a0used with any general-purpose gradient-based techniques to train an RNN.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3793",
    "text": "To gain some intuition for how the BPTT algorithm behaves, we provide an example of how to compute gradients by BPTT for the RNN equations above\u00a0(Eq. 10.8 and Eq. 10.12). The nodes of our computational graph include the\u00a0parameters U, V, W, b and c as well as the sequence of nodes indexed by t for\u00a0x(t), h(t), o(t) and L(t). For each node N we need to compute the gradient Vn L\u00a0recursively, based on the gradient computed at nodes that follow it in the graph.\u00a0We start the recursion with the nodes immediately preceding the final loss",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3794",
    "text": "dL",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3795",
    "text": "dLW",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3796",
    "text": "1",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3797",
    "text": "-10.17",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3798",
    "text": "In this derivation we assume that the outputs o(t) are used as the argument to the softmax function to obtain the vector y of probabilities over the output. We also\u00a0assume that the loss is the negative log-likelihood of the true target y(t) given the\u00a0input so far. The gradient Vo(t)L on the outputs at time step t, for all i,t, is as\u00a0follows:",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3799",
    "text": "dL dL dL(t) \u00a0\u00a0\u00a0w",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3800",
    "text": "1 \u05be i,y(t).",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3801",
    "text": "(Vm L)i",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3802",
    "text": "do,",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3803",
    "text": "P dL(t) do!t)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3804",
    "text": "Vi",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3805",
    "text": "-10.18",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3806",
    "text": "We work our way backwards, starting from the end of the sequence. At the final time step t, h(t) only has 0T) as a descendent, so its gradient is simple:",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3807",
    "text": "Vh(T) L = V",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3808",
    "text": "\u25a0T",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3809",
    "text": "V0(t )L.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3810",
    "text": "-10.19",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3811",
    "text": "We can then iterate backwards in time to back-propagate gradients through time, from t = t \u2014 1 down to t = 1, noting that h(t) (for t < t) has as descendents both\u00a0o(t) and h(t+1). Its gradient is thus given by",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3812",
    "text": "vh(t)L",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3813",
    "text": "d h(t+1) d h(*)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3814",
    "text": "T",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3815",
    "text": "(Vh(t+l) L) +",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3816",
    "text": "d h(*)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3817",
    "text": "#ERROR!",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3818",
    "text": "d o(t)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3819",
    "text": "(Vo",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3820",
    "text": "^1\u2014(h(m)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3821",
    "text": "+ V T (V o:t) L)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3822",
    "text": "-10.2",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3823",
    "text": "-10.21",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3824",
    "text": "where diag 1 \u2014 (h(t+1) \u00a0\u00a0\u00a0indicates the diagonal matrix containing the elements",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3825",
    "text": "1 \u2014 (h(t+1) )2. This is the Jacobian of the hyperbolic tangent associated with the hidden unit i at time t + 1 .",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3826",
    "text": "Once the gradients on the internal nodes of the computational graph are obtained, we can obtain the gradients on the parameter nodes. Because the\u00a0parameters are shared across many time steps, we must take some care when\u00a0denoting calculus operations involving these variables. The equations we wish to\u00a0implement use the bprop method of Sec. 6.5.6, that computes the contribution\u00a0of a single edge in the computational graph to the gradient. However, the Vwf\u00a0operator used in calculus takes into account the contribution of W to the value\u00a0of f due to all edges in the computational graph. To resolve this ambiguity, we\u00a0introduce dummy variables W(t) that are defined to be copies of W but with each\u00a0W(t) used only at time step t. We may then use V w(.) to denote the contribution\u00a0of the weights at time step t to the gradient.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3827",
    "text": "Using this notation, the gradient on the remaining parameters is given by:",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3828",
    "text": "VcL",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3829",
    "text": "VbL",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3830",
    "text": "Vv L V w L",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3831",
    "text": "E (* \u00a0\u00a0\u00a0V\u05f4WL = \u00a3 V0WL",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3832",
    "text": "E (S) \"Vh(.)L = E diag (1 - (h(t))) Vh(.)L EE(go) VvO7 = E (Vo(.)L)h(t)T",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3833",
    "text": "E \u00a0\u00a0\u00a0V W - \"",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3834",
    "text": "E diag 1 - (h(t) )2) (Vh(.)L) h(t-1)T",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3835",
    "text": "V\u05f4L =",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3836",
    "text": "dL",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3837",
    "text": "V\u05f4)\u05f4 h(t)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3838",
    "text": "\u05f4(t) 'I 2'",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3839",
    "text": "dh((t)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3840",
    "text": "diag ^1 - \u00a0\u00a0\u00a0^ (Vh(t)L) x(t)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3841",
    "text": "T",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3842",
    "text": "-10.22",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3843",
    "text": "-10.23",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3844",
    "text": "-10.24",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3845",
    "text": "-10.25",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3846",
    "text": "-10.26",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3847",
    "text": "-10.27",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3848",
    "text": "-10.28",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3849",
    "text": "We do not need to compute the gradient with respect to x(t) for training because it does not have any parameters as ancestors in the computational graph defining\u00a0the loss.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3850",
    "text": "In the example recurrent network we have developed so far, the losses L(t) were cross-entropies between training targets y(t) and outputs o(t). As with a feedforward\u00a0network, it is in principle possible to use almost any loss with a recurrent network.\u00a0The loss should be chosen based on the task. As with a feedforward network, we\u00a0usually wish to interpret the output of the RNN as a probability distribution, and\u00a0we usually use the cross-entropy associated with that distribution to define the loss.\u00a0Mean squared error is the cross-entropy loss associated with an output distribution\u00a0that is a unit Gaussian, for example, just as with a feedforward network.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3851",
    "text": "When we use a predictive log-likelihood training objective, such as Eq. 10.12, we train the RNN to estimate the conditional distribution of the next sequence element\u00a0y(t) given the past inputs. This may mean that we maximize the log-likelihood",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3852",
    "text": "logp(y(t) | x(1),..., x(t)), \u00a0\u00a0\u00a0(10.29)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3853",
    "text": "or, if the model includes connections from the output at one time step to the next time step,",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3854",
    "text": "log p(y(t) | x(1),..., x(t), y(1),..., y(t-1)). \u00a0\u00a0\u00a0(10.30)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3855",
    "text": "Decomposing the joint probability over the sequence of y values as a series of one-step probabilistic predictions is one way to capture the full joint distribution\u00a0across the whole sequence. When we do not feed past y values as inputs that\u00a0condition the next step prediction, the directed graphical model contains no edges\u00a0from any y(i) in the past to the current y(t) . In this case, the outputs y are\u00a0conditionally independent given the sequence of x values. When we do feed the\u00a0actual y values (not their prediction, but the actual observed or generated values)\u00a0back into the network, the directed graphical model contains edges from all y(i)\u00a0values in the past to the current y^ value.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3856",
    "text": " \u2713",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3857",
    "text": "\u05d0 \u2713",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3858",
    "text": "\u2713 \u00a0\u00a0\u00a0N",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3859",
    "text": "Figure 10.7: Fully connected graphical model for a sequencey(1),y(2),... ,y(t),...: every past observation yW may influence the conditional distribution of some y(t) (for t > i),\u00a0given the previous values. Parametrizing the graphical model directly according to this\u00a0graph (as in Eq. 10.6) might be very inefficient, with an ever growing number of inputs\u00a0and parameters for each element of the sequence. RNNs obtain the same full connectivity\u00a0but efficient parametrization, as illustrated in Fig. 10.8.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3860",
    "text": "As a simple example, let us consider the case where the RNN models only a sequence of scalar random variables Y = {y(1),..., y(t)}, with no additional inputs\u00a0x. The input at time step t is simply the output at time step t \u2014 1. The RNN then\u00a0defines a directed graphical model over the y variables. We parametrize the joint\u00a0distribution of these observations using the chain rule (Eq. 3.6) for conditional\u00a0probabilities:",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3861",
    "text": "p(y) = P(y(1),...,yT)) = nP(y(t) Iy(t-1)\u05f3y(t-2)\u05f3\u2022\u2022\u2022\u05f3y(1)) \u00a0\u00a0\u00a0(10-31)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3862",
    "text": "t=1",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3863",
    "text": "where the right-hand side of the bar is empty for t = 1, of course. Hence the negative log-likelihood of a set of values {y(1),..., y (t)} according to such a model\u00a0is",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3864",
    "text": "L \u00a0\u00a0\u00a0L(t)\u00a0\u00a0\u00a0\u00a0(10.32)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3865",
    "text": "where",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3866",
    "text": "L(t) = \u2014 logP(y(t) = y(t) | y(t-1),y(t2\u05be),...,y(1)).",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3867",
    "text": "-10.33",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3868",
    "text": "Figure 10.8: Introducing the state variable in the graphical model of the RNN, even though it is a deterministic function of its inputs, helps to see how we can obtain a very\u00a0efficient parametrization, based on Eq. 10.5. Every stage in the sequence (for and",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3869",
    "text": ") involves the same structure (the same number of inputs for each node) and can share the same parameters with the other stages.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3870",
    "text": "The edges in a graphical model indicate which variables depend directly on other variables. Many graphical models aim to achieve statistical and computational\u00a0efficiency by omitting edges that do not correspond to strong interactions. For\u00a0example, it is common to make the Markov assumption that the graphical model\u00a0should only contain edges from {y(t-k),..., y(t-1)} to y(t), rather than containing\u00a0edges from the entire past history. However, in some cases, we believe that all past\u00a0inputs should have an influence on the next element of the sequence. RNNs are\u00a0useful when we believe that the distribution over y(t) may depend on a value of y(i)\u00a0from the distant past in a way that is not captured by the effect of yW on y(t-1).",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3871",
    "text": "One way to interpret an RNN as a graphical model is to view the RNN as defining a graphical model whose structure is the complete graph, able to represent\u00a0direct dependencies between any pair of y values. The graphical model over the\u00a0y values with the complete graph structure is shown in Fig. 10.7. The complete\u00a0graph interpretation of the RNN is based on ignoring the hidden units h(t) by\u00a0marginalizing them out of the model.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3872",
    "text": "It is more interesting to consider the graphical model structure of RNNs that results from regarding the hidden units h(t) as random variables.1 Including the\u00a0hidden units in the graphical model reveals that the RNN provides a very efficient\u00a0parametrization of the joint distribution over the observations. Suppose that we\u00a0represented an arbitrary joint distribution over discrete values with a tabular\u00a0representation\u2014an array containing a separate entry for each possible assignment\u00a0of values, with the value of that entry giving the probability of that assignment\u00a0occurring. If y can take on k different values, the tabular representation would\u00a0have O(kT) parameters. By comparison, due to parameter sharing, the number\u00a0of parameters in the RNN is O(1) as a function of sequence length. The number\u00a0of parameters in the RNN may be adjusted to control model capacity but is not\u00a0forced to scale with sequence length. Eq. 10.5 shows that the RNN parametrizes\u00a0long-term relationships between variables efficiently, using recurrent applications\u00a0of the same function f and same parameters 6 at each time step. Fig. 10.8\u00a0illustrates the graphical model interpretation. Incorporating the h(t) nodes in\u00a0the graphical model decouples the past and the future, acting as an intermediate\u00a0quantity between them. A variable yin the distant past may influence a variable\u00a0y(t) via its effect on h. The structure of this graph shows that the model can be\u00a0efficiently parametrized by using the same conditional probability distributions at\u00a0each time step, and that when the variables are all observed, the probability of the\u00a0joint assignment of all variables can be evaluated efficiently.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3873",
    "text": "Even with the efficient parametrization of the graphical model, some operations remain computationally challenging. For example, it is difficult to predict missing\u00a0values in the middle of the sequence.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3874",
    "text": "The price recurrent networks pay for their reduced number of parameters is that optimizing the parameters may be difficult.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3875",
    "text": "The parameter sharing used in recurrent networks relies on the assumption that the same parameters can be used for different time steps. Equivalently, the\u00a0assumption is that the conditional probability distribution over the variables at\u00a0time t + 1 given the variables at time t is stationary, meaning that the relationship\u00a0between the previous time step and the next time step does not depend on t. In\u00a0principle, it would be possible to use t as an extra input at each time step and let\u00a0the learner discover any time-dependence while sharing as much as it can between\u00a0different time steps. This would already be much better than using a different\u00a0conditional probability distribution for each t, but the network would then have to\u00a0extrapolate when faced with new values of t.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3876",
    "text": "To complete our view of an RNN as a graphical model, we must describe how to draw samples from the model. The main operation that we need to perform is\u00a0simply to sample from the conditional distribution at each time step. However,\u00a0there is one additional complication. The RNN must have some mechanism for\u00a0determining the length of the sequence. This can be achieved in various ways.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3877",
    "text": "In the case when the output is a symbol taken from a vocabulary, one can add a special symbol corresponding to the end of a sequence (Schmidhuber, 2012).\u00a0When that symbol is generated, the sampling process stops. In the training set,\u00a0we insert this symbol as an extra member of the sequence, immediately after x(t)\u00a0in each training example.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3878",
    "text": "Another option is to introduce an extra Bernoulli output to the model that represents the decision to either continue generation or halt generation at each\u00a0time step. This approach is more general than the approach of adding an extra\u00a0symbol to the vocabulary, because it may be applied to any RNN, rather than\u00a0only RNNs that output a sequence of symbols. For example, it may be applied to\u00a0an RNN that emits a sequence of real numbers. The new output unit is usually a\u00a0sigmoid unit trained with the cross-entropy loss. In this approach the sigmoid is\u00a0trained to maximize the log-probability of the correct prediction as to whether the\u00a0sequence ends or continues at each time step.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3879",
    "text": "Another way to determine the sequence length t is to add an extra output to the model that predicts the integer t itself. The model can sample a value of t\u00a0and then sample t steps worth of data. This approach requires adding an extra\u00a0input to the recurrent update at each time step so that the recurrent update is\u00a0aware of whether it is near the end of the generated sequence. This extra input\u00a0can either consist of the value of t or can consist of t \u2014 t, the number of remaining\u00a0time steps. Without this extra input, the RNN might generate sequences that\u00a0end abruptly, such as a sentence that ends before it is complete. This approach is\u00a0based on the decomposition",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3880",
    "text": "P(x(1),...,x(t)) = P(t)P(x(1),...,x(t) | t). \u00a0\u00a0\u00a0(10.34)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3881",
    "text": "The strategy of predicting t directly is used for example by Goodfellow et al.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3882",
    "text": "(2014d).",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3883",
    "text": "In the previous section we described how an RNN could correspond to a directed graphical model over a sequence of random variables y(t) with no inputs x. Of\u00a0course, our development of RNNs as in Eq. 10.8 included a sequence of inputs\u00a0x(1), x(2),..., x(t) . In general, RNNs allow the extension of the graphical model\u00a0view to represent not only a joint distribution over the y variables but also a\u00a0conditional distribution over y given x. As discussed in the context of feedforward\u00a0networks in Sec. 6.2.1.1, any model representing a variable P (y; 6) can be reinterpreted as a model representing a conditional distribution P(y \\u) with u = 6. We\u00a0can extend such a model to represent a distribution P(y \\ x) by using the same\u00a0P(y \\ u) as before, but making u a function of x. In the case of an RNN, this\u00a0can be achieved in different ways. We review here the most common and obvious\u00a0choices.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3884",
    "text": "Previously, we have discussed RNNs that take a sequence of vectors x(t) for t = 1,..., t as input. Another option is to take only a single vector x as input.\u00a0When x is a fixed-size vector, we can simply make it an extra input of the RNN\u00a0that generates the y sequence. Some common ways of providing an extra input to\u00a0an RNN are:",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3885",
    "text": "1. \u00a0\u00a0\u00a0as an extra input at each time step, or",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3886",
    "text": "2. \u00a0\u00a0\u00a0as the initial state h(0), or",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3887",
    "text": "3. \u00a0\u00a0\u00a0both.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3888",
    "text": "The first and most common approach is illustrated in Fig. 10.9. The interaction between the input x and each hidden unit vector is parametrized by a newly\u00a0introduced weight matrix R that was absent from the model of only the sequence\u00a0of y values. The same product xTR is added as additional input to the hidden\u00a0units at every time step. We can think of the choice of x as determining the value\u00a0of xtR that is effectively a new bias parameter used for each of the hidden units.\u00a0The weights remain independent of the input. We can think of this model as taking\u00a0the parameters 6 of the non-conditional model and turning them into u, where\u00a0the bias parameters within u are now a function of the input.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3889",
    "text": "Rather than receiving only a single vector x as input, the RNN may receive a sequence of vectors x(t) as input. The RNN described in Eq. 10.8 corresponds to a",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3890",
    "text": "Figure 10.9: An RNN that maps a fixed-length vectorx into a distribution over sequences Y. This RNN is appropriate for tasks such as image captioning, where a single image is\u00a0used as input to a model that then produces a sequence of words describing the image.\u00a0Each element y(t) of the observed output sequence serves both as input (for the current\u00a0time step) and, during training, as target (for the previous time step).",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3891",
    "text": "Figure 10.10: A conditional recurrent neural network mapping a variable-length sequence of x values into a distribution over sequences of y values of the same length. Compared\u00a0to Fig. 10.3, this RNN contains connections from the previous output to the current state.\u00a0These connections allow this RNN to model an arbitrary distribution over sequences ofy\u00a0given sequences of x of the same length. The RNN of Fig. 10.3 is only able to represent\u00a0distributions in which the y values are conditionally independent from each other given\u00a0the x values.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3892",
    "text": "conditional distribution P(y(1),..., y(r) | x(1),..., x(t)) that makes a conditional independence assumption that this distribution factorizes as",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3893",
    "text": "JJP(y(t) | x(1)x(t)). \u00a0\u00a0\u00a0(10.35)",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3894",
    "text": "t",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3895",
    "text": "To remove the conditional independence assumption, we can add connections from the output at time t to the hidden unit at time t +1, as shown in Fig. 10.10. The\u00a0model can then represent arbitrary probability distributions over the y sequence.\u00a0This kind of model representing a distribution over a sequence given another\u00a0sequence still has one restriction, which is that the length of both sequences must\u00a0be the same. We describe how to remove this restriction in Sec. 10.4.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3896",
    "text": "Figure 10.11: Computation of a typical bidirectional recurrent neural network, meant to learn to map input sequences x to target sequences y, with loss at each step t.\u00a0The h recurrence propagates information forward in time (towards the right) while the\u00a0g recurrence propagates information backward in time (towards the left). Thus at each\u00a0point t, the output units o(t) can benefit from a relevant summary of the past in its h(t)\u00a0input and from a relevant summary of the future in its g(t) input.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3897",
    "text": "All of the recurrent networks we have considered up to now have a \u201ccausal\u201d structure, meaning that the state at time t only captures information from the past, x(1),..., x(t-1), and the present input x(t). Some of the models we have discussed\u00a0also allow information from past y values to affect the current state when the y\u00a0values are available.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3898",
    "text": "However, in many applications we want to output a prediction of y(t) which may depend on the whole input sequence. For example, in speech recognition,\u00a0the correct interpretation of the current sound as a phoneme may depend on the\u00a0next few phonemes because of co-articulation and potentially may even depend on\u00a0the next few words because of the linguistic dependencies between nearby words: if\u00a0there are two interpretations of the current word that are both acoustically plausible,\u00a0we may have to look far into the future (and the past) to disambiguate them.\u00a0This is also true of handwriting recognition and many other sequence-to-sequence\u00a0learning tasks, described in the next section.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3899",
    "text": "Bidirectional recurrent neural networks (or bidirectional RNNs) were invented to address that need (Schuster and Paliwal, 1997). They have been extremely successful (Graves, 2012) in applications where that need arises, such as handwriting\u00a0recognition (Graves et al., 2008; Graves and Schmidhuber, 2009), speech recognition (Graves and Schmidhuber, 2005; Graves et al., 2013) and bioinformatics (Baldi\u00a0et al., 1999).",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3900",
    "text": "As the name suggests, bidirectional RNNs combine an RNN that moves forward through time beginning from the start of the sequence with another RNN that\u00a0moves backward through time beginning from the end of the sequence. Fig. 10.11\u00a0illustrates the typical bidirectional RNN, with standing for the state of the\u00a0sub-RNN that moves forward through time and g(t) standing for the state of the\u00a0sub-RNN that moves backward through time. This allows the output units o(t) to\u00a0compute a representation that depends on both the past and the future but\u00a0is most sensitive to the input values around time t, without having to specify a\u00a0fixed-size window around t (as one would have to do with a feedforward network,\u00a0a convolutional network, or a regular RNN with a fixed-size look-ahead buffer).",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3901",
    "text": "This idea can be naturally extended to 2-dimensional input, such as images, by having four RNNs, each one going in one of the four directions: up, down,\u00a0left, right. At each point (i, j) of a 2-D grid, an output Oi,j could then compute a\u00a0representation that would capture mostly local information but could also depend\u00a0on long-range inputs, if the RNN is able to learn to carry that information.\u00a0Compared to a convolutional network, RNNs applied to images are typically more\u00a0expensive but allow for long-range lateral interactions between features in the\u00a0same feature map (Visin et al., 2015; Kalchbrenner et al., 2015). Indeed, the\u00a0forward propagation equations for such RNNs may be written in a form that shows\u00a0they use a convolution that computes the bottom-up input to each layer, prior\u00a0to the recurrent propagation across the feature map that incorporates the lateral\u00a0interactions.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3902",
    "text": "We have seen in Fig. 10.5 how an RNN can map an input sequence to a fixed-size vector. We have seen in Fig. 10.9 how an RNN can map a fixed-size vector to a\u00a0sequence. We have seen in Fig. 10.3, Fig. 10.4, Fig. 10.10 and Fig. 10.11 how an\u00a0RNN can map an input sequence to an output sequence of the same length.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3903",
    "text": "Here we discuss how an RNN can be trained to map an input sequence to an output sequence which is not necessarily of the same length. This comes up in\u00a0many applications, such as speech recognition, machine translation or question\u00a0answering, where the input and output sequences in the training set are generally\u00a0not of the same length (although their lengths might be related).",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3904",
    "text": "We often call the input to the RNN the \u201ccontext.\u201d We want to produce a representation of this context, C. The context C might be a vector or sequence of\u00a0vectors that summarize the input sequence X = (a^1),..., x)).",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3905",
    "text": "The simplest RNN architecture for mapping a variable-length sequence to another variable-length sequence was first proposed by Cho et al. (2014a) and shortly after by Sutskever et al. (2014), who independently developed that architecture and\u00a0were the first to obtain state-of-the-art translation using this approach. The former\u00a0system is based on scoring proposals generated by another machine translation\u00a0system, while the latter uses a standalone recurrent network to generate the translations. These authors respectively called this architecture, illustrated in Fig. 10.12,\u00a0the encoder-decoder or sequence-to-sequence architecture. The idea is very simple:\u00a0(1) an encoder or reader or input RNN processes the input sequence. The encoder\u00a0emits the context C, usually as a simple function of its final hidden state. (2) a\u00a0decoder or writer or output RNN is conditioned on that fixed-length vector (just like\u00a0in Fig. 10.9) to generate the output sequence Y = (y(1),..., y)). The innovation\u00a0of this kind of architecture over those presented in earlier sections of this chapter is\u00a0that the lengths nx and ny can vary from each other, while previous architectures\u00a0constrained nx = ny = t. In a sequence-to-sequence architecture, the two RNNs",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3906",
    "text": "Figure 10.12: Example of an encoder-decoder or sequence-to-sequence RNN architecture, for learning to generate an output sequence (y(1),...,y(ny)) given an input sequence\u00a0(x(1), x(2),..., x(nx)). It is composed of an encoder RNN that reads the input sequence\u00a0and a decoder RNN that generates the output sequence (or computes the probability of a\u00a0given output sequence). The final hidden state of the encoder RNN is used to compute a\u00a0generally fixed-size context variable C which represents a semantic summary of the input\u00a0sequence and is given as input to the decoder RNN.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3907",
    "text": "are trained jointly to maximize the average of log P (y(1),..., y(ny) | x(1),..., x(nx)) over all the pairs of x and y sequences in the training set. The last state hx of\u00a0the encoder RNN is typically used as a representation C of the input sequence\u00a0that is provided as input to the decoder RNN.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3908",
    "text": "If the context C is a vector, then the decoder RNN is simply a vector-to-sequence RNN as described in Sec. 10.2.4. As we have seen, there are at least two ways for a vector-to-sequence RNN to receive input. The input can be provided as\u00a0the initial state of the RNN, or the input can be connected to the hidden units at\u00a0each time step. These two ways can also be combined.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3909",
    "text": "There is no constraint that the encoder must have the same size of hidden layer as the decoder.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3910",
    "text": "One clear limitation of this architecture is when the context C output by the encoder RNN has a dimension that is too small to properly summarize a long\u00a0sequence. This phenomenon was observed by Bahdanau et al. (2015) in the context\u00a0of machine translation. They proposed to make C a variable-length sequence rather\u00a0than a fixed-size vector. Additionally, they introduced an attention mechanism\u00a0that learns to associate elements of the sequence C to elements of the output\u00a0sequence. See Sec. 12.4.5.1 for more details.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3911",
    "text": "1",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3912",
    "text": " The conditional distribution over these variables given their parents is deterministic. This is perfectly legitimate, though it is somewhat rare to design a graphical model with such deterministic\u00a0hidden units.",
    "chapter": "Confronting the Partition Function",
    "chapter_id": "main-21.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3913",
    "text": "The computation in most RNNs can be decomposed into three blocks of parameters and associated transformations:",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3914",
    "text": "1. \u00a0\u00a0\u00a0from the input to the hidden state,",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3915",
    "text": "2. \u00a0\u00a0\u00a0from the previous hidden state to the next hidden state, and",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3916",
    "text": "3. \u00a0\u00a0\u00a0from the hidden state to the output.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3917",
    "text": "With the RNN architecture of Fig. 10.3, each of these three blocks is associated with a single weight matrix. In other words, when the network is unfolded, each\u00a0of these corresponds to a shallow transformation. By a shallow transformation,\u00a0we mean a transformation that would be represented by a single layer within\u00a0a deep MLP. Typically this is a transformation represented by a learned affine\u00a0transformation followed by a fixed nonlinearity.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3918",
    "text": "Would it be advantageous to introduce depth in each of these operations? Experimental evidence (Graves et al., 2013; Pascanu et al., 2014a) strongly suggests\u00a0so. The experimental evidence is in agreement with the idea that we need enough",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3919",
    "text": "Figure 10.13: A recurrent neural network can be made deep in many ways (Pascanu et al., 2014a). (a) The hidden recurrent state can be broken down into groups organized\u00a0hierarchically. (b) Deeper computation (e.g., an MLP) can be introduced in the input-to-hidden, hidden-to-hidden and hidden-to-output parts. This may lengthen the shortest\u00a0path linking different time steps. (c) The path-lengthening effect can be mitigated by\u00a0introducing skip connections.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3920",
    "text": "depth in order to perform the required mappings. See also Schmidhuber (1992), El Hihi and Bengio (1996), or Jaeger (2007a) for earlier work on deep RNNs.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3921",
    "text": "Graves et al. (2013) were the first to show a significant benefit of decomposing the state of an RNN into multiple layers as in Fig. 10.13 (left). We can think\u00a0of the lower layers in the hierarchy depicted in Fig. 10.13a as playing a role in\u00a0transforming the raw input into a representation that is more appropriate, at\u00a0the higher levels of the hidden state. Pascanu et al. (2014a) go a step further\u00a0and propose to have a separate MLP (possibly deep) for each of the three blocks\u00a0enumerated above, as illustrated in Fig. 10.13b. Considerations of representational\u00a0capacity suggest to allocate enough capacity in each of these three steps, but doing\u00a0so by adding depth may hurt learning by making optimization difficult. In general,\u00a0it is easier to optimize shallower architectures, and adding the extra depth of\u00a0Fig. 10.13b makes the shortest path from a variable in time step t to a variable\u00a0in time step t + 1 become longer. For example, if an MLP with a single hidden\u00a0layer is used for the state-to-state transition, we have doubled the length of the\u00a0shortest path between variables in any two different time steps, compared with the\u00a0ordinary RNN of Fig. 10.3. However, as argued by Pascanu et al. (2014a), this\u00a0can be mitigated by introducing skip connections in the hidden-to-hidden path, as\u00a0illustrated in Fig. 10.13c.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3922",
    "text": "Recursive neural networks1 represent yet another generalization of recurrent networks, with a different kind of computational graph, which is structured as a deep tree, rather than the chain-like structure of RNNs. The typical computational\u00a0graph for a recursive network is illustrated in Fig. 10.14. Recursive neural networks\u00a0were introduced by Pollack (1990) and their potential use for learning to reason\u00a0was described by by Bottou (2011). Recursive networks have been successfully\u00a0applied to processing data structures as input to neural nets (Frasconi et al.,\u00a01997, 1998), in natural language processing (Socher et al., 2011a,c, 2013a) as well\u00a0as in computer vision (Socher et al., 2011b).",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3923",
    "text": "One clear advantage of recursive nets over recurrent nets is that for a sequence of the same length t, the depth (measured as the number of compositions of\u00a0nonlinear operations) can be drastically reduced from t to O(logt), which might\u00a0help deal with long-term dependencies. An open question is how to best structure\u00a0the tree. One option is to have a tree structure which does not depend on the data,",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3924",
    "text": "Figure 10.14: A recursive network has a computational graph that generalizes that of the recurrent network from a chain to a tree. A variable-size sequencex(1), x(2),. .., x(t) can\u00a0be mapped to a fixed-size representation (the output o), with a fixed set of parameters\u00a0(the weight matrices U, V, W). The figure illustrates a supervised learning case in which\u00a0some target y is provided which is associated with the whole sequence.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3925",
    "text": "such as a balanced binary tree. In some application domains, external methods can suggest the appropriate tree structure. For example, when processing natural\u00a0language sentences, the tree structure for the recursive network can be fixed to\u00a0the structure of the parse tree of the sentence provided by a natural language\u00a0parser (Socher et al., 2011a, 2013a). Ideally, one would like the learner itself to\u00a0discover and infer the tree structure that is appropriate for any given input, as\u00a0suggested by Bottou (2011).",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3926",
    "text": "Many variants of the recursive net idea are possible. For example, Frasconi et al. (1997) and Frasconi et al. (1998) associate the data with a tree structure,\u00a0and associate the inputs and targets with individual nodes of the tree. The\u00a0computation performed by each node does not have to be the traditional artificial\u00a0neuron computation (affine transformation of all inputs followed by a monotone\u00a0nonlinearity). For example, Socher et al. (2013a) propose using tensor operations\u00a0and bilinear forms, which have previously been found useful to model relationships\u00a0between concepts (Weston et al., 2010; Bordes et al., 2012) when the concepts are\u00a0represented by continuous vectors (embeddings).",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3927",
    "text": "The mathematical challenge of learning long-term dependencies in recurrent networks was introduced in Sec. 8.2.5. The basic problem is that gradients propagated over many stages tend to either vanish (most of the time) or explode (rarely, but\u00a0with much damage to the optimization). Even if we assume that the parameters are\u00a0such that the recurrent network is stable (can store memories, with gradients not\u00a0exploding), the difficulty with long-term dependencies arises from the exponentially\u00a0smaller weights given to long-term interactions (involving the multiplication of\u00a0many Jacobians) compared to short-term ones. Many other sources provide a\u00a0deeper treatment (Hochreiter, 1991; Doya, 1993; Bengio et al., 1994; Pascanu et al.,\u00a02013a) . In this section, we describe the problem in more detail. The remaining\u00a0sections describe approaches to overcoming the problem.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3928",
    "text": "Recurrent networks involve the composition of the same function multiple times, once per time step. These compositions can result in extremely nonlinear\u00a0behavior, as illustrated in Fig. 10.15.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3929",
    "text": "In particular, the function composition employed by recurrent neural networks somewhat resembles matrix multiplication. We can think of the recurrence relation",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3930",
    "text": "h(t) = w Th(t-1) \u00a0\u00a0\u00a0(10.36)",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3931",
    "text": "as a very simple recurrent neural network lacking a nonlinear activation function,",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3932",
    "text": "4 3\u00a02\u00a01\u00a00\u00a01\u00a02",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3933",
    "text": "3",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3934",
    "text": "4",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3935",
    "text": "Repeated function composition",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3936",
    "text": "60 \u00a0\u00a0\u00a040\u00a0\u00a0\u00a0\u00a020\u00a0\u00a0\u00a0\u00a00\u00a0\u00a0\u00a0\u00a020\u00a0\u00a0\u00a0\u00a040\u00a0\u00a0\u00a0\u00a060",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3937",
    "text": "Input coordinate",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3938",
    "text": "Figure 10.15: When composing many nonlinear functions (like the lineartanh layer shown here), the result is highly nonlinear, typically with most of the values associated with a tiny\u00a0derivative, some values with a large derivative, and many alternations between increasing\u00a0and decreasing. In this plot, we plot a linear projection of a 100-dimensional hidden state\u00a0down to a single dimension, plotted on the y-axis. The x-axis is the coordinate of the\u00a0initial state along a random direction in the 100-dimensional space. We can thus view this\u00a0plot as a linear cross-section of a high-dimensional function. The plots show the function\u00a0after each time step, or equivalently, after each number of times the transition function\u00a0has been composed.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3939",
    "text": "and lacking inputs x. As described in Sec. 8.2.5, this recurrence relation essentially describes the power method. It may be simplified to",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3940",
    "text": "h(t) = (W)T h(0), \u00a0\u00a0\u00a0(10.37)",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3941",
    "text": "and if W admits an eigendecomposition of the form",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3942",
    "text": "W = QAQt , \u00a0\u00a0\u00a0(10.38)",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3943",
    "text": "with orthogonal Q, the recurrence may be simplified further to",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3944",
    "text": "h(t) = QtAtQh(0). \u00a0\u00a0\u00a0(10.39)",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3945",
    "text": "The eigenvalues are raised to the power of t causing eigenvalues with magnitude less than one to decay to zero and eigenvalues with magnitude greater than one to\u00a0explode. Any component of h(0) that is not aligned with the largest eigenvector\u00a0will eventually be discarded.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3946",
    "text": "This problem is particular to recurrent networks. In the scalar case, imagine multiplying a weight w by itself many times. The product wt will either vanish or\u00a0explode depending on the magnitude of w\u2022 However, if we make a non-recurrent\u00a0network that has a different weight w(t) at each time step, the situation is different.\u00a0If the initial state is given by 1, then the state at time t is given by nt w(t). Suppose\u00a0that the w(t) values are generated randomly, independently from one another, with\u00a0zero mean and variance v. The variance of the product is O(vn). To obtain some\u00a0desired variance v* we may choose the individual weights with variance v = nv*.\u00a0Very deep feedforward networks with carefully chosen scaling can thus avoid the\u00a0vanishing and exploding gradient problem, as argued by Sussillo (2014).",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3947",
    "text": "The vanishing and exploding gradient problem for RNNs was independently discovered by separate researchers (Hochreiter, 1991; Bengio et al., 1993, 1994).\u00a0One may hope that the problem can be avoided simply by staying in a region of\u00a0parameter space where the gradients do not vanish or explode. Unfortunately, in\u00a0order to store memories in a way that is robust to small perturbations, the RNN\u00a0must enter a region of parameter space where gradients vanish (Bengio et al., 1993,\u00a01994). Specifically, whenever the model is able to represent long term dependencies,\u00a0the gradient of a long term interaction has exponentially smaller magnitude than\u00a0the gradient of a short term interaction. It does not mean that it is impossible\u00a0to learn, but that it might take a very long time to learn long-term dependencies,\u00a0because the signal about these dependencies will tend to be hidden by the smallest\u00a0fluctuations arising from short-term dependencies. In practice, the experiments\u00a0in Bengio et al. (1994) show that as we increase the span of the dependencies that\u00a0need to be captured, gradient-based optimization becomes increasingly difficult,\u00a0with the probability of successful training of a traditional RNN via SGD rapidly\u00a0reaching 0 for sequences of only length 10 or 20.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3948",
    "text": "For a deeper treatment of recurrent networks as dynamical systems, see Doya (1993), Bengio et al. (1994) and Siegelmann and Sontag (1995), with a review\u00a0in Pascanu et al. (2013a). The remaining sections of this chapter discuss various\u00a0approaches that have been proposed to reduce the difficulty of learning longterm dependencies (in some cases allowing an RNN to learn dependencies across\u00a0hundreds of steps), but the problem of learning long-term dependencies remains\u00a0one of the main challenges in deep learning.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3949",
    "text": "The recurrent weights mapping from h(t-1) to h(t) and the input weights mapping from to h(t) are some of the most difficult parameters to learn in a recurrent\u00a0network. One proposed (Jaeger, 2003; Maass et al., 2002; Jaeger and Haas, 2004;\u00a0Jaeger, 2007b) approach to avoiding this difficulty is to set the recurrent weights\u00a0such that the recurrent hidden units do a good job of capturing the history of\u00a0past inputs, and only learn the output weights. This is the idea that was\u00a0independently proposed for echo state networks or ESNs (Jaeger and Haas, 2004;\u00a0Jaeger, 2007b) and liquid state machines (Maass et al., 2002). The latter is similar,\u00a0except that it uses spiking neurons (with binary outputs) instead of the continuousvalued hidden units used for ESNs. Both ESNs and liquid state machines are\u00a0termed reservoir computing (Lukosevicius and Jaeger, 2009) to denote the fact\u00a0that the hidden units form of reservoir of temporal features which may capture\u00a0different aspects of the history of inputs.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3950",
    "text": "One way to think about these reservoir computing recurrent networks is that they are similar to kernel machines: they map an arbitrary length sequence (the\u00a0history of inputs up to time t) into a fixed-length vector (the recurrent state h(t)),\u00a0on which a linear predictor (typically a linear regression) can be applied to solve\u00a0the problem of interest. The training criterion may then be easily designed to be\u00a0convex as a function of the output weights. For example, if the output consists\u00a0of linear regression from the hidden units to the output targets, and the training\u00a0criterion is mean squared error, then it is convex and may be solved reliably with\u00a0simple learning algorithms (Jaeger, 2003).",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3951",
    "text": "The important question is therefore: how do we set the input and recurrent weights so that a rich set of histories can be represented in the recurrent neural\u00a0network state? The answer proposed in the reservoir computing literature is to\u00a0view the recurrent net as a dynamical system, and set the input and recurrent\u00a0weights such that the dynamical system is near the edge of stability.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3952",
    "text": "The original idea was to make the eigenvalues of the Jacobian of the state-to-state transition function be close to 1. As explained in Sec. 8.2.5, an important characteristic of a recurrent network is the eigenvalue spectrum of the Jacobians\u00a0J= dSs-1). Of particular importance is the spectral radius of J, defined to be\u00a0the maximum of the absolute values of its eigenvalues.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3953",
    "text": "To understand the effect of the spectral radius, consider the simple case of back-propagation with a Jacobian matrix J that does not change with t. This\u00a0case happens, for example, when the network is purely linear. Suppose that J has\u00a0an eigenvector v with corresponding eigenvalue A. Consider what happens as we\u00a0propagate a gradient vector backwards through time. If we begin with a gradient\u00a0vector g, then after one step of back-propagation, we will have Jg, and after n\u00a0steps we will have Jng. Now consider what happens if we instead back-propagate\u00a0a perturbed version of g. If we begin with g + 5v, then after one step, we will\u00a0have J (g + Sv). After n steps, we will have Jn(g + Sv). From this we can see\u00a0that back-propagation starting from g and back-propagation starting from g + Sv\u00a0diverge by SJnv after n steps of back-propagation. If v is chosen to be a unit\u00a0eigenvector of J with eigenvalue A, then multiplication by the Jacobian simply\u00a0scales the difference at each step. The two executions of back-propagation are\u00a0separated by a distance of S|A|n. When v corresponds to the largest value of | A|,\u00a0this perturbation achieves the widest possible separation of an initial perturbation\u00a0of size S.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3954",
    "text": "When |A| > 1, the deviation size S|A|n grows exponentially large. When |A| < 1, the deviation size becomes exponentially small.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3955",
    "text": "Of course, this example assumed that the Jacobian was the same at every time step, corresponding to a recurrent network with no nonlinearity. When a\u00a0nonlinearity is present, the derivative of the nonlinearity will approach zero on\u00a0many time steps, and help to prevent the explosion resulting from a large spectral\u00a0radius. Indeed, the most recent work on echo state networks advocates using a\u00a0spectral radius much larger than unity (Yildiz et al., 2012; Jaeger, 2012).",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3956",
    "text": "Everything we have said about back-propagation via repeated matrix multiplication applies equally to forward propagation in a network with no nonlinearity, where the state h(t+1) = h(t)TW.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3957",
    "text": "When a linear map WT always shrinks h as measured by the L2 norm, then we say that the map is contractive. When the spectral radius is less than one, the\u00a0mapping from h(t) to h(t+1) is contractive, so a small change becomes smaller after\u00a0each time step. This necessarily makes the network forget information about the\u00a0past when we use a finite level of precision (such as 32 bit integers) to store the\u00a0state vector.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3958",
    "text": "The Jacobian matrix tells us how a small change of h(t) propagates one step forward, or equivalently, how the gradient on h(t+11 propagates one step backward,\u00a0during back-propagation. Note that neither W nor J need to be symmetric (although they are square and real), so they can have complex-valued eigenvalues and\u00a0eigenvectors, with imaginary components corresponding to potentially oscillatory\u00a0behavior (if the same Jacobian was applied iteratively). Even though h(t) or a\u00a0small variation of hof interest in back-propagation are real-valued, they can\u00a0be expressed in such a complex-valued basis. What matters is what happens to\u00a0the magnitude (complex absolute value) of these possibly complex-valued basis\u00a0coefficients, when we multiply the matrix by the vector. An eigenvalue with\u00a0magnitude greater than one corresponds to magnification (exponential growth, if\u00a0applied iteratively) or shrinking (exponential decay, if applied iteratively).",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3959",
    "text": "With a nonlinear map, the Jacobian is free to change at each step. The dynamics therefore become more complicated. However, it remains true that a\u00a0small initial variation can turn into a large variation after several steps. One\u00a0difference between the purely linear case and the nonlinear case is that the use of\u00a0a squashing nonlinearity such as tanh can cause the recurrent dynamics to become\u00a0bounded. Note that it is possible for back-propagation to retain unbounded\u00a0dynamics even when forward propagation has bounded dynamics, for example,\u00a0when a sequence of tanh units are all in the middle of their linear regime and are\u00a0connected by weight matrices with spectral radius greater than 1. However, it is\u00a0rare for all of the tanh units to simultaneously lie at their linear activation point.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3960",
    "text": "The strategy of echo state networks is simply to fix the weights to have some spectral radius such as 3, where information is carried forward through time but\u00a0does not explode due to the stabilizing effect of saturating nonlinearities like tanh.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3961",
    "text": "More recently, it has been shown that the techniques used to set the weights in ESNs could be used to initialize the weights in a fully trainable recurrent network (with the hidden-to-hidden recurrent weights trained using back-propagation\u00a0through time), helping to learn long-term dependencies (Sutskever, 2012; Sutskever\u00a0et al., 2013). In this setting, an initial spectral radius of 1.2 performs well, combined\u00a0with the sparse initialization scheme described in Sec. 8.4.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3962",
    "text": "One way to deal with long-term dependencies is to design a model that operates at multiple time scales, so that some parts of the model operate at fine-grained\u00a0time scales and can handle small details, while other parts operate at coarse time\u00a0scales and transfer information from the distant past to the present more efficiently.\u00a0Various strategies for building both fine and coarse time scales are possible. These\u00a0include the addition of skip connections across time, \u201cleaky units\u201d that integrate\u00a0signals with different time constants, and the removal of some of the connections\u00a0used to model fine-grained time scales.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3963",
    "text": "One way to obtain coarse time scales is to add direct connections from variables in the distant past to variables in the present. The idea of using such skip connections\u00a0dates back to Lin et al. (1996) and follows from the idea of incorporating delays in\u00a0feedforward neural networks (Lang and Hinton, 1988). In an ordinary recurrent\u00a0network, a recurrent connection goes from a unit at time t to a unit at time t + 1.\u00a0It is possible to construct recurrent networks with longer delays (Bengio, 1991).",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3964",
    "text": "As we have seen in Sec. 8.2.5, gradients may vanish or explode exponentially with respect to the number of time steps. Lin et al. (1996) introduced\u00a0recurrent connections with a time-delay of d to mitigate this problem. Gradients\u00a0now diminish exponentially as a function of d rather than t. Since there are both\u00a0delayed and single step connections, gradients may still explode exponentially in t.\u00a0This allows the learning algorithm to capture longer dependencies although not all\u00a0long-term dependencies may be represented well in this way.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3965",
    "text": "Another way to obtain paths on which the product of derivatives is close to one is to have units with linear self-connections and a weight near one on these connections.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3966",
    "text": "When we accumulate a running average of some value vby applying the update p(t) ^ ap(t-1) + (1 \u2014 a) v(t) the a parameter is an example of a linear selfconnection from p(t-1) to\u00a0\u00a0\u00a0\u00a0. When a is near one, the running average remembers",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3967",
    "text": "information about the past for a long time, and when a is near zero, information about the past is rapidly discarded. Hidden units with linear self-connections can\u00a0behave similarly to such running averages. Such hidden units are called leaky units.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3968",
    "text": "Skip connections through d time steps are a way of ensuring that a unit can always learn to be influenced by a value from d time steps earlier. The use of a\u00a0linear self-connection with a weight near one is a different way of ensuring that the\u00a0unit can access values from the past. The linear self-connection approach allows\u00a0this effect to be adapted more smoothly and flexibly by adjusting the real-valued\u00a0a rather than by adjusting the integer-valued skip length.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3969",
    "text": "These ideas were proposed by Mozer (1992) and by El Hihi and Bengio (1996). Leaky units were also found to be useful in the context of echo state networks\u00a0(Jaeger et al., 2007).",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3970",
    "text": "There are two basic strategies for setting the time constants used by leaky units. One strategy is to manually fix them to values that remain constant, for\u00a0example by sampling their values from some distribution once at initialization time.\u00a0Another strategy is to make the time constants free parameters and learn them.\u00a0Having such leaky units at different time scales appears to help with long-term\u00a0dependencies (Mozer, 1992; Pascanu et al., 2013a).",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3971",
    "text": "Another approach to handle long-term dependencies is the idea of organizing the state of the RNN at multiple time-scales (El Hihi and Bengio, 1996), with\u00a0information flowing more easily through long distances at the slower time scales.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3972",
    "text": "This idea differs from the skip connections through time discussed earlier because it involves actively removing length-one connections and replacing them\u00a0with longer connections. Units modified in such a way are forced to operate on a\u00a0long time scale. Skip connections through time add edges. Units receiving such\u00a0new connections may learn to operate on a long time scale but may also choose to\u00a0focus on their other short-term connections.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3973",
    "text": "There are different ways in which a group of recurrent units can be forced to operate at different time scales. One option is to make the recurrent units leaky,\u00a0but to have different groups of units associated with different fixed time scales.\u00a0This was the proposal in Mozer (1992) and has been successfully used in Pascanu\u00a0et al. (2013a). Another option is to have explicit and discrete updates taking place\u00a0at different times, with a different frequency for different groups of units. This is\u00a0the approach of El Hihi and Bengio (1996) and Koutnik et al. (2014). It worked\u00a0well on a number of benchmark datasets.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3974",
    "text": "As of this writing, the most effective sequence models used in practical applications are called gated RNNs. These include the long short-term memory and networks\u00a0based on the gated recurrent unit.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3975",
    "text": "Like leaky units, gated RNNs are based on the idea of creating paths through time that have derivatives that neither vanish nor explode. Leaky units did\u00a0this with connection weights that were either manually chosen constants or were\u00a0parameters. Gated RNNs generalize this to connection weights that may change\u00a0at each time step.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3976",
    "text": "Leaky units allow the network to accumulate information (such as evidence for a particular feature or category) over a long duration. However, once that\u00a0information has been used, it might be useful for the neural network to forget the\u00a0old state. For example, if a sequence is made of sub-sequences and we want a leaky\u00a0unit to accumulate evidence inside each sub-subsequence, we need a mechanism to\u00a0forget the old state by setting it to zero. Instead of manually deciding when to\u00a0clear the state, we want the neural network to learn to decide when to do it. This\u00a0is what gated RNNs do.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3977",
    "text": "The clever idea of introducing self-loops to produce paths where the gradient can flow for long durations is a core contribution of the initial long short-term memory\u00a0(LSTM) model (Hochreiter and Schmidhuber, 1997). A crucial addition has been\u00a0to make the weight on this self-loop conditioned on the context, rather than fixed\u00a0(Gers et al., 2000). By making the weight of this self-loop gated (controlled by\u00a0another hidden unit), the time scale of integration can be changed dynamically. In\u00a0this case, we mean that even for an LSTM with fixed parameters, the time scale of\u00a0integration can change based on the input sequence, because the time constants\u00a0are output by the model itself. The LSTM has been found extremely successful\u00a0in many applications, such as unconstrained handwriting recognition (Graves\u00a0et al., 2009), speech recognition (Graves et al., 2013; Graves and Jaitly, 2014),\u00a0handwriting generation (Graves, 2013), machine translation (Sutskever et al., 2014),\u00a0image captioning (Kiros et al., 2014b; Vinyals et al., 2014b; Xu et al., 2015) and\u00a0parsing (Vinyals et al., 2014a).",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3978",
    "text": "The LSTM block diagram is illustrated in Fig. 10.16. The corresponding forward propagation equations are given below, in the case of a shallow recurrent",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3979",
    "text": "Figure 10.16: Block diagram of the LSTM recurrent network \u201ccell.\u201d Cells are connected recurrently to each other, replacing the usual hidden units of ordinary recurrent networks.\u00a0An input feature is computed with a regular artificial neuron unit. Its value can be\u00a0accumulated into the state if the sigmoidal input gate allows it. The state unit has a\u00a0linear self-loop whose weight is controlled by the forget gate. The output of the cell can\u00a0be shut off by the output gate. All the gating units have a sigmoid nonlinearity, while the\u00a0input unit can have any squashing nonlinearity. The state unit can also be used as an\u00a0extra input to the gating units. The black square indicates a delay of a single time step.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3980",
    "text": "network architecture. Deeper architectures have also been successfully used (Graves et al., 2013; Pascanu et al., 2014a). Instead of a unit that simply applies an elementwise nonlinearity to the affine transformation of inputs and recurrent units, LSTM\u00a0recurrent networks have \u201cLSTM cells\u201d that have an internal recurrence (a self-loop),\u00a0in addition to the outer recurrence of the RNN. Each cell has the same inputs\u00a0and outputs as an ordinary recurrent network, but has more parameters and a\u00a0system of gating units that controls the flow of information. The most important\u00a0component is the state unit s(t) that has a linear self-loop similar to the leaky\u00a0units described in the previous section. However, here, the self-loop weight (or the\u00a0associated time constant) is controlled by a forget gate unit f(t) (for time step t\u00a0and cell i), that sets this weight to a value between 0 and 1 via a sigmoid unit:",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3981",
    "text": "-10.4",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3982",
    "text": "a",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3983",
    "text": "If + y uf 3 + y wf. h(t-I>",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3984",
    "text": "1 \u00a0\u00a0\u00a0i3 3\u00a0\u00a0\u00a0\u00a01,3 3",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3985",
    "text": "3 \u00a0\u00a0\u00a03",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3986",
    "text": "where x(t) is the current input vector and h(t) is the current hidden layer vector, containing the outputs of all the LSTM cells, and b , Uf, Wf are respectively\u00a0biases, input weights and recurrent weights for the forget gates. The LSTM cell\u00a0internal state is thus updated as follows, but with a conditional self-loop weight",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3987",
    "text": "f (t): f i :",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3988",
    "text": "St = ff sf-1) + g (t)a",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3989",
    "text": "i",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3990",
    "text": "i",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3991",
    "text": "+ sfa I bi + E Ui,3x<<) + Ew\u2018jh<3\u2018-I)",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3992",
    "text": "33",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3993",
    "text": "A J \u05be",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3994",
    "text": "-10.41",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3995",
    "text": "where b, U and W respectively denote the biases, input weights and recurrent weights into the LSTM cell. The external input gate unit g(t) is computed similarly\u00a0to the forget gate (with a sigmoid unit to obtain a gating value between 0 and 1),\u00a0but with its own parameters:",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3996",
    "text": "g",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3997",
    "text": "(t) _",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3998",
    "text": "#ERROR!",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "3999",
    "text": "1 \u00a0\u00a0\u00a01,3 3\u00a0\u00a0\u00a0\u00a01,3 3",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4000",
    "text": "-10.42",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4001",
    "text": "The output h(t) of the LSTM cell can also be shut off, via the output gate q(t), which also uses a sigmoid unit for gating:",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4002",
    "text": "-10.43",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4003",
    "text": "-10.44",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4004",
    "text": "h(t) = tanh ^s(t)^ q(t)",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4005",
    "text": "q(t)=\u05f4 I6? + E U \u00b03\u25a0 x3t)+E W3 h3t-I)",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4006",
    "text": "which has parameters bo, Uo, Wo for its biases, input weights and recurrent weights, respectively. Among the variants, one can choose to use the cell state s(t)\u00a0as an extra input (with its weight) into the three gates of the i-th unit, as shown\u00a0in Fig. 10.16. This would require three additional parameters.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4007",
    "text": "LSTM networks have been shown to learn long-term dependencies more easily than the simple recurrent architectures, first on artificial data sets designed for\u00a0testing the ability to learn long-term dependencies (Bengio et al., 1994; Hochreiter\u00a0and Schmidhuber, 1997; Hochreiter et al., 2001), then on challenging sequence\u00a0processing tasks where state-of-the-art performance was obtained (Graves, 2012;\u00a0Graves et al., 2013; Sutskever et al., 2014). Variants and alternatives to the LSTM\u00a0have been studied and used and are discussed next.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4008",
    "text": "Which pieces of the LSTM architecture are actually necessary? What other successful architectures could be designed that allow the network to dynamically\u00a0control the time scale and forgetting behavior of different units?",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4009",
    "text": "Some answers to these questions are given with the recent work on gated RNNs, whose units are also known as gated recurrent units or GRUs (Cho et al., 2014b;\u00a0Chung et al., 2014, 2015a; Jozefowicz et al., 2015; Chrupala et al., 2015). The main\u00a0difference with the LSTM is that a single gating unit simultaneously controls the\u00a0forgetting factor and the decision to update the state unit. The update equations\u00a0are the following:",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4010",
    "text": "(,",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4011",
    "text": "\u05e5",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4012",
    "text": "\u05be \u05e5",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4013",
    "text": "-10.45",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4014",
    "text": "(t-1) h(t-1)",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4015",
    "text": "i-j \u05f3 j \u00a0\u00a0\u00a0hj",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4016",
    "text": "h(t) = u(t 1)h(t 1) + (1 - u(t 1V ( bi + \u00a3 Ujxjj 1) + \u00a3 Wi-j \u00a0\u00a0\u00a0hj",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4017",
    "text": "X",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4018",
    "text": "j",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4019",
    "text": "j",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4020",
    "text": "where u stands for \u201cupdate\u201d gate and r for \u201creset\u201d gate. Their value is defined as usual:",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4021",
    "text": "(t) - - (bu + \u00a0\u00a0\u00a0Tiu x (t) +\u00a0\u00a0\u00a0\u00a0Wu h(t) \u05e5",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4022",
    "text": "u",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4023",
    "text": "- (bu + \u00a3 Uj j+\u00a3 Wj hj",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4024",
    "text": "-10.46",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4025",
    "text": "and",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4026",
    "text": "-10.47",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4027",
    "text": "ri\u05f3 - -lb r +\u00a3 U[j j +Y, Wj h jt)| .",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4028",
    "text": "j",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4029",
    "text": "j",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4030",
    "text": "The reset and updates gates can individually \u201cignore\u201d parts of the state vector. The update gates act like conditional leaky integrators that can linearly gate any\u00a0dimension, thus choosing to copy it (at one extreme of the sigmoid) or completely\u00a0ignore it (at the other extreme) by replacing it by the new \u201ctarget state\u201d value\u00a0(towards which the leaky integrator wants to converge). The reset gates control\u00a0which parts of the state get used to compute the next target state, introducing an\u00a0additional nonlinear effect in the relationship between past state and future state.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4031",
    "text": "Many more variants around this theme can be designed. For example the reset gate (or forget gate) output could be shared across multiple hidden units.\u00a0Alternately, the product of a global gate (covering a whole group of units, such as\u00a0an entire layer) and a local gate (per unit) could be used to combine global control\u00a0and local control. However, several investigations over architectural variations\u00a0of the LSTM and GRU found no variant that would clearly beat both of these\u00a0across a wide range of tasks (Greff et al., 2015; Jozefowicz et al., 2015). Greff\u00a0et al. (2015) found that a crucial ingredient is the forget gate, while Jozefowicz\u00a0et al. (2015) found that adding a bias of 1 to the LSTM forget gate, a practice\u00a0advocated by Gers et al. (2000), makes the LSTM as strong as the best of the\u00a0explored architectural variants.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4032",
    "text": "Sec. 8.2.5 and Sec. 10.7 have described the vanishing and exploding gradient problems that occur when optimizing RNNs over many time steps.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4033",
    "text": "An interesting idea proposed by Martens and Sutskever (2011) is that second derivatives may vanish at the same time that first derivatives vanish. Second-order\u00a0optimization algorithms may roughly be understood as dividing the first derivative\u00a0by the second derivative (in higher dimension, multiplying the gradient by the\u00a0inverse Hessian). If the second derivative shrinks at a similar rate to the first\u00a0derivative, then the ratio of first and second derivatives may remain relatively\u00a0constant. Unfortunately, second-order methods have many drawbacks, including\u00a0high computational cost, the need for a large minibatch, and a tendency to be\u00a0attracted to saddle points. Martens and Sutskever (2011) found promising results\u00a0using second-order methods. Later, Sutskever et al. (2013) found that simpler\u00a0methods such as Nesterov momentum with careful initialization could achieve\u00a0similar results. See Sutskever (2012) for more detail. Both of these approaches\u00a0have largely been replaced by simply using SGD (even without momentum) applied\u00a0to LSTMs. This is part of a continuing theme in machine learning that it is often\u00a0much easier to design a model that is easy to optimize than it is to design a more\u00a0powerful optimization algorithm.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4034",
    "text": "As discussed in Sec. 8.2.4, strongly nonlinear functions such as those computed by a recurrent net over many time steps tend to have derivatives that can be either\u00a0very large or very small in magnitude. This is illustrated in Fig. 8.3 and Fig. 10.17,\u00a0in which we see that the objective function (as a function of the parameters) has a\u00a0\u201clandscape\u201d in which one finds \u201ccliffs\u201d: wide and rather flat regions separated by\u00a0tiny regions where the objective function changes quickly, forming a kind of cliff.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4035",
    "text": "The difficulty that arises is that when the parameter gradient is very large, a gradient descent parameter update could throw the parameters very far, into a\u00a0region where the objective function is larger, undoing much of the work that had\u00a0been done to reach the current solution. The gradient tells us the direction that\u00a0corresponds to the steepest descent within an infinitesimal region surrounding the\u00a0current parameters. Outside of this infinitesimal region, the cost function may\u00a0begin to curve back upwards. The update must be chosen to be small enough to\u00a0avoid traversing too much upward curvature. We typically use learning rates that\u00a0decay slowly enough that consecutive steps have approximately the same learning\u00a0rate. A step size that is appropriate for a relatively linear part of the landscape is\u00a0often inappropriate and causes uphill motion if we enter a more curved part of the\u00a0landscape on the next step.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4036",
    "text": "Without clipping",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4037",
    "text": "With clipping",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4038",
    "text": "Figure 10.17: Example of the effect of gradient clipping in a recurrent network with two parameters w and b. Gradient clipping can make gradient descent perform more\u00a0reasonably in the vicinity of extremely steep cliffs. These steep cliffs commonly occur\u00a0in recurrent networks near where a recurrent network behaves approximately linearly.\u00a0The cliff is exponentially steep in the number of time steps because the weight matrix\u00a0is multiplied by itself once for each time step. (Left) Gradient descent without gradient\u00a0clipping overshoots the bottom of this small ravine, then receives a very large gradient\u00a0from the cliff face. The large gradient catastrophically propels the parameters outside the\u00a0axes of the plot. (Right) Gradient descent with gradient clipping has a more moderate\u00a0reaction to the cliff. While it does ascend the cliff face, the step size is restricted so that\u00a0it cannot be propelled away from steep region near the solution. Figure adapted with\u00a0permission from Pascanu et al. (2013a).",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4039",
    "text": "A simple type of solution has been in use by practitioners for many years: clipping the gradient. There are different instances of this idea (Mikolov, 2012;\u00a0Pascanu et al., 2013a). One option is to clip the parameter gradient from a\u00a0minibatch element-wise (Mikolov, 2012) just before the parameter update. Another\u00a0is to clip the norm ||g|| of the gradient g (Pascanu et al., 2013a) just before the\u00a0parameter update:",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4040",
    "text": "if ||g|| > v",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4041",
    "text": "g",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4042",
    "text": "gv",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4043",
    "text": "| g|",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4044",
    "text": "-10.48",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4045",
    "text": "-10.49",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4046",
    "text": "where v is the norm threshold and g is used to update parameters. Because the gradient of all the parameters (including different groups of parameters, such as\u00a0weights and biases) is renormalized jointly with a single scaling factor, the latter\u00a0method has the advantage that it guarantees that each step is still in the gradient\u00a0direction, but experiments suggest that both forms work similarly. Although",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4047",
    "text": "the parameter update has the same direction as the true gradient, with gradient norm clipping, the parameter update vector norm is now bounded. This bounded\u00a0gradient avoids performing a detrimental step when the gradient explodes. In\u00a0fact, even simply taking a random step when the gradient magnitude is above\u00a0a threshold tends to work almost as well. If the explosion is so severe that the\u00a0gradient is numerically Inf or Nan (considered infinite or not-a-number), then\u00a0a random step of size v can be taken and will typically move away from the\u00a0numerically unstable configuration. Clipping the gradient norm per-minibatch will\u00a0not change the direction of the gradient for an individual minibatch. However,\u00a0taking the average of the norm-clipped gradient from many minibatches is not\u00a0equivalent to clipping the norm of the true gradient (the gradient formed from\u00a0using all examples). Examples that have large gradient norm, as well as examples\u00a0that appear in the same minibatch as such examples, will have their contribution\u00a0to the final direction diminished. This stands in contrast to traditional minibatch\u00a0gradient descent, where the true gradient direction is equal to the average over all\u00a0minibatch gradients. Put another way, traditional stochastic gradient descent uses\u00a0an unbiased estimate of the gradient, while gradient descent with norm clipping\u00a0introduces a heuristic bias that we know empirically to be useful. With elementwise clipping, the direction of the update is not aligned with the true gradient\u00a0or the minibatch gradient, but it is still a descent direction. It has also been\u00a0proposed (Graves, 2013) to clip the back-propagated gradient (with respect to\u00a0hidden units) but no comparison has been published between these variants; we\u00a0conjecture that all these methods behave similarly.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4048",
    "text": "Gradient clipping helps to deal with exploding gradients, but it does not help with vanishing gradients. To address vanishing gradients and better capture long-term\u00a0dependencies, we discussed the idea of creating paths in the computational graph of\u00a0the unfolded recurrent architecture along which the product of gradients associated\u00a0with arcs is near 1. One approach to achieve this is with LSTMs and other self-loops\u00a0and gating mechanisms, described above in Sec. 10.10. Another idea is to regularize\u00a0or constrain the parameters so as to encourage \u201cinformation flow.\u201d In particular,\u00a0we would like the gradient vector V h(t) L being back-propagated to maintain its\u00a0magnitude, even if the loss function only penalizes the output at the end of the\u00a0sequence. Formally, we want",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4049",
    "text": "d h(t-1)",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4050",
    "text": "-10.5",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4051",
    "text": "-10.51",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4052",
    "text": "Vh(t)L\u2022",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4053",
    "text": "to be as large as",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4054",
    "text": "With this objective, Pascanu et al. (2013a) propose the following regularizes",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4055",
    "text": "I (V h(t) L)",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4056",
    "text": "_dh(t)_ 1 dh(t-1)\u00a0\u00a0\u00a0\u00a01",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4057",
    "text": "2",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4058",
    "text": "1",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4059",
    "text": "-10.52",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4060",
    "text": "Computing the gradient of this regularizer may appear difficult, but Pascanu et al. (2013a) propose an approximation in which we consider the back-propagated\u00a0vectors Vh (t)L as if they were constants (for the purpose of this regularizer, so\u00a0that there is no need to back-propagate through them). The experiments with\u00a0this regularizer suggest that, if combined with the norm clipping heuristic (which\u00a0handles gradient explosion), the regularizer can considerably increase the span of\u00a0the dependencies that an RNN can learn. Because it keeps the RNN dynamics\u00a0on the edge of explosive gradients, the gradient clipping is particularly important.\u00a0Without gradient clipping, gradient explosion prevents learning from succeeding.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4061",
    "text": "A key weakness of this approach is that it is not as effective as the LSTM for tasks where data is abundant, such as language modeling.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4062",
    "text": "Intelligence requires knowledge and acquiring knowledge can be done via learning, which has motivated the development of large-scale deep architectures. However,\u00a0there are different kinds of knowledge. Some knowledge can be implicit, subconscious, and difficult to verbalize\u2014such as how to walk, or how a dog looks\u00a0different from a cat. Other knowledge can be explicit, declarative, and relatively\u00a0straightforward to put into words\u2014every day commonsense knowledge, like \u201ca cat\u00a0is a kind of animal,\u201d or very specific facts that you need to know to accomplish\u00a0your current goals, like \u201cthe meeting with the sales team is at 3:00 PM in room\u00a0141.\u201d",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4063",
    "text": "Neural networks excel at storing implicit knowledge. However, they struggle to memorize facts. Stochastic gradient descent requires many presentations of\u00a0the same input before it can be stored in a neural network parameters, and even\u00a0then, that input will not be stored especially precisely. Graves et al. (2014b)\u00a0hypothesized that this is because neural networks lack the equivalent of the working\u00a0memory system that allows human beings to explicitly hold and manipulate pieces\u00a0of information that are relevant to achieving some goal. Such explicit memory",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4064",
    "text": "Memory cells",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4065",
    "text": "Figure 10.18: A schematic of an example of a network with an explicit memory, capturing some of the key design elements of the neural Turing machine. In this diagram we\u00a0distinguish the \u201crepresentation\u201d part of the model (the \u201ctask network,\u201d here a recurrent\u00a0net in the bottom) from the \u201cmemory\u201d part of the model (the set of cells), which can\u00a0store facts. The task network learns to \u201ccontrol\u201d the memory, deciding where to read from\u00a0and where to write to within the memory (through the reading and writing mechanisms,\u00a0indicated by bold arrows pointing at the reading and writing addresses).",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4066",
    "text": "components would allow our systems not only to rapidly and \u201cintentionally\u201d store and retrieve specific facts but also to sequentially reason with them. The need\u00a0for neural networks that can process information in a sequence of steps, changing\u00a0the way the input is fed into the network at each step, has long been recognized\u00a0as important for the ability to reason rather than to make automatic, intuitive\u00a0responses to the input (Hinton, 1990).",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4067",
    "text": "To resolve this difficulty, Weston et al. (2014) introduced memory networks that include a set of memory cells that can be accessed via an addressing mechanism.\u00a0Memory networks originally required a supervision signal instructing them how\u00a0to use their memory cells. Graves et al. (2014b) introduced the neural Turing\u00a0machine, which is able to learn to read from and write arbitrary content to memory\u00a0cells without explicit supervision about which actions to undertake, and allowed\u00a0end-to-end training without this supervision signal, via the use of a content-based\u00a0soft attention mechanism (see Bahdanau et al. (2015) and Sec. 12.4.5.1). This\u00a0soft addressing mechanism has become standard with other related architectures\u00a0emulating algorithmic mechanisms in a way that still allows gradient-based optimization (Sukhbaatar et al., 2015; Joulin and Mikolov, 2015; Kumar et al., 2015;\u00a0Vinyals et al., 2015a; Grefenstette et al., 2015).",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4068",
    "text": "Each memory cell can be thought of as an extension of the memory cells in LSTMs and GRUs. The difference is that the network outputs an internal state\u00a0that chooses which cell to read from or write to, just as memory accesses in a\u00a0digital computer read from or write to a specific address.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4069",
    "text": "It is difficult to optimize functions that produce exact, integer addresses. To alleviate this problem, NTMs actually read to or write from many memory cells\u00a0simultaneously. To read, they take a weighted average of many cells. To write, they\u00a0modify multiple cells by different amounts. The coefficients for these operations\u00a0are chosen to be focused on a small number of cells, for example, by producing\u00a0them via a softmax function. Using these weights with non-zero derivatives allows\u00a0the functions controlling access to the memory to be optimized using gradient\u00a0descent. The gradient on these coefficients indicates whether each of them should\u00a0be increased or decreased, but the gradient will typically be large only for those\u00a0memory addresses receiving a large coefficient.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4070",
    "text": "These memory cells are typically augmented to contain a vector, rather than the single scalar stored by an LSTM or GRU memory cell. There are two reasons\u00a0to increase the size of the memory cell. One reason is that we have increased the\u00a0cost of accessing a memory cell. We pay the computational cost of producing a\u00a0coefficient for many cells, but we expect these coefficients to cluster around a small\u00a0number of cells. By reading a vector value, rather than a scalar value, we can\u00a0offset some of this cost. Another reason to use vector-valued memory cells is that\u00a0they allow for content-based addressing, where the weight used to read to or write\u00a0from a cell is a function of that cell. Vector-valued cells allow us to retrieve a\u00a0complete vector-valued memory if we are able to produce a pattern that matches\u00a0some but not all of its elements. This is analogous to the way that people can\u00a0recall the lyrics of a song based on a few words. We can think of a content-based\u00a0read instruction as saying, \u201cRetrieve the lyrics of the song that has the chorus \u2018We\u00a0all live in a yellow submarine.\u2019\u201d Content-based addressing is more useful when we\u00a0make the objects to be retrieved large\u2014if every letter of the song was stored in a\u00a0separate memory cell, we would not be able to find them this way. By comparison,\u00a0location-based addressing is not allowed to refer to the content of the memory. We\u00a0can think of a location-based read instruction as saying \u201cRetrieve the lyrics of\u00a0the song in slot 347.\u201d Location-based addressing can often be a perfectly sensible\u00a0mechanism even when the memory cells are small.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4071",
    "text": "If the content of a memory cell is copied (not forgotten) at most time steps, then the information it contains can be propagated forward in time and the gradients\u00a0propagated backward in time without either vanishing or exploding.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4072",
    "text": "The explicit memory approach is illustrated in Fig. 10.18, where we see that a \u201ctask neural network\u201d is coupled with a memory. Although that task neural\u00a0network could be feedforward or recurrent, the overall system is a recurrent network.\u00a0The task network can choose to read from or write to specific memory addresses.\u00a0Explicit memory seems to allow models to learn tasks that ordinary RNNs or LSTM\u00a0RNNs cannot learn. One reason for this advantage may be because information and\u00a0gradients can be propagated (forward in time or backwards in time, respectively)\u00a0for very long durations.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4073",
    "text": "As an alternative to back-propagation through weighted averages of memory cells, we can interpret the memory addressing coefficients as probabilities and\u00a0stochastically read just one cell (Zaremba and Sutskever, 2015). Optimizing models\u00a0that make discrete decisions requires specialized optimization algorithms, described\u00a0in Sec. 20.9.1. So far, training these stochastic architectures that make discrete\u00a0decisions remains harder than training deterministic algorithms that make soft\u00a0decisions.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4074",
    "text": "Whether it is soft (allowing back-propagation) or stochastic and hard, the mechanism for choosing an address is in its form identical to the attention mechanism which had been previously introduced in the context of machine translation (Bah-danau et al., 2015) and discussed in Sec. 12.4.5.1. The idea of attention mechanisms\u00a0for neural networks was introduced even earlier, in the context of handwriting\u00a0generation (Graves, 2013), with an attention mechanism that was constrained to\u00a0move only forward in time through the sequence. In the case of machine translation\u00a0and memory networks, at each step, the focus of attention can move to a completely\u00a0different place, compared to the previous step.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4075",
    "text": "Recurrent neural networks provide a way to extend deep learning to sequential data. They are the last major tool in our deep learning toolbox. Our discussion now\u00a0moves to how to choose and use these tools and how to apply them to real-world\u00a0tasks.",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4076",
    "text": "1",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4077",
    "text": " We suggest to not abbreviate \u201crecursive neural network\u201d as \u201cRNN\u201d to avoid confusion with\u00a0\u201crecurrent neural network.\u201d",
    "chapter": "Approximate Inference",
    "chapter_id": "main-22.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4078",
    "text": "Successfully applying deep learning techniques requires more than just a good knowledge of what algorithms exist and the principles that explain how they\u00a0work. A good machine learning practitioner also needs to know how to choose an\u00a0algorithm for a particular application and how to monitor and respond to feedback\u00a0obtained from experiments in order to improve a machine learning system. During\u00a0day to day development of machine learning systems, practitioners need to decide\u00a0whether to gather more data, increase or decrease model capacity, add or remove\u00a0regularizing features, improve the optimization of a model, improve approximate\u00a0inference in a model, or debug the software implementation of the model. All of\u00a0these operations are at the very least time-consuming to try out, so it is important\u00a0to be able to determine the right course of action rather than blindly guessing.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4079",
    "text": "Most of this book is about different machine learning models, training algorithms, and objective functions. This may give the impression that the most important ingredient to being a machine learning expert is knowing a wide variety\u00a0of machine learning techniques and being good at different kinds of math. In practice, one can usually do much better with a correct application of a commonplace\u00a0algorithm than by sloppily applying an obscure algorithm. Correct application of\u00a0an algorithm depends on mastering some fairly simple methodology. Many of the\u00a0recommendations in this chapter are adapted from Ng (2015).",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4080",
    "text": "We recommend the following practical design process:",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4081",
    "text": "\u2022 \u00a0\u00a0\u00a0Determine your goals\u2014what error metric to use, and your target value for\u00a0this error metric. These goals and error metrics should be driven by the\u00a0problem that the application is intended to solve.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4082",
    "text": "\u2022 \u00a0\u00a0\u00a0Establish a working end-to-end pipeline as soon as possible, including the",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4083",
    "text": "estimation of the appropriate performance metrics.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4084",
    "text": "\u2022 \u00a0\u00a0\u00a0Instrument the system well to determine bottlenecks in performance. Diagnose which components are performing worse than expected and whether it\u00a0is due to overfitting, underfitting, or a defect in the data or software.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4085",
    "text": "\u2022 \u00a0\u00a0\u00a0Repeatedly make incremental changes such as gathering new data, adjusting\u00a0hyperparameters, or changing algorithms, based on specific findings from\u00a0your instrumentation.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4086",
    "text": "As a running example, we will use Street View address number transcription system (Goodfellow et al., 2014d). The purpose of this application is to add\u00a0buildings to Google Maps. Street View cars photograph the buildings and record\u00a0the GPS coordinates associated with each photograph. A convolutional network\u00a0recognizes the address number in each photograph, allowing the Google Maps\u00a0database to add that address in the correct location. The story of how this\u00a0commercial application was developed gives an example of how to follow the design\u00a0methodology we advocate.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4087",
    "text": "We now describe each of the steps in this process.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4088",
    "text": "Determining your goals, in terms of which error metric to use, is a necessary first step because your error metric will guide all of your future actions. You should\u00a0also have an idea of what level of performance you desire.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4089",
    "text": "Keep in mind that for most applications, it is impossible to achieve absolute zero error. The Bayes error defines the minimum error rate that you can hope to\u00a0achieve, even if you have infinite training data and can recover the true probability\u00a0distribution. This is because your input features may not contain complete\u00a0information about the output variable, or because the system might be intrinsically\u00a0stochastic. You will also be limited by having a finite amount of training data.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4090",
    "text": "The amount of training data can be limited for a variety of reasons. When your goal is to build the best possible real-world product or service, you can typically\u00a0collect more data but must determine the value of reducing error further and weigh\u00a0this against the cost of collecting more data. Data collection can require time,\u00a0money, or human suffering (for example, if your data collection process involves\u00a0performing invasive medical tests). When your goal is to answer a scientific question\u00a0about which algorithm performs better on a fixed benchmark, the benchmark\u00a0specification usually determines the training set and you are not allowed to collect\u00a0more data.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4091",
    "text": "How can one determine a reasonable level of performance to expect? Typically, in the academic setting, we have some estimate of the error rate that is attainable\u00a0based on previously published benchmark results. In the real-word setting, we\u00a0have some idea of the error rate that is necessary for an application to be safe,\u00a0cost-effective, or appealing to consumers. Once you have determined your realistic\u00a0desired error rate, your design decisions will be guided by reaching this error rate.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4092",
    "text": "Another important consideration besides the target value of the performance metric is the choice of which metric to use. Several different performance metrics\u00a0may be used to measure the effectiveness of a complete application that includes\u00a0machine learning components. These performance metrics are usually different\u00a0from the cost function used to train the model. As described in Sec. 5.1.2, it is\u00a0common to measure the accuracy, or equivalently, the error rate, of a system.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4093",
    "text": "However, many applications require more advanced metrics.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4094",
    "text": "Sometimes it is much more costly to make one kind of a mistake than another. For example, an e-mail spam detection system can make two kinds of mistakes:\u00a0incorrectly classifying a legitimate message as spam, and incorrectly allowing a\u00a0spam message to appear in the inbox. It is much worse to block a legitimate\u00a0message than to allow a questionable message to pass through. Rather than\u00a0measuring the error rate of a spam classifier, we may wish to measure some form\u00a0of total cost, where the cost of blocking legitimate messages is higher than the cost\u00a0of allowing spam messages.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4095",
    "text": "Sometimes we wish to train a binary classifier that is intended to detect some rare event. For example, we might design a medical test for a rare disease. Suppose\u00a0that only one in every million people has this disease. We can easily achieve\u00a099.9999% accuracy on the detection task, by simply hard-coding the classifier\u00a0to always report that the disease is absent. Clearly, accuracy is a poor way to\u00a0characterize the performance of such a system. One way to solve this problem is to\u00a0instead measure precision and recall. Precision is the fraction of detections reported\u00a0by the model that were correct, while recall is the fraction of true events that\u00a0were detected. A detector that says no one has the disease would achieve perfect\u00a0precision, but zero recall. A detector that says everyone has the disease would\u00a0achieve perfect recall, but precision equal to the percentage of people who have\u00a0the disease (0.0001% in our example of a disease that only one people in a million\u00a0have). When using precision and recall, it is common to plot a PR curve, with\u00a0precision on the y-axis and recall on the x-axis. The classifier generates a score\u00a0that is higher if the event to be detected occurred. For example, a feedforward\u00a0network designed to detect a disease outputs y = P(y =1 | x), estimating the\u00a0probability that a person whose medical results are described by features x has\u00a0the disease. We choose to report a detection whenever this score exceeds some\u00a0threshold. By varying the threshold, we can trade precision for recall. In many\u00a0cases, we wish to summarize the performance of the classifier with a single number\u00a0rather than a curve. To do so, we can convert precision p and recall r into an\u00a0F-score given by",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4096",
    "text": "F = \u00a0\u00a0\u00a0(11.1)",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4097",
    "text": "p + r",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4098",
    "text": "Another option is to report the total area lying beneath the PR curve.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4099",
    "text": "In some applications, it is possible for the machine learning system to refuse to make a decision. This is useful when the machine learning algorithm can estimate\u00a0how confident it should be about a decision, especially if a wrong decision can\u00a0be harmful and if a human operator is able to occasionally take over. The Street\u00a0View transcription system provides an example of this situation. The task is to\u00a0transcribe the address number from a photograph in order to associate the location\u00a0where the photo was taken with the correct address in a map. Because the value\u00a0of the map degrades considerably if the map is inaccurate, it is important to add\u00a0an address only if the transcription is correct. If the machine learning system\u00a0thinks that it is less likely than a human being to obtain the correct transcription,\u00a0then the best course of action is to allow a human to transcribe the photo instead.\u00a0Of course, the machine learning system is only useful if it is able to dramatically\u00a0reduce the amount of photos that the human operators must process. A natural\u00a0performance metric to use in this situation is coverage. Coverage is the fraction of\u00a0examples for which the machine learning system is able to produce a response. It\u00a0is possible to trade coverage for accuracy. One can always obtain 100% accuracy\u00a0by refusing to process any example, but this reduces the coverage to 0%. For the\u00a0Street View task, the goal for the project was to reach human-level transcription\u00a0accuracy while maintaining 95% coverage. Human-level performance on this task\u00a0is 98% accuracy.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4100",
    "text": "Many other metrics are possible. We can for example, measure click-through rates, collect user satisfaction surveys, and so on. Many specialized application\u00a0areas have application-specific criteria as well.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4101",
    "text": "What is important is to determine which performance metric to improve ahead of time, then concentrate on improving this metric. Without clearly defined goals,\u00a0it can be difficult to tell whether changes to a machine learning system make\u00a0progress or not.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4102",
    "text": "After choosing performance metrics and goals, the next step in any practical application is to establish a reasonable end-to-end system as soon as possible. In\u00a0this section, we provide recommendations for which algorithms to use as the first\u00a0baseline approach in various situations. Keep in mind that deep learning research\u00a0progresses quickly, so better default algorithms are likely to become available soon\u00a0after this writing.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4103",
    "text": "Depending on the complexity of your problem, you may even want to begin without using deep learning. If your problem has a chance of being solved by\u00a0just choosing a few linear weights correctly, you may want to begin with a simple\u00a0statistical model like logistic regression.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4104",
    "text": "If you know that your problem falls into an \u201cAI-complete\u201d category like object recognition, speech recognition, machine translation, and so on, then you are likely\u00a0to do well by beginning with an appropriate deep learning model.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4105",
    "text": "First, choose the general category of model based on the structure of your data. If you want to perform supervised learning with fixed-size vectors as input,\u00a0use a feedforward network with fully connected layers. If the input has known\u00a0topological structure (for example, if the input is an image), use a convolutional\u00a0network. In these cases, you should begin by using some kind of piecewise linear\u00a0unit (ReLUs or their generalizations like Leaky ReLUs, PreLus and maxout). If\u00a0your input or output is a sequence, use a gated recurrent net (LSTM or GRU).",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4106",
    "text": "A reasonable choice of optimization algorithm is SGD with momentum with a decaying learning rate (popular decay schemes that perform better or worse on\u00a0different problems include decaying linearly until reaching a fixed minimum learning\u00a0rate, decaying exponentially, or decreasing the learning rate by a factor of 2-10\u00a0each time validation error plateaus). Another very reasonable alternative is Adam.\u00a0Batch normalization can have a dramatic effect on optimization performance,\u00a0especially for convolutional networks and networks with sigmoidal nonlinearities.\u00a0While it is reasonable to omit batch normalization from the very first baseline, it\u00a0should be introduced quickly if optimization appears to be problematic.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4107",
    "text": "Unless your training set contains tens of millions of examples or more, you should include some mild forms of regularization from the start. Early stopping\u00a0should be used almost universally. Dropout is an excellent regularizer that is easy\u00a0to implement and compatible with many models and training algorithms. Batch\u00a0normalization also sometimes reduces generalization error and allows dropout to\u00a0be omitted, due to the noise in the estimate of the statistics used to normalize\u00a0each variable.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4108",
    "text": "If your task is similar to another task that has been studied extensively, you will probably do well by first copying the model and algorithm that is already\u00a0known to perform best on the previously studied task. You may even want to copy\u00a0a trained model from that task. For example, it is common to use the features\u00a0from a convolutional network trained on ImageNet to solve other computer vision\u00a0tasks (Girshick et al., 2015).",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4109",
    "text": "A common question is whether to begin by using unsupervised learning, described further in Part III. This is somewhat domain specific. Some domains, such as natural language processing, are known to benefit tremendously from unsupervised learning techniques such as learning unsupervised word embeddings. In other\u00a0domains, such as computer vision, current unsupervised learning techniques do\u00a0not bring a benefit, except in the semi-supervised setting, when the number of\u00a0labeled examples is very small (Kingma et al., 2014; Rasmus et al., 2015). If your\u00a0application is in a context where unsupervised learning is known to be important,\u00a0then include it in your first end-to-end baseline. Otherwise, only use unsupervised\u00a0learning in your first attempt if the task you want to solve is unsupervised. You\u00a0can always try adding unsupervised learning later if you observe that your initial\u00a0baseline overfits.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4110",
    "text": "After the first end-to-end system is established, it is time to measure the performance of the algorithm and determine how to improve it. Many machine learning novices are tempted to make improvements by trying out many different algorithms.\u00a0However, it is often much better to gather more data than to improve the learning\u00a0algorithm.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4111",
    "text": "How does one decide whether to gather more data? First, determine whether the performance on the training set is acceptable. If performance on the training\u00a0set is poor, the learning algorithm is not using the training data that is already\u00a0available, so there is no reason to gather more data. Instead, try increasing the\u00a0size of the model by adding more layers or adding more hidden units to each layer.\u00a0Also, try improving the learning algorithm, for example by tuning the learning rate\u00a0hyperparameter. If large models and carefully tuned optimization algorithms do\u00a0not work well, then the problem might be the quality of the training data. The\u00a0data may be too noisy or may not include the right inputs needed to predict the\u00a0desired outputs. This suggests starting over, collecting cleaner data or collecting a\u00a0richer set of features.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4112",
    "text": "If the performance on the training set is acceptable, then measure the performance on a test set. If the performance on the test set is also acceptable, then there is nothing left to be done. If test set performance is much worse than\u00a0training set performance, then gathering more data is one of the most effective\u00a0solutions. The key considerations are the cost and feasibility of gathering more\u00a0data, the cost and feasibility of reducing the test error by other means, and the\u00a0amount of data that is expected to be necessary to improve test set performance\u00a0significantly. At large internet companies with millions or billions of users, it is\u00a0feasible to gather large datasets, and the expense of doing so can be considerably\u00a0less than the other alternatives, so the answer is almost always to gather more\u00a0training data. For example, the development of large labeled datasets was one of\u00a0the most important factors in solving object recognition. In other contexts, such as\u00a0medical applications, it may be costly or infeasible to gather more data. A simple\u00a0alternative to gathering more data is to reduce the size of the model or improve\u00a0regularization, by adjusting hyperparameters such as weight decay coefficients,\u00a0or by adding regularization strategies such as dropout. If you find that the gap\u00a0between train and test performance is still unacceptable even after tuning the\u00a0regularization hyperparameters, then gathering more data is advisable.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4113",
    "text": "When deciding whether to gather more data, it is also necessary to decide how much to gather. It is helpful to plot curves showing the relationship between\u00a0training set size and generalization error, like in Fig. 5.4. By extrapolating such\u00a0curves, one can predict how much additional training data would be needed to\u00a0achieve a certain level of performance. Usually, adding a small fraction of the total\u00a0number of examples will not have a noticeable impact on generalization error. It is\u00a0therefore recommended to experiment with training set sizes on a logarithmic scale,\u00a0for example doubling the number of examples between consecutive experiments.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4114",
    "text": "If gathering much more data is not feasible, the only other way to improve generalization error is to improve the learning algorithm itself. This becomes the\u00a0domain of research and not the domain of advice for applied practitioners.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4115",
    "text": "Most deep learning algorithms come with many hyperparameters that control many aspects of the algorithm\u2019s behavior. Some of these hyperparameters affect the time\u00a0and memory cost of running the algorithm. Some of these hyperparameters affect\u00a0the quality of the model recovered by the training process and its ability to infer\u00a0correct results when deployed on new inputs.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4116",
    "text": "There are two basic approaches to choosing these hyperparameters: choosing them manually and choosing them automatically. Choosing the hyperparameters\u00a0manually requires understanding what the hyperparameters do and how machine\u00a0learning models achieve good generalization. Automatic hyperparameter selection\u00a0algorithms greatly reduce the need to understand these ideas, but they are often\u00a0much more computationally costly.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4117",
    "text": "To set hyperparameters manually, one must understand the relationship between hyperparameters, training error, generalization error and computational resources\u00a0(memory and runtime). This means establishing a solid foundation on the fundamental ideas concerning the effective capacity of a learning algorithm from\u00a0Chapter 5.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4118",
    "text": "The goal of manual hyperparameter search is usually to find the lowest generalization error subject to some runtime and memory budget. We do not discuss how to determine the runtime and memory impact of various hyperparameters here\u00a0because this is highly platform-dependent.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4119",
    "text": "The primary goal of manual hyperparameter search is to adjust the effective capacity of the model to match the complexity of the task. Effective capacity\u00a0is constrained by three factors: the representational capacity of the model, the\u00a0ability of the learning algorithm to successfully minimize the cost function used to\u00a0train the model, and the degree to which the cost function and training procedure\u00a0regularize the model. A model with more layers and more hidden units per layer has\u00a0higher representational capacity\u2014it is capable of representing more complicated\u00a0functions. It can not necessarily actually learn all of these functions though, if\u00a0the training algorithm cannot discover that certain functions do a good job of\u00a0minimizing the training cost, or if regularization terms such as weight decay forbid\u00a0some of these functions.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4120",
    "text": "The generalization error typically follows a U-shaped curve when plotted as a function of one of the hyperparameters, as in Fig. 5.3. At one extreme, the\u00a0hyperparameter value corresponds to low capacity, and generalization error is high\u00a0because training error is high. This is the underfitting regime. At the other extreme,\u00a0the hyperparameter value corresponds to high capacity, and the generalization\u00a0error is high because the gap between training and test error is high. Somewhere\u00a0in the middle lies the optimal model capacity, which achieves the lowest possible\u00a0generalization error, by adding a medium generalization gap to a medium amount\u00a0of training error.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4121",
    "text": "For some hyperparameters, overfitting occurs when the value of the hyperparameter is large. The number of hidden units in a layer is one such example, because increasing the number of hidden units increases the capacity of the model.\u00a0For some hyperparameters, overfitting occurs when the value of the hyperparameter is small. For example, the smallest allowable weight decay coefficient of zero\u00a0corresponds to the greatest effective capacity of the learning algorithm.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4122",
    "text": "Not every hyperparameter will be able to explore the entire U-shaped curve. Many hyperparameters are discrete, such as the number of units in a layer or the\u00a0number of linear pieces in a maxout unit, so it is only possible to visit a few points\u00a0along the curve. Some hyperparameters are binary. Usually these hyperparameters\u00a0are switches that specify whether or not to use some optional component of\u00a0the learning algorithm, such as a preprocessing step that normalizes the input\u00a0features by subtracting their mean and dividing by their standard deviation. These\u00a0hyperparameters can only explore two points on the curve. Other hyperparameters\u00a0have some minimum or maximum value that prevents them from exploring some\u00a0part of the curve. For example, the minimum weight decay coefficient is zero. This\u00a0means that if the model is underfitting when weight decay is zero, we can not enter\u00a0the overfitting region by modifying the weight decay coefficient. In other words,\u00a0some hyperparameters can only subtract capacity.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4123",
    "text": "The learning rate is perhaps the most important hyperparameter. If you have time to tune only one hyperparameter, tune the learning rate. It controls the effective capacity of the model in a more complicated way than other\u00a0hyperparameters\u2014the effective capacity of the model is highest when the learning\u00a0rate is correct for the optimization problem, not when the learning rate is especially large or especially small. The learning rate has a U-shaped curve for training\u00a0error, illustrated in Fig. 11.1. When the learning rate is too large, gradient descent\u00a0can inadvertently increase rather than decrease the training error. In the idealized\u00a0quadratic case, this occurs if the learning rate is at least twice as large as its\u00a0optimal value (LeCun et al., 1998a). When the learning rate is too small, training\u00a0is not only slower, but may become permanently stuck with a high training error.\u00a0This effect is poorly understood (it would not happen for a convex loss function).",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4124",
    "text": "Tuning the parameters other than the learning rate requires monitoring both training and test error to diagnose whether your model is overfitting or underfitting,\u00a0then adjusting its capacity appropriately.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4125",
    "text": "If your error on the training set is higher than your target error rate, you have no choice but to increase capacity. If you are not using regularization and you are\u00a0confident that your optimization algorithm is performing correctly, then you must\u00a0add more layers to your network or add more hidden units. Unfortunately, this\u00a0increases the computational costs associated with the model.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4126",
    "text": "If your error on the test set is higher than than your target error rate, you can",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4127",
    "text": "S\u05beH",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4128",
    "text": "S\u05beh",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4129",
    "text": "\u05e0\u05e1",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4130",
    "text": "bO",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4131",
    "text": ".s",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4132",
    "text": "*3",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4133",
    "text": "*3",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4134",
    "text": "o",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4135",
    "text": "Figure 11.1: Typical relationship between the learning rate and the training error. Notice the sharp rise in error when the learning is above an optimal value. This is for a fixed\u00a0training time, as a smaller learning rate may sometimes only slow down training by a\u00a0factor proportional to the learning rate reduction. Generalization error can follow this\u00a0curve or be complicated by regularization effects arising out of having a too large or\u00a0too small learning rates, since poor optimization can, to some degree, reduce or prevent\u00a0overfitting, and even points with equivalent training error can have different generalization\u00a0error.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4136",
    "text": "now take two kinds of actions. The test error is the sum of the training error and the gap between training and test error. The optimal test error is found by trading\u00a0off these quantities. Neural networks typically perform best when the training\u00a0error is very low (and thus, when capacity is high) and the test error is primarily\u00a0driven by the gap between train and test error. Your goal is to reduce this gap\u00a0without increasing training error faster than the gap decreases. To reduce the gap,\u00a0change regularization hyperparameters to reduce effective model capacity, such as\u00a0by adding dropout or weight decay. Usually the best performance comes from a\u00a0large model that is regularized well, for example by using dropout.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4137",
    "text": "Most hyperparameters can be set by reasoning about whether they increase or decrease model capacity. Some examples are included in Table 11.1.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4138",
    "text": "While manually tuning hyperparameters, do not lose sight of your end goal: good performance on the test set. Adding regularization is only one way to achieve\u00a0this goal. As long as you have low training error, you can always reduce generalization error by collecting more training data. The brute force way to practically\u00a0guarantee success is to continually increase model capacity and training set size\u00a0until the task is solved. This approach does of course increase the computational\u00a0cost of training and inference, so it is only feasible given appropriate resources. In",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4139",
    "text": "Hyperparameter",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4140",
    "text": "Increases capacity\u00a0when. . .",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4141",
    "text": "Reason",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4142",
    "text": "Caveats",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4143",
    "text": "Number of hidden units",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4144",
    "text": "increased",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4145",
    "text": "Increasing the number of hidden units increases the\u00a0representational capacity\u00a0of the model.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4146",
    "text": "Increasing the number of hidden units increases\u00a0both the time and memory\u00a0cost of essentially every operation on the model.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4147",
    "text": "Learning rate",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4148",
    "text": "tuned optimally",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4149",
    "text": "An improper learning rate, whether too high or too\u00a0low, results in a model\u00a0with low effective capacity\u00a0due to optimization failure",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4150",
    "text": "",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4151",
    "text": "Convolution kernel width",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4152",
    "text": "increased",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4153",
    "text": "Increasing the kernel width increases the number of parameters in the model",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4154",
    "text": "A wider kernel results in a narrower output dimension, reducing model capacity unless you use implicit zero padding to reduce this effect. Wider\u00a0kernels require more memory for parameter storage\u00a0and increase runtime, but\u00a0a narrower output reduces\u00a0memory cost.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4155",
    "text": "Implicit zero padding",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4156",
    "text": "increased",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4157",
    "text": "Adding implicit zeros before convolution keeps the representation size large",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4158",
    "text": "Increased time and memory cost of most operations.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4159",
    "text": "Weight decay coefficient",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4160",
    "text": "decreased",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4161",
    "text": "Decreasing the weight decay coefficient frees the model parameters to become larger",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4162",
    "text": "",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4163",
    "text": "Dropout rate",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4164",
    "text": "decreased",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4165",
    "text": "Dropping units less often gives the units more opportunities to \u201cconspire\u201d with\u00a0each other to fit the training set",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4166",
    "text": "",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4167",
    "text": "Table 11.1: The effect of various hyperparameters on model capacity.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4168",
    "text": "principle, this approach could fail due to optimization difficulties, but for many problems optimization does not seem to be a significant barrier, provided that the\u00a0model is chosen appropriately.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4169",
    "text": "The ideal learning algorithm just takes a dataset and outputs a function, without requiring hand-tuning of hyperparameters. The popularity of several learning\u00a0algorithms such as logistic regression and SVMs stems in part from their ability to\u00a0perform well with only one or two tuned hyperparameters. Neural networks can\u00a0sometimes perform well with only a small number of tuned hyperparameters, but\u00a0often benefit significantly from tuning of forty or more hyperparameters. Manual\u00a0hyperparameter tuning can work very well when the user has a good starting point,\u00a0such as one determined by others having worked on the same type of application\u00a0and architecture, or when the user has months or years of experience in exploring\u00a0hyperparameter values for neural networks applied to similar tasks. However,\u00a0for many applications, these starting points are not available. In these cases,\u00a0automated algorithms can find useful values of the hyperparameters.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4170",
    "text": "If we think about the way in which the user of a learning algorithm searches for good values of the hyperparameters, we realize that an optimization is taking\u00a0place: we are trying to find a value of the hyperparameters that optimizes an\u00a0objective function, such as validation error, sometimes under constraints (such as a\u00a0budget for training time, memory or recognition time). It is therefore possible, in\u00a0principle, to develop hyperparameter optimization algorithms that wrap a learning\u00a0algorithm and choose its hyperparameters, thus hiding the hyperparameters of the\u00a0learning algorithm from the user. Unfortunately, hyperparameter optimization\u00a0algorithms often have their own hyperparameters, such as the range of values that\u00a0should be explored for each of the learning algorithm\u2019s hyperparameters. However,\u00a0these secondary hyperparameters are usually easier to choose, in the sense that\u00a0acceptable performance may be achieved on a wide range of tasks using the same\u00a0secondary hyperparameters for all tasks.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4171",
    "text": "When there are three or fewer hyperparameters, the common practice is to perform grid search. For each hyperparameter, the user selects a small finite set of values to\u00a0explore. The grid search algorithm then trains a model for every joint specification\u00a0of hyperparameter values in the Cartesian product of the set of values for each\u00a0individual hyperparameter. The experiment that yields the best validation set",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4172",
    "text": "Random",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4173",
    "text": "Grid",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4174",
    "text": "Figure 11.2: Comparison of grid search and random search. For illustration purposes we display two hyperparameters but we are typically interested in having many more. (Left)\u00a0To perform grid search, we provide a set of values for each hyperparameter. The search\u00a0algorithm runs training for every joint hyperparameter setting in the cross product of these\u00a0sets. (Right) To perform random search, we provide a probability distribution over joint\u00a0hyperparameter configurations. Usually most of these hyperparameters are independent\u00a0from each other. Common choices for the distribution over a single hyperparameter include\u00a0uniform and log-uniform (to sample from a log-uniform distribution, take the exp of a\u00a0sample from a uniform distribution). The search algorithm then randomly samples joint\u00a0hyperparameter configurations and runs training with each of them. Both grid search\u00a0and random search evaluate the validation set error and return the best configuration.\u00a0The figure illustrates the typical case where only some hyperparameters have a significant\u00a0influence on the result. In this illustration, only the hyperparameter on the horizontal axis\u00a0has a significant effect. Grid search wastes an amount of computation that is exponential\u00a0in the number of non-influential hyperparameters, while random search tests a unique\u00a0value of every influential hyperparameter on nearly every trial.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4175",
    "text": "error is then chosen as having found the best hyperparameters. See the left of Fig. 11.2 for an illustration of a grid of hyperparameter values.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4176",
    "text": "How should the lists of values to search over be chosen? In the case of numerical (ordered) hyperparameters, the smallest and largest element of each list is chosen\u00a0conservatively, based on prior experience with similar experiments, to make sure\u00a0that the optimal value is very likely to be in the selected range. Typically, a\u00a0grid search involves picking values approximately on a logarithmic scale, e.g., a\u00a0learning rate taken within the set {.1, .01,10_3, 10_4, 10-5}, or a number of hidden\u00a0units taken with the set {50,100, 200,500,1000,2000}.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4177",
    "text": "Grid search usually performs best when it is performed repeatedly. For example, suppose that we ran a grid search over a hyperparameter a using values of {-1, 0, 1}.\u00a0If the best value found is 1, then we underestimated the range in which the best a\u00a0lies and we should shift the grid and run another search with a in, for example,\u00a0{1, 2, 3}. If we find that the best value of a is 0, then we may wish to refine our\u00a0estimate by zooming in and running a grid search over {-.1, 0, .1}.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4178",
    "text": "The obvious problem with grid search is that its computational cost grows exponentially with the number of hyperparameters. If there are m hyperparameters,\u00a0each taking at most n values, then the number of training and evaluation trials\u00a0required grows as O (nm). The trials may be run in parallel and exploit loose\u00a0parallelism (with almost no need for communication between different machines\u00a0carrying out the search) Unfortunately, due to the exponential cost of grid search,\u00a0even parallelization may not provide a satisfactory size of search.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4179",
    "text": "Fortunately, there is an alternative to grid search that is as simple to program, more convenient to use, and converges much faster to good values of the hyperparameters:\u00a0random search (Bergstra and Bengio, 2012).",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4180",
    "text": "A random search proceeds as follows. First we define a marginal distribution for each hyperparameter, e.g., a Bernoulli or multinoulli for binary or discrete\u00a0hyperparameters, or a uniform distribution on a log-scale for positive real-valued\u00a0hyperparameters. For example,",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4181",
    "text": "log_learning_rate ~ u(\u20141, -5) \u00a0\u00a0\u00a0(11.2)",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4182",
    "text": "learning_rate = 10log-leaming_rate \u00a0\u00a0\u00a0(11.3)",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4183",
    "text": "where u(a, b) indicates a sample of the uniform distribution in the interval (a,b). Similarly the log_number_of _hidden_units may be sampled from u(log(50),\u00a0log(2000)).",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4184",
    "text": "Unlike in the case of a grid search, one should not discretize or bin the values of the hyperparameters. This allows one to explore a larger set of values, and\u00a0does not incur additional computational cost. In fact, as illustrated in Fig. 11.2, a\u00a0random search can be exponentially more efficient than a grid search, when there\u00a0are several hyperparameters that do not strongly affect the performance measure.\u00a0This is studied at length in Bergstra and Bengio (2012), who found that random\u00a0search reduces the validation set error much faster than grid search, in terms of\u00a0the number of trials run by each method.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4185",
    "text": "As with grid search, one may often want to run repeated versions of random search, to refine the search based on the results of the first run.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4186",
    "text": "The main reason why random search finds good solutions faster than grid search is that the there are no wasted experimental runs, unlike in the case of grid search,\u00a0when two values of a hyperparameter (given values of the other hyperparameters)\u00a0would give the same result. In the case of grid search, the other hyperparameters\u00a0would have the same values for these two runs, whereas with random search, they\u00a0would usually have different values. Hence if the change between these two values\u00a0does not marginally make much difference in terms of validation set error, grid\u00a0search will unnecessarily repeat two equivalent experiments while random search\u00a0will still give two independent explorations of the other hyperparameters.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4187",
    "text": "The search for good hyperparameters can be cast as an optimization problem. The decision variables are the hyperparameters. The cost to be optimized is the\u00a0validation set error that results from training using these hyperparameters. In\u00a0simplified settings where it is feasible to compute the gradient of some differentiable\u00a0error measure on the validation set with respect to the hyperparameters, we can\u00a0simply follow this gradient (Bengio et al., 1999; Bengio, 2000; Maclaurin et al.,\u00a02015). Unfortunately, in most practical settings, this gradient is unavailable, either\u00a0due to its high computation and memory cost, or due to hyperparameters having\u00a0intrinsically non-differentiable interactions with the validation set error, as in the\u00a0case of discrete-valued hyperparameters.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4188",
    "text": "To compensate for this lack of a gradient, we can build a model of the validation set error, then propose new hyperparameter guesses by performing optimization\u00a0within this model. Most model-based algorithms for hyperparameter search use a\u00a0Bayesian regression model to estimate both the expected value of the validation set\u00a0error for each hyperparameter and the uncertainty around this expectation. Optimization thus involves a tradeoff between exploration (proposing hyperparameters\u00a0for which there is high uncertainty, which may lead to a large improvement but may\u00a0also perform poorly) and exploitation (proposing hyperparameters which the model\u00a0is confident will perform as well as any hyperparameters it has seen so far\u2014usually\u00a0hyperparameters that are very similar to ones it has seen before). Contemporary\u00a0approaches to hyperparameter optimization include Spearmint (Snoek et al., 2012),\u00a0TPE (Bergstra et al., 2011) and SMAC (Hutter et al., 2011).",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4189",
    "text": "Currently, we cannot unambiguously recommend Bayesian hyperparameter optimization as an established tool for achieving better deep learning results or\u00a0for obtaining those results with less effort. Bayesian hyperparameter optimization\u00a0sometimes performs comparably to human experts, sometimes better, but fails\u00a0catastrophically on other problems. It may be worth trying to see if it works on\u00a0a particular problem but is not yet sufficiently mature or reliable. That being\u00a0said, hyperparameter optimization is an important field of research that, while\u00a0often driven primarily by the needs of deep learning, holds the potential to benefit\u00a0not only the entire field of machine learning but the discipline of engineering in\u00a0general.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4190",
    "text": "One drawback common to most hyperparameter optimization algorithms with more sophistication than random search is that they require for a training experiment to run to completion before they are able to extract any information\u00a0from the experiment. This is much less efficient, in the sense of how much information can be gleaned early in an experiment, than manual search by a human\u00a0practitioner, since one can usually tell early on if some set of hyperparameters is\u00a0completely pathological. Swersky et al. (2014) have introduced an early version\u00a0of an algorithm that maintains a set of multiple experiments. At various time\u00a0points, the hyperparameter optimization algorithm can choose to begin a new\u00a0experiment, to \u201cfreeze\u201d a running experiment that is not promising, or to \u201cthaw\u201d\u00a0and resume an experiment that was earlier frozen but now appears promising given\u00a0more information.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4191",
    "text": "When a machine learning system performs poorly, it is usually difficult to tell whether the poor performance is intrinsic to the algorithm itself or whether there\u00a0is a bug in the implementation of the algorithm. Machine learning systems are\u00a0difficult to debug for a variety of reasons.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4192",
    "text": "In most cases, we do not know a priori what the intended behavior of the algorithm is. In fact, the entire point of using machine learning is that it will\u00a0discover useful behavior that we were not able to specify ourselves. If we train a\u00a0neural network on a new classification task and it achieves 5% test error, we have\u00a0no straightforward way of knowing if this is the expected behavior or sub-optimal\u00a0behavior.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4193",
    "text": "A further difficulty is that most machine learning models have multiple parts that are each adaptive. If one part is broken, the other parts can adapt and still\u00a0achieve roughly acceptable performance. For example, suppose that we are training\u00a0a neural net with several layers parametrized by weights W and biases b. Suppose\u00a0further that we have manually implemented the gradient descent rule for each\u00a0parameter separately, and we made an error in the update for the biases:",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4194",
    "text": "b ^ b \u2014 a \u00a0\u00a0\u00a0(11.4)",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4195",
    "text": "where a is the learning rate. This erroneous update does not use the gradient at all. It causes the biases to constantly become negative throughout learning, which\u00a0is clearly not a correct implementation of any reasonable learning algorithm. The\u00a0bug may not be apparent just from examining the output of the model though.\u00a0Depending on the distribution of the input, the weights may be able to adapt to\u00a0compensate for the negative biases.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4196",
    "text": "Most debugging strategies for neural nets are designed to get around one or both of these two difficulties. Either we design a case that is so simple that the\u00a0correct behavior actually can be predicted, or we design a test that exercises one\u00a0part of the neural net implementation in isolation.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4197",
    "text": "Some important debugging tests include:",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4198",
    "text": "Visualize the model in action : When training a model to detect objects in images, view some images with the detections proposed by the model displayed\u00a0superimposed on the image. When training a generative model of speech, listen to\u00a0some of the speech samples it produces. This may seem obvious, but it is easy to\u00a0fall into the practice of only looking at quantitative performance measurements\u00a0like accuracy or log-likelihood. Directly observing the machine learning model\u00a0performing its task will help you to determine whether the quantitative performance\u00a0numbers it achieves seem reasonable. Evaluation bugs can be some of the most\u00a0devastating bugs because they can mislead you into believing your system is\u00a0performing well when it is not.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4199",
    "text": "Visualize the worst mistakes : Most models are able to output some sort of confidence measure for the task they perform. For example, classifiers based on a\u00a0softmax output layer assign a probability to each class. The probability assigned\u00a0to the most likely class thus gives an estimate of the confidence the model has in\u00a0its classification decision. Typically, maximum likelihood training results in these\u00a0values being overestimates rather than accurate probabilities of correct prediction,\u00a0but they are somewhat useful in the sense that examples that are actually less\u00a0likely to be correctly labeled receive smaller probabilities under the model. By\u00a0viewing the training set examples that are the hardest to model correctly, one can\u00a0often discover problems with the way the data has been preprocessed or labeled.\u00a0For example, the Street View transcription system originally had a problem where\u00a0the address number detection system would crop the image too tightly and omit\u00a0some of the digits. The transcription network then assigned very low probability\u00a0to the correct answer on these images. Sorting the images to identify the most\u00a0confident mistakes showed that there was a systematic problem with the cropping.\u00a0Modifying the detection system to crop much wider images resulted in much better\u00a0performance of the overall system, even though the transcription network needed\u00a0to be able to process greater variation in the position and scale of the address\u00a0numbers.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4200",
    "text": "Reasoning about software using train and test error. It is often difficult to determine whether the underlying software is correctly implemented. Some clues\u00a0can be obtained from the train and test error. If training error is low but test error\u00a0is high, then it is likely that that the training procedure works correctly, and the\u00a0model is overfitting for fundamental algorithmic reasons. An alternative possibility\u00a0is that the test error is measured incorrectly due to a problem with saving the\u00a0model after training then reloading it for test set evaluation, or if the test data\u00a0was prepared differently from the training data. If both train and test error are\u00a0high, then it is difficult to determine whether there is a software defect or whether\u00a0the model is underfitting due to fundamental algorithmic reasons. This scenario\u00a0requires further tests, described next.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4201",
    "text": "Fit a tiny dataset: If you have high error on the training set, determine whether it is due to genuine underfitting or due to a software defect. Usually even small\u00a0models can be guaranteed to be able fit a sufficiently small dataset. For example,\u00a0a classification dataset with only one example can be fit just by setting the biases\u00a0of the output layer correctly. Usually if you cannot train a classifier to correctly\u00a0label a single example, an autoencoder to successfully reproduce a single example\u00a0with high fidelity, or a generative model to consistently emit samples resembling a\u00a0single example, there is a software defect preventing successful optimization on the\u00a0training set. This test can be extended to a small dataset with few examples.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4202",
    "text": "Compare ba,ck-propagated derivatives to numerical derivatives: If you are using a software framework that requires you to implement your own gradient computations, or if you are adding a new operation to a differentiation library and\u00a0must define its bprop method, then a common source of error is implementing this\u00a0gradient expression incorrectly. One way to verify that these derivatives are correct",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4203",
    "text": "is to compare the derivatives computed by your implementation of automatic differentiation to the derivatives computed by a finite differences. Because",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4204",
    "text": "f (x) \u2014 lim",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4205",
    "text": "e-\u25ba 0",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4206",
    "text": "f(x + e) - f(x)",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4207",
    "text": "e",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4208",
    "text": "-11.5",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4209",
    "text": "we can approximate the derivative by using a small, finite e:",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4210",
    "text": "f\u05f3(x)",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4211",
    "text": "f (x + e) - f (x)",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4212",
    "text": "e",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4213",
    "text": "-11.6",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4214",
    "text": "We can improve the accuracy of the approximation by using the centered difference:",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4215",
    "text": "f \u05f3(x)",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4216",
    "text": "f (x + 2e) - f (x - l e)",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4217",
    "text": "-11.7",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4218",
    "text": "The perturbation size e must chosen to be large enough to ensure that the perturbation is not rounded down too much by finite-precision numerical computations.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4219",
    "text": "Usually, we will want to test the gradient or Jacobian of a vector-valued function g : Rm ^ Rn. Unfortunately, finite differencing only allows us to take a single\u00a0derivative at a time. We can either run finite differencing mn times to evaluate all\u00a0of the partial derivatives of g, or we can apply the test to a new function that uses\u00a0random projections at both the input and output of g. For example, we can apply\u00a0our test of the implementation of the derivatives to f (x) where f (x) \u2014 uTg(vx),\u00a0where u and v are randomly chosen vectors. Computing f \u05f3(x) correctly requires\u00a0being able to back-propagate through g correctly, yet is efficient to do with finite\u00a0differences because f has only a single input and a single output. It is usually\u00a0a good idea to repeat this test for more than one value of u and v to reduce\u00a0the chance that the test overlooks mistakes that are orthogonal to the random\u00a0projection.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4220",
    "text": "If one has access to numerical computation on complex numbers, then there is a very efficient way to numerically estimate the gradient by using complex numbers\u00a0as input to the function (Squire and Trapp, 1998). The method is based on the\u00a0observation that",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4221",
    "text": "f (x + ie) \u2014 f (x) + ief(x) + O(e2)",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4222",
    "text": "real(f (x + ie)) \u2014 f (x) + O(e2), imag(",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4223",
    "text": "f (x + ie)",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4224",
    "text": "e",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4225",
    "text": ") \u2014 f (x) + O(e2),",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4226",
    "text": "-11.8",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4227",
    "text": "-11.9",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4228",
    "text": "where i \u2014 \u00a0\u00a0\u00a0-1. Unlike in the real-valued case above, there is no cancellation effect",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4229",
    "text": "due to taking the difference between the value of f at different points. This allows the use of tiny values of e like e \u2014 10 -150, which make the O(e2) error insignificant\u00a0for all practical purposes.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4230",
    "text": "Monitor histograms of activations and gradient: It is often useful to visualize statistics of neural network activations and gradients, collected over a large amount\u00a0of training iterations (maybe one epoch). The pre-activation value of hidden units\u00a0can tell us if the units saturate, or how often they do. For example, for rectifiers,\u00a0how often are they off? Are there units that are always off? For tanh units,\u00a0the average of the absolute value of the pre-activations tells us how saturated\u00a0the unit is. In a deep network where the propagated gradients quickly grow or\u00a0quickly vanish, optimization may be hampered. Finally, it is useful to compare the\u00a0magnitude of parameter gradients to the magnitude of the parameters themselves.\u00a0As suggested by Bottou (2015), we would like the magnitude of parameter updates\u00a0over a minibatch to represent something like 1% of the magnitude of the parameter,\u00a0not 50% or 0.001% (which would make the parameters move too slowly). It may\u00a0be that some groups of parameters are moving at a good pace while others are\u00a0stalled. When the data is sparse (like in natural language), some parameters may\u00a0be very rarely updated, and this should be kept in mind when monitoring their\u00a0evolution.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4231",
    "text": "Finally, many deep learning algorithms provide some sort of guarantee about the results produced at each step. For example, in Part III, we will see some\u00a0approximate inference algorithms that work by using algebraic solutions to optimization problems. Typically these can be debugged by testing each of their\u00a0guarantees. Some guarantees that some optimization algorithms offer include that\u00a0the objective function will never increase after one step of the algorithm, that\u00a0the gradient with respect to some subset of variables will be zero after each step\u00a0of the algorithm, and that the gradient with respect to all variables will be zero\u00a0at convergence. Usually due to rounding error, these conditions will not hold\u00a0exactly in a digital computer, so the debugging test should include some tolerance\u00a0parameter.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4232",
    "text": "To provide an end-to-end description of how to apply our design methodology in practice, we present a brief account of the Street View transcription system,\u00a0from the point of view of designing the deep learning components. Obviously,\u00a0many other components of the complete system, such as the Street View cars, the\u00a0database infrastructure, and so on, were of paramount importance.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4233",
    "text": "From the point of view of the machine learning task, the process began with data collection. The cars collected the raw data and human operators provided\u00a0labels. The transcription task was preceded by a significant amount of dataset\u00a0curation, including using other machine learning techniques to detect the house\u00a0numbers prior to transcribing them.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4234",
    "text": "The transcription project began with a choice of performance metrics and desired values for these metrics. An important general principle is to tailor the\u00a0choice of metric to the business goals for the project. Because maps are only useful\u00a0if they have high accuracy, it was important to set a high accuracy requirement\u00a0for this project. Specifically, the goal was to obtain human-level, 98% accuracy.\u00a0This level of accuracy may not always be feasible to obtain. In order to reach\u00a0this level of accuracy, the Street View transcription system sacrifices coverage.\u00a0Coverage thus became the main performance metric optimized during the project,\u00a0with accuracy held at 98%. As the convolutional network improved, it became\u00a0possible to reduce the confidence threshold below which the network refuses to\u00a0transcribe the input, eventually exceeding the goal of 95% coverage.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4235",
    "text": "After choosing quantitative goals, the next step in our recommended methodology is to rapidly establish a sensible baseline system. For vision tasks, this means a convolutional network with rectified linear units. The transcription project began\u00a0with such a model. At the time, it was not common for a convolutional network\u00a0to output a sequence of predictions. In order to begin with the simplest possible\u00a0baseline, the first implementation of the output layer of the model consisted of n\u00a0different softmax units to predict a sequence of n characters. These softmax units\u00a0were trained exactly the same as if the task were classification, with each softmax\u00a0unit trained independently.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4236",
    "text": "Our recommended methodology is to iteratively refine the baseline and test whether each change makes an improvement. The first change to the Street View\u00a0transcription system was motivated by a theoretical understanding of the coverage\u00a0metric and the structure of the data. Specifically, the network refuses to classify\u00a0an input x whenever the probability of the output sequence p (y | x ) < t for\u00a0some threshold t. Initially, the definition of p(y | x) was ad-hoc, based on simply\u00a0multiplying all of the softmax outputs together. This motivated the development\u00a0of a specialized output layer and cost function that actually computed a principled\u00a0log-likelihood. This approach allowed the example rejection mechanism to function\u00a0much more effectively.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4237",
    "text": "At this point, coverage was still below 90%, yet there were no obvious theoretical problems with the approach. Our methodology therefore suggests to instrument\u00a0the train and test set performance in order to determine whether the problem\u00a0is underfitting or overfitting. In this case, train and test set error were nearly\u00a0identical. Indeed, the main reason this project proceeded so smoothly was the\u00a0availability of a dataset with tens of millions of labeled examples. Because train\u00a0and test set error were so similar, this suggested that the problem was either due\u00a0to underfitting or due to a problem with the training data. One of the debugging\u00a0strategies we recommend is to visualize the model\u2019s worst errors. In this case, that\u00a0meant visualizing the incorrect training set transcriptions that the model gave the\u00a0highest confidence. These proved to mostly consist of examples where the input\u00a0image had been cropped too tightly, with some of the digits of the address being\u00a0removed by the cropping operation. For example, a photo of an address \u201c1849\u201d\u00a0might be cropped too tightly, with only the \u201c849\u201d remaining visible. This problem\u00a0could have been resolved by spending weeks improving the accuracy of the address\u00a0number detection system responsible for determining the cropping regions. Instead,\u00a0the team took a much more practical decision, to simply expand the width of the\u00a0crop region to be systematically wider than the address number detection system\u00a0predicted. This single change added ten percentage points to the transcription\u00a0system\u2019s coverage.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4238",
    "text": "Finally, the last few percentage points of performance came from adjusting hyperparameters. This mostly consisted of making the model larger while maintaining some restrictions on its computational cost. Because train and test error\u00a0remained roughly equal, it was always clear that any performance deficits were due\u00a0to underfitting, as well as due to a few remaining problems with the dataset itself.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4239",
    "text": "Overall, the transcription project was a great success, and allowed hundreds of millions of addresses to be transcribed both faster and at lower cost than would\u00a0have been possible via human effort.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4240",
    "text": "We hope that the design principles described in this chapter will lead to many other similar successes.",
    "chapter": "Deep Generative Models",
    "chapter_id": "main-23.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4241",
    "text": "In this chapter, we describe how to use deep learning to solve applications in computer vision, speech recognition, natural language processing, and other application areas of commercial interest. We begin by discussing the large scale neural network\u00a0implementations required for most serious AI applications. Next, we review several\u00a0specific application areas that deep learning has been used to solve. While one\u00a0goal of deep learning is to design algorithms that are capable of solving a broad\u00a0variety of tasks, so far some degree of specialization is needed. For example, vision\u00a0tasks require processing a large number of input features (pixels) per example.\u00a0Language tasks require modeling a large number of possible values (words in the\u00a0vocabulary) per input feature.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4242",
    "text": "Deep learning is based on the philosophy of connectionism: while an individual biological neuron or an individual feature in a machine learning model is not\u00a0intelligent, a large population of these neurons or features acting together can\u00a0exhibit intelligent behavior. It truly is important to emphasize the fact that the\u00a0number of neurons must be large. One of the key factors responsible for the\u00a0improvement in neural network\u2019s accuracy and the improvement of the complexity\u00a0of tasks they can solve between the 1980s and today is the dramatic increase in\u00a0the size of the networks we use. As we saw in Sec. 1.2.3, network sizes have grown\u00a0exponentially for the past three decades, yet artificial neural networks are only as\u00a0large as the nervous systems of insects.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4243",
    "text": "Because the size of neural networks is of paramount importance, deep learning",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4244",
    "text": "requires high performance hardware and software infrastructure.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4245",
    "text": "Traditionally, neural networks were trained using the CPU of a single machine. Today, this approach is generally considered insufficient. We now mostly use GPU\u00a0computing or the CPUs of many machines networked together. Before moving to\u00a0these expensive setups, researchers worked hard to demonstrate that CPUs could\u00a0not manage the high computational workload required by neural networks.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4246",
    "text": "A description of how to implement efficient numerical CPU code is beyond the scope of this book, but we emphasize here that careful implementation for\u00a0specific CPU families can yield large improvements. For example, in 2011, the best\u00a0CPUs available could run neural network workloads faster when using fixed-point\u00a0arithmetic rather than floating-point arithmetic. By creating a carefully tuned\u00a0fixed-point implementation, Vanhoucke et al. (2011) obtained a 3x speedup over\u00a0a strong floating-point system. Each new model of CPU has different performance\u00a0characteristics, so sometimes floating-point implementations can be faster too.\u00a0The important principle is that careful specialization of numerical computation\u00a0routines can yield a large payoff. Other strategies, besides choosing whether to use\u00a0fixed or floating point, include optimizing data structures to avoid cache misses\u00a0and using vector instructions. Many machine learning researchers neglect these\u00a0implementation details, but when the performance of an implementation restricts\u00a0the size of the model, the accuracy of the model suffers.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4247",
    "text": "Most modern neural network implementations are based on graphics processing units. Graphics processing units (GPUs) are specialized hardware components\u00a0that were originally developed for graphics applications. The consumer market for\u00a0video gaming systems spurred development of graphics processing hardware. The\u00a0performance characteristics needed for good video gaming systems turn out to be\u00a0beneficial for neural networks as well.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4248",
    "text": "Video game rendering requires performing many operations in parallel quickly. Models of characters and environments are specified in terms of lists of 3-D\u00a0coordinates of vertices. Graphics cards must perform matrix multiplication and\u00a0division on many vertices in parallel to convert these 3-D coordinates into 2-D\u00a0on-screen coordinates. The graphics card must then perform many computations\u00a0at each pixel in parallel to determine the color of each pixel. In both cases, the\u00a0computations are fairly simple and do not involve much branching compared to\u00a0the computational workload that a CPU usually encounters. For example, each\u00a0vertex in the same rigid object will be multiplied by the same matrix; there is no\u00a0need to evaluate an if statement per-vertex to determine which matrix to multiply\u00a0by. The computations are also entirely independent of each other, and thus may\u00a0be parallelized easily. The computations also involve processing massive buffers of\u00a0memory, containing bitmaps describing the texture (color pattern) of each object\u00a0to be rendered. Together, this results in graphics cards having been designed to\u00a0have a high degree of parallelism and high memory bandwidth, at the cost of\u00a0having a lower clock speed and less branching capability relative to traditional\u00a0CPUs.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4249",
    "text": "Neural network algorithms require the same performance characteristics as the real-time graphics algorithms described above. Neural networks usually involve\u00a0large and numerous buffers of parameters, activation values, and gradient values,\u00a0each of which must be completely updated during every step of training. These\u00a0buffers are large enough to fall outside the cache of a traditional desktop computer\u00a0so the memory bandwidth of the system often becomes the rate limiting factor.\u00a0GPUs offer a compelling advantage over CPUs due to their high memory bandwidth.\u00a0Neural network training algorithms typically do not involve much branching or\u00a0sophisticated control, so they are appropriate for GPU hardware. Since neural\u00a0networks can be divided into multiple individual \u201cneurons\u201d that can be processed\u00a0independently from the other neurons in the same layer, neural networks easily\u00a0benefit from the parallelism of GPU computing.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4250",
    "text": "GPU hardware was originally so specialized that it could only be used for graphics tasks. Over time, GPU hardware became more flexible, allowing custom\u00a0subroutines to be used to transform the coordinates of vertices or assign colors\u00a0to pixels. In principle, there was no requirement that these pixel values actually\u00a0be based on a rendering task. These GPUs could be used for scientific computing\u00a0by writing the output of a computation to a buffer of pixel values. Steinkrau\u00a0et al. (2005) implemented a two-layer fully connected neural network on a GPU\u00a0and reported a 3X speedup over their CPU-based baseline. Shortly thereafter,\u00a0Chellapilla et al. (2006) demonstrated that the same technique could be used to\u00a0accelerate supervised convolutional networks.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4251",
    "text": "The popularity of graphics cards for neural network training exploded after the advent of general purpose GPUs. These GP-GPUs could execute arbitrary code,\u00a0not just rendering subroutines. NVIDIA\u2019s CUDA programming language provided\u00a0a way to write this arbitrary code in a C-like language. With their relatively\u00a0convenient programming model, massive parallelism, and high memory bandwidth,",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4252",
    "text": "GP-GPUs now offer an ideal platform for neural network programming. This platform was rapidly adopted by deep learning researchers soon after it became\u00a0available (Raina et al., 2009; Ciresan et al., 2010).",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4253",
    "text": "Writing efficient code for GP-GPUs remains a difficult task best left to specialists. The techniques required to obtain good performance on GPU are very different from those used on CPU. For example, good CPU-based code is usually\u00a0designed to read information from the cache as much as possible. On GPU, most\u00a0writable memory locations are not cached, so it can actually be faster to compute\u00a0the same value twice, rather than compute it once and read it back from memory.\u00a0GPU code is also inherently multi-threaded and the different threads must be\u00a0coordinated with each other carefully. For example, memory operations are faster\u00a0if they can be coalesced. Coalesced reads or writes occur when several threads can\u00a0each read or write a value that they need simultaneously, as part of a single memory\u00a0transaction. Different models of GPUs are able to coalesce different kinds of read\u00a0or write patterns. Typically, memory operations are easier to coalesce if among n\u00a0threads, thread i accesses byte i + j of memory, and j is a multiple of some power\u00a0of 2. The exact specifications differ between models of GPU. Another common\u00a0consideration for GPUs is making sure that each thread in a group executes the\u00a0same instruction simultaneously. This means that branching can be difficult on\u00a0GPU. Threads are divided into small groups called warps. Each thread in a warp\u00a0executes the same instruction during each cycle, so if different threads within the\u00a0same warp need to execute different code paths, these different code paths must\u00a0be traversed sequentially rather than in parallel.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4254",
    "text": "Due to the difficulty of writing high performance GPU code, researchers should structure their workflow to avoid needing to write new GPU code in order to test\u00a0new models or algorithms. Typically, one can do this by building a software library\u00a0of high performance operations like convolution and matrix multiplication, then\u00a0specifying models in terms of calls to this library of operations. For example, the\u00a0machine learning library Pylearn2 (Goodfellow et al., 2013c) specifies all of its\u00a0machine learning algorithms in terms of calls to Theano (Bergstra et al., 2010;\u00a0Bastien et al., 2012) and cuda-convnet (Krizhevsky, 2010), which provide these\u00a0high-performance operations. This factored approach can also ease support for\u00a0multiple kinds of hardware. For example, the same Theano program can run on\u00a0either CPU or GPU, without needing to change any of the calls to Theano itself.\u00a0Other libraries like TensorFlow (Abadi et al., 2015) and Torch (Collobert et al.,\u00a02011b) provide similar features.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4255",
    "text": "In many cases, the computational resources available on a single machine are insufficient. We therefore want to distribute the workload of training and inference\u00a0across many machines.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4256",
    "text": "Distributing inference is simple, because each input example we want to process can be run by a separate machine. This is known as data parallelism.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4257",
    "text": "It is also possible to get model parallelism, where multiple machines work together on a single datapoint, with each machine running a different part of the\u00a0model. This is feasible for both inference and training.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4258",
    "text": "Data parallelism during training is somewhat harder. We can increase the size of the minibatch used for a single SGD step, but usually we get less than linear\u00a0returns in terms of optimization performance. It would be better to allow multiple\u00a0machines to compute multiple gradient descent steps in parallel. Unfortunately,\u00a0the standard definition of gradient descent is as a completely sequential algorithm:\u00a0the gradient at step t is a function of the parameters produced by step t \u2014 1.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4259",
    "text": "This can be solved using a.synchronous stochastic gradient descent (Bengio et al., 2001; Recht et al., 2011). In this approach, several processor cores share\u00a0the memory representing the parameters. Each core reads parameters without a\u00a0lock, then computes a gradient, then increments the parameters without a lock.\u00a0This reduces the average amount of improvement that each gradient descent step\u00a0yields, because some of the cores overwrite each other\u2019s progress, but the increased\u00a0rate of production of steps causes the learning process to be faster overall. Dean\u00a0et al. (2012) pioneered the multi-machine implementation of this lock-free approach\u00a0to gradient descent, where the parameters are managed by a parameter server\u00a0rather than stored in shared memory. Distributed asynchronous gradient descent\u00a0remains the primary strategy for training large deep networks and is used by\u00a0most major deep learning groups in industry (Chilimbi et al., 2014; Wu et al.,\u00a02015). Academic deep learning researchers typically cannot afford the same scale\u00a0of distributed learning systems but some research has focused on how to build\u00a0distributed networks with relatively low-cost hardware available in the university\u00a0setting (Coates et al., 2013).",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4260",
    "text": "In many commercial applications, it is much more important that the time and memory cost of running inference in a machine learning model be low than that\u00a0the time and memory cost of training be low. For applications that do not require\u00a0personalization, it is possible to train a model once, then deploy it to be used by\u00a0billions of users. In many cases, the end user is more resource-constrained than\u00a0the developer. For example, one might train a speech recognition network with a\u00a0powerful computer cluster, then deploy it on mobile phones.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4261",
    "text": "A key strategy for reducing the cost of inference is model compression (Bucilua et al., 2006). The basic idea of model compression is to replace the original,\u00a0expensive model with a smaller model that requires less memory and runtime to\u00a0store and evaluate.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4262",
    "text": "Model compression is applicable when the size of the original model is driven primarily by a need to prevent overfitting. In most cases, the model with the\u00a0lowest generalization error is an ensemble of several independently trained models.\u00a0Evaluating all n ensemble members is expensive. Sometimes, even a single model\u00a0generalizes better if it is large (for example, if it is regularized with dropout).",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4263",
    "text": "These large models learn some function f (x), but do so using many more parameters than are necessary for the task. Their size is necessary only due to\u00a0the limited number of training examples. As soon as we have fit this function\u00a0f (x), we can generate a training set containing infinitely many examples, simply\u00a0by applying f to randomly sampled points x. We then train the new, smaller,\u00a0model to match f (x) on these points. In order to most efficiently use the capacity\u00a0of the new, small model, it is best to sample the new x points from a distribution\u00a0resembling the actual test inputs that will be supplied to the model later. This can\u00a0be done by corrupting training examples or by drawing points from a generative\u00a0model trained on the original training set.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4264",
    "text": "Alternatively, one can train the smaller model only on the original training points, but train it to copy other features of the model, such as its posterior\u00a0distribution over the incorrect classes (Hinton et al., 2014, 2015).",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4265",
    "text": "One strategy for accelerating data processing systems in general is to build systems that have dynamic structure in the graph describing the computation needed to\u00a0process an input. Data processing systems can dynamically determine which\u00a0subset of many neural networks should be run on a given input. Individual neural\u00a0networks can also exhibit dynamic structure internally by determining which subset\u00a0of features (hidden units) to compute given information from the input. This\u00a0form of dynamic structure inside neural networks is sometimes called conditional\u00a0computation (Bengio, 2013; Bengio et al., 2013b). Since many components of the\u00a0architecture may be relevant only for a small amount of possible inputs, the system",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4266",
    "text": "can run faster by computing these features only when they are needed.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4267",
    "text": "Dynamic structure of computations is a basic computer science principle applied generally throughout the software engineering discipline. The simplest versions\u00a0of dynamic structure applied to neural networks are based on determining which\u00a0subset of some group of neural networks (or other machine learning models) should\u00a0be applied to a particular input.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4268",
    "text": "A venerable strategy for accelerating inference in a classifier is to use a cascade of classifiers. The cascade strategy may be applied when the goal is to detect the\u00a0presence of a rare object (or event). To know for sure that the object is present,\u00a0we must use a sophisticated classifier with high capacity, that is expensive to run.\u00a0However, because the object is rare, we can usually use much less computation\u00a0to reject inputs as not containing the object. In these situations, we can train\u00a0a sequence of classifiers. The first classifiers in the sequence have low capacity,\u00a0and are trained to have high recall. In other words, they are trained to make sure\u00a0we do not wrongly reject an input when the object is present. The final classifier\u00a0is trained to have high precision. At test time, we run inference by running the\u00a0classifiers in a sequence, abandoning any example as soon as any one element in\u00a0the cascade rejects it. Overall, this allows us to verify the presence of objects with\u00a0high confidence, using a high capacity model, but does not force us to pay the cost\u00a0of full inference for every example. There are two different ways that the cascade\u00a0can achieve high capacity. One way is to make the later members of the cascade\u00a0individually have high capacity. In this case, the system as a whole obviously has\u00a0high capacity, because some of its individual members do. It is also possible to\u00a0make a cascade in which every individual model has low capacity but the system\u00a0as a whole has high capacity due to the combination of many small models. Viola\u00a0and Jones (2001) used a cascade of boosted decision trees to implement a fast and\u00a0robust face detector suitable for use in handheld digital cameras. Their classifier\u00a0localizes a face using essentially a sliding window approach in which many windows\u00a0are examined and rejected if they do not contain faces. Another version of cascades\u00a0uses the earlier models to implement a sort of hard attention mechanism: the\u00a0early members of the cascade localize an object and later members of the cascade\u00a0perform further processing given the location of the object. For example, Google\u00a0transcribes address numbers from Street View imagery using a two-step cascade\u00a0that first locates the address number with one machine learning model and then\u00a0transcribes it with another (Goodfellow et al, 2014d).",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4269",
    "text": "Decision trees themselves are an example of dynamic structure, because each node in the tree determines which of its subtrees should be evaluated for each input.\u00a0A simple way to accomplish the union of deep learning and dynamic structure\u00a0is to train a decision tree in which each node uses a neural network to make the\u00a0splitting decision (Guo and Gelfand, 1992), though this has typically not been\u00a0done with the primary goal of accelerating inference computations.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4270",
    "text": "In the same spirit, one can use a neural network, called the gater to select which one out of several expert networks will be used to compute the output, given the\u00a0current input. The first version of this idea is called the mixture of experts (Nowlan,\u00a01990; Jacobs et al., 1991), in which the gater outputs a set of probabilities or\u00a0weights (obtained via a softmax nonlinearity), one per expert, and the final output\u00a0is obtained by the weighted combination of the output of the experts. In that\u00a0case, the use of the gater does not offer a reduction in computational cost, but if a\u00a0single expert is chosen by the gater for each example, we obtain the hard mixture\u00a0of experts (Collobert et al., 2001, 2002), which can considerably accelerate training\u00a0and inference time. This strategy works well when the number of gating decisions is\u00a0small because it is not combinatorial. But when we want to select different subsets\u00a0of units or parameters, it is not possible to use a \u201csoft switch\u201d because it requires\u00a0enumerating (and computing outputs for) all the gater configurations. To deal\u00a0with this problem, several approaches have been explored to train combinatorial\u00a0gaters. Bengio et al. (2013b) experiment with several estimators of the gradient\u00a0on the gating probabilities, while Bacon et al. (2015) and Bengio et al. (2015a) use\u00a0reinforcement learning techniques (policy gradient) to learn a form of conditional\u00a0dropout on blocks of hidden units and get an actual reduction in computational\u00a0cost without impacting negatively on the quality of the approximation.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4271",
    "text": "Another kind of dynamic structure is a switch, where a hidden unit can receive input from different units depending on the context. This dynamic routing\u00a0approach can be interpreted as an attention mechanism (Olshausen et al., 1993).\u00a0So far, the use of a hard switch has not proven effective on large-scale applications.\u00a0Contemporary approaches instead use a weighted average over many possible inputs,\u00a0and thus do not achieve all of the possible computational benefits of dynamic\u00a0structure. Contemporary attention mechanisms are described in Sec. 12.4.5.1.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4272",
    "text": "One major obstacle to using dynamically structured systems is the decreased degree of parallelism that results from the system following different code branches\u00a0for different inputs. This means that few operations in the network can be described\u00a0as matrix multiplication or batch convolution on a minibatch of examples. We\u00a0can write more specialized sub-routines that convolve each example with different\u00a0kernels or multiply each row of a design matrix by a different set of columns\u00a0of weights. Unfortunately, these more specialized subroutines are difficult to\u00a0implement efficiently. CPU implementations will be slow due to the lack of cache\u00a0coherence and GPU implementations will be slow due to the lack of coalesced\u00a0memory transactions and the need to serialize warps when members of a warp take\u00a0different branches. In some cases, these issues can be mitigated by partitioning the\u00a0examples into groups that all take the same branch, and processing these groups\u00a0of examples simultaneously. This can be an acceptable strategy for minimizing\u00a0the time required to process a fixed amount of examples in an offline setting. In\u00a0a real-time setting where examples must be processed continuously, partitioning\u00a0the workload can result in load-balancing issues. For example, if we assign one\u00a0machine to process the first step in a cascade and another machine to process\u00a0the last step in a cascade, then the first will tend to be overloaded and the last\u00a0will tend to be underloaded. Similar issues arise if each machine is assigned to\u00a0implement different nodes of a neural decision tree.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4273",
    "text": "Since the early days of neural networks research, hardware designers have worked on specialized hardware implementations that could speed up training and/or\u00a0inference of neural network algorithms. See early and more recent reviews of\u00a0specialized hardware for deep networks (Lindsey and Lindblad, 1994; Beiu et al.,\u00a02003; Misra and Saha, 2010).",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4274",
    "text": "Different forms of specialized hardware (Graf and Jackel, 1989; Mead and Ismail, 2012; Kim et al., 2009; Pham et al., 2012; Chen et al., 2014a,b) have\u00a0been developed over the last decades, either with ASICs (application-specific integrated circuit), either with digital (based on binary representations of numbers),\u00a0analog (Graf and Jackel, 1989; Mead and Ismail, 2012) (based on physical implementations of continuous values as voltages or currents) or hybrid implementations\u00a0(combining digital and analog components). In recent years more flexible FPGA\u00a0(field programmable gated array) implementations (where the particulars of the\u00a0circuit can be written on the chip after it has been built) have been developed.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4275",
    "text": "Though software implementations on general-purpose processing units (CPUs and GPUs) typically use 32 or 64 bits of precision to represent floating point\u00a0numbers, it has long been known that it was possible to use less precision, at\u00a0least at inference time (Holt and Baker, 1991; Holi and Hwang, 1993; Presley\u00a0and Haggard, 1994; Simard and Graf, 1994; Wawrzynek et al., 1996; Savich et al.,\u00a02007). This has become a more pressing issue in recent years as deep learning\u00a0has gained in popularity in industrial products, and as the great impact of faster\u00a0hardware was demonstrated with GPUs. Another factor that motivates current\u00a0research on specialized hardware for deep networks is that the rate of progress of\u00a0a single CPU or GPU core has slowed down, and most recent improvements in\u00a0computing speed have come from parallelization across cores (either in CPUs or",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4276",
    "text": "GPUs). This is very different from the situation of the 1990s (the previous neural network era) where the hardware implementations of neural networks (which might\u00a0take two years from inception to availability of a chip) could not keep up with\u00a0the rapid progress and low prices of general-purpose CPUs. Building specialized\u00a0hardware is thus a way to push the envelope further, at a time when new hardware\u00a0designs are being developed for low-power devices such as phones, aiming for\u00a0general-public applications of deep learning (e.g., with speech, computer vision or\u00a0natural language).",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4277",
    "text": "Recent work on low-precision implementations of backprop-based neural nets (Vanhoucke et al., 2011; Courbariaux et al., 2015; Gupta et al., 2015) suggests\u00a0that between 8 and 16 bits of precision can suffice for using or training deep\u00a0neural networks with back-propagation. What is clear is that more precision is\u00a0required during training than at inference time, and that some forms of dynamic\u00a0fixed point representation of numbers can be used to reduce how many bits are\u00a0required per number. Traditional fixed point numbers are restricted to a fixed\u00a0range (which corresponds to a given exponent in a floating point representation).\u00a0Dynamic fixed point representations share that range among a set of numbers\u00a0(such as all the weights in one layer). Using fixed point rather than floating point\u00a0representations and using less bits per number reduces the hardware surface area,\u00a0power requirements and computing time needed for performing multiplications,\u00a0and multiplications are the most demanding of the operations needed to use or\u00a0train a modern deep network with backprop.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4278",
    "text": "Computer vision has traditionally been one of the most active research areas for deep learning applications, because vision is a task that is effortless for humans\u00a0and many animals but challenging for computers (Ballard et al., 1983). Many of\u00a0the most popular standard benchmark tasks for deep learning algorithms are forms\u00a0of object recognition or optical character recognition.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4279",
    "text": "Computer vision is a very broad field encompassing a wide variety of ways of processing images, and an amazing diversity of applications. Applications of\u00a0computer vision range from reproducing human visual abilities, such as recognizing\u00a0faces, to creating entirely new categories of visual abilities. As an example of\u00a0the latter category, one recent computer vision application is to recognize sound\u00a0waves from the vibrations they induce in objects visible in a video (Davis et al.,",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4280",
    "text": "2014). Most deep learning research on computer vision has not focused on such exotic applications that expand the realm of what is possible with imagery but\u00a0rather a small core of AI goals aimed at replicating human abilities. Most deep\u00a0learning for computer vision is used for object recognition or detection of some\u00a0form, whether this means reporting which object is present in an image, annotating\u00a0an image with bounding boxes around each object, transcribing a sequence of\u00a0symbols from an image, or labeling each pixel in an image with the identity of the\u00a0object it belongs to. Because generative modeling has been a guiding principle\u00a0of deep learning research, there is also a large body of work on image synthesis\u00a0using deep models. While image synthesis ex nihilo is usually not considered a\u00a0computer vision endeavor, models capable of image synthesis are usually useful for\u00a0image restoration, a computer vision task involving repairing defects in images or\u00a0removing objects from images.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4281",
    "text": "Many application areas require sophisticated preprocessing because the original input comes in a form that is difficult for many deep learning architectures to\u00a0represent. Computer vision usually requires relatively little of this kind of preprocessing. The images should be standardized so that their pixels all lie in the same,\u00a0reasonable range, like [0,1] or [-1, 1]. Mixing images that lie in [0,1] with images\u00a0that lie in [0, 255] will usually result in failure. Formatting images to have the same\u00a0scale is the only kind of preprocessing that is strictly necessary. Many computer\u00a0vision architectures require images of a standard size, so images must be cropped or\u00a0scaled to fit that size. However, even this rescaling is not always strictly necessary.\u00a0Some convolutional models accept variably-sized inputs and dynamically adjust\u00a0the size of their pooling regions to keep the output size constant (Waibel et al.,\u00a01989). Other convolutional models have variable-sized output that automatically\u00a0scales in size with the input, such as models that denoise or label each pixel in an\u00a0image (Hadsell et al., 2007).",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4282",
    "text": "Dataset augmentation may be seen as a way of preprocessing the training set only. Dataset augmentation is an excellent way to reduce the generalization error\u00a0of most computer vision models. A related idea applicable at test time is to show\u00a0the model many different versions of the same input (for example, the same image\u00a0cropped at slightly different locations) and have the different instantiations of the\u00a0model vote to determine the output. This latter idea can be interpreted as an\u00a0ensemble approach, and helps to reduce generalization error.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4283",
    "text": "Other kinds of preprocessing are applied to both the train and the test set with the goal of putting each example into a more canonical form in order to reduce the\u00a0amount of variation that the model needs to account for. Reducing the amount of\u00a0variation in the data can both reduce generalization error and reduce the size of\u00a0the model needed to fit the training set. Simpler tasks may be solved by smaller\u00a0models, and simpler solutions are more likely to generalize well. Preprocessing\u00a0of this kind is usually designed to remove some kind of variability in the input\u00a0data that is easy for a human designer to describe and that the human designer\u00a0is confident has no relevance to the task. When training with large datasets and\u00a0large models, this kind of preprocessing is often unnecessary, and it is best to just\u00a0let the model learn which kinds of variability it should become invariant to. For\u00a0example, the AlexNet system for classifying ImageNet only has one preprocessing\u00a0step: subtracting the mean across training examples of each pixel (Krizhevsky\u00a0et al., 2012).",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4284",
    "text": "12.2.1.1 Contrast Normalization",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4285",
    "text": "One of the most obvious sources of variation that can be safely removed for many tasks is the amount of contrast in the image. Contrast simply refers to the\u00a0magnitude of the difference between the bright and the dark pixels in an image.\u00a0There are many ways of quantifying the contrast of an image. In the context of\u00a0deep learning, contrast usually refers to the standard deviation of the pixels in an\u00a0image or region of an image. Suppose we have an image represented by a tensor\u00a0X \u00a3 Rrxcx3, with Xbeing the red intensity at row i and column j, Xj2 giving\u00a0the green intensity and Xj3 giving the blue intensity. Then the contrast of the\u00a0entire image is given by",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4286",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4287",
    "text": "r c 3",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4288",
    "text": "3rc 'Xl'Xl5Z(Xi\u2019j\u2019fc X)",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4289",
    "text": "2",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4290",
    "text": "-12.1",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4291",
    "text": "i=1 j=1 k= 1",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4292",
    "text": "where X is the mean intensity of the entire image:",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4293",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4294",
    "text": "r c 3",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4295",
    "text": "X3 \u05beZXj-k \u2022",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4296",
    "text": "-12.2",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4297",
    "text": "i=1j=1 k=1",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4298",
    "text": "Global contrast normalization (GCN) aims to prevent images from having varying amounts of contrast by subtracting the mean from each image, then\u00a0rescaling it so that the standard deviation across its pixels is equal to some\u00a0constant s. This approach is complicated by the fact that no scaling factor can\u00a0change the contrast of a zero-contrast image (one whose pixels all have equal\u00a0intensity). Images with very low but non-zero contrast often have little information\u00a0content. Dividing by the true standard deviation usually accomplishes nothing\u00a0more than amplifying sensor noise or compression artifacts in such cases. This",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4299",
    "text": "motivates introducing a small, positive regularization parameter A to bias the estimate of the standard deviation. Alternately, one can constrain the denominator\u00a0to be at least e. Given an input image X, GCN produces an output image X',\u00a0defined such that",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4300",
    "text": "Xi,j,k \u00a0\u00a0\u00a0S",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4301",
    "text": "max e",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4302",
    "text": "{e^A + ^ K1\u05be j ELi (-j - X )2 }",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4303",
    "text": "-12.3",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4304",
    "text": "Datasets consisting of large images cropped to interesting objects are unlikely to contain any images with nearly constant intensity. In these cases, it is safe\u00a0to practically ignore the small denominator problem by setting A = 0 and avoid\u00a0division by 0 in extremely rare cases by setting e to an extremely low value like\u00a010-8. This is the approach used by Goodfellow et al. (2013a) on the CIFAR-10\u00a0dataset. Small images cropped randomly are more likely to have nearly constant\u00a0intensity, making aggressive regularization more useful. Coates et al. (2011) used\u00a0e = 0 and A = 10 on small, randomly selected patches drawn from CIFAR-10.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4305",
    "text": "The scale parameter s can usually be set to 1, as done by Coates et al. (2011), or chosen to make each individual pixel have standard deviation across examples\u00a0close to 1, as done by Goodfellow et al. (2013a).",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4306",
    "text": "The standard deviation in Eq. 12.3 is just a rescaling of the L2 norm of the image (assuming the mean of the image has already been removed). It is preferable\u00a0to define GCN in terms of standard deviation rather than L2 norm because the\u00a0standard deviation includes division by the number of pixels, so GCN based on\u00a0standard deviation allows the same s to be used regardless of image size. However,\u00a0the observation that the L2 norm is proportional to the standard deviation can\u00a0help build a useful intuition. One can understand GCN as mapping examples to\u00a0a spherical shell. See Fig. 12.1 for an illustration. This can be a useful property\u00a0because neural networks are often better at responding to directions in space rather\u00a0than exact locations. Responding to multiple distances in the same direction\u00a0requires hidden units with collinear weight vectors but different biases. Such\u00a0coordination can be difficult for the learning algorithm to discover. Additionally,\u00a0many shallow graphical models have problems with representing multiple separated\u00a0modes along the same line. GCN avoids these problems by reducing each example\u00a0to a direction rather than a direction and a distance.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4307",
    "text": "Counterintuitively, there is a preprocessing operation known as sphering and it is not the same operation as GCN. Sphering does not refer to making the data lie\u00a0on a spherical shell, but rather to rescaling the principal components to have equal\u00a0variance, so that the multivariate normal distribution used by PCA has spherical\u00a0contours. Sphering is more commonly known as whitening.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4308",
    "text": "1.5",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4309",
    "text": "0",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4310",
    "text": "1.5",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4311",
    "text": "_L",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4312",
    "text": "Raw input",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4313",
    "text": "_L",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4314",
    "text": "GCN, A = 0",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4315",
    "text": ",'ft",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4316",
    "text": "_L",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4317",
    "text": "-1.5 \u00a0\u00a0\u00a00.0\u00a0\u00a0\u00a0\u00a01.5",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4318",
    "text": "x0",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4319",
    "text": "_L",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4320",
    "text": "-1.5 \u00a0\u00a0\u00a00.0\u00a0\u00a0\u00a0\u00a01.5",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4321",
    "text": "x0",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4322",
    "text": "GCN, A = 10-2",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4323",
    "text": "\u05be\u05be1-1-1\u05be",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4324",
    "text": "Vl )",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4325",
    "text": "_L",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4326",
    "text": "_L",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4327",
    "text": "Figure 12.1: GCN maps examples onto a sphere. (Left) Raw input data may have any norm. (Center) GCN with A =0 maps all non-zero examples perfectly onto a sphere.\u00a0Here we use s = 1 and e = 10-8. Because we use GCN based on normalizing the standard\u00a0deviation rather than the L2 norm, the resulting sphere is not the unit sphere. (Right)\u00a0Regularized GCN, with A > 0, draws examples toward the sphere but does not completely\u00a0discard the variation in their norm. We leave s and e the same as before.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4328",
    "text": "Global contrast normalization will often fail to highlight image features we would like to stand out, such as edges and corners. If we have a scene with a large\u00a0dark area and a large bright area (such as a city square with half the image in\u00a0the shadow of a building) then global contrast normalization will ensure there is a\u00a0large difference between the brightness of the dark area and the brightness of the\u00a0light area. It will not, however, ensure that edges within the dark region stand out.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4329",
    "text": "This motivates local contrast normalization. Local contrast normalization ensures that the contrast is normalized across each small window, rather than over\u00a0the image as a whole. See Fig. 12.2 for a comparison of global and local contrast\u00a0normalization.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4330",
    "text": "Various definitions of local contrast normalization are possible. In all cases, one modifies each pixel by subtracting a mean of nearby pixels and dividing by\u00a0a standard deviation of nearby pixels. In some cases, this is literally the mean\u00a0and standard deviation of all pixels in a rectangular window centered on the\u00a0pixel to be modified (Pinto et al., 2008). In other cases, this is a weighted mean\u00a0and weighted standard deviation using Gaussian weights centered on the pixel to\u00a0be modified. In the case of color images, some strategies process different color\u00a0channels separately while others combine information from different channels to\u00a0normalize each pixel (Sermanet et al., 2012).",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4331",
    "text": "Input image",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4332",
    "text": "GCN",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4333",
    "text": "LCN",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4334",
    "text": "Figure 12.2: A comparison of global and local contrast normalization. Visually, the effects of global contrast normalization are subtle. It places all images on roughly the same\u00a0scale, which reduces the burden on the learning algorithm to handle multiple scales. Local\u00a0contrast normalization modifies the image much more, discarding all regions of constant\u00a0intensity. This allows the model to focus on just the edges. Regions of fine texture,\u00a0such as the houses in the second row, may lose some detail due to the bandwidth of the\u00a0normalization kernel being too high.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4335",
    "text": "Local contrast normalization can usually be implemented efficiently by using separable convolution (see Sec. 9.8) to compute feature maps of local means and\u00a0local standard deviations, then using element-wise subtraction and element-wise\u00a0division on different feature maps.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4336",
    "text": "Local contrast normalization is a differentiable operation and can also be used as a nonlinearity applied to the hidden layers of a network, as well as a preprocessing\u00a0operation applied to the input.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4337",
    "text": "As with global contrast normalization, we typically need to regularize local contrast normalization to avoid division by zero. In fact, because local contrast\u00a0normalization typically acts on smaller windows, it is even more important to\u00a0regularize. Smaller windows are more likely to contain values that are all nearly\u00a0the same as each other, and thus more likely to have zero standard deviation.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4338",
    "text": "12.2.1.2 Dataset Augmentation",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4339",
    "text": "As described in Sec. 7.4, it is easy to improve the generalization of a classifier by increasing the size of the training set by adding extra copies of the training\u00a0examples that have been modified with transformations that do not change the\u00a0class. Object recognition is a classification task that is especially amenable to\u00a0this form of dataset augmentation because the class is invariant to so many\u00a0transformations and the input can be easily transformed with many geometric\u00a0operations. As described before, classifiers can benefit from random translations,\u00a0rotations, and in some cases, flips of the input to augment the dataset. In specialized\u00a0computer vision applications, more advanced transformations are commonly used\u00a0for dataset augmentation. These schemes include random perturbation of the\u00a0colors in an image (Krizhevsky et al., 2012) and nonlinear geometric distortions of\u00a0the input (LeCun et al., 1998b).",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4340",
    "text": "The task of speech recognition is to map an acoustic signal containing a spoken natural language utterance into the corresponding sequence of words intended by\u00a0the speaker. Let X = (x(1),\u00a0\u00a0\u00a0\u00a0,..., x(T)) denote the sequence of acoustic input",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4341",
    "text": "vectors (traditionally produced by splitting the audio into 20ms frames). Most speech recognition systems preprocess the input using specialized hand-designed\u00a0features, but some (Jaitly and Hinton, 2011) deep learning systems learn features\u00a0from raw input. Let y = (y1, y2,..., yN) denote the target output sequence (usually\u00a0a sequence of words or characters). The automatic speech recognition (ASR) task\u00a0consists of creating a function fAsr that computes the most probable linguistic\u00a0sequence y given the acoustic sequence X:",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4342",
    "text": "fAsa(X) = argmaxP* (y | X = X) \u00a0\u00a0\u00a0(12.4)",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4343",
    "text": "y",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4344",
    "text": "where P* is the true conditional distribution relating the inputs X to the targets",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4345",
    "text": "y.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4346",
    "text": "Since the 1980s and until about 2009-2012, state-of-the art speech recognition systems primarily combined hidden Markov models (HMMs) and Gaussian mixture\u00a0models (GMMs). GMMs modeled the association between acoustic features and\u00a0phonemes (Bahl et al., 1987), while HMMs modeled the sequence of phonemes.\u00a0The GMM-HMM model family treats acoustic waveforms as being generated\u00a0by the following process: first an HMM generates a sequence of phonemes and\u00a0discrete sub-phonemic states (such as the beginning, middle, and end of each\u00a0phoneme), then a GMM transforms each discrete symbol into a brief segment of\u00a0audio waveform. Although GMM-HMM systems dominated ASR until recently,\u00a0speech recognition was actually one of the first areas where neural networks were\u00a0applied, and numerous ASR systems from the late 1980s and early 1990s used\u00a0neural nets (Bourlard and Wellekens, 1989; Waibel et al1989; Robinson and\u00a0Fallside, 1991; Bengio et al., 1991, 1992; Konig et al., 1996). At the time, the\u00a0performance of ASR based on neural nets approximately matched the performance\u00a0of GMM-HMM systems. For example, Robinson and Fallside (1991) achieved\u00a026% phoneme error rate on the TIMIT (Garofolo et al., 1993) corpus (with 39\u00a0phonemes to discriminate between), which was better than or comparable to\u00a0HMM-based systems. Since then, TIMIT has been a benchmark for phoneme\u00a0recognition, playing a role similar to the role MNIST plays for object recognition.\u00a0However, because of the complex engineering involved in software systems for\u00a0speech recognition and the effort that had been invested in building these systems\u00a0on the basis of GMM-HMMs, the industry did not see a compelling argument\u00a0for switching to neural networks. As a consequence, until the late 2000s, both\u00a0academic and industrial research in using neural nets for speech recognition mostly\u00a0focused on using neural nets to learn extra features for GMM-HMM systems.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4347",
    "text": "Later, with much larger and deeper models and much larger datasets, recognition accuracy was dramatically improved by using neural networks to\u00a0replace GMMs for the task of associating acoustic features to phonemes (or subphonemic states). Starting in 2009, speech researchers applied a form of deep\u00a0learning based on unsupervised learning to speech recognition. This approach\u00a0to deep learning was based on training undirected probabilistic models called\u00a0restricted Boltzmann machines (RBMs) to model the input data. RBMs will be\u00a0described in Part III. To solve speech recognition tasks, unsupervised pretraining\u00a0was used to build deep feedforward networks whose layers were each initialized\u00a0by training an RBM. These networks take spectral acoustic representations in\u00a0a fixed-size input window (around a center frame) and predict the conditional\u00a0probabilities of HMM states for that center frame. Training such deep networks\u00a0helped to significantly improve the recognition rate on TIMIT (Mohamed et al.,\u00a02009, 2012a), bringing down the phoneme error rate from about 26% to 20.7%.\u00a0See Mohamed et al. (2012b) for an analysis of reasons for the success of these\u00a0models. Extensions to the basic phone recognition pipeline included the addition\u00a0of speaker-adaptive features (Mohamed et al., 2011) that further reduced the\u00a0error rate. This was quickly followed up by work to expand the architecture from\u00a0phoneme recognition (which is what TIMIT is focused on) to large-vocabulary\u00a0speech recognition (Dahl et al., 2012), which involves not just recognizing phonemes\u00a0but also recognizing sequences of words from a large vocabulary. Deep networks\u00a0for speech recognition eventually shifted from being based on pretraining and\u00a0Boltzmann machines to being based on techniques such as rectified linear units and\u00a0dropout (Zeiler et al., 2013; Dahl et al., 2013). By that time, several of the major\u00a0speech groups in industry had started exploring deep learning in collaboration with\u00a0academic researchers. Hinton et al. (2012a) describe the breakthroughs achieved\u00a0by these collaborators, which are now deployed in products such as mobile phones.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4348",
    "text": "Later, as these groups explored larger and larger labeled datasets and incorporated some of the methods for initializing, training, and setting up the architecture of deep nets, they realized that the unsupervised pretraining phase was either\u00a0unnecessary or did not bring any significant improvement.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4349",
    "text": "These breakthroughs in recognition performance for word error rate in speech recognition were unprecedented (around 30% improvement) and were following a\u00a0long period of about ten years during which error rates did not improve much with\u00a0the traditional GMM-HMM technology, in spite of the continuously growing size\u00a0of training sets (see Fig. 2.4 of Deng and Yu (2014)). This created a rapid shift in\u00a0the speech recognition community towards deep learning. In a matter of roughly\u00a0two years, most of the industrial products for speech recognition incorporated deep\u00a0neural networks and this success spurred a new wave of research into deep learning\u00a0algorithms and architectures for ASR, which is still ongoing today.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4350",
    "text": "One of these innovations was the use of convolutional networks (Sainath et al., 2013) that replicate weights across time and frequency, improving over the earlier\u00a0time-delay neural networks that replicated weights only across time. The new\u00a0two-dimensional convolutional models regard the input spectrogram not as one\u00a0long vector but as an image, with one axis corresponding to time and the other to\u00a0frequency of spectral components.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4351",
    "text": "Another important push, still ongoing, has been towards end-to-end deep learning speech recognition systems that completely remove the HMM. The first\u00a0major breakthrough in this direction came from Graves et al. (2013) who trained a\u00a0deep LSTM RNN (see Sec. 10.10), using MAP inference over the frame-to-phoneme\u00a0alignment, as in LeCun et al. (1998b) and in the CTC framework (Graves et al.,\u00a02006; Graves, 2012). A deep RNN (Graves et al., 2013) has state variables from\u00a0several layers at each time step, giving the unfolded graph two kinds of depth:\u00a0ordinary depth due to a stack of layers, and depth due to time unfolding. This\u00a0work brought the phoneme error rate on TIMIT to a record low of 17.7%. See\u00a0Pascanu et al. (2014a) and Chung et al. (2014) for other variants of deep RNNs,\u00a0applied in other settings.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4352",
    "text": "Another contemporary step toward end-to-end deep learning ASR is to let the system learn how to \u201calign\u201d the acoustic-level information with the phonetic-level\u00a0information (Chorowski et al., 2014; Lu et al., 2015).",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4353",
    "text": "Natural language processing (NLP) is the use of human languages, such as English or French, by a computer. Computer programs typically read and emit specialized\u00a0languages designed to allow efficient and unambiguous parsing by simple programs.\u00a0More naturally occurring languages are often ambiguous and defy formal description.\u00a0Natural language processing includes applications such as machine translation,\u00a0in which the learner must read a sentence in one human language and emit an\u00a0equivalent sentence in another human language. Many NLP applications are based\u00a0on language models that define a probability distribution over sequences of words,\u00a0characters or bytes in a natural language.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4354",
    "text": "As with the other applications discussed in this chapter, very generic neural network techniques can be successfully applied to natural language processing.\u00a0However, to achieve excellent performance and to scale well to large applications,\u00a0some domain-specific strategies become important. To build an efficient model of\u00a0natural language, we must usually use techniques that are specialized for processing\u00a0sequential data. In many cases, we choose to regard natural language as a sequence\u00a0of words, rather than a sequence of individual characters or bytes. Because the total\u00a0number of possible words is so large, word-based language models must operate on\u00a0an extremely high-dimensional and sparse discrete space. Several strategies have\u00a0been developed to make models of such a space efficient, both in a computational\u00a0and in a statistical sense.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4355",
    "text": "A language model defines a probability distribution over sequences of tokens in a natural language. Depending on how the model is designed, a token may be\u00a0a word, a character, or even a byte. Tokens are always discrete entities. The\u00a0earliest successful language models were based on models of fixed-length sequences\u00a0of tokens called n-grams. An n-gram is a sequence of n tokens.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4356",
    "text": "Models based on n-grams define the conditional probability of the n-th token given the preceding n \u2014 1 tokens. The model uses products of these conditional\u00a0distributions to define the probability distribution over longer sequences:",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4357",
    "text": "T",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4358",
    "text": "P (x!, . . . ,Xt ) = P (x! , . . . ,x1-\u05f4) J] P (x t | xt-n+1, \u2022 \u2022 . ,Xt-1). \u00a0\u00a0\u00a0(12.5)",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4359",
    "text": "t=n",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4360",
    "text": "This decomposition is justified by the chain rule of probability. The probability distribution over the initial sequence P (x!,..., xn-!) may be modeled by a different\u00a0model with a smaller value of n.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4361",
    "text": "Training n-gram models is straightforward because the maximum likelihood estimate can be computed simply by counting how many times each possible n\u00a0gram occurs in the training set. Models based on n-grams have been the core\u00a0building block of statistical language modeling for many decades (Jelinek and\u00a0Mercer, 1980; Katz, 1987; Chen and Goodman, 1999).",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4362",
    "text": "For small values of n, models have particular names: unigram for n=1, bigram for n=2, and trigram for n=3. These names derive from the Latin prefixes for the\u00a0corresponding numbers and the Greek suffix \u201c-gram\u201d denoting something that is\u00a0written.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4363",
    "text": "Usually we train both an n-gram model and an n \u2014 1 gram model simultaneously. This makes it easy to compute",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4364",
    "text": "-12.6",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4365",
    "text": "P(xt I xt-n+1, \u2022 \u2022 \u2022 \u05dcX) =",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4366",
    "text": "Pn (xt-n+1 \u05dc \u2022 \u2022 \u2022 \u05dc xt)",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4367",
    "text": "Pn\u2014 1(xt-n+1 \u05dc \u2022 \u2022 \u2022 \u05dc xt-1)",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4368",
    "text": "simply by looking up two stored probabilities. For this to exactly reproduce inference in Pn, we must omit the final character from each sequence when we\u00a0train Pn-1.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4369",
    "text": "As an example, we demonstrate how a trigram model computes the probability of the sentence \u201cTHE DOG RAN AWAY.\u201d The first words of the sentence cannot be\u00a0handled by the default formula based on conditional probability because there is no\u00a0context at the beginning of the sentence. Instead, we must use the marginal probability over words at the start of the sentence. We thus evaluate P3 (THE DOG RAN).\u00a0Finally, the last word may be predicted using the typical case, of using the conditional distribution P(AWAY | DOG RAN). Putting this together with Eq. 12.6, we\u00a0obtain:",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4370",
    "text": "P(THE DOG RAN AWAY) = P3(THE DOG RAN)P3(DOG RAN AWAY)/P2(DOG RAN)\u2022",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4371",
    "text": "-12.7",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4372",
    "text": "A fundamental limitation of maximum likelihood for n-gram models is that Pn as estimated from training set counts is very likely to be zero in many cases, even\u00a0though the tuple (xt-n+1, \u2022 \u2022 \u2022 \u05dc xt) may appear in the test set. This can cause two\u00a0different kinds of catastrophic outcomes. When Pn-1 is zero, the ratio is undefined,\u00a0so the model does not even produce a sensible output. When Pn-1 is non-zero but\u00a0Pn is zero, the test log-likelihood is \u2014to. To avoid such catastrophic outcomes,\u00a0most n-gram models employ some form of smoothing. Smoothing techniques shift\u00a0probability mass from the observed tuples to unobserved ones that are similar.\u00a0See Chen and Goodman (1999) for a review and empirical comparisons. One basic\u00a0technique consists of adding non-zero probability mass to all of the possible next\u00a0symbol values. This method can be justified as Bayesian inference with a uniform\u00a0or Dirichlet prior over the count parameters. Another very popular idea is to form\u00a0a mixture model containing higher-order and lower-order n-gram models, with the\u00a0higher-order models providing more capacity and the lower-order models being\u00a0more likely to avoid counts of zero. Back-off methods look-up the lower-order\u00a0n-grams if the frequency of the context xt-1,..., xt-n+1 is too small to use the\u00a0higher-order model. More formally, they estimate the distribution over xt by using\u00a0contexts xt-n+k,..., xt-1, for increasing k, until a sufficiently reliable estimate is\u00a0found.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4373",
    "text": "Classical n-gram models are particularly vulnerable to the curse of dimensionality. There are |V|n possible n-grams and |V| is often very large. Even with a massive training set and modest n, most n-grams will not occur in the training set.\u00a0One way to view a classical n-gram model is that it is performing nearest-neighbor\u00a0lookup. In other words, it can be viewed as a local non-parametric predictor,\u00a0similar to k-nearest neighbors. The statistical problems facing these extremely\u00a0local predictors are described in Sec. 5.11.2. The problem for a language model is\u00a0even more severe than usual, because any two different words have the same distance from each other in one-hot vector space. It is thus difficult to leverage much\u00a0information from any \u201cneighbors\u201d\u2014only training examples that repeat literally the\u00a0same context are useful for local generalization. To overcome these problems, a\u00a0language model must be able to share knowledge between one word and other\u00a0semantically similar words.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4374",
    "text": "To improve the statistical efficiency of n-gram models, class-based language models (Brown et al., 1992; Ney and Kneser, 1993; Niesler et al., 1998) introduce\u00a0the notion of word categories and then share statistical strength between words that\u00a0are in the same category. The idea is to use a clustering algorithm to partition the\u00a0set of words into clusters or classes, based on their co-occurrence frequencies with\u00a0other words. The model can then use word class IDs rather than individual word\u00a0IDs to represent the context on the right side of the conditioning bar. Composite\u00a0models combining word-based and class-based models via mixing or back-off are\u00a0also possible. Although word classes provide a way to generalize between sequences\u00a0in which some word is replaced by another of the same class, much information is\u00a0lost in this representation.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4375",
    "text": "Neural language models or NLMs are a class of language model designed to overcome the curse of dimensionality problem for modeling natural language sequences by\u00a0using a distributed representation of words (Bengio et al., 2001). Unlike class-based n-gram models, neural language models are able to recognize that two words",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4376",
    "text": "are similar without losing the ability to encode each word as distinct from the other. Neural language models share statistical strength between one word (and\u00a0its context) and other similar words and contexts. The distributed representation\u00a0the model learns for each word enables this sharing by allowing the model to treat\u00a0words that have features in common similarly. For example, if the word dog and\u00a0the word cat map to representations that share many attributes, then sentences\u00a0that contain the word cat can inform the predictions that will be made by the\u00a0model for sentences that contain the word dog, and vice-versa. Because there are\u00a0many such attributes, there are many ways in which generalization can happen,\u00a0transferring information from each training sentence to an exponentially large\u00a0number of semantically related sentences. The curse of dimensionality requires the\u00a0model to generalize to a number of sentences that is exponential in the sentence\u00a0length. The model counters this curse by relating each training sentence to an\u00a0exponential number of similar sentences.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4377",
    "text": "We sometimes call these word representations word embeddings. In this interpretation, we view the raw symbols as points in a space of dimension equal to the vocabulary size. The word representations embed those points in a feature space\u00a0of lower dimension. In the original space, every word is represented by a one-hot\u00a0vector, so every pair of words is at Euclidean distance 2/\u05e5 from each other. In the\u00a0embedding space, words that frequently appear in similar contexts (or any pair\u00a0of words sharing some \u201cfeatures\u201d learned by the model) are close to each other.\u00a0This often results in words with similar meanings being neighbors. Fig. 12.3 zooms\u00a0in on specific areas of a learned word embedding space to show how semantically\u00a0similar words map to representations that are close to each other.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4378",
    "text": "Neural networks in other domains also define embeddings. For example, a hidden layer of a convolutional network provides an \u201cimage embedding.\u201d Usually\u00a0NLP practitioners are much more interested in this idea of embeddings because\u00a0natural language does not originally lie in a real-valued vector space. The hidden\u00a0layer has provided a more qualitatively dramatic change in the way the data is\u00a0represented.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4379",
    "text": "The basic idea of using distributed representations to improve models for natural language processing is not restricted to neural networks. It may also be\u00a0used with graphical models that have distributed representations in the form of\u00a0multiple latent variables (Mnih and Hinton, 2007).",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4380",
    "text": "-6 -7\u00a0-8\u00a0-9\u00a0-10\u00a0-11\u00a0-12\u00a0-13\u00a0-14",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4381",
    "text": "-34 \u00a0\u00a0\u00a0-32\u00a0\u00a0\u00a0\u00a0-30\u00a0\u00a0\u00a0\u00a0-28\u00a0\u00a0\u00a0\u00a0-26",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4382",
    "text": "\u05e8-1-1-r",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4383",
    "text": "France China .",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4384",
    "text": "Russian",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4385",
    "text": "gBgldh",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4386",
    "text": "Germany Iraq Ontario",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4387",
    "text": "South_",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4388",
    "text": "22 21\u00a020\u00a019\u00a018\u00a017",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4389",
    "text": "AtEUASEyni \u00a0\u00a0\u00a0Japan",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4390",
    "text": "European",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4391",
    "text": "^rltlshNorth \u00a0\u00a0\u00a0,",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4392",
    "text": "Cainaiiff 1",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4393",
    "text": "-1-",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4394",
    "text": "-1-1-1-",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4395",
    "text": "22000098",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4396",
    "text": "2004",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4397",
    "text": "2003",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4398",
    "text": "2006 200i07\u05f4",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4399",
    "text": "-",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4400",
    "text": "2005 1999\u00b0\u00b0",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4401",
    "text": "1995",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4402",
    "text": "_1_",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4403",
    "text": "2002 1998996 _1_1_1_",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4404",
    "text": "35.0 35.5 36.0 36.5 37.0 37.5 38.0",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4405",
    "text": "Figure 12.3: Two-dimensional visualizations of word embeddings obtained from a neural machine translation model (Bahdanau et al., 2015), zooming in on specific areas where\u00a0semantically related words have embedding vectors that are close to each other. Countries\u00a0appear on the left and numbers on the right. Keep in mind that these embeddings are 2-D\u00a0for the purpose of visualization. In real applications, embeddings typically have higher\u00a0dimensionality and can simultaneously capture many kinds of similarity between words.",
    "chapter": "",
    "chapter_id": "main-24.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4406",
    "text": "In many natural language applications, we often want our models to produce words (rather than characters) as the fundamental unit of the output. For large\u00a0vocabularies, it can be very computationally expensive to represent an output\u00a0distribution over the choice of a word, because the vocabulary size is large. In many\u00a0applications, V contains hundreds of thousands of words. The naive approach to\u00a0representing such a distribution is to apply an affine transformation from a hidden\u00a0representation to the output space, then apply the softmax function. Suppose\u00a0we have a vocabulary V with size |V|. The weight matrix describing the linear\u00a0component of this affine transformation is very large, because its output dimension\u00a0is |V|. This imposes a high memory cost to represent the matrix, and a high\u00a0computational cost to multiply by it. Because the softmax is normalized across all\u00a0|V| outputs, it is necessary to perform the full matrix multiplication at training\u00a0time as well as test time\u2014we cannot calculate only the dot product with the weight\u00a0vector for the correct output. The high computational costs of the output layer\u00a0thus arise both at training time (to compute the likelihood and its gradient) and\u00a0at test time (to compute probabilities for all or selected words). For specialized\u00a0loss functions, the gradient can be computed efficiently (Vincent et al., 2015), but\u00a0the standard cross-entropy loss applied to a traditional softmax output layer poses\u00a0many difficulties.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4407",
    "text": "Suppose that h is the top hidden layer used to predict the output probabilities y. If we parametrize the transformation from h to y with learned weights W\u00a0and learned biases b, then the affine-softmax output layer performs the following\u00a0computations:",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4408",
    "text": "a = bi + \u00a0\u00a0\u00a0Wijhj Vi e {1.....|V|}, \u00a0\u00a0\u00a0(12.8)",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4409",
    "text": "j",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4410",
    "text": "ea \u00a0\u00a0\u00a0.\u00a0\u00a0\u00a0\u00a0.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4411",
    "text": "Vi = \u00a0\u00a0\u00a0|V| ea9\u05be12)\u00a0\u00a0\u00a0\u00a0\u2022 \u05f3)",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4412",
    "text": "i 1=\u05f3 e 4",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4413",
    "text": "If h contains nh elements then the above operation is O(|V|nh). With nh in the thousands and |V| in the hundreds of thousands, this operation dominates the\u00a0computation of most neural language models.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4414",
    "text": "12.4.3.1 Use of a Short List",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4415",
    "text": "The first neural language models (Bengio et al., 2001, 2003) dealt with the high cost of using a softmax over a large number of output words by limiting the vocabulary\u00a0size to 10,000 or 20,000 words. Schwenk and Gauvain (2002) and Schwenk (2007)\u00a0built upon this approach by splitting the vocabulary V into a shortlist L of most\u00a0frequent words (handled by the neural net) and a tail T = V\\L of more rare words\u00a0(handled by an n-gram model). To be able to combine the two predictions, the\u00a0neural net also has to predict the probability that a word appearing after context\u00a0C belongs to the tail list. This may be achieved by adding an extra sigmoid output\u00a0unit to provide an estimate of P(i e T | C). The extra output can then be used to\u00a0achieve an estimate of the probability distribution over all words in V as follows:",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4416",
    "text": "P(y = i | C) =1 i^P(y = i | C,i e L)(1 - P(i e T | C)) \u00a0\u00a0\u00a0(12.10)",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4417",
    "text": "+1 i\u20acTP(y = i I C,i e T)P(i e T | C) \u00a0\u00a0\u00a0(12.11)",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4418",
    "text": "where P(y = i | C, i e L) is provided by the neural language model and P (y = i | C, i e T) is provided by the n-gram model. With slight modification, this approach\u00a0can also work using an extra output value in the neural language model\u2019s softmax\u00a0layer, rather than a separate sigmoid unit.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4419",
    "text": "An obvious disadvantage of the short list approach is that the potential generalization advantage of the neural language models is limited to the most frequent words, where, arguably, it is the least useful. This disadvantage has stimulated\u00a0the exploration of alternative methods to deal with high-dimensional outputs,\u00a0described below.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4420",
    "text": "12.4.3.2 Hierarchical Softmax",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4421",
    "text": "A classical approach (Goodman, 2001) to reducing the computational burden of high-dimensional output layers over large vocabulary sets V is to decompose\u00a0probabilities hierarchically. Instead of necessitating a number of computations\u00a0proportional to |V| (and also proportional to the number of hidden units, nh),\u00a0the |V| factor can be reduced to as low as log |V|. Bengio (2002) and Morin and\u00a0Bengio (2005) introduced this factorized approach to the context of neural language\u00a0models.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4422",
    "text": "One can think of this hierarchy as building categories of words, then categories of categories of words, then categories of categories of categories of words, etc.\u00a0These nested categories form a tree, with words at the leaves. In a balanced tree,\u00a0the tree has depth O(log |V|). The probability of a choosing a word is given by the\u00a0product of the probabilities of choosing the branch leading to that word at every\u00a0node on a path from the root of the tree to the leaf containing the word. Fig. 12.4\u00a0illustrates a simple example. Mnih and Hinton (2009) also describe how to use\u00a0multiple paths to identify a single word in order to better model words that have\u00a0multiple meanings. Computing the probability of a word then involves summation\u00a0over all of the paths that lead to that word.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4423",
    "text": "To predict the conditional probabilities required at each node of the tree, we typically use a logistic regression model at each node of the tree, and provide the\u00a0same context C as input to all of these models. Because the correct output is\u00a0encoded in the training set, we can use supervised learning to train the logistic\u00a0regression models. This is typically done using a standard cross-entropy loss,\u00a0corresponding to maximizing the log-likelihood of the correct sequence of decisions.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4424",
    "text": "Because the output log-likelihood can be computed efficiently (as low as log |V| rather than |V|), its gradients may also be computed efficiently. This includes not\u00a0only the gradient with respect to the output parameters but also the gradients\u00a0with respect to the hidden layer activations.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4425",
    "text": "It is possible but usually not practical to optimize the tree structure to minimize the expected number of computations. Tools from information theory specify how\u00a0to choose the optimal binary code given the relative frequencies of the words. To\u00a0do so, we could structure the tree so that the number of bits associated with a word\u00a0is approximately equal to the logarithm of the frequency of that word. However, in\u00a0practice, the computational savings are typically not worth the effort because the\u00a0computation of the output probabilities is only one part of the total computation\u00a0in the neural language model. For example, suppose there are l fully connected\u00a0hidden layers of width nh. Let nb be the weighted average of the number of bits",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4426",
    "text": "Figure 12.4: Illustration of a simple hierarchy of word categories, with 8 wordsw0,..., w7 organized into a three level hierarchy. The leaves of the tree represent actual specific words.\u00a0Internal nodes represent groups of words. Any node can be indexed by the sequence\u00a0of binary decisions (0=left, 1=right) to reach the node from the root. Super-class (0)\u00a0contains the classes (0, 0) and (0, 1), which respectively contain the sets of words {wo,w1}\u00a0and {w2, W3}, and similarly super-class (1) contains the classes (1,0) and (1,1), which\u00a0respectively contain the words (w4,w5) and (w6, w7). If the tree is sufficiently balanced,\u00a0the maximum depth (number of binary decisions) is on the order of the logarithm of\u00a0the number of words | V|: the choice of one out of | V| words can be obtained by doing\u00a0O(log |V|) operations (one for each of the nodes on the path from the root). In this example,\u00a0computing the probability of a word y can be done by multiplying three probabilities,\u00a0associated with the binary decisions to move left or right at each node on the path from\u00a0the root to a node y. Let bi(y) be the i-th binary decision when traversing the tree\u00a0towards the value y. The probability of sampling an output y decomposes into a product\u00a0of conditional probabilities, using the chain rule for conditional probabilities, with each\u00a0node indexed by the prefix of these bits. For example, node (1, 0) corresponds to the\u00a0prefix (b0 (w4) = 1,61 (w4) = 0), and the probability of w can be decomposed as follows:",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4427",
    "text": "P (y = w 4) = \u00a0\u00a0\u00a0P (bo\u00a0\u00a0\u00a0\u00a0= 1, b1 =\u00a0\u00a0\u00a0\u00a00, b2 = 0)\u00a0\u00a0\u00a0\u00a0(12.12)",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4428",
    "text": "#ERROR!",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4429",
    "text": "required to identify a word, with the weighting given by the frequency of these words. In this example, the number of operations needed to compute the hidden\u00a0activations grows as as O(lnh) while the output computations grow as O(nhn).\u00a0As long as nb < In h, we can reduce computation more by shrinking nh than by\u00a0shrinking nb. Indeed, nb is often small. Because the size of the vocabulary rarely\u00a0exceeds a million words and log2 (106) ~ 20, it is possible to reduce nb to about 20,\u00a0but nh is often much larger, around 103 or more. Rather than carefully optimizing\u00a0a tree with a branching factor of 2, one can instead define a tree with depth two\u00a0and a branching factor of y^Vj. Such a tree corresponds to simply defining a set\u00a0of mutually exclusive word classes. The simple approach based on a tree of depth\u00a0two captures most of the computational benefit of the hierarchical strategy.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4430",
    "text": "One question that remains somewhat open is how to best define these word classes, or how to define the word hierarchy in general. Early work used existing\u00a0hierarchies (Morin and Bengio, 2005) but the hierarchy can also be learned, ideally\u00a0jointly with the neural language model. Learning the hierarchy is difficult. An exact\u00a0optimization of the log-likelihood appears intractable because the choice of a word\u00a0hierarchy is a discrete one, not amenable to gradient-based optimization. However,\u00a0one could use discrete optimization to approximately optimize the partition of\u00a0words into word classes.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4431",
    "text": "An important advantage of the hierarchical softmax is that it brings computational benefits both at training time and at test time, if at test time we want to compute the probability of specific words.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4432",
    "text": "Of course, computing the probability of all jVj words will remain expensive even with the hierarchical softmax. Another important operation is selecting the\u00a0most likely word in a given context. Unfortunately the tree structure does not\u00a0provide an efficient and exact solution to this problem.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4433",
    "text": "A disadvantage is that in practice the hierarchical softmax tends to give worse test results than sampling-based methods we will describe next. This may be due\u00a0to a poor choice of word classes.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4434",
    "text": "12.4.3.3 Importance Sampling",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4435",
    "text": "One way to speed up the training of neural language models is to avoid explicitly computing the contribution of the gradient from all of the words that do not appear\u00a0in the next position. Every incorrect word should have low probability under the\u00a0model. It can be computationally costly to enumerate all of these words. Instead,\u00a0it is possible to sample only a subset of the words. Using the notation introduced\u00a0where a is the vector of pre-softmax activations (or scores), with one element\u00a0per word. The first term is the positive phase term (pushing ay up) while the\u00a0second term is the negative phase term (pushing ai down for all i, with weight\u00a0P(i | C). Since the negative phase term is an expectation, we can estimate it with\u00a0a Monte Carlo sample. However, that would require sampling from the model itself.\u00a0Sampling from the model requires computing P (i | C) for all i in the vocabulary,\u00a0which is precisely what we are trying to avoid.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4436",
    "text": "Instead of sampling from the model, one can sample from another distribution, called the proposal distribution (denoted q), and use appropriate weights to correct\u00a0for the bias introduced by sampling from the wrong distribution (Bengio and\u00a0Senecal, 2003; Bengio and Senecal, 2008). This is an application of a more general\u00a0technique called importance sampling, which will be described in more detail in\u00a0Sec. 17.2. Unfortunately, even exact importance sampling is not efficient because it\u00a0requires computing weights pi/qi, where pi = P (i | C), which can only be computed\u00a0if all the scores ai are computed. The solution adopted for this application is called\u00a0biased importance sampling, where the importance weights are normalized to sum\u00a0to 1. When negative word ni is sampled, the associated gradient is weighted by",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4437",
    "text": "-12.18",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4438",
    "text": "Wi",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4439",
    "text": "in Eq. 12.8, the gradient can be written as follows:",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4440",
    "text": "d log P(y | C) \u00a0\u00a0\u00a0d logsoftmaxy (a)",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4441",
    "text": "d9",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4442",
    "text": "d9",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4443",
    "text": "d \u00a0\u00a0\u00a0eay",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4444",
    "text": "#ERROR!",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4445",
    "text": "i",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4446",
    "text": "d",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4447",
    "text": "<99",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4448",
    "text": "da",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4449",
    "text": "d9",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4450",
    "text": "(ay - 10gj]eai)",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4451",
    "text": "i",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4452",
    "text": "dai",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4453",
    "text": "39",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4454",
    "text": "-12.14",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4455",
    "text": "-12.15",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4456",
    "text": "(12.16) (12.17)",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4457",
    "text": "p n / qn i",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4458",
    "text": "\u00a31 Pnj/qn",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4459",
    "text": "These weights are used to give the appropriate importance to the m negative samples from q used to form the estimated negative phase contribution to the\u00a0gradient:",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4460",
    "text": "|V| \u00a0\u00a0\u00a0m",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4461",
    "text": "EP(iic) % - m Ewi %. \u00a0\u00a0\u00a0(12.19)",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4462",
    "text": "i=1",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4463",
    "text": "i=1",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4464",
    "text": "d9",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4465",
    "text": "m",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4466",
    "text": "d9",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4467",
    "text": "A unigram or a bigram distribution works well as the proposal distribution q. It is easy to estimate the parameters of such a distribution from data. After estimating\u00a0the parameters, it is also possible to sample from such a distribution very efficiently.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4468",
    "text": "Importance sampling is not only useful for speeding up models with large softmax outputs. More generally, it is useful for accelerating training with large\u00a0sparse output layers, where the output is a sparse vector rather than a 1-of-n\u00a0choice. An example is a bag of words. A bag of words is a sparse vector v where vi\u00a0indicates the presence or absence of word i from the vocabulary in the document.\u00a0Alternately, vi can indicate the number of times that word i appears. Machine\u00a0learning models that emit such sparse vectors can be expensive to train for a\u00a0variety of reasons. Early in learning, the model may not actually choose to make\u00a0the output truly sparse. Moreover, the loss function we use for training might\u00a0most naturally be described in terms of comparing every element of the output to\u00a0every element of the target. This means that it is not always clear that there is a\u00a0computational benefit to using sparse outputs, because the model may choose to\u00a0make the majority of the output non-zero and all of these non-zero values need to\u00a0be compared to the corresponding training target, even if the training target is zero.\u00a0Dauphin et al. (2011) demonstrated that such models can be accelerated using\u00a0importance sampling. The efficient algorithm minimizes the loss reconstruction for\u00a0the \u201cpositive words\u201d (those that are non-zero in the target) and an equal number\u00a0of \u201cnegative words.\u201d The negative words are chosen randomly, using a heuristic to\u00a0sample words that are more likely to be mistaken. The bias introduced by this\u00a0heuristic oversampling can then be corrected using importance weights.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4469",
    "text": "In all of these cases, the computational complexity of gradient estimation for the output layer is reduced to be proportional to the number of negative samples\u00a0rather than proportional to the size of the output vector.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4470",
    "text": "12.4.3.4 Noise-Contrastive Estimation and Ranking Loss",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4471",
    "text": "Other approaches based on sampling have been proposed to reduce the computational cost of training neural language models with large vocabularies. An early example is the ranking loss proposed by Collobert and Weston (2008a), which\u00a0views the output of the neural language model for each word as a score and tries to\u00a0make the score of the correct word ay be ranked high in comparison to the other\u00a0scores ai. The ranking loss proposed then is",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4472",
    "text": "L = max(0,1 \u2014 ay + ai). \u00a0\u00a0\u00a0(12.20)",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4473",
    "text": "i",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4474",
    "text": "The gradient is zero for the i-th term if the score of the observed word, ay, is greater than the score of the negative word ai by a margin of 1. One issue with\u00a0this criterion is that it does not provide estimated conditional probabilities, which\u00a0are useful in some applications, including speech recognition and text generation\u00a0(including conditional text generation tasks such as translation).",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4475",
    "text": "A more recently used training objective for neural language model is noise-contrastive estimation, which is introduced in Sec. 18.6. This approach has been successfully applied to neural language models (Mnih and Teh, 2012; Mnih and\u00a0Kavukcuoglu, 2013).",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4476",
    "text": "A major advantage of n-gram models over neural networks is that n-gram models achieve high model capacity (by storing the frequencies of very many tuples)\u00a0while requiring very little computation to process an example (by looking up\u00a0only a few tuples that match the current context). If we use hash tables or trees\u00a0to access the counts, the computation used for n-grams is almost independent\u00a0of capacity. In comparison, doubling a neural network\u2019s number of parameters\u00a0typically also roughly doubles its computation time. Exceptions include models\u00a0that avoid using all parameters on each pass. Embedding layers index only a single\u00a0embedding in each pass, so we can increase the vocabulary size without increasing\u00a0the computation time per example. Some other models, such as tiled convolutional\u00a0networks, can add parameters while reducing the degree of parameter sharing\u00a0in order to maintain the same amount of computation. However, typical neural\u00a0network layers based on matrix multiplication use an amount of computation\u00a0proportional to the number of parameters.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4477",
    "text": "One easy way to add capacity is thus to combine both approaches in an ensemble consisting of a neural language model and an n-gram language model (Bengio\u00a0et al., 2001, 2003). As with any ensemble, this technique can reduce test error if\u00a0the ensemble members make independent mistakes. The field of ensemble learning\u00a0provides many ways of combining the ensemble members\u2019 predictions, including\u00a0uniform weighting and weights chosen on a validation set. Mikolov et al. (2011a)\u00a0extended the ensemble to include not just two models but a large array of models.\u00a0It is also possible to pair a neural network with a maximum entropy model and\u00a0train both jointly (Mikolov et al., 2011b). This approach can be viewed as training\u00a0a neural network with an extra set of inputs that are connected directly to the\u00a0output, and not connected to any other part of the model. The extra inputs are\u00a0indicators for the presence of particular n-grams in the input context, so these\u00a0variables are very high-dimensional and very sparse. The increase in model capacity\u00a0is huge\u2014the new portion of the architecture contains up to |sV |n parameters\u2014but\u00a0the amount of added computation needed to process an input is minimal because\u00a0the extra inputs are very sparse.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4478",
    "text": "Machine translation is the task of reading a sentence in one natural language and emitting a sentence with the equivalent meaning in another language. Machine\u00a0translation systems often involve many components. At a high level, there is\u00a0often one component that proposes many candidate translations. Many of these\u00a0translations will not be grammatical due to differences between the languages. For\u00a0example, many languages put adjectives after nouns, so when translated to English\u00a0directly they yield phrases such as \u201capple red.\u201d The proposal mechanism suggests\u00a0many variants of the suggested translation, ideally including \u201cred apple.\u201d A second\u00a0component of the translation system, a language model, evaluates the proposed\u00a0translations, and can score \u201cred apple\u201d as better than \u201capple red.\u201d",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4479",
    "text": "The earliest use of neural networks for machine translation was to upgrade the language model of a translation system by using a neural language model (Schwenk\u00a0et al., 2006; Schwenk, 2010). Previously, most machine translation systems had\u00a0used an n-gram model for this component. The n-gram based models used for\u00a0machine translation include not just traditional back-off n-gram models (Jelinek\u00a0and Mercer, 1980; Katz, 1987; Chen and Goodman, 1999) but also maximum\u00a0entropy language models (Berger et al., 1996), in which an affine-softmax layer\u00a0predicts the next word given the presence of frequent n-grams in the context.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4480",
    "text": "Traditional language models simply report the probability of a natural language sentence. Because machine translation involves producing an output sentence given\u00a0an input sentence, it makes sense to extend the natural language model to be\u00a0conditional. As described in Sec. 6.2.1.1, it is straightforward to extend a model\u00a0that defines a marginal distribution over some variable to define a conditional\u00a0distribution over that variable given a context C, where C might be a single variable\u00a0or a list of variables. Devlin et al. (2014) beat the state-of-the-art in some statistical\u00a0machine translation benchmarks by using an MLP to score a phrase 11, t2,..., t&\u00a0in the target language given a phrase s!, s2,..., sn in the source language. The\u00a0MLP estimates P (t1, t2,..., tk | s1, s2,..., s\u05f4). The estimate formed by this MLP\u00a0replaces the estimate provided by conditional n-gram models.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4481",
    "text": "A drawback of the MLP-based approach is that it requires the sequences to be preprocessed to be of fixed length. To make the translation more flexible, we would\u00a0like to use a model that can accommodate variable length inputs and variable\u00a0length outputs. An RNN provides this ability. Sec. 10.2.4 describes several ways\u00a0of constructing an RNN that represents a conditional distribution over a sequence\u00a0given some input, and Sec. 10.4 describes how to accomplish this conditioning\u00a0when the input is a sequence. In all cases, one model first reads the input sequence\u00a0and emits a data structure that summarizes the input sequence. We call this",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4482",
    "text": "/",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4483",
    "text": "Output object (English",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4484",
    "text": "\\",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4485",
    "text": "",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4486",
    "text": "sentence)",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4487",
    "text": "J",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4488",
    "text": "Decoder",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4489",
    "text": "C",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4490",
    "text": "Intermediate, semantic representation",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4491",
    "text": "Encoder",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4492",
    "text": "c",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4493",
    "text": "Source object (French sentence or image)",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4494",
    "text": "J",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4495",
    "text": "Figure 12.5: The encoder-decoder architecture to map back and forth between a surface representation (such as a sequence of words or an image) and a semantic representation.\u00a0By using the output of an encoder of data from one modality (such as the encoder mapping\u00a0from French sentences to hidden representations capturing the meaning of sentences) as\u00a0the input to a decoder for another modality (such as the decoder mapping from hidden\u00a0representations capturing the meaning of sentences to English), we can train systems that\u00a0translate from one modality to another. This idea has been applied successfully not just\u00a0to machine translation but also to caption generation from images.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4496",
    "text": "summary the \u201ccontext\u201d C. The context C may be a list of vectors, or it may be a vector or tensor. The model that reads the input to produce C may be an RNN\u00a0(Cho et al., 2014a; Sutskever et al., 2014; Jean et al., 2014) or a convolutional\u00a0network (Kalchbrenner and Blunsom, 2013). A second model, usually an RNN,\u00a0then reads the context C and generates a sentence in the target language. This\u00a0general idea of an encoder-decoder framework for machine translation is illustrated\u00a0in Fig. 12.5.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4497",
    "text": "In order to generate an entire sentence conditioned on the source sentence, the model must have a way to represent the entire source sentence. Earlier models\u00a0were only able to represent individual words or phrases. From a representation\u00a0learning point of view, it can be useful to learn a representation in which sentences\u00a0that have the same meaning have similar representations regardless of whether\u00a0they were written in the source language or the target language. This strategy was\u00a0explored first using a combination of convolutions and RNNs (Kalchbrenner and\u00a0Blunsom, 2013). Later work introduced the use of an RNN for scoring proposed\u00a0translations (Cho et al., 2014a) and for generating translated sentences (Sutskever\u00a0et al., 2014). Jean et al. (2014) scaled these models to larger vocabularies.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4498",
    "text": "Using an Attention Mechanism and Aligning Pieces of Data",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4499",
    "text": "12.4.5.1",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4500",
    "text": "Figure 12.6: A modern attention mechanism, as introduced by Bahdanau et al. (2015), is essentially a weighted average. A context vector c is formed by taking a weighted average\u00a0of feature vectors h(t) with weights a(t). In some applications, the feature vectors h are\u00a0hidden units of a neural network, but they may also be raw input to the model. The\u00a0weights a(t) are produced by the model itself. They are usually values in the interval\u00a0[0,1] and are intended to concentrate around just one h(t) so that the weighted average\u00a0approximates reading that one specific time step precisely. The weights a(t) are usually\u00a0produced by applying a softmax function to relevance scores emitted by another portion\u00a0of the model. The attention mechanism is more expensive computationally than directly\u00a0indexing the desired h(t), but direct indexing cannot be trained with gradient descent. The\u00a0attention mechanism based on weighted averages is a smooth, differentiable approximation\u00a0that can be trained with existing optimization algorithms.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4501",
    "text": "Using a fixed-size representation to capture all the semantic details of a very long sentence of say 60 words is very difficult. It can be achieved by training a\u00a0sufficiently large RNN well enough and for long enough, as demonstrated by Cho\u00a0et al. (2014a) and Sutskever et al. (2014). However, a more efficient approach is\u00a0to read the whole sentence or paragraph (to get the context and the gist of what\u00a0is being expressed), then produce the translated words one at a time, each time\u00a0focusing on a different part of the input sentence in order to gather the semantic\u00a0details that are required to produce the next output word. That is exactly the\u00a0idea that Bahdanau et al. (2015) first introduced. The attention mechanism used\u00a0to focus on specific parts of the input sequence at each time step is illustrated in\u00a0Fig. 12.6.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4502",
    "text": "We can think of an attention-based system as having three components:",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4503",
    "text": "1. \u00a0\u00a0\u00a0A process that \u201creads\u05f4 raw data (such as source words in a source sentence),\u00a0and converts them into distributed representations, with one feature vector\u00a0associated with each word position.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4504",
    "text": "2. \u00a0\u00a0\u00a0A list of feature vectors storing the output of the reader. This can be\u00a0understood as a \u201c memory\u2019 containing a sequence of facts, which can be\u00a0retrieved later, not necessarily in the same order, without having to visit all\u00a0of them.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4505",
    "text": "3. \u00a0\u00a0\u00a0A process that \u201c exploits\u201d the content of the memory to sequentially perform\u00a0a task, at each time step having the ability put attention on the content of\u00a0one memory element (or a few, with a different weight).",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4506",
    "text": "The third component generates the translated sentence.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4507",
    "text": "When words in a sentence written in one language are aligned with corresponding words in a translated sentence in another language, it becomes possible to relate the corresponding word embeddings. Earlier work showed that one could learn a\u00a0kind of translation matrix relating the word embeddings in one language with the\u00a0word embeddings in another (Kocisky et al., 2014), yielding lower alignment error\u00a0rates than traditional approaches based on the frequency counts in the phrase table.\u00a0There is even earlier work on learning cross-lingual word vectors (Klementiev et al.,\u00a02012). Many extensions to this approach are possible. For example, more efficient\u00a0cross-lingual alignment (Gouws et al., 2014) allows training on larger datasets.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4508",
    "text": "The idea of distributed representations for symbols was introduced by Rumelhart et al. (1986a) in one of the first explorations of back-propagation, with symbols\u00a0corresponding to the identity of family members and the neural network capturing\u00a0the relationships between family members, with training examples forming triplets\u00a0such as (Colin, Mother, Victoria). The first layer of the neural network learned\u00a0a representation of each family member. For example, the features for Colin\u00a0might represent which family tree Colin was in, what branch of that tree he was\u00a0in, what generation he was from, etc. One can think of the neural network as\u00a0computing learned rules relating these attributes together in order to obtain the\u00a0desired predictions. The model can then make predictions such as inferring who is\u00a0the mother of Colin.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4509",
    "text": "The idea of forming an embedding for a symbol was extended to the idea of an embedding for a word by Deerwester et al. (1990). These embeddings were learned\u00a0using the SVD. Later, embeddings would be learned by neural networks.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4510",
    "text": "The history of natural language processing is marked by transitions in the popularity of different ways of representing the input to the model. Following\u00a0this early work on symbols or words, some of the earliest applications of neural\u00a0networks to NLP (Miikkulainen and Dyer, 1991; Schmidhuber, 1996) represented\u00a0the input as a sequence of characters.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4511",
    "text": "Bengio et al. (2001) returned the focus to modeling words and introduced neural language models, which produce interpretable word embeddings. These\u00a0neural models have scaled up from defining representations of a small set of symbols\u00a0in the 1980s to millions of words (including proper nouns and misspellings) in\u00a0modern applications. This computational scaling effort led to the invention of the\u00a0techniques described above in Sec. 12.4.3.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4512",
    "text": "Initially, the use of words as the fundamental units of language models yielded improved language modeling performance (Bengio et al., 2001). To this day,\u00a0new techniques continually push both character-based models (Sutskever et al.,\u00a02011) and word-based models forward, with recent work (Gillick et al., 2015) even\u00a0modeling individual bytes of Unicode characters.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4513",
    "text": "The ideas behind neural language models have been extended into several natural language processing applications, such as parsing (Henderson, 2003, 2004;\u00a0Collobert, 2011), part-of-speech tagging, semantic role labeling, chunking, etc,\u00a0sometimes using a single multi-task learning architecture (Collobert and Weston,\u00a02008a; Collobert et al., 2011a) in which the word embeddings are shared across\u00a0tasks.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4514",
    "text": "Two-dimensional visualizations of embeddings became a popular tool for analyzing language models following the development of the t-SNE dimensionality reduction algorithm (van der Maaten and Hinton, 2008) and its high-profile application to visualization word embeddings by Joseph Turian in 2009.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4515",
    "text": "In this section we cover a few other types of applications of deep learning that are different from the standard object recognition, speech recognition and natural\u00a0language processing tasks discussed above. Part III of this book will expand\u00a0that scope even further to include tasks requiring the ability to generate rich\u00a0high-dimensional samples (unlike \u201cthe next word,\u201d in language models).",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4516",
    "text": "One of the major families of applications of machine learning in the information technology sector is the ability to make recommendations of items to potential\u00a0users or customers. Two major types of applications can be distinguished: online\u00a0advertising and item recommendations (often these recommendations are still for\u00a0the purpose of selling a product). Both rely on predicting the association between\u00a0a user and an item, either to predict the probability of some action (the user\u00a0buying the product, or some proxy for this action) or the expected gain (which\u00a0may depend on the value of the product) if an ad is shown or a recommendation is\u00a0made regarding that product to that user. The internet is currently financed in\u00a0great part by various forms of online advertising. There are major parts of the\u00a0economy that rely on online shopping. Companies including Amazon and eBay\u00a0use machine learning, including deep learning, for their product recommendations.\u00a0Sometimes, the items are not products that are actually for sale. Examples include\u00a0selecting posts to display on social network news feeds, recommending movies to\u00a0watch, recommending jokes, recommending advice from experts, matching players\u00a0for video games, or matching people in dating services.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4517",
    "text": "Often, this association problem is handled like a supervised learning problem: given some information about the item and about the user, predict the proxy of\u00a0interest (user clicks on ad, user enters a rating, user clicks on a \u201clike\u201d button, user\u00a0buys product, user spends some amount of money on the product, user spends\u00a0time visiting a page for the product, etc). This often ends up being either a\u00a0regression problem (predicting some conditional expected value) or a probabilistic\u00a0classification problem (predicting the conditional probability of some discrete\u00a0event).",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4518",
    "text": "The early work on recommender systems relied on minimal information as inputs for these predictions: the user ID and the item ID. In this context, the only\u00a0way to generalize is to rely on the similarity between the patterns of values of the\u00a0target variable for different users or for different items. Suppose that user 1 and\u00a0user 2 both like items A, B and C. From this, we may infer that user 1 and user 2\u00a0have similar tastes. If user 1 likes item D, then this should be a strong cue that\u00a0user 2 will also like D. Algorithms based on this principle come under the name of\u00a0collaborative filtering. Both non-parametric approaches (such as nearest-neighbor\u00a0methods based on the estimated similarity between patterns of preferences) and\u00a0parametric methods are possible. Parametric methods often rely on learning a\u00a0distributed representation (also called an embedding) for each user and for each\u00a0item. Bilinear prediction of the target variable (such as a rating) is a simple\u00a0parametric method that is highly successful and often found as a component of\u00a0state-of-the-art systems. The prediction is obtained by the dot product between\u00a0the user embedding and the item embedding (possibly corrected by constants that\u00a0depend only on either the user ID or the item ID). Let R be the matrix containing\u00a0our predictions, A a matrix with user embeddings in its rows and B a matrix with\u00a0item embeddings in its columns. Let b and c be vectors that contain respectively\u00a0a kind of bias for each user (representing how grumpy or positive that user is\u00a0in general) and for each item (representing its general popularity). The bilinear\u00a0prediction is thus obtained as follows:",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4519",
    "text": "Ru,i = bu + ci + ^ ' Au,jBj,i. \u00a0\u00a0\u00a0(12.21)",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4520",
    "text": "j",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4521",
    "text": "Typically one wants to minimize the squared error between predicted ratings RU,i and actual ratings RUji. User embeddings and item embeddings can then be\u00a0conveniently visualized when they are first reduced to a low dimension (two or\u00a0three), or they can be used to compare users or items against each other, just\u00a0like word embeddings. One way to obtain these embeddings is by performing a\u00a0singular value decomposition of the matrix R of actual targets (such as ratings).\u00a0This corresponds to factorizing R = UDV' (or a normalized variant) into the\u00a0product of two factors, the lower rank matrices A = UD and B = V'. One\u00a0problem with the SVD is that it treats the missing entries in an arbitrary way,\u00a0as if they corresponded to a target value of 0. Instead we would like to avoid\u00a0paying any cost for the predictions made on missing entries. Fortunately, the\u00a0sum of squared errors on the observed ratings can also be easily minimized by\u00a0gradient-based optimization. The SVD and the bilinear prediction of Eq. 12.21 both\u00a0performed very well in the competition for the Netflix prize (Bennett and Lanning,\u00a02007), aiming at predicting ratings for films, based only on previous ratings by\u00a0a large set of anonymous users. Many machine learning experts participated in\u00a0this competition, which took place between 2006 and 2009. It raised the level of\u00a0research in recommender systems using advanced machine learning and yielded\u00a0improvements in recommender systems. Even though it did not win by itself,\u00a0the simple bilinear prediction or SVD was a component of the ensemble models\u00a0presented by most of the competitors, including the winners (Toscher et al., 2009;\u00a0Koren, 2009).",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4522",
    "text": "Beyond these bilinear models with distributed representations, one of the first uses of neural networks for collaborative filtering is based on the RBM undirected\u00a0probabilistic model (Salakhutdinov et al., 2007). RBMs were an important element\u00a0of the ensemble of methods that won the Netflix competition (Toscher et al., 2009;\u00a0Koren, 2009). More advanced variants on the idea of factorizing the ratings matrix\u00a0have also been explored in the neural networks community (Salakhutdinov and",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4523",
    "text": "Mnih, 2008).",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4524",
    "text": "However, there is a basic limitation of collaborative filtering systems: when a new item or a new user is introduced, its lack of rating history means that there\u00a0is no way to evaluate its similarity with other items or users (respectively), or\u00a0the degree of association between, say, that new user and existing items. This\u00a0is called the problem of cold-start recommendations. A general way of solving\u00a0the cold-start recommendation problem is to introduce extra information about\u00a0the individual users and items. For example, this extra information could be user\u00a0profile information or features of each item. Systems that use such information are\u00a0called content-based recommender systems. The mapping from a rich set of user\u00a0features or item features to an embedding can be learned through a deep learning\u00a0architecture (Huang et al., 2013; Elkahky et al., 2015).",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4525",
    "text": "Specialized deep learning architectures such as convolutional networks have also been applied to learn to extract features from rich content such as from musical\u00a0audio tracks, for music recommendation (van den Oord et al., 2013). In that work,\u00a0the convolutional net takes acoustic features as input and computes an embedding\u00a0for the associated song. The dot product between this song embedding and the\u00a0embedding for a user is then used to predict whether a user will listen to the song.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4526",
    "text": "12.5.1.1 Exploration Versus Exploitation",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4527",
    "text": "When making recommendations to users, an issue arises that goes beyond ordinary supervised learning and into the realm of reinforcement learning. Many recommendation problems are most accurately described theoretically as contextual bandits\u00a0(Langford and Zhang, 2008; Lu et al., 2010). The issue is that when we use the\u00a0recommendation system to collect data, we get a biased and incomplete view of\u00a0the preferences of users: we only see the responses of users to the items they were\u00a0recommended and not to the other items. In addition, in some cases we may not\u00a0get any information on users for whom no recommendation has been made (for\u00a0example, with ad auctions, it may be that the price proposed for an ad was below\u00a0a minimum price threshold, or does not win the auction, so the ad is not shown at\u00a0all). More importantly, we get no information about what outcome would have\u00a0resulted from recommending any of the other items. This would be like training a\u00a0classifier by picking one class y for each training example x (typically the class\u00a0with the highest probability according to the model) and then only getting as\u00a0feedback whether this was the correct class or not. Clearly, each example conveys\u00a0less information than in the supervised case where the true label y is directly\u00a0accessible, so more examples are necessary. Worse, if we are not careful, we could\u00a0end up with a system that continues picking the wrong decisions even as more\u00a0and more data is collected, because the correct decision initially had a very low\u00a0probability: until the learner picks that correct decision, it does not learn about\u00a0the correct decision. This is similar to the situation in reinforcement learning\u00a0where only the reward for the selected action is observed. In general, reinforcement\u00a0learning can involve a sequence of many actions and many rewards. The bandits\u00a0scenario is a special case of reinforcement learning, in which the learner takes only\u00a0a single action and receives a single reward. The bandit problem is easier in the\u00a0sense that the learner knows which reward is associated with which action. In\u00a0the general reinforcement learning scenario, a high reward or a low reward might\u00a0have been caused by a recent action or by an action in the distant past. The term\u00a0contextual bandits refers to the case where the action is taken in the context of\u00a0some input variable that can inform the decision. For example, we at least know\u00a0the user identity, and we want to pick an item. The mapping from context to\u00a0action is also called a policy. The feedback loop between the learner and the data\u00a0distribution (which now depends on the actions of the learner) is a central research\u00a0issue in the reinforcement learning and bandits literature.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4528",
    "text": "Reinforcement learning requires choosing a tradeoff between exploration and exploitation. Exploitation refers to taking actions that come from the current, best\u00a0version of the learned policy\u2014actions that we know will achieve a high reward.\u00a0Exploration refers to taking actions specifically in order to obtain more training\u00a0data. If we know that given context x, action a gives us a reward of 1, we do not\u00a0know whether that is the best possible reward. We may want to exploit our current\u00a0policy and continue taking action a in order to be relatively sure of obtaining a\u00a0reward of 1. However, we may also want to explore by trying action a'. We do not\u00a0know what will happen if we try action a'. We hope to get a reward of 2, but we\u00a0run the risk of getting a reward of 0. Either way, we at least gain some knowledge.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4529",
    "text": "Exploration can be implemented in many ways, ranging from occasionally taking random actions intended to cover the entire space of possible actions, to\u00a0model-based approaches that compute a choice of action based on its expected\u00a0reward and the model\u2019s amount of uncertainty about that reward.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4530",
    "text": "Many factors determine the extent to which we prefer exploration or exploitation. One of the most prominent factors is the time scale we are interested in. If the\u00a0agent has only a short amount of time to accrue reward, then we prefer more\u00a0exploitation. If the agent has a long time to accrue reward, then we begin with\u00a0more exploration so that future actions can be planned more effectively with more\u00a0knowledge. As time progresses and our learned policy improves, we move toward\u00a0more exploitation.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4531",
    "text": "Supervised learning has no tradeoff between exploration and exploitation because the supervision signal always specifies which output is correct for each\u00a0input. There is no need to try out different outputs to determine if one is better\u00a0than the model\u2019s current output\u2014we always know that the label is the best output.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4532",
    "text": "Another difficulty arising in the context of reinforcement learning, besides the exploration-exploitation trade-off, is the difficulty of evaluating and comparing\u00a0different policies. Reinforcement learning involves interaction between the learner\u00a0and the environment. This feedback loop means that it is not straightforward to\u00a0evaluate the learner\u2019s performance using a fixed set of test set input values. The\u00a0policy itself determines which inputs will be seen. Dudik et al. (2011) present\u00a0techniques for evaluating contextual bandits.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4533",
    "text": "Deep learning approaches have been very successful in language modeling, machine translation and natural language processing due to the use of embeddings for\u00a0symbols (Rumelhart et al., 1986a) and words (Deerwester et al., 1990; Bengio et al.,\u00a02001). These embeddings represent semantic knowledge about individual words\u00a0and concepts. A research frontier is to develop embeddings for phrases and for\u00a0relations between words and facts. Search engines already use machine learning for\u00a0this purpose but much more remains to be done to improve these more advanced\u00a0representations.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4534",
    "text": "12.5.2.1 Knowledge, Relations and Question Answering",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4535",
    "text": "indexRelations One interesting research direction is determining how distributed representations can be trained to capture the relations between two entities. These\u00a0relations allow us to formalize facts about objects and how objects interact with\u00a0each other.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4536",
    "text": "In mathematics, a binary relation is a set of ordered pairs of objects. Pairs that are in the set are said to have the relation while those who are not in the set\u00a0do not. For example, we can define the relation \u201cis less than\u201d on the set of entities\u00a0{1, 2,3} by defining the set of ordered pairs S = {(1,2), (1, 3), (2, 3)}. Once this\u00a0relation is defined, we can use it like a verb. Because (1, 2) G S, we say that 1 is\u00a0less than 2. Because (2,1) G S ,we can not say that 2 is less than 1. Of course, the\u00a0entities that are related to one another need not be numbers. We could define a\u00a0relation is_a_type_of containing tuples like (dog, mammal).",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4537",
    "text": "In the context of AI, we think of a relation as a sentence in a syntactically simple and highly structured language. The relation plays the role of a verb,\u00a0while two arguments to the relation play the role of its subject and object. These\u00a0sentences take the form of a triplet of tokens",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4538",
    "text": "-12.22",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4539",
    "text": "-12.23",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4540",
    "text": "(subject, verb, object)",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4541",
    "text": "with values",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4542",
    "text": "(entity ^ relation^ entity k).",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4543",
    "text": "We can also define an attribute, a concept analogous to a relation, but taking only one argument:",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4544",
    "text": "(entity^, attribute j). \u00a0\u00a0\u00a0(12.24)",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4545",
    "text": "For example, we could define the has_fur attribute, and apply it to entities like dog.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4546",
    "text": "Many applications require representing relations and reasoning about them. How should we best do this within the context of neural networks?",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4547",
    "text": "Machine learning models of course require training data. We can infer relations between entities from training datasets consisting of unstructured natural language.\u00a0There are also structured databases that identify relations explicitly. A common\u00a0structure for these databases is the relational database, which stores this same\u00a0kind of information, albeit not formatted as three token sentences. When a\u00a0database is intended to convey commonsense knowledge about everyday life or\u00a0expert knowledge about an application area to an artificial intelligence system,\u00a0we call the database a knowledge base. Knowledge bases range from general\u00a0ones like Freebase, OpenCyc, WordNet, or Wikibase,1 etc. to more specialized\u00a0knowledge bases, like GeneOntology.2 Representations for entities and relations\u00a0can be learned by considering each triplet in a knowledge base as a training example\u00a0and maximizing a training objective that captures their joint distribution (Bordes\u00a0et al., 2013a).",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4548",
    "text": "In addition to training data, we also need to define a model family to train. A common approach is to extend neural language models to model entities and\u00a0relations. Neural language models learn a vector that provides a distributed\u00a0representation of each word. They also learn about interactions between words,\u00a0such as which word is likely to come after a sequence of words, by learning functions\u00a0of these vectors. We can extend this approach to entities and relations by learning\u00a0an embedding vector for each relation. In fact, the parallel between modeling",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4549",
    "text": "1Respectively available from these web sites: princeton.edu, wikiba.se",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4550",
    "text": "freebase.com, cyc.com/opencyc, wordnet.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4551",
    "text": "geneontology.org",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4552",
    "text": "language and modeling knowledge encoded as relations is so close that researchers have trained representations of such entities by using both knowledge bases and\u00a0natural language sentences (Bordes et al., 2011, 2012; Wang et al., 2014a) or\u00a0combining data from multiple relational databases (Bordes et al., 2013b). Many\u00a0possibilities exist for the particular parametrization associated with such a model.\u00a0Early work on learning about relations between entities (Paccanaro and Hinton,\u00a02000) posited highly constrained parametric forms (\u201clinear relational embeddings\u201d),\u00a0often using a different form of representation for the relation than for the entities.\u00a0For example, Paccanaro and Hinton (2000) and Bordes et al. (2011) used vectors for\u00a0entities and matrices for relations, with the idea that a relation acts like an operator\u00a0on entities. Alternatively, relations can be considered as any other entity (Bordes\u00a0et al., 2012), allowing us to make statements about relations, but more flexibility is\u00a0put in the machinery that combines them in order to model their joint distribution.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4553",
    "text": "A practical short-term application of such models is link prediction: predicting missing arcs in the knowledge graph. This is a form of generalization to new\u00a0facts, based on old facts. Most of the knowledge bases that currently exist have\u00a0been constructed through manual labor, which tends to leave many and probably\u00a0the majority of true relations absent from the knowledge base. See Wang et al.\u00a0(2014b), Lin et al. (2015) and Garcia-Duran et al. (2015) for examples of such an\u00a0application.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4554",
    "text": "Evaluating the performance of a model on a link prediction task is difficult because we have only a dataset of positive examples (facts that are known to\u00a0be true). If the model proposes a fact that is not in the dataset, we are unsure\u00a0whether the model has made a mistake or discovered a new, previously unknown\u00a0fact. The metrics are thus somewhat imprecise and are based on testing how the\u00a0model ranks a held-out of set of known true positive facts compared to other facts\u00a0that are less likely to be true. A common way to construct interesting examples\u00a0that are probably negative (facts that are probably false) is to begin with a true\u00a0fact and create corrupted versions of that fact, for example by replacing one entity\u00a0in the relation with a different entity selected at random. The popular precision at\u00a010% metric counts how many times the model ranks a \u201ccorrect\u201d fact among the\u00a0top 10% of all corrupted versions of that fact.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4555",
    "text": "Another application of knowledge bases and distributed representations for them is word-sense disambiguation (Navigli and Velardi, 2005; Bordes et al., 2012),\u00a0which is the task of deciding which of the senses of a word is the appropriate one,\u00a0in some context.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4556",
    "text": "Eventually, knowledge of relations combined with a reasoning process and understanding of natural language could allow us to build a general question\u00a0answering system. A general question answering system must be able to process\u00a0input information and remember important facts, organized in a way that enables\u00a0it to retrieve and reason about them later. This remains a difficult open problem\u00a0which can only be solved in restricted \u201ctoy\u201d environments. Currently, the best\u00a0approach to remembering and retrieving specific declarative facts is to use an\u00a0explicit memory mechanism, as described in Sec. 10.12. Memory networks were\u00a0first proposed to solve a toy question answering task (Weston et al., 2014). Kumar\u00a0et al. (2015) have proposed an extension that uses GRU recurrent nets to read\u00a0the input into the memory and to produce the answer given the contents of the\u00a0memory.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4557",
    "text": "Deep learning has been applied to many other applications besides the ones described here, and will surely be applied to even more after this writing. It would\u00a0be impossible to describe anything remotely resembling a comprehensive coverage\u00a0of such a topic. This survey provides a representative sample of what is possible\u00a0as of this writing.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4558",
    "text": "This concludes Part II, which has described modern practices involving deep networks, comprising all of the most successful methods. Generally speaking, these\u00a0methods involve using the gradient of a cost function to find the parameters of a\u00a0model that approximates some desired function. With enough training data, this\u00a0approach is extremely powerful. We now turn to Part III, in which we step into the\u00a0territory of research\u2014methods that are designed to work with less training data\u00a0or to perform a greater variety of tasks, where the challenges are more difficult\u00a0and not as close to being solved as the situations we have described so far.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4559",
    "text": "Part III",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4560",
    "text": "Deep Learning Research",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4561",
    "text": "This part of the book describes the more ambitious and advanced approaches to deep learning, currently pursued by the research community.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4562",
    "text": "In the previous parts of the book, we have shown how to solve supervised learning problems\u2014how to learn to map one vector to another, given enough\u00a0examples of the mapping.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4563",
    "text": "Not all problems we might want to solve fall into this category. We may wish to generate new examples, or determine how likely some point is, or handle\u00a0missing values and take advantage of a large set of unlabeled examples or examples\u00a0from related tasks. A shortcoming of the current state of the art for industrial\u00a0applications is that our learning algorithms require large amounts of supervised\u00a0data to achieve good accuracy. In this part of the book, we discuss some of\u00a0the speculative approaches to reducing the amount of labeled data necessary\u00a0for existing models to work well and be applicable across a broader range of\u00a0tasks. Accomplishing these goals usually requires some form of unsupervised or\u00a0semi-supervised learning.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4564",
    "text": "Many deep learning algorithms have been designed to tackle unsupervised learning problems, but none have truly solved the problem in the same way that\u00a0deep learning has largely solved the supervised learning problem for a wide variety of\u00a0tasks. In this part of the book, we describe the existing approaches to unsupervised\u00a0learning and some of the popular thought about how we can make progress in this\u00a0field.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4565",
    "text": "A central cause of the difficulties with unsupervised learning is the high dimensionality of the random variables being modeled. This brings two distinct challenges: a statistical challenge and a computational challenge. The statistical\u00a0challenge regards generalization: the number of configurations we may want to\u00a0distinguish can grow exponentially with the number of dimensions of interest, and\u00a0this quickly becomes much larger than the number of examples one can possibly\u00a0have (or use with bounded computational resources). The computational challenge\u00a0associated with high-dimensional distributions arises because many algorithms for\u00a0learning or using a trained model (especially those based on estimating an explicit\u00a0probability function) involve intractable computations that grow exponentially\u00a0with the number of dimensions.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4566",
    "text": "With probabilistic models, this computational challenge arises from the need to perform intractable inference or simply from the need to normalize the distribution.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4567",
    "text": "\u2022 Intractable inference: inference is discussed mostly in Chapter 19. It regards the question of guessing the probable values of some variables a,\u00a0given other variables b, with respect to a model that captures the joint\u00a0distribution between a, b and c. In order to even compute such conditional\u00a0probabilities one needs to sum over the values of the variables c, as well as\u00a0compute a normalization constant which sums over the values of a and c.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4568",
    "text": "\u2022 Intractable normalization constants (the partition function): the",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4569",
    "text": "partition function is discussed mostly in Chapter 18. Normalizing constants of probability functions come up in inference (above) as well as in learning.\u00a0Many probabilistic models involve such a normalizing constant. Unfortunately, learning such a model often requires computing the gradient of the\u00a0logarithm of the partition function with respect to the model parameters.\u00a0That computation is generally as intractable as computing the partition\u00a0function itself. Monte Carlo Markov chain (MCMC) methods (Chapter 17)\u00a0are often used to deal with the partition function (computing it or its gradient). Unfortunately, MCMC methods suffer when the modes of the model\u00a0distribution are numerous and well-separated, especially in high-dimensional\u00a0spaces (Sec. 17.5).",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4570",
    "text": "One way to confront these intractable computations is to approximate them, and many approaches have been proposed as discussed in this third part of the\u00a0book. Another interesting way, also discussed here, would be to avoid these\u00a0intractable computations altogether by design, and methods that do not require\u00a0such computations are thus very appealing. Several generative models have been\u00a0proposed in recent years, with that motivation. A wide variety of contemporary\u00a0approaches to generative modeling are discussed in Chapter 20.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4571",
    "text": "Part III is the most important for a researcher\u2014someone who wants to understand the breadth of perspectives that have been brought to the field of deep learning, and push the field forward towards true artificial intelligence.",
    "chapter": "",
    "chapter_id": "main-25.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4572",
    "text": "Many of the research frontiers in deep learning involve building a probabilistic model of the input, pmode1 (x). Such a model can, in principle, use probabilistic inference to\u00a0predict any of the variables in its environment given any of the other variables. Many\u00a0of these models also have latent variables h, with pmode1(x) = Ehpmodei(x | h).\u00a0These latent variables provide another means of representing the data. Distributed\u00a0representations based on latent variables can obtain all of the advantages of\u00a0representation learning that we have seen with deep feedforward and recurrent\u00a0networks.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4573",
    "text": "In this chapter, we describe some of the simplest probabilistic models with latent variables: linear factor models. These models are sometimes used as building\u00a0blocks of mixture models (Hinton et al., 1995a; Ghahramani and Hinton, 1996;\u00a0Roweis et al., 2002) or larger, deep probabilistic models (Tang et al., 2012). They\u00a0also show many of the basic approaches necessary to build generative models that\u00a0the more advanced deep models will extend further.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4574",
    "text": "A linear factor model is defined by the use of a stochastic, linear decoder function that generates x by adding noise to a linear transformation of h.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4575",
    "text": "These models are interesting because they allow us to discover explanatory factors that have a simple joint distribution. The simplicity of using a linear decoder\u00a0made these models some of the first latent variable models to be extensively studied.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4576",
    "text": "A linear factor model describes the data generation process as follows. First, we sample the explanatory factors h from a distribution",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4577",
    "text": "h - p(h), \u00a0\u00a0\u00a0(13.1)",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4578",
    "text": "where p(h) is a factorial distribution, with p(h) = ip(h), so that it is easy to",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4579",
    "text": "Figure 13.1: The directed graphical model describing the linear factor model family, in which we assume that an observed data vector x is obtained by a linear combination of\u00a0independent latent factors h, plus some noise. Different models, such as probabilistic\u00a0PCA, factor analysis or ICA, make different choices about the form of the noise and of\u00a0the prior p(h).",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4580",
    "text": "Probabilistic PCA (principal components analysis), factor analysis and other linear factor models are special cases of the above equations (13.1 and 13.2) and only\u00a0differ in the choices made for the noise distribution and the model\u2019s prior over\u00a0latent variables h before observing x.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4581",
    "text": "In factor analysis (Bartholomew, 1987; Basilevsky, 1994), the latent variable prior is just the unit variance Gaussian",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4582",
    "text": "h (h; 0,1) \u00a0\u00a0\u00a0(13.3)",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4583",
    "text": "while the observed variables xi are assumed to be conditionally independent, givenh. Specifically, the noise is assumed to be drawn from a diagonal covariance Gaussian\u00a0distribution, with covariance matrix 0 = diag(a2), with a2 = [a|, 00 ,...,2\u05ben] a\u00a0vector of per-variable variances.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4584",
    "text": "The role of the latent variables is thus to capture the dependencies between the different observed variables xi. Indeed, it can easily be shown that x is just a\u00a0multivariate normal random variable, with",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4585",
    "text": "x ~ N(x; b, WWT + 0). \u00a0\u00a0\u00a0(13.4)",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4586",
    "text": "In order to cast PCA in a probabilistic framework, we can make a slight modification to the factor analysis model, making the conditional variances a2",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4587",
    "text": "\u05be\u05ber \u00a0\u00a0\u00a0<r\\",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4588",
    "text": "equal to each other. In that case the covariance of x is just WW 1 + a21, where",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4589",
    "text": "0\u2666",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4590",
    "text": "a2 is now a scalar. This yields the conditional distribution",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4591",
    "text": "-13.5",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4592",
    "text": "N(x; b, WWT + a 2I)",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4593",
    "text": "or equivalently",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4594",
    "text": "x = W h + b + az",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4595",
    "text": "-13.6",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4596",
    "text": "where z N(z; 0,1 ) is Gaussian noise. Tipping and Bishop (1999) then show an iterative EM algorithm for estimating the parameters W and a2.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4597",
    "text": "This probabilistic PCA model takes advantage of the observation that most variations in the data can be captured by the latent variables h, up to some\u00a0small residual reconstruction error a2. As shown by Tipping and Bishop (1999),\u00a0probabilistic PCA becomes PCA as a ^ 0. In that case, the conditional expected\u00a0value of h given x becomes an orthogonal projection of x \u2014 b onto the space\u00a0spanned by the d columns of W, like in PCA.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4598",
    "text": "As a ^ 0, the density model defined by probabilistic PCA becomes very sharp around these d dimensions spanned by the columns of W. This can make the\u00a0model assign very low likelihood to the data if the data does not actually cluster\u00a0near a hyperplane.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4599",
    "text": "Independent component analysis (ICA) is among the oldest representation learning algorithms (Herault and Ans, 1984; Jutten and Herault, 1991; Comon, 1994;\u00a0Hyvarinen, 1999; Hyvarinen et al., 2001a; Hinton et al., 2001; Teh et al., 2003).\u00a0It is an approach to modeling linear factors that seeks to separate an observed\u00a0signal into many underlying signals that are scaled and added together to form\u00a0the observed data. These signals are intended to be fully independent, rather than\u00a0merely decorrelated from each other.1",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4600",
    "text": "Many different specific methodologies are referred to as ICA. The variant that is most similar to the other generative models we have described here is a\u00a0variant (Pham et al., 1992) that trains a fully parametric generative model. The\u00a0prior distribution over the underlying factors, p(h), must be fixed ahead of time by\u00a0the user. The model then deterministically generates x = Wh. We can perform\u00a0a nonlinear change of variables (using Eq. 3.47) to determine p(x). Learning the\u00a0model then proceeds as usual, using maximum likelihood.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4601",
    "text": "The motivation for this approach is that by choosingp (h) to be independent, we can recover underlying factors that are as close as possible to independent.\u00a0This is commonly used, not to capture high-level abstract causal factors, but to\u00a0recover low-level signals that have been mixed together. In this setting, each\u00a0training example is one moment in time, each Xi is one sensor\u2019s observation of\u00a0the mixed signals, and each hi is one estimate of one of the original signals. For\u00a0example, we might have n people speaking simultaneously. If we have n different\u00a0microphones placed in different locations, ICA can detect the changes in the volume\u00a0between each speaker as heard by each microphone, and separate the signals so\u00a0that each h i contains only one person speaking clearly. This is commonly used\u00a0in neuroscience for electroencephalography, a technology for recording electrical\u00a0signals originating in the brain. Many electrode sensors placed on the subject\u2019s\u00a0head are used to measure many electrical signals coming from the body. The\u00a0experimenter is typically only interested in signals from the brain, but signals from\u00a0the subject\u2019s heart and eyes are strong enough to confound measurements taken\u00a0at the subject\u2019s scalp. The signals arrive at the electrodes mixed together, so\u00a0ICA is necessary to separate the electrical signature of the heart from the signals\u00a0originating in the brain, and to separate signals in different brain regions from\u00a0each other.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4602",
    "text": "As mentioned before, many variants of ICA are possible. Some add some noise in the generation of x rather than using a deterministic decoder. Most do not\u00a0use the maximum likelihood criterion, but instead aim to make the elements of\u00a0h = W-1 x independent from each other. Many criteria that accomplish this goal\u00a0are possible. Eq. 3.47 requires taking the determinant of W, which can be an\u00a0expensive and numerically unstable operation. Some variants of ICA avoid this\u00a0problematic operation by constraining W to be orthonormal.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4603",
    "text": "All variants of ICA require that p( h) be non-Gaussian. This is because if p(h) is an independent prior with Gaussian components, then W is not identifiable.\u00a0We can obtain the same distribution over p(x) for many values of W. This is very\u00a0different from other linear factor models like probabilistic PCA and factor analysis,\u00a0that often require p(h) to be Gaussian in order to make many operations on the\u00a0model have closed form solutions. In the maximum likelihood approach where the\u00a0user explicitly specifies the distribution, a typical choice is to use p (h) = df. a(hi).\u00a0Typical choices of these non-Gaussian distributions have larger peaks near 0 than\u00a0does the Gaussian distribution, so we can also see most implementations of ICA\u00a0as learning sparse features.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4604",
    "text": "Many variants of ICA are not generative models in the sense that we use the phrase. In this book, a generative model either representsp(x) or can draw samples\u00a0from it. Many variants of ICA only know how to transform between x and h, but\u00a0do not have any way of representingp(h), and thus do not impose a distribution\u00a0over p(x). For example, many ICA variants aim to increase the sample kurtosis of\u00a0h = W-1 x, because high kurtosis indicates thatp(h) is non-Gaussian, but this is\u00a0accomplished without explicitly representing p (h). This is because ICA is more\u00a0often used as an analysis tool for separating signals, rather than for generating\u00a0data or estimating its density.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4605",
    "text": "Just as PCA can be generalized to the nonlinear autoencoders described in Chapter 14, ICA can be generalized to a nonlinear generative model, in which\u00a0we use a nonlinear function f to generate the observed data. See Hyvarinen\u00a0and Pajunen (1999) for the initial work on nonlinear ICA and its successful\u00a0use with ensemble learning by Roberts and Everson (2001) and Lappalainen\u00a0et al. (2000). Another nonlinear extension of ICA is the approach of nonlinear\u00a0independent components estimation, or NICE (Dinh et al., 2014), which stacks a\u00a0series of invertible transformations (encoder stages) that have the property that\u00a0the determinant of the Jacobian of each transformation can be computed efficiently.\u00a0This makes it possible to compute the likelihood exactly and, like ICA, attempts\u00a0to transform the data into a space where it has a factorized marginal distribution,\u00a0but is more likely to succeed thanks to the nonlinear encoder. Because the encoder\u00a0is associated with a decoder that is its perfect inverse, it is straightforward to\u00a0generate samples from the model (by first sampling from p(h) and then applying\u00a0the decoder).",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4606",
    "text": "Another generalization of ICA is to learn groups of features, with statistical dependence allowed within a group but discouraged between groups (Hyvarinen\u00a0and Hoyer, 1999; Hyvarinen et al., 2001b). When the groups of related units are\u00a0chosen to be non-overlapping, this is called independent subspace analysis. It is also\u00a0possible to assign spatial coordinates to each hidden unit and form overlapping\u00a0groups of spatially neighboring units. This encourages nearby units to learn similar\u00a0features. When applied to natural images, this topographic ICA approach learns\u00a0Gabor filters, such that neighboring features have similar orientation, location or\u00a0frequency. Many different phase offsets of similar Gabor functions occur within\u00a0each region, so that pooling over small regions yields translation invariance.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4607",
    "text": "Slow feature analysis (SFA) is a linear factor model that uses information from time signals to learn invariant features (Wiskott and Sejnowski, 2002).",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4608",
    "text": "Slow feature analysis is motivated by a general principle called the slowness principle. The idea is that the important characteristics of scenes change very\u00a0slowly compared to the individual measurements that make up a description of a\u00a0scene. For example, in computer vision, individual pixel values can change very\u00a0rapidly. If a zebra moves from left to right across the image, an individual pixel\u00a0will rapidly change from black to white and back again as the zebra\u2019s stripes pass\u00a0over the pixel. By comparison, the feature indicating whether a zebra is in the\u00a0image will not change at all, and the feature describing the zebra\u2019s position will\u00a0change slowly. We therefore may wish to regularize our model to learn features\u00a0that change slowly over time.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4609",
    "text": "The slowness principle predates slow feature analysis and has been applied to a wide variety of models (Hinton, 1989; Foldiak, 1989; Mobahi et al., 2009;\u00a0Bergstra and Bengio, 2009). In general, we can apply the slowness principle to any\u00a0differentiable model trained with gradient descent. The slowness principle may be\u00a0introduced by adding a term to the cost function of the form",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4610",
    "text": "A \u00a3L(f (x(t+1)),f(x(t))) \u00a0\u00a0\u00a0(13.7)",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4611",
    "text": "t",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4612",
    "text": "where A is a hyperparameter determining the strength of the slowness regularization term, t is the index into a time sequence of examples, f is the feature extractor\u00a0to be regularized, and L is a loss function measuring the distance between f (x(t))\u00a0and f (x(t+1)). A common choice for L is the mean squared difference.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4613",
    "text": "Slow feature analysis is a particularly efficient application of the slowness principle. It is efficient because it is applied to a linear feature extractor, and can\u00a0thus be trained in closed form. Like some variants of ICA, SFA is not quite a\u00a0generative model per se, in the sense that it defines a linear map between input\u00a0space and feature space but does not define a prior over feature space and thus\u00a0does not impose a distribution p(x) on input space.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4614",
    "text": "The SFA algorithm (Wiskott and Sejnowski, 2002) consists of defining f (x; 6) to be a linear transformation, and solving the optimization problem",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4615",
    "text": "minEt(f (x(t+1)) - f (x(t)) ;)2",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4616",
    "text": "-13.8",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4617",
    "text": "subject to the constraints",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4618",
    "text": "",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4619",
    "text": "Ef (x(t) )i = 0",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4620",
    "text": "-13.9",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4621",
    "text": "and",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4622",
    "text": "",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4623",
    "text": "Et [f (x(t))2 ] = 1.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4624",
    "text": "-13.1",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4625",
    "text": "The constraint that the learned feature have zero mean is necessary to make the problem have a unique solution; otherwise we could add a constant to all feature\u00a0values and obtain a different solution with equal value of the slowness objective.\u00a0The constraint that the features have unit variance is necessary to prevent the\u00a0pathological solution where all features collapse to 0. Like PCA, the SFA features\u00a0are ordered, with the first feature being the slowest. To learn multiple features, we\u00a0must also add the constraint",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4626",
    "text": "Vi < j, E [f (x(t))i f (x(t) )j] = 0. \u00a0\u00a0\u00a0(13.11)",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4627",
    "text": "This specifies that the learned features must be linearly decorrelated from each other. Without this constraint, all of the learned features would simply capture the\u00a0one slowest signal. One could imagine using other mechanisms, such as minimizing\u00a0reconstruction error, to force the features to diversify, but this decorrelation\u00a0mechanism admits a simple solution due to the linearity of SFA features. The SFA\u00a0problem may be solved in closed form by a linear algebra package.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4628",
    "text": "SFA is typically used to learn nonlinear features by applying a nonlinear basis expansion to x before running SFA. For example, it is common to replace x by the\u00a0quadratic basis expansion, a vector containing elements xiXj for all i and j. Linear\u00a0SFA modules may then be composed to learn deep nonlinear slow feature extractors\u00a0by repeatedly learning a linear SFA feature extractor, applying a nonlinear basis\u00a0expansion to its output, and then learning another linear SFA feature extractor on\u00a0top of that expansion.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4629",
    "text": "When trained on small spatial patches of videos of natural scenes, SFA with quadratic basis expansions learns features that share many characteristics with\u00a0those of complex cells in V1 cortex (Berkes and Wiskott, 2005). When trained\u00a0on videos of random motion within 3-D computer rendered environments, deep\u00a0SFA learns features that share many characteristics with the features represented\u00a0by neurons in rat brains that are used for navigation (Franzius et al., 2007). SFA\u00a0thus seems to be a reasonably biologically plausible model.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4630",
    "text": "A major advantage of SFA is that it is possibly to theoretically predict which features SFA will learn, even in the deep, nonlinear setting. To make such theoretical\u00a0predictions, one must know about the dynamics of the environment in terms of\u00a0configuration space (e.g., in the case of random motion in the 3-D rendered\u00a0environment, the theoretical analysis proceeds from knowledge of the probability\u00a0distribution over position and velocity of the camera). Given the knowledge of how\u00a0the underlying factors actually change, it is possible to analytically solve for the\u00a0optimal functions expressing these factors. In practice, experiments with deep SFA\u00a0applied to simulated data seem to recover the theoretically predicted functions.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4631",
    "text": "This is in comparison to other learning algorithms where the cost function depends highly on specific pixel values, making it much more difficult to determine what\u00a0features the model will learn.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4632",
    "text": "Deep SFA has also been used to learn features for object recognition and pose estimation (Franzius et al., 2008). So far, the slowness principle has not become\u00a0the basis for any state of the art applications. It is unclear what factor has limited\u00a0its performance. We speculate that perhaps the slowness prior is too strong, and\u00a0that, rather than imposing a prior that features should be approximately constant,\u00a0it would be better to impose a prior that features should be easy to predict from\u00a0one time step to the next. The position of an object is a useful feature regardless of\u00a0whether the object\u2019s velocity is high or low, but the slowness principle encourages\u00a0the model to ignore the position of objects that have high velocity.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4633",
    "text": "Sparse coding (Olshausen and Field, 1996) is a linear factor model that has been heavily studied as an unsupervised feature learning and feature extraction\u00a0mechanism. Strictly speaking, the term \u201csparse coding\u201d refers to the process of\u00a0inferring the value of h in this model, while \u201csparse modeling\u201d refers to the process\u00a0of designing and learning the model, but the term \u201csparse coding\u201d is often used to\u00a0refer to both.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4634",
    "text": "Like most other linear factor models, it uses a linear decoder plus noise to obtain reconstructions of x, as specified in Eq. 13.2. More specifically, sparse\u00a0coding models typically assume that the linear factors have Gaussian noise with\u00a0isotropic precision (3:",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4635",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4636",
    "text": "p(x | h) = N(x; Wh + b, 31).",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4637",
    "text": "3",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4638",
    "text": "-13.12",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4639",
    "text": "The distribution p(h) is chosen to be one with sharp peaks near 0 (Olshausen and Field, 1996). Common choices include factorized Laplace, Cauchy or factorized\u00a0Student-t distributions. For example, the Laplace prior parametrized in terms of\u00a0the sparsity penalty coefficient A is given by",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4640",
    "text": "p(hi) = Laplace(hi;0, -) = -e 2 A|h 1",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4641",
    "text": "A 4",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4642",
    "text": "-13.13",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4643",
    "text": "2. A",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4644",
    "text": "and the Student-t prior by",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4645",
    "text": "p(h i) \u00ab",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4646",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4647",
    "text": ". \u00a0\u00a0\u00a0h2 v+1",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4648",
    "text": "(1 + h",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4649",
    "text": "-13.14",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4650",
    "text": "Training sparse coding with maximum likelihood is intractable. Instead, the training alternates between encoding the data and training the decoder to better\u00a0reconstruct the data given the encoding. This approach will be justified further as\u00a0a principled approximation to maximum likelihood later, in Sec. 19.3.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4651",
    "text": "For models such as PCA, we have seen the use of a parametric encoder function that predicts h and consists only of multiplication by a weight matrix. The encoder\u00a0that we use with sparse coding is not a parametric encoder. Instead, the encoder\u00a0is an optimization algorithm, that solves an optimization problem in which we seek\u00a0the single most likely code value:",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4652",
    "text": "h* = f (x) = argmaxp(h | x). \u00a0\u00a0\u00a0(13.15)",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4653",
    "text": "h",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4654",
    "text": "When combined with Eq. 13.13 and Eq. 13.12, this yields the following optimization problem:",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4655",
    "text": "argmaxp(h | x) \u00a0\u00a0\u00a0(13.16)",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4656",
    "text": "h",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4657",
    "text": "#ERROR!",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4658",
    "text": "h",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4659",
    "text": "#ERROR!",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4660",
    "text": "h",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4661",
    "text": "where we have dropped terms not depending on h and divided by positive scaling factors to simplify the equation.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4662",
    "text": "Due to the imposition of an L1 norm on h, that this procedure will yield a",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4663",
    "text": "sparse h* (See Sec. 7.1.2).",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4664",
    "text": "To train the model rather than just perform inference, we alternate between minimization with respect to h and minimization with respect to W. In this\u00a0presentation, we treat fl as a hyperparameter. Typically it is set to 1 because its\u00a0role in this optimization problem is shared with A and there is no need for both\u00a0hyperparameters. In principle, we could also treat (3 as a parameter of the model\u00a0and learn it. Our presentation here has discarded some terms that do not depend\u00a0on h but do depend on (3. To learn fl, these terms must be included, or (3 will\u00a0collapse to 0.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4665",
    "text": "Not all approaches to sparse coding explicitly build a p(h) and a p(x | h). Often we are just interested in learning a dictionary of features with activation\u00a0values that will often be zero when extracted using this inference procedure.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4666",
    "text": "If we sample h from a Laplace prior, it is in fact a zero probability event for an element of h to actually be zero. The generative model itself is not especially\u00a0sparse, only the feature extractor is. Goodfellow et al. (2013d) describe approximate\u00a0inference in a different model family, the spike and slab sparse coding model, for\u00a0which samples from the prior usually contain true zeros.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4667",
    "text": "The sparse coding approach combined with the use of the non-parametric encoder can in principle minimize the combination of reconstruction error and\u00a0log-prior better than any specific parametric encoder. Another advantage is that\u00a0there is no generalization error to the encoder. A parametric encoder must learn\u00a0how to map x to h in a way that generalizes. For unusual x that do not resemble\u00a0the training data, a learned, parametric encoder may fail to find an h that results\u00a0in accurate reconstruction or a sparse code. For the vast majority of formulations\u00a0of sparse coding models, where the inference problem is convex, the optimization\u00a0procedure will always find the optimal code (unless degenerate cases such as\u00a0replicated weight vectors occur). Obviously, the sparsity and reconstruction costs\u00a0can still rise on unfamiliar points, but this is due to generalization error in the\u00a0decoder weights, rather than generalization error in the encoder. The lack of\u00a0generalization error in sparse coding\u2019s optimization-based encoding process may\u00a0result in better generalization when sparse coding is used as a feature extractor for\u00a0a classifier than when a parametric function is used to predict the code. Coates\u00a0and Ng (2011) demonstrated that sparse coding features generalize better for\u00a0object recognition tasks than the features of a related model based on a parametric\u00a0encoder, the linear-sigmoid autoencoder. Inspired by their work, Goodfellow et al.\u00a0(2013d) showed that a variant of sparse coding generalizes better than other feature\u00a0extractors in the regime where extremely few labels are available (twenty or fewer\u00a0labels per class).",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4668",
    "text": "The primary disadvantage of the non-parametric encoder is that it requires greater time to compute h given x because the non-parametric approach requires\u00a0running an iterative algorithm. The parametric autoencoder approach, developed\u00a0in Chapter 14, uses only a fixed number of layers, often only one. Another\u00a0disadvantage is that it is not straight-forward to back-propagate through the\u00a0non-parametric encoder, which makes it difficult to pretrain a sparse coding model\u00a0with an unsupervised criterion and then fine-tune it using a supervised criterion.\u00a0Modified versions of sparse coding that permit approximate derivatives do exist\u00a0but are not widely used (Bagnell and Bradley, 2009).",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4669",
    "text": "Sparse coding, like other linear factor models, often produces poor samples, as shown in Fig. 13.2. This happens even when the model is able to reconstruct\u00a0the data well and provide useful features for a classifier. The reason is that each\u00a0individual feature may be learned well, but the factorial prior on the hidden code\u00a0results in the model including random subsets of all of the features in each generated\u00a0sample. This motivates the development of deeper models that can impose a non-",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4670",
    "text": "Figure 13.2: Example samples and weights from a spike and slab sparse coding model trained on the MNIST dataset. (Left) The samples from the model do not resemble the\u00a0training examples. At first glance, one might assume the model is poorly fit. (Right) The\u00a0weight vectors of the model have learned to represent penstrokes and sometimes complete\u00a0digits. The model has thus learned useful features. The problem is that the factorial prior\u00a0over features results in random subsets of features being combined. Few such subsets\u00a0are appropriate to form a recognizable MNIST digit. This motivates the development of\u00a0generative models that have more powerful distributions over their latent codes. Figure\u00a0reproduced with permission from Goodfellow et al. (2013d).",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4671",
    "text": "factorial distribution on the deepest code layer, as well as the development of more sophisticated shallow models.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4672",
    "text": "Linear factor models including PCA and factor analysis can be interpreted as learning a manifold (Hinton et al., 1997). We can view probabilistic PCA as\u00a0defining a thin pancake-shaped region of high probability\u2014a Gaussian distribution\u00a0that is very narrow along some axes, just as a pancake is very flat along its vertical\u00a0axis, but is elongated along other axes, just as a pancake is wide along its horizontal\u00a0axes. This is illustrated in Fig. 13.3. PCA can be interpreted as aligning this\u00a0pancake with a linear manifold in a higher-dimensional space. This interpretation\u00a0applies not just to traditional PCA but also to any linear autoencoder that learns\u00a0matrices W and V with the goal of making the reconstruction of x lie as close to\u00a0x as possible,",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4673",
    "text": "Let the encoder be",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4674",
    "text": "h = f (x) = WT(x - ^). \u00a0\u00a0\u00a0(13.19)",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4675",
    "text": "The encoder computes a low-dimensional representation of h. With the autoencoder view, we have a decoder computing the reconstruction",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4676",
    "text": "x = g(h) = b + Vh. \u00a0\u00a0\u00a0(13.20)",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4677",
    "text": "Figure 13.3: Flat Gaussian capturing probability concentration near a low-dimensional manifold. The figure shows the upper half of the \u201cpancake\u201d above the \u201cmanifold plane\u201d\u00a0which goes through its middle. The variance in the direction orthogonal to the manifold is\u00a0very small (arrow pointing out of plane) and can be considered like \u201cnoise,\u201d while the other\u00a0variances are large (arrows in the plane) and correspond to \u201csignal,\u201d and a coordinate\u00a0system for the reduced-dimension data.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4678",
    "text": "The choices of linear encoder and decoder that minimize reconstruction error",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4679",
    "text": "-13.21",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4680",
    "text": "E[||x \u2014 x|| 2]",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4681",
    "text": "correspond to V = W, ^ = b = E[x] and the columns of W form an orthonormal basis which spans the same subspace as the principal eigenvectors of the covariance\u00a0matrix",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4682",
    "text": "C = E[(x \u2014 ^)(x \u2014 ^)T ]. \u00a0\u00a0\u00a0(13.22)",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4683",
    "text": "In the case of PCA, the columns of W are these eigenvectors, ordered by the magnitude of the corresponding eigenvalues (which are all real and non-negative).",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4684",
    "text": "One can also show that eigenvalue Ai of C corresponds to the variance of x in the direction of eigenvector v(i). If x G RD and h G with d < D, then the",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4685",
    "text": "optimal reconstruction error (choosing i, b, V and W as above) is",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4686",
    "text": "D",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4687",
    "text": "minE[||x \u2014 x||2] = \u00a0\u00a0\u00a0Xi.\u00a0\u00a0\u00a0\u00a0(13.23)",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4688",
    "text": "i=d+1",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4689",
    "text": "Hence, if the covariance has rank d, the eigenvalues Xd+1 to Xd are 0 and reconstruction error is 0.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4690",
    "text": "Furthermore, one can also show that the above solution can be obtained by maximizing the variances of the elements of h, under orthonormal W, instead of\u00a0minimizing reconstruction error.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4691",
    "text": "Linear factor models are some of the simplest generative models and some of the simplest models that learn a representation of data. Much as linear classifiers and\u00a0linear regression models may be extended to deep feedforward networks, these linear\u00a0factor models may be extended to autoencoder networks and deep probabilistic\u00a0models that perform the same tasks but with a much more powerful and flexible\u00a0model family.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4692",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4693",
    "text": " See Sec. 3.8 for a discussion of the difference between uncorrelated variables and independent variables.",
    "chapter": "",
    "chapter_id": "main-26.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4694",
    "text": "An autoencoder is a neural network that is trained to attempt to copy its input to its output. Internally, it has a hidden layer h that describes a code used to\u00a0represent the input. The network may be viewed as consisting of two parts: an\u00a0encoder function h = f (x) and a decoder that produces a reconstruction r = g(h).\u00a0This architecture is presented in Fig. 14.1. If an autoencoder succeeds in simply\u00a0learning to set g(f (x)) = x everywhere, then it is not especially useful. Instead,\u00a0autoencoders are designed to be unable to learn to copy perfectly. Usually they are\u00a0restricted in ways that allow them to copy only approximately, and to copy only\u00a0input that resembles the training data. Because the model is forced to prioritize\u00a0which aspects of the input should be copied, it often learns useful properties of the\u00a0data.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4695",
    "text": "Modern autoencoders have generalized the idea of an encoder and a decoder beyond deterministic functions to stochastic mappings pencoder (h | x) and",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4696",
    "text": "pdecoder (x 1 h).",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4697",
    "text": "The idea of autoencoders has been part of the historical landscape of neural networks for decades (LeCun, 1987; Bourlard and Kamp, 1988; Hinton and Zemel,\u00a01994). Traditionally, autoencoders were used for dimensionality reduction or\u00a0feature learning. Recently, theoretical connections between autoencoders and\u00a0latent variable models have brought autoencoders to the forefront of generative\u00a0modeling, as we will see in Chapter 20. Autoencoders may be thought of as being\u00a0a special case of feedforward networks, and may be trained with all of the same\u00a0techniques, typically minibatch gradient descent following gradients computed\u00a0by back-propagation. Unlike general feedforward networks, autoencoders may\u00a0also be trained using recirculation (Hinton and McClelland, 1988), a learning\u00a0algorithm based on comparing the activations of the network on the original input\u00a0to the activations on the reconstructed input. Recirculation is regarded as more\u00a0biologically plausible than back-propagation, but is rarely used for machine learning\u00a0applications.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4698",
    "text": "Figure 14.1: The general structure of an autoencoder, mapping an input x to an output (called reconstruction) r through an internal representation or code h. The autoencoder\u00a0has two components: the encoder f (mapping x to h) and the decoder g (mapping h to",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4699",
    "text": "r).",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4700",
    "text": "Copying the input to the output may sound useless, but we are typically not interested in the output of the decoder. Instead, we hope that training the\u00a0autoencoder to perform the input copying task will result in h taking on useful\u00a0properties.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4701",
    "text": "One way to obtain useful features from the autoencoder is to constrain h to have smaller dimension than x. An autoencoder whose code dimension is less\u00a0than the input dimension is called undercomplete. Learning an undercomplete\u00a0representation forces the autoencoder to capture the most salient features of the\u00a0training data.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4702",
    "text": "The learning process is described simply as minimizing a loss function",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4703",
    "text": "L(x,g(/(x))) \u00a0\u00a0\u00a0(14A)",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4704",
    "text": "where L is a loss function penalizing g(/(x)) for being dissimilar from x, such as the mean squared error.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4705",
    "text": "When the decoder is linear and L is the mean squared error, an undercomplete autoencoder learns to span the same subspace as PCA. In this case, an autoencoder\u00a0trained to perform the copying task has learned the principal subspace of the\u00a0training data as a side-effect.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4706",
    "text": "Autoencoders with nonlinear encoder functions / and nonlinear decoder functions g can thus learn a more powerful nonlinear generalization of PCA. Unfortunately, if the encoder and decoder are allowed too much capacity, the autoencoder can learn to perform the copying task without extracting useful information about\u00a0the distribution of the data. Theoretically, one could imagine that an autoencoder\u00a0with a one-dimensional code but a very powerful nonlinear encoder could learn to\u00a0represent each training example with the code i. The decoder could learn to\u00a0map these integer indices back to the values of specific training examples. This\u00a0specific scenario does not occur in practice, but it illustrates clearly that an autoencoder trained to perform the copying task can fail to learn anything useful about\u00a0the dataset if the capacity of the autoencoder is allowed to become too great.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4707",
    "text": "Undercomplete autoencoders, with code dimension less than the input dimension, can learn the most salient features of the data distribution. We have seen that\u00a0these autoencoders fail to learn anything useful if the encoder and decoder are\u00a0given too much capacity.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4708",
    "text": "A similar problem occurs if the hidden code is allowed to have dimension equal to the input, and in the overcomplete case in which the hidden code has dimension\u00a0greater than the input. In these cases, even a linear encoder and linear decoder\u00a0can learn to copy the input to the output without learning anything useful about\u00a0the data distribution.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4709",
    "text": "Ideally, one could train any architecture of autoencoder successfully, choosing the code dimension and the capacity of the encoder and decoder based on the\u00a0complexity of distribution to be modeled. Regularized autoencoders provide the\u00a0ability to do so. Rather than limiting the model capacity by keeping the encoder\u00a0and decoder shallow and the code size small, regularized autoencoders use a loss\u00a0function that encourages the model to have other properties besides the ability\u00a0to copy its input to its output. These other properties include sparsity of the\u00a0representation, smallness of the derivative of the representation, and robustness\u00a0to noise or to missing inputs. A regularized autoencoder can be nonlinear and\u00a0overcomplete but still learn something useful about the data distribution even if\u00a0the model capacity is great enough to learn a trivial identity function.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4710",
    "text": "In addition to the methods described here which are most naturally interpreted as regularized autoencoders, nearly any generative model with latent variables\u00a0and equipped with an inference procedure (for computing latent representations\u00a0given input) may be viewed as a particular form of autoencoder. Two generative\u00a0modeling approaches that emphasize this connection with autoencoders are the\u00a0descendants of the Helmholtz machine (Hinton et al., 1995b), such as the variational\u00a0autoencoder (Sec. 20.10.3) and the generative stochastic networks (Sec. 20.12).\u00a0These models naturally learn high-capacity, overcomplete encodings of the input\u00a0and do not require regularization for these encodings to be useful. Their encodings\u00a0are naturally useful because the models were trained to approximately maximize\u00a0the probability of the training data rather than to copy the input to the output.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4711",
    "text": "A sparse autoencoder is simply an autoencoder whose training criterion involves a sparsity penalty Q(h) on the code layer h, in addition to the reconstruction error:",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4712",
    "text": "L(x,g(f (x))) + ft(h) \u00a0\u00a0\u00a0(14.2)",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4713",
    "text": "where g (h) is the decoder output and typically we have h = f (x), the encoder output.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4714",
    "text": "Sparse autoencoders are typically used to learn features for another task such as classification. An autoencoder that has been regularized to be sparse must\u00a0respond to unique statistical features of the dataset it has been trained on, rather\u00a0than simply acting as an identity function. In this way, training to perform the\u00a0copying task with a sparsity penalty can yield a model that has learned useful\u00a0features as a byproduct.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4715",
    "text": "We can think of the penalty Q(h) simply as a regularizer term added to a feedforward network whose primary task is to copy the input to the output\u00a0(unsupervised learning objective) and possibly also perform some supervised task\u00a0(with a supervised learning objective) that depends on these sparse features.\u00a0Unlike other regularizers such as weight decay, there is not a straightforward\u00a0Bayesian interpretation to this regularizer. As described in Sec. 5.6.1, training\u00a0with weight decay and other regularization penalties can be interpreted as a\u00a0MAP approximation to Bayesian inference, with the added regularizing penalty\u00a0corresponding to a prior probability distribution over the model parameters. In\u00a0this view, regularized maximum likelihood corresponds to maximizing p (6 | x),\u00a0which is equivalent to maximizing logp(x | 6) + logp(6). The logp (x | 6) term\u00a0is the usual data log-likelihood term and the logp(6) term, the log-prior over\u00a0parameters, incorporates the preference over particular values of 6. This view\u00a0was described in Sec. 5.6. Regularized autoencoders defy such an interpretation\u00a0because the regularizer depends on the data and is therefore by definition not a\u00a0prior in the formal sense of the word. We can still think of these regularization\u00a0terms as implicitly expressing a preference over functions.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4716",
    "text": "Rather than thinking of the sparsity penalty as a regularizer for the copying task, we can think of the entire sparse autoencoder framework as approximating\u00a0maximum likelihood training of a generative model that has latent variables.\u00a0Suppose we have a model with visible variables x and latent variables h, with\u00a0an explicit joint distribution pmode1 (x, h) = pmodel(h)pmode1(x | h). We refer to\u00a0pmodei(h) as the model\u2019s prior distribution over the latent variables, representing\u00a0the model\u2019s beliefs prior to seeing x. This is different from the way we have\u00a0previously used the word \u201cprior,\u201d to refer to the distribution p(6) encoding our\u00a0beliefs about the model\u2019s parameters before we have seen the training data. The\u00a0log-likelihood can be decomposed as",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4717",
    "text": "-14.3",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4718",
    "text": "logPmodel(x) = !0g2J Pmodel (h, x).",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4719",
    "text": "h",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4720",
    "text": "We can think of the autoencoder as approximating this sum with a point estimate for just one highly likely value for h. This is similar to the sparse coding generative\u00a0model (Sec. 13.4), but with h being the output of the parametric encoder rather\u00a0than the result of an optimization that infers the most likely h. From this point of\u00a0view, with this chosen h, we are maximizing",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4721",
    "text": "10gPmodel(h, x) = 10gPmodel(h) + 10gPmodel (x 1 h)\u2022 \u00a0\u00a0\u00a0(14.4)",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4722",
    "text": "The logpmode1 (h) term can be sparsity-inducing. For example, the Laplace prior,",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4723",
    "text": "Pmodel(hi) = Ae A|\u05be\u05f3i 1.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4724",
    "text": "-14.5",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4725",
    "text": "corresponds to an absolute value sparsity penalty. Expressing the log-prior as an absolute value penalty, we obtain",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4726",
    "text": "-14.6",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4727",
    "text": "-14.7",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4728",
    "text": "fi(h) = \u00a0\u00a0\u00a0|hi |",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4729",
    "text": "i",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4730",
    "text": "log Pmodel (h) = ^2 (A|h i | - log ^ = 0(h) + const",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4731",
    "text": "where the constant term depends only on A and not h. We typically treat A as a hyperparameter and discard the constant term since it does not affect the parameter\u00a0learning. Other priors such as the Student-t prior can also induce sparsity. From\u00a0this point of view of sparsity as resulting from the effect of Pmodel(h) on approximate\u00a0maximum likelihood learning, the sparsity penalty is not a regularization term at\u00a0all. It is just a consequence of the model\u2019s distribution over its latent variables.\u00a0This view provides a different motivation for training an autoencoder: it is a way\u00a0of approximately training a generative model. It also provides a different reason for\u00a0why the features learned by the autoencoder are useful: they describe the latent\u00a0variables that explain the input.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4732",
    "text": "Early work on sparse autoencoders (Ranzato et al., 2007a, 2008) explored various forms of sparsity and proposed a connection between the sparsity penalty\u00a0and the log Z term that arises when applying maximum likelihood to an undirected\u00a0probabilistic model p(x) = Zp(x). The idea is that minimizing logZ prevents a\u00a0probabilistic model from having high probability everywhere, and imposing sparsity\u00a0on an autoencoder prevents the autoencoder from having low reconstruction\u00a0error everywhere. In this case, the connection is on the level of an intuitive\u00a0understanding of a general mechanism rather than a mathematical correspondence.\u00a0The interpretation of the sparsity penalty as corresponding to logpmode1 (h) in a\u00a0directed model pmode1 (h)pmode1(x | h) is more mathematically straightforward.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4733",
    "text": "One way to achieve actual zeros in h for sparse (and denoising) autoencoders was introduced in Glorot et al. (2011b). The idea is to use rectified linear units to\u00a0produce the code layer. With a prior that actually pushes the representations to\u00a0zero (like the absolute value penalty), one can thus indirectly control the average\u00a0number of zeros in the representation.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4734",
    "text": "Rather than adding a penalty Q to the cost function, we can obtain an autoencoder that learns something useful by changing the reconstruction error term of the cost\u00a0function.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4735",
    "text": "Traditionally, autoencoders minimize some function",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4736",
    "text": "L(x,g(f (x))) \u00a0\u00a0\u00a0(14.8)",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4737",
    "text": "where L is a loss function penalizing g(f (x)) for being dissimilar from x, such as the L2 norm of their difference. This encourages g o f to learn to be merely an\u00a0identity function if they have the capacity to do so.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4738",
    "text": "A denoising autoencoder or DAE instead minimizes",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4739",
    "text": "L(x,g(f(x))), \u00a0\u00a0\u00a0(14.9)",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4740",
    "text": "where x is a copy of x that has been corrupted by some form of noise. Denoising autoencoders must therefore undo this corruption rather than simply copying their\u00a0input.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4741",
    "text": "Denoising training forces f and g to implicitly learn the structure of pdata (x), as shown by Alain and Bengio (2013) and Bengio et al. (2013c). Denoising\u00a0autoencoders thus provide yet another example of how useful properties can emerge\u00a0as a byproduct of minimizing reconstruction error. They are also an example of\u00a0how overcomplete, high-capacity models may be used as autoencoders so long\u00a0as care is taken to prevent them from learning the identity function. Denoising\u00a0autoencoders are presented in more detail in Sec. 14.5.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4742",
    "text": "Another strategy for regularizing an autoencoder is to use a penalty Q as in sparse autoencoders,",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4743",
    "text": "L(x,g(f (x))) + Q(h, x), \u00a0\u00a0\u00a0(14.10)",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4744",
    "text": "but with a different form of Q:",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4745",
    "text": "-14.11",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4746",
    "text": "Q(h,x) = A^ ||V*hi||2.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4747",
    "text": "This forces the model to learn a function that does not change much when x changes slightly. Because this penalty is applied only at training examples, it forces\u00a0the autoencoder to learn features that capture information about the training\u00a0distribution.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4748",
    "text": "An autoencoder regularized in this way is called a contractive autoencoder or CAE. This approach has theoretical connections to denoising autoencoders,\u00a0manifold learning and probabilistic modeling. The CAE is described in more detail\u00a0in Sec. 14.7.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4749",
    "text": "Autoencoders are often trained with only a single layer encoder and a single layer decoder. However, this is not a requirement. In fact, using deep encoders and\u00a0decoders offers many advantages.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4750",
    "text": "Recall from Sec. 6.4.1 that there are many advantages to depth in a feedforward network. Because autoencoders are feedforward networks, these advantages also\u00a0apply to autoencoders. Moreover, the encoder is itself a feedforward network as\u00a0is the decoder, so each of these components of the autoencoder can individually\u00a0benefit from depth.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4751",
    "text": "One major advantage of non-trivial depth is that the universal approximator theorem guarantees that a feedforward neural network with at least one hidden\u00a0layer can represent an approximation of any function (within a broad class) to an\u00a0arbitrary degree of accuracy, provided that it has enough hidden units. This means\u00a0that an autoencoder with a single hidden layer is able to represent the identity\u00a0function along the domain of the data arbitrarily well. However, the mapping from\u00a0input to code is shallow. This means that we are not able to enforce arbitrary\u00a0constraints, such as that the code should be sparse. A deep autoencoder, with at\u00a0least one additional hidden layer inside the encoder itself, can approximate any\u00a0mapping from input to code arbitrarily well, given enough hidden units.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4752",
    "text": "Depth can exponentially reduce the computational cost of representing some functions. Depth can also exponentially decrease the amount of training data\u00a0needed to learn some functions. See Sec. 6.4.1 for a review of the advantages of\u00a0depth in feedforward networks.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4753",
    "text": "Experimentally, deep autoencoders yield much better compression than corresponding shallow or linear autoencoders (Hinton and Salakhutdinov, 2006).",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4754",
    "text": "A common strategy for training a deep autoencoder is to greedily pretrain the deep architecture by training a stack of shallow autoencoders, so we often\u00a0encounter shallow autoencoders, even when the ultimate goal is to train a deep\u00a0autoencoder.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4755",
    "text": "Autoencoders are just feedforward networks. The same loss functions and output unit types that can be used for traditional feedforward networks are also used for\u00a0autoencoders.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4756",
    "text": "As described in Sec. 6.2.2.4, a general strategy for designing the output units and the loss function of a feedforward network is to define an output distribution\u00a0p(y | x) and minimize the negative log-likelihood \u2014 logp(y | x). In that setting, y\u00a0was a vector of targets, such as class labels.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4757",
    "text": "In the case of an autoencoder, x is now the target as well as the input. However, we can still apply the same machinery as before. Given a hidden code h, we may\u00a0think of the decoder as providing a conditional distribution p decoder(x | h). We\u00a0may then train the autoencoder by minimizing \u2014 log pdecoder(x | h). The exact\u00a0form of this loss function will change depending on the form of Pdecoder. As with\u00a0traditional feedforward networks, we usually use linear output units to parametrize\u00a0the mean of a Gaussian distribution if x is real-valued. In that case, the negative\u00a0log-likelihood yields a mean squared error criterion. Similarly, binary x values\u00a0correspond to a Bernoulli distribution whose parameters are given by a sigmoid\u00a0output unit, discrete x values correspond to a softmax distribution, and so on.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4758",
    "text": "Typically, the output variables are treated as being conditionally independent given h so that this probability distribution is inexpensive to evaluate, but some\u00a0techniques such as mixture density outputs allow tractable modeling of outputs\u00a0with correlations.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4759",
    "text": "Figure 14.2: The structure of a stochastic autoencoder, in which both the encoder and the decoder are not simple functions but instead involve some noise injection, meaning that\u00a0their output can be seen as sampled from a distribution, pencoder (h | x) for the encoder\u00a0and pdecoder (x | h) for the decoder.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4760",
    "text": "To make a more radical departure from the feedforward networks we have seen previously, we can also generalize the notion of an encoding function f (x) to an\u00a0encoding distribution pencoder(h | x), as illustrated in Fig. 14.2.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4761",
    "text": "Any latent variable model pmode1 (h, x) defines a stochastic encoder",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4762",
    "text": "Pencoder(h 1 x) \u00a0\u00a0\u00a0Pmodel(h 1 x)\u00a0\u00a0\u00a0\u00a0(14.12)",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4763",
    "text": "and a stochastic decoder",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4764",
    "text": "pdecoder(x 1 h) \u00a0\u00a0\u00a0pmode1(x 1 h) \u2022\u00a0\u00a0\u00a0\u00a0(14.13)",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4765",
    "text": "In general, the encoder and decoder distributions are not necessarily conditional distributions compatible with a unique joint distribution pmode1(x, h). Alain et al.\u00a0(2015) showed that training the encoder and decoder as a denoising autoencoder\u00a0will tend to make them compatible asymptotically (with enough capacity and\u00a0examples).",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4766",
    "text": "The denoising autoencoder (DAE) is an autoencoder that receives a corrupted data point as input and is trained to predict the original, uncorrupted data point as its\u00a0output.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4767",
    "text": "The DAE training procedure is illustrated in Fig. 14.3. We introduce a corruption process C(X | x) which represents a conditional distribution over",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4768",
    "text": "Figure 14.3: The computational graph of the cost function for a denoising autoencoder, which is trained to reconstruct the clean data point x from its corrupted version x.\u00a0This is accomplished by minimizing the loss L = \u2014 logpdecoder (x | h = f (X)), where\u00a0X is a corrupted version of the data example x, obtained through a given corruption\u00a0process C(x | x). Typically the distribution Pdecoder is a factorial distribution whose mean\u00a0parameters are emitted by a feedforward network g.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4769",
    "text": "corrupted samples x, given a data sample x. The autoencoder then learns a reconstruction distribution preconstruct (x | x) estimated from training pairs (x, x),\u00a0as follows:",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4770",
    "text": "1. \u00a0\u00a0\u00a0Sample a training example x from the training data.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4771",
    "text": "2. \u00a0\u00a0\u00a0Sample a corrupted version x from C(x | x = x).",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4772",
    "text": "3. \u00a0\u00a0\u00a0Use (x, x) as a training example for estimating the autoencoder reconstruction\u00a0distribution preconstruct(x | x) = Pdecoder (x | h) with h the output of encoder\u00a0f (x) and Pdecoder typically defined by a decoder g(h).",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4773",
    "text": "Typically we can simply perform gradient-based approximate minimization (such as minibatch gradient descent) on the negative log-likelihood \u2014 logpdecoder(x | h).\u00a0So long as the encoder is deterministic, the denoising autoencoder is a feedforward\u00a0network and may be trained with exactly the same techniques as any other\u00a0feedforward network.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4774",
    "text": "We can therefore view the DAE as performing stochastic gradient descent on the following expectation:",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4775",
    "text": "Ex~p)data ^)\u00aex^C(x|x) 1ogpdecoder (x 1 h \u00a0\u00a0\u00a0f (x))\u00a0\u00a0\u00a0\u00a0(14T4)",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4776",
    "text": "where pdata (x) is the training distribution.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4777",
    "text": "Figure 14.4: A denoising autoencoder is trained to map a corrupted data point x back to the original data point x. We illustrate training examples x as red crosses lying near a\u00a0low-dimensional manifold illustrated with the bold black line. We illustrate the corruption\u00a0process C (X | x) with a gray circle of equiprobable corruptions. A gray arrow demonstrates\u00a0how one training example is transformed into one sample from this corruption process.\u00a0When the denoising autoencoder is trained to minimize the average of squared errors\u00a0\\\\g(f (x)) -x||2, the reconstructiong(f (x)) estimates Exx-pdata (x)C(X|x)[x I x]. The vector\u00a0g(f(x)) \u2014 x points approximately towards the nearest point on the manifold, sinceg(f(x))\u00a0estimates the center of mass of the clean points x which could have given rise to x. The\u00a0autoencoder thus learns a vector field g(f (x)) \u2014 x indicated by the green arrows. This\u00a0vector field estimates the score V xlog pdata (x) up to a multiplicative factor that is the\u00a0average root mean square reconstruction error.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4778",
    "text": "Score matching (Hyvarinen, 2005) is an alternative to maximum likelihood. It provides a consistent estimator of probability distributions based on encouraging\u00a0the model to have the same score as the data distribution at every training point\u00a0x. In this context, the score is a particular gradient field:",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4779",
    "text": "Vx log p(x). \u00a0\u00a0\u00a0(14.15)",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4780",
    "text": "Score matching is discussed further in Sec. 18.4. For the present discussion regarding autoencoders, it is sufficient to understand that learning the gradient\u00a0field of log Pdata is one way to learn the structure of pdata itself.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4781",
    "text": "A very important property of DAEs is that their training criterion (with conditionally Gaussian p( x | h)) makes the autoencoder learn a vector field\u00a0(g(f(x)) \u2014 x) that estimates the score of the data distribution. This is illustrated\u00a0in Fig. 14.4.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4782",
    "text": "Denoising training of a specific kind of autoencoder (sigmoidal hidden units, linear reconstruction units) using Gaussian noise and mean squared error as the\u00a0reconstruction cost is equivalent (Vincent, 2011) to training a specific kind of\u00a0undirected probabilistic model called an RBM with Gaussian visible units. This\u00a0kind of model will be described in detail in Sec. 20.5.1; for the present discussion\u00a0it suffices to know that it is a model that provides an explicit pmode1 (x; 6). When\u00a0the RBM is trained using denoising score matching (Kingma and LeCun, 2010),\u00a0its learning algorithm is equivalent to denoising training in the corresponding\u00a0autoencoder. With a fixed noise level, regularized score matching is not a consistent\u00a0estimator; it instead recovers a blurred version of the distribution. However, if\u00a0the noise level is chosen to approach 0 when the number of examples approaches\u00a0infinity, then consistency is recovered. Denoising score matching is discussed in\u00a0more detail in Sec. 18.5.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4783",
    "text": "Other connections between autoencoders and RBMs exist. Score matching applied to RBMs yields a cost function that is identical to reconstruction error\u00a0combined with a regularization term similar to the contractive penalty of the\u00a0CAE (Swersky et al., 2011). Bengio and Delalleau (2009) showed that an autoencoder gradient provides an approximation to contrastive divergence training of\u00a0RBMs.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4784",
    "text": "For continuous-valued x, the denoising criterion with Gaussian corruption and reconstruction distribution yields an estimator of the score that is applicable to\u00a0general encoder and decoder parametrizations (Alain and Bengio, 2013). This\u00a0means a generic encoder-decoder architecture may be made to estimate the score",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4785",
    "text": "by training with the squared error criterion",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4786",
    "text": "\\\\g(f (x)) - x\\\\2 \u00a0\u00a0\u00a0(14\u202216)",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4787",
    "text": "and corruption",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4788",
    "text": "C(x = x\\x) = N(x; ^ = x, E = a21) \u00a0\u00a0\u00a0(14.17)",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4789",
    "text": "with noise variance a2. See Fig. 14.5 for an illustration of how this works.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4790",
    "text": "Figure 14.5: Vector field learned by a denoising autoencoder around a 1-D curved manifold near which the data concentrates in a 2-D space. Each arrow is proportional to the\u00a0reconstruction minus input vector of the autoencoder and points towards higher probability\u00a0according to the implicitly estimated probability distribution. The vector field has zeros\u00a0at both maxima of the estimated density function (on the data manifolds) and at minima\u00a0of that density function. For example, the spiral arm forms a one-dimensional manifold of\u00a0local maxima that are connected to each other. Local minima appear near the middle of\u00a0the gap between two arms. When the norm of reconstruction error (shown by the length\u00a0of the arrows) is large, it means that probability can be significantly increased by moving\u00a0in the direction of the arrow, and that is mostly the case in places of low probability.\u00a0The autoencoder maps these low probability points to higher probability reconstructions.\u00a0Where probability is maximal, the arrows shrink because the reconstruction becomes more\u00a0accurate.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4791",
    "text": "In general, there is no guarantee that the reconstruction g(f (x)) minus the input x corresponds to the gradient of any function, let alone to the score. That is",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4792",
    "text": "why the early results (Vincent, 2011) are specialized to particular parametrizations where g (f (x)) \u2014 x may be obtained by taking the derivative of another function.\u00a0Kamyshanska and Memisevic (2015) generalized the results of Vincent (2011) by\u00a0identifying a family of shallow autoencoders such that g(f (x)) \u2014 x corresponds to\u00a0a score for all members of the family.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4793",
    "text": "So far we have described only how the denoising autoencoder learns to represent a probability distribution. More generally, one may want to use the autoencoder as\u00a0a generative model and draw samples from this distribution. This will be described\u00a0later, in Sec. 20.11.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4794",
    "text": "14.5.1.1 Historical Perspective",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4795",
    "text": "The idea of using MLPs for denoising dates back to the work of LeCun (1987) and Gallinari et al. (1987). Behnke (2001) also used recurrent networks to denoise\u00a0images. Denoising autoencoders are, in some sense, just MLPs trained to denoise.\u00a0However, the name \u201cdenoising autoencoder\u201d refers to a model that is intended not\u00a0merely to learn to denoise its input but to learn a good internal representation\u00a0as a side effect of learning to denoise. This idea came much later (Vincent\u00a0et al., 2008, 2010). The learned representation may then be used to pretrain a\u00a0deeper unsupervised network or a supervised network. Like sparse autoencoders,\u00a0sparse coding, contractive autoencoders and other regularized autoencoders, the\u00a0motivation for DAEs was to allow the learning of a very high-capacity encoder\u00a0while preventing the encoder and decoder from learning a useless identity function.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4796",
    "text": "Prior to the introduction of the modern DAE, Inayoshi and Kurita (2005) explored some of the same goals with some of the same methods. Their approach\u00a0minimizes reconstruction error in addition to a supervised objective while injecting\u00a0noise in the hidden layer of a supervised MLP, with the objective to improve\u00a0generalization by introducing the reconstruction error and the injected noise.\u00a0However, their method was based on a linear encoder and could not learn function\u00a0families as powerful as can the modern DAE.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4797",
    "text": "Like many other machine learning algorithms, autoencoders exploit the idea that data concentrates around a low-dimensional manifold or a small set of such\u00a0manifolds, as described in Sec. 5.11.3. Some machine learning algorithms exploit\u00a0this idea only insofar as that they learn a function that behaves correctly on the\u00a0manifold but may have unusual behavior if given an input that is off the manifold.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4798",
    "text": "Autoencoders take this idea further and aim to learn the structure of the manifold.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4799",
    "text": "To understand how autoencoders do this, we must present some important characteristics of manifolds.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4800",
    "text": "An important characterization of a manifold is the set of its tangent planes. At a point x on a d-dimensional manifold, the tangent plane is given by d basis vectors\u00a0that span the local directions of variation allowed on the manifold. As illustrated\u00a0in Fig. 14.6, these local directions specify how one can change x infinitesimally\u00a0while staying on the manifold.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4801",
    "text": "All autoencoder training procedures involve a compromise between two forces:",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4802",
    "text": "1. \u00a0\u00a0\u00a0Learning a representation h of a training example x such that x can be\u00a0approximately recovered from h through a decoder. The fact that x is drawn\u00a0from the training data is crucial, because it means the autoencoder need\u00a0not successfully reconstruct inputs that are not probable under the data\u00a0generating distribution.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4803",
    "text": "2. \u00a0\u00a0\u00a0Satisfying the constraint or regularization penalty. This can be an architectural constraint that limits the capacity of the autoencoder, or it can be\u00a0a regularization term added to the reconstruction cost. These techniques\u00a0generally prefer solutions that are less sensitive to the input.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4804",
    "text": "Clearly, neither force alone would be useful\u2014copying the input to the output is not useful on its own, nor is ignoring the input. Instead, the two forces together\u00a0are useful because they force the hidden representation to capture information\u00a0about the structure of the data generating distribution. The important principle\u00a0is that the autoencoder can afford to represent only the variations that are needed\u00a0to reconstruct training examples. If the data generating distribution concentrates\u00a0near a low-dimensional manifold, this yields representations that implicitly capture\u00a0a local coordinate system for this manifold: only the variations tangent to the\u00a0manifold around x need to correspond to changes in h = f (x). Hence the encoder\u00a0learns a mapping from the input space x to a representation space, a mapping that\u00a0is only sensitive to changes along the manifold directions, but that is insensitive to\u00a0changes orthogonal to the manifold.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4805",
    "text": "A one-dimensional example is illustrated in Fig. 14.7, showing that by making the reconstruction function insensitive to perturbations of the input around the\u00a0data points we recover the manifold structure.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4806",
    "text": "To understand why autoencoders are useful for manifold learning, it is instructive to compare them to other approaches. What is most commonly learned to characterize a manifold is a representation of the data points on (or near) the",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4807",
    "text": "Figure 14.6: An illustration of the concept of a tangent hyperplane. Here we create a one-dimensional manifold in 784-dimensional space. We take an MNIST image with 784\u00a0pixels and transform it by translating it vertically. The amount of vertical translation\u00a0defines a coordinate along a one-dimensional manifold that traces out a curved path\u00a0through image space. This plot shows a few points along this manifold. For visualization,\u00a0we have projected the manifold into two dimensional space using PCA. An n-dimensional\u00a0manifold has an n-dimensional tangent plane at every point. This tangent plane touches\u00a0the manifold exactly at that point and is oriented parallel to the surface at that point.\u00a0It defines the space of directions in which it is possible to move while remaining on\u00a0the manifold. This one-dimensional manifold has a single tangent line. We indicate an\u00a0example tangent line at one point, with an image showing how this tangent direction\u00a0appears in image space. Gray pixels indicate pixels that do not change as we move along\u00a0the tangent line, white pixels indicate pixels that brighten, and black pixels indicate pixels\u00a0that darken.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4808",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4809",
    "text": "0.8",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4810",
    "text": "0.6",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4811",
    "text": "0.4",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4812",
    "text": "0.2",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4813",
    "text": "0",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4814",
    "text": "Identity",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4815",
    "text": "Optimal reconstruction",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4816",
    "text": "xo",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4817",
    "text": "X 1",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4818",
    "text": "X",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4819",
    "text": "X2",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4820",
    "text": "Figure 14.7: If the autoencoder learns a reconstruction function that is invariant to small perturbations near the data points, it captures the manifold structure of the data. Here\u00a0the manifold structure is a collection of 0-dimensional manifolds. The dashed diagonal\u00a0line indicates the identity function target for reconstruction. The optimal reconstruction\u00a0function crosses the identity function wherever there is a data point. The horizontal\u00a0arrows at the bottom of the plot indicate the r (x) \u2014 x reconstruction direction vector\u00a0at the base of the arrow, in input space, always pointing towards the nearest \u201cmanifold\u201d\u00a0(a single datapoint, in the 1-D case). The denoising autoencoder explicitly tries to make\u00a0the derivative of the reconstruction function r(x) small around the data points. The\u00a0contractive autoencoder does the same for the encoder. Although the derivative ofr(x) is\u00a0asked to be small around the data points, it can be large between the data points. The\u00a0space between the data points corresponds to the region between the manifolds, where\u00a0the reconstruction function must have a large derivative in order to map corrupted points\u00a0back onto the manifold.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4821",
    "text": "manifold. Such a representation for a particular example is also called its embedding. It is typically given by a low-dimensional vector, with less dimensions than the \u201cambient\u201d space of which the manifold is a low-dimensional subset. Some\u00a0algorithms (non-parametric manifold learning algorithms, discussed below) directly\u00a0learn an embedding for each training example, while others learn a more general\u00a0mapping, sometimes called an encoder, or representation function, that maps any\u00a0point in the ambient space (the input space) to its embedding.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4822",
    "text": "Manifold learning has mostly focused on unsupervised learning procedures that attempt to capture these manifolds. Most of the initial machine learning research\u00a0on learning nonlinear manifolds has focused on non-parametric methods based on\u00a0the nearest-neighbor graph. This graph has one node per training example and\u00a0edges connecting near neighbors to each other. These methods (SchOlkopf et al.,\u00a01998; Roweis and Saul, 2000; Tenenbaum et al., 2000; Brand, 2003; Belkin and",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4823",
    "text": "Figure 14.8: Non-parametric manifold learning procedures build a nearest neighbor graph whose nodes are training examples and arcs connect nearest neighbors. Various procedures\u00a0can thus obtain the tangent plane associated with a neighborhood of the graph as well\u00a0as a coordinate system that associates each training example with a real-valued vector\u00a0position, or embedding. It is possible to generalize such a representation to new examples\u00a0by a form of interpolation. So long as the number of examples is large enough to cover\u00a0the curvature and twists of the manifold, these approaches work well. Images from the\u00a0QMUL Multiview Face Dataset (Gong et al., 2000).",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4824",
    "text": "Niyogi, 2003; Donoho and Grimes, 2003; Weinberger and Saul, 2004; Hinton and Roweis, 2003; van der Maaten and Hinton, 2008) associate each of nodes with a\u00a0tangent plane that spans the directions of variations associated with the difference\u00a0vectors between the example and its neighbors, as illustrated in Fig. 14.8.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4825",
    "text": "A global coordinate system can then be obtained through an optimization or solving a linear system. Fig. 14.9 illustrates how a manifold can be tiled by a\u00a0large number of locally linear Gaussian-like patches (or \u201cpancakes,\u201d because the\u00a0Gaussians are flat in the tangent directions).",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4826",
    "text": "However, there is a fundamental difficulty with such local non-parametric approaches to manifold learning, raised in Bengio and Monperrus (2005): if the\u00a0manifolds are not very smooth (they have many peaks and troughs and twists),\u00a0one may need a very large number of training examples to cover each one of these\u00a0variations, with no chance to generalize to unseen variations. Indeed, these methods",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4827",
    "text": "Figure 14.9: If the tangent planes (see Fig. 14.6) at each location are known, then they can be tiled to form a global coordinate system or a density function. Each local patch\u00a0can be thought of as a local Euclidean coordinate system or as a locally flat Gaussian, or\u00a0\u201cpancake\u2019\u2019, with a very small variance in the directions orthogonal to the pancake and a\u00a0very large variance in the directions defining the coordinate system on the pancake. A\u00a0mixture of these Gaussians provides an estimated density function, as in the manifold\u00a0Parzen window algorithm (Vincent and Bengio, 2003) or its non-local neural-net based\u00a0variant (Bengio et al., 2006c).",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4828",
    "text": "can only generalize the shape of the manifold by interpolating between neighboring examples. Unfortunately, the manifolds involved in AI problems can have very\u00a0complicated structure that can be difficult to capture from only local interpolation.\u00a0Consider for example the manifold resulting from translation shown in Fig. 14.6. If\u00a0we watch just one coordinate within the input vector, xi, as the image is translated,\u00a0we will observe that one coordinate encounters a peak or a trough in its value\u00a0once for every peak or trough in brightness in the image. In other words, the\u00a0complexity of the patterns of brightness in an underlying image template drives\u00a0the complexity of the manifolds that are generated by performing simple image\u00a0transformations. This motivates the use of distributed representations and deep\u00a0learning for capturing manifold structure.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4829",
    "text": "14.7 Contractive Autoencoders",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4830",
    "text": "",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4831",
    "text": "",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4832",
    "text": "The contractive autoencoder (Rifai et al., 2011a,b) introduces an explicit regularizer on the code h = f (x), encouraging the derivatives of f to be as small as possible",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4833",
    "text": "Q(h) = A",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4834",
    "text": "df (x)",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4835",
    "text": "2",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4836",
    "text": "-14.18",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4837",
    "text": "d x",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4838",
    "text": "F",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4839",
    "text": "The penalty Q(h) is the squared Frobenius norm (sum of squared elements) of the Jacobian matrix of partial derivatives associated with the encoder function.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4840",
    "text": "There is a connection between the denoising autoencoder and the contractive autoencoder: Alain and Bengio (2013) showed that in the limit of small Gaussian\u00a0input noise, the denoising reconstruction error is equivalent to a contractive\u00a0penalty on the reconstruction function that maps x to r = g(f(x)). In other\u00a0words, denoising autoencoders make the reconstruction function resist small but\u00a0finite-sized perturbations of the input, while contractive autoencoders make the\u00a0feature extraction function resist infinitesimal perturbations of the input. When\u00a0using the Jacobian-based contractive penalty to pretrain features f (x) for use\u00a0with a classifier, the best classification accuracy usually results from applying the\u00a0contractive penalty to f (x) rather than to g(f (x)). A contractive penalty on f (x)\u00a0also has close connections to score matching, as discussed in Sec. 14.5.1.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4841",
    "text": "The name contractive arises from the way that the CAE warps space. Specifically, because the CAE is trained to resist perturbations of its input, it is encouraged to map a neighborhood of input points to a smaller neighborhood of output points.\u00a0We can think of this as contracting the input neighborhood to a smaller output\u00a0neighborhood.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4842",
    "text": "To clarify, the CAE is contractive only locally\u2014all perturbations of a training point x are mapped near to f (x). Globally, two different points x and x' may be\u00a0mapped to f (x) and f(x') points that are farther apart than the original points.\u00a0It is plausible that f be expanding in-between or far from the data manifolds (see\u00a0for example what happens in the 1-D toy example of Fig. 14.7). When the Q(h)\u00a0penalty is applied to sigmoidal units, one easy way to shrink the Jacobian is to\u00a0make the sigmoid units saturate to 0 or 1. This encourages the CAE to encode\u00a0input points with extreme values of the sigmoid that may be interpreted as a\u00a0binary code. It also ensures that the CAE will spread its code values throughout\u00a0most of the hypercube that its sigmoidal hidden units can span.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4843",
    "text": "We can think of the Jacobian matrix J at a point x as approximating the nonlinear encoder f (x) as being a linear operator. This allows us to use the word\u00a0\u201ccontractive\u201d more formally. In the theory of linear operators, a linear operator\u00a0is said to be contractive if the norm of Jx remains less than or equal to 1 for\u00a0all unit-norm x. In other words, J is contractive if it shrinks the unit sphere.\u00a0We can think of the CAE as penalizing the Frobenius norm of the local linear\u00a0approximation of f (x) at every training point x in order to encourage each of\u00a0these local linear operator to become a contraction.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4844",
    "text": "As described in Sec. 14.6, regularized autoencoders learn manifolds by balancing two opposing forces. In the case of the CAE, these two forces are reconstruction\u00a0error and the contractive penalty Q(h). Reconstruction error alone would encourage\u00a0the CAE to learn an identity function. The contractive penalty alone would\u00a0encourage the CAE to learn features that are constant with respect to x. The\u00a0compromise between these two forces yields an autoencoder whose derivatives\u00a0are mostly tiny. Only a small number of hidden units, corresponding to a\u00a0small number of directions in the input, may have significant derivatives.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4845",
    "text": "The goal of the CAE is to learn the manifold structure of the data. Directions x with large Jx rapidly change h, so these are likely to be directions which\u00a0approximate the tangent planes of the manifold. Experiments by Rifai et al. (2011a)\u00a0and Rifai et al. (2011b) show that training the CAE results in most singular values\u00a0of J dropping below 1 in magnitude and therefore becoming contractive. However,\u00a0some singular values remain above 1, because the reconstruction error penalty\u00a0encourages the CAE to encode the directions with the most local variance. The\u00a0directions corresponding to the largest singular values are interpreted as the tangent\u00a0directions that the contractive autoencoder has learned. Ideally, these tangent\u00a0directions should correspond to real variations in the data. For example, a CAE\u00a0applied to images should learn tangent vectors that show how the image changes as\u00a0objects in the image gradually change pose, as shown in Fig. 14.6. Visualizations of\u00a0the experimentally obtained singular vectors do seem to correspond to meaningful\u00a0transformations of the input image, as shown in Fig. 14.10.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4846",
    "text": "One practical issue with the CAE regularization criterion is that although it is cheap to compute in the case of a single hidden layer autoencoder, it becomes\u00a0much more expensive in the case of deeper autoencoders. The strategy followed by\u00a0Rifai et al. (2011a) is to separately train a series of single-layer autoencoders, each\u00a0trained to reconstruct the previous autoencoder\u2019s hidden layer. The composition\u00a0of these autoencoders then forms a deep autoencoder. Because each layer was\u00a0separately trained to be locally contractive, the deep autoencoder is contractive\u00a0as well. The result is not the same as what would be obtained by jointly training\u00a0the entire architecture with a penalty on the Jacobian of the deep model, but it\u00a0captures many of the desirable qualitative characteristics.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4847",
    "text": "Another practical issue is that the contraction penalty can obtain useless results",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4848",
    "text": "Tangent vectors",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4849",
    "text": "Input",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4850",
    "text": "point",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4851",
    "text": "Local PCA (no sharing across regions)",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4852",
    "text": "BS",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4853",
    "text": "Contractive autoencoder",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4854",
    "text": "Figure 14.10: Illustration of tangent vectors of the manifold estimated by local PCA and by a contractive autoencoder. The location on the manifold is defined by the input\u00a0image of a dog drawn from the CIFAR-10 dataset. The tangent vectors are estimated\u00a0by the leading singular vectors of the Jacobian matrix of the input-to-code mapping.\u00a0Although both local PCA and the CAE can capture local tangents, the CAE is able to\u00a0form more accurate estimates from limited training data because it exploits parameter\u00a0sharing across different locations that share a subset of active hidden units. The CAE\u00a0tangent directions typically correspond to moving or changing parts of the object (such as\u00a0the head or legs).",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4855",
    "text": "if we do not impose some sort of scale on the decoder. For example, the encoder could consist of multiplying the input by a small constant e and the decoder\u00a0could consist of dividing the code by e. As e approaches 0, the encoder drives the\u00a0contractive penalty Q(h) to approach 0 without having learned anything about the\u00a0distribution. Meanwhile, the decoder maintains perfect reconstruction. In Rifai\u00a0et al. (2011a), this is prevented by tying the weights of f and g. Both f and g are\u00a0standard neural network layers consisting of an affine transformation followed by\u00a0an element-wise nonlinearity, so it is straightforward to set the weight matrix of g\u00a0to be the transpose of the weight matrix of f.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4856",
    "text": "Predictive sparse decomposition (PSD) is a model that is a hybrid of sparse coding and parametric autoencoders (Kavukcuoglu et al., 2008). A parametric\u00a0encoder is trained to predict the output of iterative inference. PSD has been\u00a0applied to unsupervised feature learning for object recognition in images and video\u00a0(Kavukcuoglu et al., 2009, 2010; Jarrett et al., 2009; Farabet et al., 2011), as well\u00a0as for audio (Henaff et al., 2011). The model consists of an encoder f (x) and a\u00a0decoder g(h) that are both parametric. During training, h is controlled by the\u00a0optimization algorithm. Training proceeds by minimizing",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4857",
    "text": "||x - g(h)||2 + A|h|1 + Y||h - f (x)||2. \u00a0\u00a0\u00a0(14.19)",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4858",
    "text": "Like in sparse coding, the training algorithm alternates between minimization with respect to h and minimization with respect to the model parameters. Minimization\u00a0with respect to h is fast because f (x) provides a good initial value of h and the\u00a0cost function constrains h to remain near f (x) anyway. Simple gradient descent\u00a0can obtain reasonable values of h in as few as ten steps.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4859",
    "text": "The training procedure used by PSD is different from first training a sparse coding model and then training f (x) to predict the values of the sparse coding\u00a0features. The PSD training procedure regularizes the decoder to use parameters\u00a0for which f (x) can infer good code values.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4860",
    "text": "Predictive sparse coding is an example of learned approximate inference. In Sec. 19.5, this topic is developed further. The tools presented in Chapter 19 make it\u00a0clear that PSD can be interpreted as training a directed sparse coding probabilistic\u00a0model by maximizing a lower bound on the log-likelihood of the model.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4861",
    "text": "In practical applications of PSD, the iterative optimization is only used during training. The parametric encoder f is used to compute the learned features when\u00a0the model is deployed. Evaluating f is computationally inexpensive compared to\u00a0inferring h via gradient descent. Because f is a differentiable parametric function,\u00a0PSD models may be stacked and used to initialize a deep network to be trained\u00a0with another criterion.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4862",
    "text": "Autoencoders have been successfully applied to dimensionality reduction and information retrieval tasks. Dimensionality reduction was one of the first applications of representation learning and deep learning. It was one of the early motivations\u00a0for studying autoencoders. For example, Hinton and Salakhutdinov (2006) trained\u00a0a stack of RBMs and then used their weights to initialize a deep autoencoder\u00a0with gradually smaller hidden layers, culminating in a bottleneck of 30 units. The\u00a0resulting code yielded less reconstruction error than PCA into 30 dimensions and\u00a0the learned representation was qualitatively easier to interpret and relate to the\u00a0underlying categories, with these categories manifesting as well-separated clusters.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4863",
    "text": "Lower-dimensional representations can improve performance on many tasks, such as classification. Models of smaller spaces consume less memory and runtime.\u00a0Many forms of dimensionality reduction place semantically related examples near\u00a0each other, as observed by Salakhutdinov and Hinton (2007b) and Torralba et al.\u00a0(2008). The hints provided by the mapping to the lower-dimensional space aid\u00a0generalization.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4864",
    "text": "One task that benefits even more than usual from dimensionality reduction is information retrieval, the task of finding entries in a database that resemble a\u00a0query entry. This task derives the usual benefits from dimensionality reduction\u00a0that other tasks do, but also derives the additional benefit that search can become\u00a0extremely efficient in certain kinds of low dimensional spaces. Specifically, if\u00a0we train the dimensionality reduction algorithm to produce a code that is lowdimensional and binary, then we can store all database entries in a hash table\u00a0mapping binary code vectors to entries. This hash table allows us to perform\u00a0information retrieval by returning all database entries that have the same binary\u00a0code as the query. We can also search over slightly less similar entries very\u00a0efficiently, just by flipping individual bits from the encoding of the query. This\u00a0approach to information retrieval via dimensionality reduction and binarization\u00a0is called semantic hashing (Salakhutdinov and Hinton, 2007b, 2009b), and has\u00a0been applied to both textual input (Salakhutdinov and Hinton, 2007b, 2009b) and\u00a0images (Torralba et al., 2008; Weiss et al., 2008; Krizhevsky and Hinton, 2011).",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4865",
    "text": "To produce binary codes for semantic hashing, one typically uses an encoding function with sigmoids on the final layer. The sigmoid units must be trained to be\u00a0saturated to nearly 0 or nearly 1 for all input values. One trick that can accomplish\u00a0this is simply to inject additive noise just before the sigmoid nonlinearity during\u00a0training. The magnitude of the noise should increase over time. To fight that\u00a0noise and preserve as much information as possible, the network must increase the\u00a0magnitude of the inputs to the sigmoid function, until saturation occurs.",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4866",
    "text": "The idea of learning a hashing function has been further explored in several directions, including the idea of training the representations so as to optimize\u00a0a loss more directly linked to the task of finding nearby examples in the hash\u00a0table (Norouzi and Fleet, 2011).",
    "chapter": "",
    "chapter_id": "main-27.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4867",
    "text": "In this chapter, we first discuss what it means to learn representations and how the notion of representation can be useful to design deep architectures. We discuss\u00a0how learning algorithms share statistical strength across different tasks, including\u00a0using information from unsupervised tasks to perform supervised tasks. Shared\u00a0representations are useful to handle multiple modalities or domains, or to transfer\u00a0learned knowledge to tasks for which few or no examples are given but a task\u00a0representation exists. Finally, we step back and argue about the reasons for the\u00a0success of representation learning, starting with the theoretical advantages of\u00a0distributed representations (Hinton et al., 1986) and deep representations and\u00a0ending with the more general idea of underlying assumptions about the data\u00a0generating process, in particular about underlying causes of the observed data.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4868",
    "text": "Many information processing tasks can be very easy or very difficult depending on how the information is represented. This is a general principle applicable to\u00a0daily life, computer science in general, and to machine learning. For example, it\u00a0is straightforward for a person to divide 210 by 6 using long division. The task\u00a0becomes considerably less straightforward if it is instead posed using the Roman\u00a0numeral representation of the numbers. Most modern people asked to divide CCX\u00a0by VI would begin by converting the numbers to the Arabic numeral representation,\u00a0permitting long division procedures that make use of the place value system. More\u00a0concretely, we can quantify the asymptotic runtime of various operations using\u00a0appropriate or inappropriate representations. For example, inserting a number\u00a0into the correct position in a sorted list of numbers is an O(n) operation if the\u00a0list is represented as a linked list, but only O(log n) if the list is represented as a\u00a0red-black tree.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4869",
    "text": "In the context of machine learning, what makes one representation better than another? Generally speaking, a good representation is one that makes a subsequent\u00a0learning task easier. The choice of representation will usually depend on the choice\u00a0of the subsequent learning task.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4870",
    "text": "We can think of feedforward networks trained by supervised learning as performing a kind of representation learning. Specifically, the last layer of the network is typically a linear classifier, such as a softmax regression classifier. The rest of\u00a0the network learns to provide a representation to this classifier. Training with a\u00a0supervised criterion naturally leads to the representation at every hidden layer (but\u00a0more so near the top hidden layer) taking on properties that make the classification\u00a0task easier. For example, classes that were not linearly separable in the input\u00a0features may become linearly separable in the last hidden layer. In principle, the\u00a0last layer could be another kind of model, such as a nearest neighbor classifier\u00a0(Salakhutdinov and Hinton, 2007a). The features in the penultimate layer should\u00a0learn different properties depending on the type of the last layer.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4871",
    "text": "Supervised training of feedforward networks does not involve explicitly imposing any condition on the learned intermediate features. Other kinds of representation\u00a0learning algorithms are often explicitly designed to shape the representation in\u00a0some particular way. For example, suppose we want to learn a representation that\u00a0makes density estimation easier. Distributions with more independences are easier\u00a0to model, so we could design an objective function that encourages the elements\u00a0of the representation vector h to be independent. Just like supervised networks,\u00a0unsupervised deep learning algorithms have a main training objective but also\u00a0learn a representation as a side effect. Regardless of how a representation was\u00a0obtained, it can can be used for another task. Alternatively, multiple tasks (some\u00a0supervised, some unsupervised) can be learned together with some shared internal\u00a0representation.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4872",
    "text": "Most representation learning problems face a tradeoff between preserving as much information about the input as possible and attaining nice properties (such\u00a0as independence).",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4873",
    "text": "Representation learning is particularly interesting because it provides one way to perform unsupervised and semi-supervised learning. We often have very\u00a0large amounts of unlabeled training data and relatively little labeled training\u00a0data. Training with supervised learning techniques on the labeled subset often\u00a0results in severe overfitting. Semi-supervised learning offers the chance to resolve\u00a0this overfitting problem by also learning from the unlabeled data. Specifically,\u00a0we can learn good representations for the unlabeled data, and then use these\u00a0representations to solve the supervised learning task.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4874",
    "text": "Humans and animals are able to learn from very few labeled examples. We do",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4875",
    "text": "not yet know how this is possible. Many factors could explain improved human performance\u2014for example, the brain may use very large ensembles of classifiers\u00a0or Bayesian inference techniques. One popular hypothesis is that the brain is\u00a0able to leverage unsupervised or semi-supervised learning. There are many ways\u00a0to leverage unlabeled data. In this chapter, we focus on the hypothesis that the\u00a0unlabeled data can be used to learn a good representation.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4876",
    "text": "Unsupervised learning played a key historical role in the revival of deep neural networks, allowing for the first time to train a deep supervised network without\u00a0requiring architectural specializations like convolution or recurrence. We call this\u00a0procedure unsupervised pretraining, or more precisely, greedy layer-wise unsupervised pretraining. This procedure is a canonical example of how a representation\u00a0learned for one task (unsupervised learning, trying to capture the shape of the\u00a0input distribution) can sometimes be useful for another task (supervised learning\u00a0with the same input domain).",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4877",
    "text": "Greedy layer-wise unsupervised pretraining relies on a single-layer representation learning algorithm such as an RBM, a single-layer autoencoder, a sparse coding model, or another model that learns latent representations. Each layer is\u00a0pretrained using unsupervised learning, taking the output of the previous layer\u00a0and producing as output a new representation of the data, whose distribution (or\u00a0its relation to other variables such as categories to predict) is hopefully simpler.\u00a0See Algorithm 15.1 for a formal description.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4878",
    "text": "Greedy layer-wise training procedures based on unsupervised criteria have long been used to sidestep the difficulty of jointly training the layers of a deep neural net\u00a0for a supervised task. This approach dates back at least as far as the Neocognitron\u00a0(Fukushima, 1975). The deep learning renaissance of 2006 began with the discovery\u00a0that this greedy learning procedure could be used to find a good initialization for\u00a0a joint learning procedure over all the layers, and that this approach could be used\u00a0to successfully train even fully connected architectures (Hinton et al., 2006; Hinton\u00a0and Salakhutdinov, 2006; Hinton, 2006; Bengio et al., 2007; Ranzato et al., 2007a).\u00a0Prior to this discovery, only convolutional deep networks or networks whose depth\u00a0resulted from recurrence were regarded as feasible to train. Today, we now know\u00a0that greedy layer-wise pretraining is not required to train fully connected deep\u00a0architectures, but the unsupervised pretraining approach was the first method to\u00a0succeed.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4879",
    "text": "Greedy layer-wise pretraining is called greedy because it is a greedy algorithm, meaning that it optimizes each piece of the solution independently, one piece at a\u00a0time, rather than jointly optimizing all pieces. It is called layer-wise because these\u00a0independent pieces are the layers of the network. Specifically, greedy layer-wise\u00a0pretraining proceeds one layer at a time, training the k-th layer while keeping the\u00a0previous ones fixed. In particular, the lower layers (which are trained first) are not\u00a0adapted after the upper layers are introduced. It is called unsupervised because each\u00a0layer is trained with an unsupervised representation learning algorithm. However\u00a0it is also called pretraining, because it is supposed to be only a first step before\u00a0a joint training algorithm is applied to fine-tune all the layers together. In the\u00a0context of a supervised learning task, it can be viewed as a regularizer (in some\u00a0experiments, pretraining decreases test error without decreasing training error)\u00a0and a form of parameter initialization.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4880",
    "text": "It is common to use the word \u201cpretraining\u201d to refer not only to the pretraining stage itself but to the entire two phase protocol that combines the pretraining\u00a0phase and a supervised learning phase. The supervised learning phase may involve\u00a0training a simple classifier on top of the features learned in the pretraining phase,\u00a0or it may involve supervised fine-tuning of the entire network learned in the\u00a0pretraining phase. No matter what kind of unsupervised learning algorithm or\u00a0what model type is employed, in the vast majority of cases, the overall training\u00a0scheme is nearly the same. While the choice of unsupervised learning algorithm\u00a0will obviously impact the details, most applications of unsupervised pretraining\u00a0follow this basic protocol.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4881",
    "text": "Greedy layer-wise unsupervised pretraining can also be used as initialization for other unsupervised learning algorithms, such as deep autoencoders (Hinton\u00a0and Salakhutdinov, 2006) and probabilistic models with many layers of latent\u00a0variables. Such models include deep belief networks (Hinton et al., 2006) and deep\u00a0Boltzmann machines (Salakhutdinov and Hinton, 2009a). These deep generative\u00a0models will be described in Chapter 20.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4882",
    "text": "As discussed in Sec. 8.7.4, it is also possible to have greedy layer-wise supervised pretraining. This builds on the premise that training a shallow network is easier than training a deep one, which seems to have been validated in several\u00a0contexts (Erhan et al., 2010).",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4883",
    "text": "On many tasks, greedy layer-wise unsupervised pretraining can yield substantial improvements in test error for classification tasks. This observation was responsible\u00a0for the renewed interested in deep neural networks starting in 2006 (Hinton et al.,",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4884",
    "text": "Algorithm 15.1 Greedy layer-wise unsupervised pretraining protocol.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4885",
    "text": "Given the following: Unsupervised feature learning algorithm L, which takes a training set of examples and returns an encoder or feature function f. The raw\u00a0input data is X, with one row per example and f (1)(X) is the output of the first\u00a0stage encoder on X and the dataset used by the second level unsupervised feature\u00a0learner. In the case where fine-tuning is performed, we use a learner T which takes\u00a0an initial function f, input examples X (and in the supervised fine-tuning case,\u00a0associated targets Y), and returns a tuned function. The number of stages is m.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4886",
    "text": "f ^ Identity function",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4887",
    "text": "X = X",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4888",
    "text": "for k = 1,..., m do",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4889",
    "text": "f(k) = L(X)",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4890",
    "text": "f ^ f(k) \u25e6 f X ^ f (k)(X)",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4891",
    "text": "end for",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4892",
    "text": "if fine-tuning then f\u00a0\u00a0\u00a0\u00a0(f, X, Y)",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4893",
    "text": "end if",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4894",
    "text": "Return f",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4895",
    "text": "2006; Bengio et al., 2007; Ranzato et al., 2007a). On many other tasks, however, unsupervised pretraining either does not confer a benefit or even causes noticeable\u00a0harm. Ma et al. (2015) studied the effect of pretraining on machine learning\u00a0models for chemical activity prediction and found that, on average, pretraining was\u00a0slightly harmful, but for many tasks was significantly helpful. Because unsupervised\u00a0pretraining is sometimes helpful but often harmful it is important to understand\u00a0when and why it works in order to determine whether it is applicable to a particular\u00a0task.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4896",
    "text": "At the outset, it is important to clarify that most of this discussion is restricted to greedy unsupervised pretraining in particular. There are other, completely\u00a0different paradigms for performing semi-supervised learning with neural networks,\u00a0such as virtual adversarial training described in Sec. 7.13. It is also possible to\u00a0train an autoencoder or generative model at the same time as the supervised model.\u00a0Examples of this single-stage approach include the discriminative RBM (Larochelle\u00a0and Bengio, 2008) and the ladder network (Rasmus et al., 2015), in which the total\u00a0objective is an explicit sum of the two terms (one using the labels and one only\u00a0using the input).",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4897",
    "text": "Unsupervised pretraining combines two different ideas. First, it makes use of the idea that the choice of initial parameters for a deep neural network can have\u00a0a significant regularizing effect on the model (and, to a lesser extent, that it can\u00a0improve optimization). Second, it makes use of the more general idea that learning\u00a0about the input distribution can help to learn about the mapping from inputs to\u00a0outputs.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4898",
    "text": "Both of these ideas involve many complicated interactions between several parts of the machine learning algorithm that are not entirely understood.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4899",
    "text": "The first idea, that the choice of initial parameters for a deep neural network can have a strong regularizing effect on its performance, is the least well understood.\u00a0At the time that pretraining became popular, it was understood as initializing the\u00a0model in a location that would cause it to approach one local minimum rather than\u00a0another. Today, local minima are no longer considered to be a serious problem\u00a0for neural network optimization. We now know that our standard neural network\u00a0training procedures usually do not arrive at a critical point of any kind. It remains\u00a0possible that pretraining initializes the model in a location that would otherwise\u00a0be inaccessible\u2014for example, a region that is surrounded by areas where the cost\u00a0function varies so much from one example to another that minibatches give only\u00a0a very noisy estimate of the gradient, or a region surrounded by areas where the\u00a0Hessian matrix is so poorly conditioned that gradient descent methods must use\u00a0very small steps. However, our ability to characterize exactly what aspects of the\u00a0pretrained parameters are retained during the supervised training stage is limited.\u00a0This is one reason that modern approaches typically use simultaneous unsupervised\u00a0learning and supervised learning rather than two sequential stages. One may\u00a0also avoid struggling with these complicated ideas about how optimization in the\u00a0supervised learning stage preserves information from the unsupervised learning\u00a0stage by simply freezing the parameters for the feature extractors and using\u00a0supervised learning only to add a classifier on top of the learned features.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4900",
    "text": "The other idea, that a learning algorithm can use information learned in the unsupervised phase to perform better in the supervised learning stage, is better\u00a0understood. The basic idea is that some features that are useful for the unsupervised\u00a0task may also be useful for the supervised learning task. For example, if we train\u00a0a generative model of images of cars and motorcycles, it will need to know about\u00a0wheels, and about how many wheels should be in an image. If we are fortunate,\u00a0the representation of the wheels will take on a form that is easy for the supervised\u00a0learner to access. This is not yet understood at a mathematical, theoretical level,\u00a0so it is not always possible to predict which tasks will benefit from unsupervised\u00a0learning in this way. Many aspects of this approach are highly dependent on\u00a0the specific models used. For example, if we wish to add a linear classifier on\u00a0top of pretrained features, the features must make the underlying classes linearly\u00a0separable. These properties often occur naturally but do not always do so. This\u00a0is another reason that simultaneous supervised and unsupervised learning can be\u00a0preferable\u2014the constraints imposed by the output layer are naturally included\u00a0from the start.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4901",
    "text": "From the point of view of unsupervised pretraining as learning a representation, we can expect unsupervised pretraining to be more effective when the initial\u00a0representation is poor. One key example of this is the use of word embeddings.\u00a0Words represented by one-hot vectors are not very informative because every two\u00a0distinct one-hot vectors are the same distance from each other (squared L2 distance\u00a0of 2). Learned word embeddings naturally encode similarity between words by their\u00a0distance from each other. Because of this, unsupervised pretraining is especially\u00a0useful when processing words. It is less useful when processing images, perhaps\u00a0because images already lie in a rich vector space where distances provide a low\u00a0quality similarity metric.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4902",
    "text": "From the point of view of unsupervised pretraining as a regularizer, we can expect unsupervised pretraining to be most helpful when the number of labeled\u00a0examples is very small. Because the source of information added by unsupervised\u00a0pretraining is the unlabeled data, we may also expect unsupervised pretraining\u00a0to perform best when the number of unlabeled examples is very large. The\u00a0advantage of semi-supervised learning via unsupervised pretraining with many\u00a0unlabeled examples and few labeled examples was made particularly clear in\u00a02011 with unsupervised pretraining winning two international transfer learning\u00a0competitions (Mesnil et al., 2011; Goodfellow et al., 2011), in settings where the\u00a0number of labeled examples in the target task was small (from a handful to dozens\u00a0of examples per class). These effects were also documented in carefully controlled\u00a0experiments by Paine et al. (2014).",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4903",
    "text": "Other factors are likely to be involved. For example, unsupervised pretraining is likely to be most useful when the function to be learned is extremely complicated.\u00a0Unsupervised learning differs from regularizers like weight decay because it does not\u00a0bias the learner toward discovering a simple function but rather toward discovering\u00a0feature functions that are useful for the unsupervised learning task. If the true\u00a0underlying functions are complicated and shaped by regularities of the input\u00a0distribution, unsupervised learning can be a more appropriate regularizer.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4904",
    "text": "These caveats aside, we now analyze some success cases where unsupervised pretraining is known to cause an improvement, and explain what is known about\u00a0why this improvement occurs. Unsupervised pretraining has usually been used\u00a0to improve classifiers, and is usually most interesting from the point of view of",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4905",
    "text": "1500 1000\u00a0500\u00a00",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4906",
    "text": "4000 \u00a0\u00a0\u00a03000\u00a0\u00a0\u00a0\u00a02000\u00a0\u00a0\u00a0\u00a01000\u00a0\u00a0\u00a0\u00a00\u00a0\u00a0\u00a0\u00a01000\u00a0\u00a0\u00a0\u00a02000\u00a0\u00a0\u00a0\u00a03000\u00a0\u00a0\u00a0\u00a04000",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4907",
    "text": "500 1000\u00a01500",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4908",
    "text": "Figure 15.1: Visualization via nonlinear projection of the learning trajectories of different neural networks in function space (not parameter space, to avoid the issue of many-to-one mappings from parameter vectors to functions), with different random initializations\u00a0and with or without unsupervised pretraining. Each point corresponds to a different\u00a0neural network, at a particular time during its training process. This figure is adapted\u00a0with permission from Erhan et al. (2010). A coordinate in function space is an infinitedimensional vector associating every input x with an output y. Erhan et al. (2010) made\u00a0a linear projection to high-dimensional space by concatenating the y for many specific x\u00a0points. They then made a further nonlinear projection to 2-D by Isomap (Tenenbaum\u00a0et al., 2000). Color indicates time. All networks are initialized near the center of the plot\u00a0(corresponding to the region of functions that produce approximately uniform distributions\u00a0over the class y for most inputs). Over time, learning moves the function outward, to\u00a0points that make strong predictions. Training consistently terminates in one region when\u00a0using pretraining and in another, non-overlapping region when not using pretraining.\u00a0Isomap tries to preserve global relative distances (and hence volumes) so the small region\u00a0corresponding to pretrained models may indicate that the pretraining-based estimator\u00a0has reduced variance.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4909",
    "text": "reducing test set error. However, unsupervised pretraining can help tasks other than classification, and can act to improve optimization rather than being merely\u00a0a regularizer. For example, it can improve both train and test reconstruction error\u00a0for deep autoencoders (Hinton and Salakhutdinov, 2006).",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4910",
    "text": "Erhan et al. (2010) performed many experiments to explain several successes of unsupervised pretraining. Both improvements to training error and improvements\u00a0to test error may be explained in terms of unsupervised pretraining taking the\u00a0parameters into a region that would otherwise be inaccessible. Neural network\u00a0training is non-deterministic, and converges to a different function every time it\u00a0is run. Training may halt at a point where the gradient becomes small, a point\u00a0where early stopping ends training to prevent overfitting, or at a point where the\u00a0gradient is large but it is difficult to find a downhill step due to problems such as\u00a0stochasticity or poor conditioning of the Hessian. Neural networks that receive\u00a0unsupervised pretraining consistently halt in the same region of function space,\u00a0while neural networks without pretraining consistently halt in another region. See\u00a0Fig. 15.1 for a visualization of this phenomenon. The region where pretrained\u00a0networks arrive is smaller, suggesting that pretraining reduces the variance of the\u00a0estimation process, which can in turn reduce the risk of severe over-fitting. In\u00a0other words, unsupervised pretraining initializes neural network parameters into\u00a0a region that they do not escape, and the results following this initialization are\u00a0more consistent and less likely to be very bad than without this initialization.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4911",
    "text": "Erhan et al. (2010) also provide some answers as to when pretraining works best\u2014the mean and variance of the test error were most reduced by pretraining for\u00a0deeper networks. Keep in mind that these experiments were performed before the\u00a0invention and popularization of modern techniques for training very deep networks\u00a0(rectified linear units, dropout and batch normalization) so less is known about the\u00a0effect of unsupervised pretraining in conjunction with contemporary approaches.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4912",
    "text": "An important question is how unsupervised pretraining can act as a regularizer. One hypothesis is that pretraining encourages the learning algorithm to discover\u00a0features that relate to the underlying causes that generate the observed data.\u00a0This is an important idea motivating many other algorithms besides unsupervised\u00a0pretraining, and is described further in Sec. 15.3.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4913",
    "text": "Compared to other ways of incorporating this belief by using unsupervised learning, unsupervised pretraining has the disadvantage that it operates with\u00a0two separate training phases. One reason that these two training phases are\u00a0disadvantageous is that there is not a single hyperparameter that predictably\u00a0reduces or increases the strength of the regularization arising from the unsupervised\u00a0pretraining. Instead, there are very many hyperparameters, whose effect may be\u00a0measured after the fact but is often difficult to predict ahead of time. When we\u00a0perform unsupervised and supervised learning simultaneously, instead of using the\u00a0pretraining strategy, there is a single hyperparameter, usually a coefficient attached\u00a0to the unsupervised cost, that determines how strongly the unsupervised objective\u00a0will regularize the supervised model. One can always predictably obtain less\u00a0regularization by decreasing this coefficient. In the case of unsupervised pretraining,\u00a0there is not a way of flexibly adapting the strength of the regularization\u2014either\u00a0the supervised model is initialized to pretrained parameters, or it is not.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4914",
    "text": "Another disadvantage of having two separate training phases is that each phase has its own hyperparameters. The performance of the second phase usually cannot\u00a0be predicted during the first phase, so there is a long delay between proposing\u00a0hyperparameters for the first phase and being able to update them using feedback\u00a0from the second phase. The most principled approach is to use validation set error\u00a0in the supervised phase in order to select the hyperparameters of the pretraining\u00a0phase, as discussed in Larochelle et al. (2009). In practice, some hyperparameters,\u00a0like the number of pretraining iterations, are more conveniently set during the\u00a0pretraining phase, using early stopping on the unsupervised objective, which is\u00a0not ideal but computationally much cheaper than using the supervised objective.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4915",
    "text": "Today, unsupervised pretraining has been largely abandoned, except in the field of natural language processing, where the natural representation of words as\u00a0one-hot vectors conveys no similarity information and where very large unlabeled\u00a0sets are available. In that case, the advantage of pretraining is that one can pretrain\u00a0once on a huge unlabeled set (for example with a corpus containing billions of\u00a0words), learn a good representation (typically of words, but also of sentences), and\u00a0then use this representation or fine-tune it for a supervised task for which the\u00a0training set contains substantially fewer examples. This approach was pioneered\u00a0by by Collobert and Weston (2008b), Turian et al. (2010), and Collobert et al.\u00a0(2011a) and remains in common use today.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4916",
    "text": "Deep learning techniques based on supervised learning, regularized with dropout or batch normalization, are able to achieve human-level performance on very many\u00a0tasks, but only with extremely large labeled datasets. These same techniques\u00a0outperform unsupervised pretraining on medium-sized datasets such as CIFAR-10\u00a0and MNIST, which have roughly 5,000 labeled examples per class. On extremely\u00a0small datasets, such as the alternative splicing dataset, Bayesian methods outperform methods based on unsupervised pretraining (Srivastava, 2013). For these\u00a0reasons, the popularity of unsupervised pretraining has declined. Nevertheless,\u00a0unsupervised pretraining remains an important milestone in the history of deep\u00a0learning research and continues to influence contemporary approaches. The idea of\u00a0pretraining has been generalized to supervised pretraining discussed in Sec. 8.7.4,\u00a0as a very common approach for transfer learning. Supervised pretraining for\u00a0transfer learning is popular (Oquab et al., 2014; Yosinski et al., 2014) for use with\u00a0convolutional networks pretrained on the ImageNet dataset. Practitioners publish\u00a0the parameters of these trained networks for this purpose, just like pretrained word\u00a0vectors are published for natural language tasks (Collobert et al., 2011a; Mikolov\u00a0et al., 2013a).",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4917",
    "text": "Transfer learning and domain adaptation refer to the situation where what has been learned in one setting (i.e., distribution P!) is exploited to improve generalization\u00a0in another setting (say distribution P2). This generalizes the idea presented in the\u00a0previous section, where we transferred representations between an unsupervised\u00a0learning task and a supervised learning task.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4918",
    "text": "In transfer learning, the learner must perform two or more different tasks, but we assume that many of the factors that explain the variations in P! are\u00a0relevant to the variations that need to be captured for learning P2. This is typically\u00a0understood in a supervised learning context, where the input is the same but the\u00a0target may be of a different nature. For example, we may learn about one set of\u00a0visual categories, such as cats and dogs, in the first setting, then learn about a\u00a0different set of visual categories, such as ants and wasps, in the second setting. If\u00a0there is significantly more data in the first setting (sampled from P!), then that\u00a0may help to learn representations that are useful to quickly generalize from only\u00a0very few examples drawn from P2. Many visual categories share low-level notions\u00a0of edges and visual shapes, the effects of geometric changes, changes in lighting, etc.\u00a0In general, transfer learning, multi-task learning (Sec. 7.7), and domain adaptation\u00a0can be achieved via representation learning when there exist features that are\u00a0useful for the different settings or tasks, corresponding to underlying factors that\u00a0appear in more than one setting. This is illustrated in Fig. 7.2, with shared lower\u00a0layers and task-dependent upper layers.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4919",
    "text": "However, sometimes, what is shared among the different tasks is not the semantics of the input but the semantics of the output. For example, a speech\u00a0recognition system needs to produce valid sentences at the output layer, but\u00a0the earlier layers near the input may need to recognize very different versions of\u00a0the same phonemes or sub-phonemic vocalizations depending on which person\u00a0is speaking. In cases like these, it makes more sense to share the upper layers\u00a0(near the output) of the neural network, and have a task-specific preprocessing, as",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4920",
    "text": "illustrated in Fig. 15.2.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4921",
    "text": "",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4922",
    "text": "",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4923",
    "text": "",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4924",
    "text": "( y )",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4925",
    "text": "",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4926",
    "text": "",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4927",
    "text": "h(shared)",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4928",
    "text": "\\ Selection switch",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4929",
    "text": "\\ ^(1) )",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4930",
    "text": "( h(2M",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4931",
    "text": "( h(3) '",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4932",
    "text": "x(1)",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4933",
    "text": "f *(2n",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4934",
    "text": "i x(3)",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4935",
    "text": "Figure 15.2: Example architecture for multi-task or transfer learning when the output variable y has the same semantics for all tasks while the input variable x has a different\u00a0meaning (and possibly even a different dimension) for each task (or, for example, each\u00a0user), called x(1), x(2) and x(3) for three tasks. The lower levels (up to the selection\u00a0switch) are task-specific, while the upper levels are shared. The lower levels learn to\u00a0translate their task-specific input into a generic set of features.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4936",
    "text": "In the related case of domain adaptation, the task (and the optimal input-to-output mapping) remains the same between each setting, but the input distribution is slightly different. For example, consider the task of sentiment analysis, which\u00a0consists of determining whether a comment expresses positive or negative sentiment.\u00a0Comments posted on the web come from many categories. A domain adaptation\u00a0scenario can arise when a sentiment predictor trained on customer reviews of\u00a0media content such as books, videos and music is later used to analyze comments\u00a0about consumer electronics such as televisions or smartphones. One can imagine\u00a0that there is an underlying function that tells whether any statement is positive,\u00a0neutral or negative, but of course the vocabulary and style may vary from one\u00a0domain to another, making it more difficult to generalize across domains. Simple\u00a0unsupervised pretraining (with denoising autoencoders) has been found to be very\u00a0successful for sentiment analysis with domain adaptation (Glorot et al., 2011b).",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4937",
    "text": "A related problem is that of concept drift, which we can view as a form of transfer learning due to gradual changes in the data distribution over time. Both concept\u00a0drift and transfer learning can be viewed as particular forms of multi-task learning.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4938",
    "text": "While the phrase \u201cmulti-task learning\u201d typically refers to supervised learning tasks, the more general notion of transfer learning is applicable to unsupervised learning\u00a0and reinforcement learning as well.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4939",
    "text": "In all of these cases, the objective is to take advantage of data from the first setting to extract information that may be useful when learning or even when\u00a0directly making predictions in the second setting. The core idea of representation\u00a0learning is that the same representation may be useful in both settings. Using the\u00a0same representation in both settings allows the representation to benefit from the\u00a0training data that is available for both tasks.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4940",
    "text": "As mentioned before, unsupervised deep learning for transfer learning has found success in some machine learning competitions (Mesnil et al., 2011; Goodfellow\u00a0et al., 2011). In the first of these competitions, the experimental setup is the\u00a0following. Each participant is first given a dataset from the first setting (from\u00a0distribution P!), illustrating examples of some set of categories. The participants\u00a0must use this to learn a good feature space (mapping the raw input to some\u00a0representation), such that when we apply this learned transformation to inputs\u00a0from the transfer setting (distribution P2), a linear classifier can be trained and\u00a0generalize well from very few labeled examples. One of the most striking results\u00a0found in this competition is that as an architecture makes use of deeper and\u00a0deeper representations (learned in a purely unsupervised way from data collected\u00a0in the first setting, P!), the learning curve on the new categories of the second\u00a0(transfer) setting P2 becomes much better. For deep representations, fewer labeled\u00a0examples of the transfer tasks are necessary to achieve the apparently asymptotic\u00a0generalization performance.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4941",
    "text": "Two extreme forms of transfer learning are one-shot learning and zero-shot learning, sometimes also called zero-data learning. Only one labeled example of the\u00a0transfer task is given for one-shot learning, while no labeled examples are given at\u00a0all for the zero-shot learning task.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4942",
    "text": "One-shot learning (Fei-Fei et al., 2006) is possible because the representation learns to cleanly separate the underlying classes during the first stage. During the\u00a0transfer learning stage, only one labeled example is needed to infer the label of many\u00a0possible test examples that all cluster around the same point in representation\u00a0space. This works to the extent that the factors of variation corresponding to\u00a0these invariances have been cleanly separated from the other factors, in the learned\u00a0representation space, and we have somehow learned which factors do and do not\u00a0matter when discriminating objects of certain categories.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4943",
    "text": "As an example of a zero-shot learning setting, consider the problem of having a learner read a large collection of text and then solve object recognition problems.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4944",
    "text": "It may be possible to recognize a specific object class even without having seen an image of that object, if the text describes the object well enough. For example,\u00a0having read that a cat has four legs and pointy ears, the learner might be able to\u00a0guess that an image is a cat, without having seen a cat before.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4945",
    "text": "Zero-data learning (Larochelle et al., 2008) and zero-shot learning (Palatucci et al., 2009; Socher et al., 2013b) are only possible because additional information\u00a0has been exploited during training. We can think of the zero-data learning scenario\u00a0as including three random variables: the traditional inputs x, the traditional\u00a0outputs or targets y, and an additional random variable describing the task, T.\u00a0The model is trained to estimate the conditional distribution p(y | x,T) where\u00a0T is a description of the task we wish the model to perform. In our example of\u00a0recognizing cats after having read about cats, the output is a binary variable y\u00a0with y = 1 indicating \u201cyes\u201d and y = 0 indicating \u201cno.\u201d The task variable T then\u00a0represents questions to be answered such as \u201cIs there a cat in this image?\u201d If we\u00a0have a training set containing unsupervised examples of objects that live in the\u00a0same space as T, we may be able to infer the meaning of unseen instances of T.\u00a0In our example of recognizing cats without having seen an image of the cat, it is\u00a0important that we have had unlabeled text data containing sentences such as \u201ccats\u00a0have four legs\u201d or \u201ccats have pointy ears.\u201d",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4946",
    "text": "Zero-shot learning requires T to be represented in a way that allows some sort of generalization. For example, T cannot be just a one-hot code indicating an\u00a0object category. Socher et al. (2013b) provide instead a distributed representation\u00a0of object categories by using a learned word embedding for the word associated\u00a0with each category.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4947",
    "text": "A similar phenomenon happens in machine translation (Klementiev et al., 2012; Mikolov et al., 2013b; Gouws et al., 2014): we have words in one language, and\u00a0the relationships between words can be learned from unilingual corpora; on the\u00a0other hand, we have translated sentences which relate words in one language with\u00a0words in the other. Even though we may not have labeled examples translating\u00a0word A in language X to word B in language Y, we can generalize and guess a\u00a0translation for word A because we have learned a distributed representation for\u00a0words in language X, a distributed representation for words in language Y, and\u00a0created a link (possibly two-way) relating the two spaces, via training examples\u00a0consisting of matched pairs of sentences in both languages. This transfer will be\u00a0most successful if all three ingredients (the two representations and the relations\u00a0between them) are learned jointly.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4948",
    "text": "Zero-shot learning is a particular form of transfer learning. The same principle explains how one can perform multi-modal learning, capturing a representation in",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4949",
    "text": "hx = fx (x)",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4950",
    "text": "\u25a1 1=\u05be \u2014 \u25ba fy : encoder function for y",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4951",
    "text": "+ -.....p. Relationship between embedded points within one of the domains",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4952",
    "text": "- \u00a0\u00a0\u00a0\u00bb Maps between representation spaces",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4953",
    "text": "Figure 15.3: Transfer learning between two domains x and y enables zero-shot learning. Labeled or unlabeled examples of x allow one to learn a representation function fx and\u00a0similarly with examples of y to learn fy. Each application of the fx and f y functions\u00a0appears as an upward arrow, with the style of the arrows indicating which function is\u00a0applied. Distance in hx space provides a similarity metric between any pair of points\u00a0in x space that may be more meaningful than distance in x space. Likewise, distance\u00a0in hy space provides a similarity metric between any pair of points in y space. Both\u00a0of these similarity functions are indicated with dotted bidirectional arrows. Labeled\u00a0examples (dashed horizontal lines) are pairs (x, y) which allow one to learn a one-way\u00a0or two-way map (solid bidirectional arrow) between the representationsfx (x) and the\u00a0representations f y (y) and anchor these representations to each other. Zero-data learning\u00a0is then enabled as follows. One can associate an image xtest to a word ytest, even if no\u00a0image of that word was ever presented, simply because word-representations fy (ytest)\u00a0and image-representations fx (xtest) can be related to each other via the maps between\u00a0representation spaces. It works because, although that image and that word were never\u00a0paired, their respective feature vectors fx(xtest) and fy(ytest) have been related to each\u00a0other. Figure inspired from suggestion by Hrant Khachatrian.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4954",
    "text": "one modality, a representation in the other, and the relationship (in general a joint distribution) between pairs (x, y) consisting of one observation x in one modality\u00a0and another observation y in the other modality (Srivastava and Salakhutdinov,\u00a02012). By learning all three sets of parameters (from x to its representation, from\u00a0y to its representation, and the relationship between the two representations),\u00a0concepts in one representation are anchored in the other, and vice-versa, allowing\u00a0one to meaningfully generalize to new pairs. The procedure is illustrated in\u00a0Fig. 15.3.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4955",
    "text": "An important question about representation learning is \u201cwhat makes one representation better than another?\u201d One hypothesis is that an ideal representation is one in which the features within the representation correspond to the underlying causes of the observed data, with separate features or directions in feature\u00a0space corresponding to different causes, so that the representation disentangles the\u00a0causes from one another. This hypothesis motivates approaches in which we first\u00a0seek a good representation for p(x). Such a representation may also be a good\u00a0representation for computing p( y | x) if y is among the most salient causes of\u00a0x. This idea has guided a large amount of deep learning research since at least\u00a0the 1990s (Becker and Hinton, 1992; Hinton and Sejnowski, 1999), in more detail.\u00a0For other arguments about when semi-supervised learning can outperform pure\u00a0supervised learning, we refer the reader to Sec. 1.2 of Chapelle et al. (2006).",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4956",
    "text": "In other approaches to representation learning, we have often been concerned with a representation that is easy to model\u2014for example, one whose entries are\u00a0sparse, or independent from each other. A representation that cleanly separates\u00a0the underlying causal factors may not necessarily be one that is easy to model.\u00a0However, a further part of the hypothesis motivating semi-supervised learning\u00a0via unsupervised representation learning is that for many AI tasks, these two\u00a0properties coincide: once we are able to obtain the underlying explanations for\u00a0what we observe, it generally becomes easy to isolate individual attributes from\u00a0the others. Specifically, if a representation h represents many of the underlying\u00a0causes of the observed x, and the outputs y are among the most salient causes,\u00a0then it is easy to predict y from h.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4957",
    "text": "First, let us see how semi-supervised learning can fail because unsupervised learning of p(x) is of no help to learn p(y | x). Consider for example the case\u00a0where p(x) is uniformly distributed and we want to learn f (x) = E[y | x]. Clearly,\u00a0observing a training set of x values alone gives us no information about p(y | x).",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4958",
    "text": "Mixture model",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4959",
    "text": "Figure 15.4: Example of a density over x that is a mixture over three components. The component identity is an underlying explanatory factor, y. Because the mixture\u00a0components (e.g., natural object classes in image data) are statistically salient, just\u00a0modeling p(x) in an unsupervised way with no labeled example already reveals the factor",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4960",
    "text": "y.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4961",
    "text": "Next, let us see a simple example of how semi-supervised learning can succeed. Consider the situation where x arises from a mixture, with one mixture component\u00a0per value of y, as illustrated in Fig. 15.4. If the mixture components are well-separated, then modeling p(x) reveals precisely where each component is, and a\u00a0single labeled example of each class will then be enough to perfectly learn p (y | x).\u00a0But more generally, what could make p(y | x) and p(x) be tied together?",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4962",
    "text": "If y is closely associated with one of the causal factors of x, then p(x) and p(y | x) will be strongly tied, and unsupervised representation learning that\u00a0tries to disentangle the underlying factors of variation is likely to be useful as a\u00a0semi-supervised learning strategy.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4963",
    "text": "Consider the assumption that y is one of the causal factors of x, and let h represent all those factors. The true generative process can be conceived as\u00a0structured according to this directed graphical model, with h as the parent of x:",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4964",
    "text": "p(h, x) = p(x | h)p(h). \u00a0\u00a0\u00a0(15.1)",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4965",
    "text": "As a consequence, the data has marginal probability",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4966",
    "text": "p(x) = Ehp(x | h). \u00a0\u00a0\u00a0(15.2)",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4967",
    "text": "From this straightforward observation, we conclude that the best possible model of x (from a generalization point of view) is the one that uncovers the above \u201ctrue\u201d\u00a0structure, with h as a latent variable that explains the observed variations in x.\u00a0The \u201cideal\u201d representation learning discussed above should thus recover these latent\u00a0factors. If y is one of these (or closely related to one of them), then it will be\u00a0very easy to learn to predict y from such a representation. We also see that the\u00a0conditional distribution of y given x is tied by Bayes rule to the components in\u00a0the above equation:",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4968",
    "text": "p(x 1 y)p(y)",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4969",
    "text": "p(y 1 x) = \u00a0\u00a0\u00a0p(x)\u00a0\u00a0\u00a0\u00a0\u25a0\u00a0\u00a0\u00a0\u00a0(15'3)",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4970",
    "text": "Thus the marginal p(x) is intimately tied to the conditional p(y | x) and knowledge of the structure of the former should be helpful to learn the latter. Therefore, in\u00a0situations respecting these assumptions, semi-supervised learning should improve\u00a0performance.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4971",
    "text": "An important research problem regards the fact that most observations are formed by an extremely large number of underlying causes. Suppose y = hj, but\u00a0the unsupervised learner does not know which hi. The brute force solution is for\u00a0an unsupervised learner to learn a representation that captures all the reasonably\u00a0salient generative factors hj and disentangles them from each other, thus making\u00a0it easy to predict y from h, regardless of which hj is associated with y.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4972",
    "text": "In practice, the brute force solution is not feasible because it is not possible to capture all or most of the factors of variation that influence an observation.\u00a0For example, in a visual scene, should the representation always encode all of\u00a0the smallest objects in the background? It is a well-documented psychological\u00a0phenomenon that human beings fail to perceive changes in their environment that\u00a0are not immediately relevant to the task they are performing\u2014see, e.g., Simons\u00a0and Levin (1998). An important research frontier in semi-supervised learning is\u00a0determining what to encode in each situation. Currently, two of the main strategies\u00a0for dealing with a large number of underlying causes are to use a supervised learning\u00a0signal at the same time as the unsupervised learning signal so that the model will\u00a0choose to capture the most relevant factors of variation, or to use much larger\u00a0representations if using purely unsupervised learning.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4973",
    "text": "An emerging strategy for unsupervised learning is to modify the definition of which underlying causes are most salient. Historically, autoencoders and generative\u00a0models have been trained to optimize a fixed criterion, often similar to mean\u00a0squared error. These fixed criteria determine which causes are considered salient.\u00a0For example, mean squared error applied to the pixels of an image implicitly\u00a0specifies that an underlying cause is only salient if it significantly changes the\u00a0brightness of a large number of pixels. This can be problematic if the task we\u00a0wish to solve involves interacting with small objects. See Fig. 15.5 for an example",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4974",
    "text": "Figure 15.5: An autoencoder trained with mean squared error for a robotics task has failed to reconstruct a ping pong ball. The existence of the ping pong ball and all of its\u00a0spatial coordinates are important underlying causal factors that generate the image and\u00a0are relevant to the robotics task. Unfortunately, the autoencoder has limited capacity,\u00a0and the training with mean squared error did not identify the ping pong ball as being\u00a0salient enough to encode. Images graciously provided by Chelsea Finn.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4975",
    "text": "of a robotics task in which an autoencoder has failed to learn to encode a small ping pong ball. This same robot is capable of successfully interacting with larger\u00a0objects, such as baseballs, which are more salient according to mean squared error.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4976",
    "text": "Other definitions of salience are possible. For example, if a group of pixels follow a highly recognizable pattern, even if that pattern does not involve extreme\u00a0brightness or darkness, then that pattern could be considered extremely salient.\u00a0One way to implement such a definition of salience is to use a recently developed\u00a0approach called generative adversarial networks (Goodfellow et al., 2014c). In\u00a0this approach, a generative model is trained to fool a feedforward classifier. The\u00a0feedforward classifier attempts to recognize all samples from the generative model\u00a0as being fake, and all samples from the training set as being real. In this framework,\u00a0any structured pattern that the feedforward network can recognize is highly salient.\u00a0The generative adversarial network will be described in more detail in Sec. 20.10.4.\u00a0For the purposes of the present discussion, it is sufficient to understand that they\u00a0learn how to determine what is salient. Lotter et al. (2015) showed that models\u00a0trained to generate images of human heads will often neglect to generate the ears\u00a0when trained with mean squared error, but will successfully generate the ears when\u00a0trained with the adversarial framework. Because the ears are not extremely bright\u00a0or dark compared to the surrounding skin, they are not especially salient according\u00a0to mean squared error loss, but their highly recognizable shape and consistent",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4977",
    "text": "Figure 15.6: Predictive generative networks provide an example of the importance of learning which features are salient. In this example, the predictive generative network\u00a0has been trained to predict the appearance of a 3-D model of a human head at a specific\u00a0viewing angle. (Left) Ground truth. This is the correct image, that the network should\u00a0emit. (Center) Image produced by a predictive generative network trained with mean\u00a0squared error alone. Because the ears do not cause an extreme difference in brightness\u00a0compared to the neighboring skin, they were not sufficiently salient for the model to learn\u00a0to represent them. (Right) Image produced by a model trained with a combination of\u00a0mean squared error and adversarial loss. Using this learned cost function, the ears are\u00a0salient because they follow a predictable pattern. Learning which underlying causes are\u00a0important and relevant enough to model is an important active area of research. Figures\u00a0graciously provided by Lotter et al. (2015).",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4978",
    "text": "position means that a feedforward network can easily learn to detect them, making them highly salient under the generative adversarial framework. See Fig. 15.6\u00a0for example images. Generative adversarial networks are only one step toward\u00a0determining which factors should be represented. We expect that future research\u00a0will discover better ways of determining which factors to represent, and develop\u00a0mechanisms for representing different factors depending on the task.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4979",
    "text": "A benefit of learning the underlying causal factors, as pointed out by Scholkopf et al. (2012), is that if the true generative process has x as an effect and y as\u00a0a cause, then modeling p(x | y) is robust to changes in p(y). If the cause-effect\u00a0relationship was reversed, this would not be true, since by Bayes rule, p(x | y)\u00a0would be sensitive to changes in p( y). Very often, when we consider changes in\u00a0distribution due to different domains, temporal non-stationarity, or changes in\u00a0the nature of the task, the causal mechanisms remain invariant (\u201cthe laws\u00a0of the universe are constant\u201d) while the marginal distribution over the underlying\u00a0causes can change. Hence, better generalization and robustness to all kinds of\u00a0changes can be expected via learning a generative model that attempts to recover\u00a0the causal factors h and p(x | h).",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4980",
    "text": "Distributed representations of concepts\u2014representations composed of many elements that can be set separately from each other\u2014are one of the most important tools for representation learning. Distributed representations are powerful because\u00a0they can use n features with k values to describe kn different concepts. As we\u00a0have seen throughout this book, both neural networks with multiple hidden units\u00a0and probabilistic models with multiple latent variables make use of the strategy of\u00a0distributed representation. We now introduce an additional observation. Many\u00a0deep learning algorithms are motivated by the assumption that the hidden units\u00a0can learn to represent the underlying causal factors that explain the data, as\u00a0discussed in Sec. 15.3. Distributed representations are natural for this approach,\u00a0because each direction in representation space can correspond to the value of a\u00a0different underlying configuration variable.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4981",
    "text": "An example of a distributed representation is a vector of n binary features, which can take 2n configurations, each potentially corresponding to a different\u00a0region in input space, as illustrated in Fig. 15.7. This can be compared with\u00a0a symbolic representation, where the input is associated with a single symbol or\u00a0category. If there are n symbols in the dictionary, one can imagine n feature\u00a0detectors, each corresponding to the detection of the presence of the associated\u00a0category. In that case only n different configurations of the representation space\u00a0are possible, carving n different regions in input space, as illustrated in Fig. 15.8.\u00a0Such a symbolic representation is also called a one-hot representation, since it can\u00a0be captured by a binary vector with n bits that are mutually exclusive (only one\u00a0of them can be active). A symbolic representation is a specific example of the\u00a0broader class of non-distributed representations, which are representations that\u00a0may contain many entries but without significant meaningful separate control over\u00a0each entry.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4982",
    "text": "Examples of learning algorithms based on non-distributed representations include:",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4983",
    "text": "\u2022 \u00a0\u00a0\u00a0Clustering methods, including the k-means algorithm: each input point is\u00a0assigned to exactly one cluster.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4984",
    "text": "\u2022 \u00a0\u00a0\u00a0k-nearest neighbors algorithms: one or a few templates or prototype examples\u00a0are associated with a given input. In the case of k > 1, there are multiple",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4985",
    "text": "h2 \u00a0\u00a0\u00a0h3",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4986",
    "text": "Figure 15.7: Illustration of how a learning algorithm based on a distributed representation breaks up the input space into regions. In this example, there are three binary features\u00a0hi, h2, and h3. Each feature is defined by thresholding the output of a learned, linear\u00a0transformation. Each feature divides R2 into two half-planes. Let h+ be the set of input\u00a0points for which hi = 1 and h- be the set of input points for which h = 0. In this\u00a0illustration, each line represents the decision boundary for onehi, with the corresponding\u00a0arrow pointing to the h+ side of the boundary. The representation as a whole takes\u00a0on a unique value at each possible intersection of these half-planes. For example, the\u00a0representation value [1,1, 1]T corresponds to the region h+ \u05d7 h+ H h+. Compare this to\u00a0the non-distributed representations in Fig. 15.8. In the general case ofd input dimensions,\u00a0a distributed representation dividesRd by intersecting half-spaces rather than half-planes.\u00a0The distributed representation with n features assigns unique codes to O(nd) different\u00a0regions, while the nearest neighbor algorithm withn examples assigns unique codes to only\u00a0n regions. The distributed representation is thus able to distinguish exponentially many\u00a0more regions than the non-distributed one. Keep in mind that not allh values are feasible\u00a0(there is no h = 0 in this example) and that a linear classifier on top of the distributed\u00a0representation is not able to assign different class identities to every neighboring region;\u00a0even a deep linear-threshold network has a VC dimension of only O (w log w) where w\u00a0is the number of weights (Sontag, 1998). The combination of a powerful representation\u00a0layer and a weak classifier layer can be a strong regularizer; a classifier trying to learn\u00a0the concept of \u201cperson\u201d versus \u201cnot a person\u201d does not need to assign a different class to\u00a0an input represented as \u201cwoman with glasses\u201d than it assigns to an input represented as\u00a0\u201cman without glasses.\u201d This capacity constraint encourages each classifier to focus on few\u00a0hi and encourages h to learn to represent the classes in a linearly separable way.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4987",
    "text": "values describing each input, but they can not be controlled separately from each other, so this does not qualify as a true distributed representation.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4988",
    "text": "\u2022 \u00a0\u00a0\u00a0Decision trees: only one leaf (and the nodes on the path from root to leaf) is\u00a0activated when an input is given.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4989",
    "text": "\u2022 \u00a0\u00a0\u00a0Gaussian mixtures and mixtures of experts: the templates (cluster centers)\u00a0or experts are now associated with a degree of activation. As with the\u00a0k-nearest neighbors algorithm, each input is represented with multiple values,\u00a0but those values cannot readily be controlled separately from each other.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4990",
    "text": "\u2022 \u00a0\u00a0\u00a0Kernel machines with a Gaussian kernel (or other similarly local kernel):\u00a0although the degree of activation of each \u201csupport vector\u201d or template example\u00a0is now continuous-valued, the same issue arises as with Gaussian mixtures.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4991",
    "text": "\u2022 \u00a0\u00a0\u00a0Language or translation models based on n-grams. The set of contexts\u00a0(sequences of symbols) is partitioned according to a tree structure of suffixes.\u00a0A leaf may correspond to the last two words being w 1 and w2, for example.\u00a0Separate parameters are estimated for each leaf of the tree (with some sharing\u00a0being possible).",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4992",
    "text": "For some of these non-distributed algorithms, the output is not constant by parts but instead interpolates between neighboring regions. The relationship\u00a0between the number of parameters (or examples) and the number of regions they\u00a0can define remains linear.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4993",
    "text": "An important related concept that distinguishes a distributed representation from a symbolic one is that generalization arises due to shared attributes",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4994",
    "text": "between different concepts. As pure symbols, \u201ccat\u201d and \u201cdog\u201d are as far from each other as any other two symbols. However, if one associates them with a meaningful\u00a0distributed representation, then many of the things that can be said about cats\u00a0can generalize to dogs and vice-versa. For example, our distributed representation\u00a0may contain entries such as \u201chas_fur\u201d or \u201cnumber_of_legs\u201d that have the same\u00a0value for the embedding of both \u201c cat\u201d and \u201cdog.\u201d Neural language models that\u00a0operate on distributed representations of words generalize much better than other\u00a0models that operate directly on one-hot representations of words, as discussed\u00a0in Sec. 12.4. Distributed representations induce a rich similarity space, in which\u00a0semantically close concepts (or inputs) are close in distance, a property that is\u00a0absent from purely symbolic representations.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4995",
    "text": "When and why can there be a statistical advantage from using a distributed representation as part of a learning algorithm? Distributed representations can",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4996",
    "text": "o",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4997",
    "text": "Figure 15.8: Illustration of how the nearest neighbor algorithm breaks up the input space into different regions. The nearest neighbor algorithm provides an example of a learning\u00a0algorithm based on a non-distributed representation. Different non-distributed algorithms\u00a0may have different geometry, but they typically break the input space into regions,with\u00a0a separate set of parameters for each region The advantage of a non-distributed\u00a0approach is that, given enough parameters, it can fit the training set without solving a\u00a0difficult optimization algorithm, because it is straightforward to choose a different output\u00a0independently for each region. The disadvantage is that such non-distributed models\u00a0generalize only locally via the smoothness prior, making it difficult to learn a complicated\u00a0function with more peaks and troughs than the available number of examples. Contrast\u00a0this with a distributed representation, Fig. 15.7.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4998",
    "text": "have a statistical advantage when an apparently complicated structure can be compactly represented using a small number of parameters. Some traditional nondistributed learning algorithms generalize only due to the smoothness assumption,\u00a0which states that if u ~ v, then the target function f to be learned has the\u00a0property that f (u) \u00ab f(v), in general. There are many ways of formalizing such an\u00a0assumption, but the end result is that if we have an example (x,y) for which we\u00a0know that f (x) ~ y, then we choose an estimator f that approximately satisfies\u00a0these constraints while changing as little as possible when we move to a nearby\u00a0input x + e. This assumption is clearly very useful, but it suffers from the curse of\u00a0dimensionality: in order to learn a target function that increases and decreases\u00a0many times in many different regions,1 we may need a number of examples that is\u00a0at least as large as the number of distinguishable regions. One can think of each of\u00a0these regions as a category or symbol: by having a separate degree of freedom for\u00a0each symbol (or region), we can learn an arbitrary decoder mapping from symbol\u00a0to value. However, this does not allow us to generalize to new symbols for new\u00a0regions.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "4999",
    "text": "If we are lucky, there may be some regularity in the target function, besides being smooth. For example, a convolutional network with max-pooling can recognize an\u00a0object regardless of its location in the image, even though spatial translation of\u00a0the object may not correspond to smooth transformations in the input space.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5000",
    "text": "Let us examine a special case of a distributed representation learning algorithm, that extracts binary features by thresholding linear functions of the input. Each\u00a0binary feature in this representation divides Rd into a pair of half-spaces, as\u00a0illustrated in Fig. 15.7. The exponentially large number of intersections of n\u00a0of the corresponding half-spaces determines how many regions this distributed\u00a0representation learner can distinguish. How many regions are generated by an\u00a0arrangement of n hyperplanes in Rd ? By applying a general result concerning the\u00a0intersection of hyperplanes (Zaslavsky, 1975), one can show (Pascanu et al., 2014b)\u00a0that the number of regions this binary feature representation can distinguish is",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5001",
    "text": "E n = O(nd). \u00a0\u00a0\u00a0(15.4)",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5002",
    "text": "j=0 ' j",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5003",
    "text": "Therefore, we see a growth that is exponential in the input size and polynomial in the number of hidden units.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5004",
    "text": "This provides a geometric argument to explain the generalization power of distributed representation: with O (nd) parameters (for n linear-threshold features\u00a0in Rd) we can distinctly represent O(nd) regions in input space. If instead we made\u00a0no assumption at all about the data, and used a representation with one unique\u00a0symbol for each region, and separate parameters for each symbol to recognize its\u00a0corresponding portion of then specifying O (nd) regions would require O(nd)\u00a0examples. More generally, the argument in favor of the distributed representation\u00a0could be extended to the case where instead of using linear threshold units we\u00a0use nonlinear, possibly continuous, feature extractors for each of the attributes in\u00a0the distributed representation. The argument in this case is that if a parametric\u00a0transformation with k parameters can learn about r regions in input space, with\u00a0k ^ r, and if obtaining such a representation was useful to the task of interest, then\u00a0we could potentially generalize much better in this way than in a non-distributed\u00a0setting where we would need O (r) examples to obtain the same features and\u00a0associated partitioning of the input space into r regions. Using fewer parameters to\u00a0represent the model means that we have fewer parameters to fit, and thus require\u00a0far fewer training examples to generalize well.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5005",
    "text": "A further part of the argument for why models based on distributed representations generalize well is that their capacity remains limited despite being able to distinctly encode so many different regions. For example, the VC dimension of a\u00a0neural network of linear threshold units is only O(w log w), where w is the number\u00a0of weights (Sontag, 1998). This limitation arises because, while we can assign very\u00a0many unique codes to representation space, we cannot use absolutely all of the code\u00a0space, nor can we learn arbitrary functions mapping from the representation space\u00a0h to the output y using a linear classifier. The use of a distributed representation\u00a0combined with a linear classifier thus expresses a prior belief that the classes to\u00a0be recognized are linearly separable as a function of the underlying causal factors\u00a0captured by h. We will typically want to learn categories such as the set of all\u00a0images of all green objects or the set of all images of cars, but not categories that\u00a0require nonlinear, XOR logic. For example, we typically do not want to partition\u00a0the data into the set of all red cars and green trucks as one class and the set of all\u00a0green cars and red trucks as another class.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5006",
    "text": "The ideas discussed so far have been abstract, but they may be experimentally validated. Zhou et al. (2015) find that hidden units in a deep convolutional\u00a0network trained on the ImageNet and Places benchmark datasets learn features\u00a0that are very often interpretable, corresponding to a label that humans would\u00a0naturally assign. In practice it is certainly not always the case that hidden units\u00a0learn something that has a simple linguistic name, but it is interesting to see this\u00a0emerge near the top levels of the best computer vision deep networks. What such",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5007",
    "text": "Figure 15.9: A generative model has learned a distributed representation that disentangles the concept of gender from the concept of wearing glasses. If we begin with the representation of the concept of a man with glasses, then subtract the vector representing the\u00a0concept of a man without glasses, and finally add the vector representing the concept\u00a0of a woman without glasses, we obtain the vector representing the concept of a woman\u00a0with glasses. The generative model correctly decodes all of these representation vectors to\u00a0images that may be recognized as belonging to the correct class. Images reproduced with\u00a0permission from Radford et al. (2015).",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5008",
    "text": "features have in common is that one could imagine learning about each of them without having to see all the configurations of all the others. Radford\u00a0et al. (2015) demonstrated that a generative model can learn a representation of\u00a0images of faces, with separate directions in representation space capturing different\u00a0underlying factors of variation. Fig. 15.9 demonstrates that one direction in\u00a0representation space corresponds to whether the person is male or female, while\u00a0another corresponds to whether the person is wearing glasses. These features were\u00a0discovered automatically, not fixed a priori. There is no need to have labels for\u00a0the hidden unit classifiers: gradient descent on an objective function of interest\u00a0naturally learns semantically interesting features, so long as the task requires\u00a0such features. We can learn about the distinction between male and female, or\u00a0about the presence or absence of glasses, without having to characterize all of\u00a0the configurations of the n \u2014 1 other features by examples covering all of these\u00a0combinations of values. This form of statistical separability is what allows one to\u00a0generalize to new configurations of a person\u2019s features that have never been seen\u00a0during training.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5009",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5010",
    "text": " Potentially, we may want to learn a function whose behavior is distinct in exponentially many regions: in a d-dimensional space with at least 2 different values to distinguish per dimension, we\u00a0might want f to differ in 2d different regions, requiring O(2 d) training examples.",
    "chapter": "",
    "chapter_id": "main-28.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5011",
    "text": "We have seen in Sec. 6.4.1 that multilayer perceptrons are universal approximators, and that some functions can be represented by exponentially smaller deep networks\u00a0compared to shallow networks. This decrease in model size leads to improved\u00a0statistical efficiency. In this section, we describe how similar results apply more\u00a0generally to other kinds of models with distributed hidden representations.",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5012",
    "text": "In Sec. 15.4, we saw an example of a generative model that learned about the explanatory factors underlying images of faces, including the person\u2019s gender and\u00a0whether they are wearing glasses. The generative model that accomplished this\u00a0task was based on a deep neural network. It would not be reasonable to expect a\u00a0shallow network, such as a linear network, to learn the complicated relationship\u00a0between these abstract explanatory factors and the pixels in the image. In this and\u00a0other AI tasks, the factors that can be chosen almost independently in order to\u00a0generate data are more likely to be very high-level and related in highly nonlinear\u00a0ways to the input. We argue that this demands deep distributed representations,\u00a0where the higher level features (seen as functions of the input) or factors (seen as\u00a0generative causes) are obtained through the composition of many nonlinearities.",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5013",
    "text": "It has been proven in many different settings that organizing computation through the composition of many nonlinearities and a hierarchy of reused features\u00a0can give an exponential boost to statistical efficiency, on top of the exponential\u00a0boost given by using a distributed representation. Many kinds of networks (e.g.,\u00a0with saturating nonlinearities, Boolean gates, sum/products, or RBF units) with\u00a0a single hidden layer can be shown to be universal approximators. A model\u00a0family that is a universal approximator can approximate a large class of functions\u00a0(including all continuous functions) up to any non-zero tolerance level, given enough\u00a0hidden units. However, the required number of hidden units may be very large.\u00a0Theoretical results concerning the expressive power of deep architectures state that\u00a0there are families of functions that can be represented efficiently by an architecture\u00a0of depth k, but would require an exponential number of hidden units (with respect\u00a0to the input size) with insufficient depth (depth 2 or depth k \u2014 1).",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5014",
    "text": "In Sec. 6.4.1, we saw that deterministic feedforward networks are universal approximators of functions. Many structured probabilistic models with a single\u00a0hidden layer of latent variables, including restricted Boltzmann machines and deep\u00a0belief networks, are universal approximators of probability distributions (Le Roux\u00a0and Bengio, 2008, 2010; Montufar and Ay, 2011; Montufar, 2014; Krause et al.,\u00a02013).",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5015",
    "text": "In Sec. 6.4.1, we saw that a sufficiently deep feedforward network can have an exponential advantage over a network that is too shallow. Such results can also\u00a0be obtained for other models such as probabilistic models. One such probabilistic\u00a0model is the sum-product network or SPN (Poon and Domingos, 2011). These\u00a0models use polynomial circuits to compute the probability distribution over a\u00a0set of random variables. Delalleau and Bengio (2011) showed that there exist\u00a0probability distributions for which a minimum depth of SPN is required to avoid\u00a0needing an exponentially large model. Later, Martens and Medabalimi (2014)\u00a0showed that there are significant differences between every two finite depths of\u00a0SPN, and that some of the constraints used to make SPNs tractable may limit\u00a0their representational power.",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5016",
    "text": "Another interesting development is a set of theoretical results for the expressive power of families of deep circuits related to convolutional nets, highlighting an\u00a0exponential advantage for the deep circuit even when the shallow circuit is allowed\u00a0to only approximate the function computed by the deep circuit (Cohen et al.,",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5017",
    "text": "2015). By comparison, previous theoretical work made claims regarding only the case where the shallow circuit must exactly replicate particular functions.",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5018",
    "text": "To close this chapter, we come back to one of our original questions: what makes one representation better than another? One answer, first introduced in Sec. 15.3,\u00a0is that an ideal representation is one that disentangles the underlying causal factors\u00a0of variation that generated the data, especially those factors that are relevant to our\u00a0applications. Most strategies for representation learning are based on introducing\u00a0clues that help the learning to find these underlying factors of variations. The clues\u00a0can help the learner separate these observed factors from the others. Supervised\u00a0learning provides a very strong clue: a label y, presented with each x, that usually\u00a0specifies the value of at least one of the factors of variation directly. More generally,\u00a0to make use of abundant unlabeled data, representation learning makes use of\u00a0other, less direct, hints about the underlying factors. These hints take the form of\u00a0implicit prior beliefs that we, the designers of the learning algorithm, impose in\u00a0order to guide the learner. Results such as the no free lunch theorem show that\u00a0regularization strategies are necessary to obtain good generalization. While it is\u00a0impossible to find a universally superior regularization strategy, one goal of deep\u00a0learning is to find a set of fairly generic regularization strategies that are applicable\u00a0to a wide variety of AI tasks, similar to the tasks that people and animals are able\u00a0to solve.",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5019",
    "text": "We provide here a list of these generic regularization strategies. The list is clearly not exhaustive, but gives some concrete examples of ways that learning\u00a0algorithms can be encouraged to discover features that correspond to underlying\u00a0factors. This list was introduced in Sec. 3.1 of Bengio et al. (2013d) and has been\u00a0partially expanded here.",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5020",
    "text": "\u2022 Smoothness: This is the assumption that f (x + ed) \u00ab f (x) for unit d and small e. This assumption allows the learner to generalize from training\u00a0examples to nearby points in input space. Many machine learning algorithms\u00a0leverage this idea, but it is insufficient to overcome the curse of dimensionality.",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5021",
    "text": "\u2022 \u00a0\u00a0\u00a0Linearity: Many learning algorithms assume that relationships between\u00a0some variables are linear. This allows the algorithm to make predictions even\u00a0very far from the observed data, but can sometimes lead to overly extreme\u00a0predictions. Most simple machine learning algorithms that do not make the\u00a0smoothness assumption instead make the linearity assumption. These are\u00a0in fact different assumptions\u2014linear functions with large weights applied\u00a0to high-dimensional spaces may not be very smooth. See Goodfellow et al.\u00a0(2014b) for a further discussion of the limitations of the linearity assumption.",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5022",
    "text": "\u2022 \u00a0\u00a0\u00a0Multiple explanatory factors: Many representation learning algorithms\u00a0are motivated by the assumption that the data is generated by multiple\u00a0underlying explanatory factors, and that most tasks can be solved easily\u00a0given the state of each of these factors. Sec. 15.3 describes how this view\u00a0motivates semi-supervised learning via representation learning. Learning\u00a0the structure of p( x) requires learning some of the same features that are\u00a0useful for modeling p(y | x) because both refer to the same underlying\u00a0explanatory factors. Sec. 15.4 describes how this view motivates the use of\u00a0distributed representations, with separate directions in representation space\u00a0corresponding to separate factors of variation.",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5023",
    "text": "\u2022 \u00a0\u00a0\u00a0Causal factors: the model is constructed in such a way that it treats the\u00a0factors of variation described by the learned representation h as the causes\u00a0of the observed data x, and not vice-versa. As discussed in Sec. 15.3, this\u00a0is advantageous for semi-supervised learning and makes the learned model\u00a0more robust when the distribution over the underlying causes changes or\u00a0when we use the model for a new task.",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5024",
    "text": "\u2022 Depth, or a hierarchical organization of explanatory factors: High-",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5025",
    "text": "level, abstract concepts can be defined in terms of simple concepts, forming a hierarchy. From another point of view, the use of a deep architecture expresses\u00a0our belief that the task should be accomplished via a multi-step program,\u00a0with each step referring back to the output of the processing accomplished\u00a0via previous steps.",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5026",
    "text": "\u2022 \u00a0\u00a0\u00a0Shared factors across tasks: In the context where we have many tasks,\u00a0corresponding to different y^ variables sharing the same input x or where\u00a0each task is associated with a subset or a function f(i)( x) of a global input\u00a0x, the assumption is that each y^ is associated with a different subset from a\u00a0common pool of relevant factors h. Because these subsets overlap, learning\u00a0all the P(yi | x) via a shared intermediate representation P(h | x) allows\u00a0sharing of statistical strength between the tasks.",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5027",
    "text": "\u2022 \u00a0\u00a0\u00a0Manifolds: Probability mass concentrates, and the regions in which it concentrates are locally connected and occupy a tiny volume. In the continuous\u00a0case, these regions can be approximated by low-dimensional manifolds with\u00a0a much smaller dimensionality than the original space where the data lives.\u00a0Many machine learning algorithms behave sensibly only on this manifold\u00a0(Goodfellow et al., 2014b). Some machine learning algorithms, especially\u00a0autoencoders, attempt to explicitly learn the structure of the manifold.",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5028",
    "text": "\u2022 \u00a0\u00a0\u00a0Natural clustering: Many machine learning algorithms assume that each\u00a0connected manifold in the input space may be assigned to a single class. The\u00a0data may lie on many disconnected manifolds, but the class remains constant\u00a0within each one of these. This assumption motivates a variety of learning\u00a0algorithms, including tangent propagation, double backprop, the manifold\u00a0tangent classifier and adversarial training.",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5029",
    "text": "\u2022 \u00a0\u00a0\u00a0Temporal and spatial coherence: Slow feature analysis and related\u00a0algorithms make the assumption that the most important explanatory factors\u00a0change slowly over time, or at least that it is easier to predict the true\u00a0underlying explanatory factors than to predict raw observations such as pixel\u00a0values. See Sec. 13.3 for further description of this approach.",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5030",
    "text": "\u2022 \u00a0\u00a0\u00a0Sparsity: Most features should presumably not be relevant to describing\u00a0most inputs\u2014there is no need to use a feature that detects elephant trunks\u00a0when representing an image of a cat. It is therefore reasonable to impose a\u00a0prior that any feature that can be interpreted as \u201cpresent\u201d or \u201cabsent\u201d should\u00a0be absent most of the time.",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5031",
    "text": "\u2022 \u00a0\u00a0\u00a0Simplicity of Factor Dependencies: In good high-level representations,",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5032",
    "text": "the factors are related to each other through simple dependencies. The simplest possible is marginal independence, P(h) =\u00a0\u00a0\u00a0\u00a0i P(hi), but linear\u00a0dependencies or those captured by a shallow autoencoder are also reasonable\u00a0assumptions. This can be seen in many laws of physics, and is assumed\u00a0when plugging a linear predictor or a factorized prior on top of a learned\u00a0representation.",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5033",
    "text": "The concept of representation learning ties together all of the many forms of deep learning. Feedforward and recurrent networks, autoencoders and deep\u00a0probabilistic models all learn and exploit representations. Learning the best\u00a0possible representation remains an exciting avenue of research.",
    "chapter": "",
    "chapter_id": "main-29.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5034",
    "text": "Deep learning draws upon many modeling formalisms that researchers can use to guide their design efforts and describe their algorithms. One of these formalisms is\u00a0the idea of structured probabilistic models. We have already discussed structured\u00a0probabilistic models briefly in Sec. 3.14. That brief presentation was sufficient to\u00a0understand how to use structured probabilistic models as a language to describe\u00a0some of the algorithms in Part II. Now, in Part III, structured probabilistic models\u00a0are a key ingredient of many of the most important research topics in deep learning.\u00a0In order to prepare to discuss these research ideas, this chapter describes structured\u00a0probabilistic models in much greater detail. This chapter is intended to be self-contained; the reader does not need to review the earlier introduction before\u00a0continuing with this chapter.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5035",
    "text": "A structured probabilistic model is a way of describing a probability distribution, using a graph to describe which random variables in the probability distribution\u00a0interact with each other directly. Here we use \u201cgraph\u201d in the graph theory sense\u2014a\u00a0set of vertices connected to one another by a set of edges. Because the structure of\u00a0the model is defined by a graph, these models are often also referred to as graphical\u00a0models.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5036",
    "text": "The graphical models research community is large and has developed many different models, training algorithms, and inference algorithms. In this chapter, we\u00a0provide basic background on some of the most central ideas of graphical models,\u00a0with an emphasis on the concepts that have proven most useful to the deep learning\u00a0research community. If you already have a strong background in graphical models,\u00a0you may wish to skip most of this chapter. However, even a graphical model expert\u00a0may benefit from reading the final section of this chapter, Sec. 16.7, in which we\u00a0highlight some of the unique ways that graphical models are used for deep learning\u00a0algorithms. Deep learning practitioners tend to use very different model structures,\u00a0learning algorithms and inference procedures than are commonly used by the rest\u00a0of the graphical models research community. In this chapter, we identify these\u00a0differences in preferences and explain the reasons for them.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5037",
    "text": "In this chapter we first describe the challenges of building large-scale probabilistic models. Next, we describe how to use a graph to describe the structure of a probability distribution. While this approach allows us to overcome many\u00a0challenges, it is not without its own complications. One of the major difficulties in\u00a0graphical modeling is understanding which variables need to be able to interact\u00a0directly, i.e., which graph structures are most suitable for a given problem. We\u00a0outline two approaches to resolving this difficulty by learning about the dependencies in Sec. 16.5. Finally, we close with a discussion of the unique emphasis that\u00a0deep learning practitioners place on specific approaches to graphical modeling in\u00a0Sec. 16.7.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5038",
    "text": "The goal of deep learning is to scale machine learning to the kinds of challenges needed to solve artificial intelligence. This means being able to understand highdimensional data with rich structure. For example, we would like AI algorithms to\u00a0be able to understand natural images,1 audio waveforms representing speech, and\u00a0documents containing multiple words and punctuation characters.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5039",
    "text": "Classification algorithms can take an input from such a rich high-dimensional distribution and summarize it with a categorical label\u2014what object is in a photo,\u00a0what word is spoken in a recording, what topic a document is about. The process\u00a0of classification discards most of the information in the input and produces a\u00a0single output (or a probability distribution over values of that single output). The\u00a0classifier is also often able to ignore many parts of the input. For example, when\u00a0recognizing an object in a photo, it is usually possible to ignore the background of\u00a0the photo.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5040",
    "text": "It is possible to ask probabilistic models to do many other tasks. These tasks are often more expensive than classification. Some of them require producing multiple\u00a0output values. Most require a complete understanding of the entire structure of",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5041",
    "text": "the input, with no option to ignore sections of it. These tasks include the following:",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5042",
    "text": "\u2022 \u00a0\u00a0\u00a0Density estimation: given an input x, the machine learning system returns an\u00a0estimate of the true density p(x) under the data generating distribution. This\u00a0requires only a single output, but it does require a complete understanding\u00a0of the entire input. If even one element of the vector is unusual, the system\u00a0must assign it a low probability.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5043",
    "text": "\u2022 \u00a0\u00a0\u00a0Denoising: given a damaged or incorrectly observed input X, the machine\u00a0learning system returns an estimate of the original or correct x. For example,\u00a0the machine learning system might be asked to remove dust or scratches\u00a0from an old photograph. This requires multiple outputs (every element of the\u00a0estimated clean example x) and an understanding of the entire input (since\u00a0even one damaged area will still reveal the final estimate as being damaged).",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5044",
    "text": "\u2022 \u00a0\u00a0\u00a0Missing value imputation: given the observations of some elements of x,\u00a0the model is asked to return estimates of or a probability distribution over\u00a0some or all of the unobserved elements of x. This requires multiple outputs.\u00a0Because the model could be asked to restore any of the elements of x, it\u00a0must understand the entire input.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5045",
    "text": "\u2022 \u00a0\u00a0\u00a0Sampling: the model generates new samples from the distribution p(x).\u00a0Applications include speech synthesis, i.e. producing new waveforms that\u00a0sound like natural human speech. This requires multiple output values and a\u00a0good model of the entire input. If the samples have even one element drawn\u00a0from the wrong distribution, then the sampling process is wrong.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5046",
    "text": "For an example of a sampling task using small natural images, see Fig. 16.1.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5047",
    "text": "Modeling a rich distribution over thousands or millions of random variables is a challenging task, both computationally and statistically. Suppose we only wanted\u00a0to model binary variables. This is the simplest possible case, and yet already it\u00a0seems overwhelming. For a small, 32 x 32 pixel color (RGB) image, there are 23072\u00a0possible binary images of this form. This number is over 10800 times larger than\u00a0the estimated number of atoms in the universe.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5048",
    "text": "In general, if we wish to model a distribution over a random vector x containing n discrete variables capable of taking on k values each, then the naive approach of\u00a0representing P (x) by storing a lookup table with one probability value per possible\u00a0outcome requires kn parameters!",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5049",
    "text": "This is not feasible for several reasons:",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5050",
    "text": "\u25a0\u05f3",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5051",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5052",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5053",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5054",
    "text": "K",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5055",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5056",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5057",
    "text": "y",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5058",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5059",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5060",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5061",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5062",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5063",
    "text": "V",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5064",
    "text": "1 *5",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5065",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5066",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5067",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5068",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5069",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5070",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5071",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5072",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5073",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5074",
    "text": "r \u05df",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5075",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5076",
    "text": "w.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5077",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5078",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5079",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5080",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5081",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5082",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5083",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5084",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5085",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5086",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5087",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5088",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5089",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5090",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5091",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5092",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5093",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5094",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5095",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5096",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5097",
    "text": "\u00abu-*",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5098",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5099",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5100",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5101",
    "text": "<5",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5102",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5103",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5104",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5105",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5106",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5107",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5108",
    "text": "\u25bc",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5109",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5110",
    "text": "It*",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5111",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5112",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5113",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5114",
    "text": "*",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5115",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5116",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5117",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5118",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5119",
    "text": "\u05d1",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5120",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5121",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5122",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5123",
    "text": "t.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5124",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5125",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5126",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5127",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5128",
    "text": "*\u25a0e",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5129",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5130",
    "text": "\u2014",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5131",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5132",
    "text": "m",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5133",
    "text": "\u2022\u05d9\u05d9 * '",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5134",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5135",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5136",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5137",
    "text": "\u05f3\u2022A*",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5138",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5139",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5140",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5141",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5142",
    "text": "jj",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5143",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5144",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5145",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5146",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5147",
    "text": "\u05d5\u05d3\u05d9\u05d5",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5148",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5149",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5150",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5151",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5152",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5153",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5154",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5155",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5156",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5157",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5158",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5159",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5160",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5161",
    "text": "&",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5162",
    "text": "\u05d3\u05be\u2022*.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5163",
    "text": "\\",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5164",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5165",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5166",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5167",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5168",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5169",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5170",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5171",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5172",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5173",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5174",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5175",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5176",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5177",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5178",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5179",
    "text": "Figure 16.1: Probabilistic modeling of natural images. (Top) Example 32x 32 pixel color images from the CIFAR-10 dataset (Krizhevsky and Hinton, 2009). (Bottom) Samples\u00a0drawn from a structured probabilistic model trained on this dataset. Each sample appears\u00a0at the same position in the grid as the training example that is closest to it in Euclidean\u00a0space. This comparison allows us to see that the model is truly synthesizing new images,\u00a0rather than memorizing the training data. Contrast of both sets of images has been\u00a0adjusted for display. Figure reproduced with permission from Courville et al. (2011).",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5180",
    "text": "\u2022 \u00a0\u00a0\u00a0Memory: the cost of storing the representation: For all but very\u00a0small values of n and k, representing the distribution as a table will require\u00a0too many values to store.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5181",
    "text": "\u2022 \u00a0\u00a0\u00a0Statistical efficiency: As the number of parameters in a model increases,\u00a0so does the amount of training data needed to choose the values of those\u00a0parameters using a statistical estimator. Because the table-based model\u00a0has an astronomical number of parameters, it will require an astronomically\u00a0large training set to fit accurately. Any such model will overfit the training\u00a0set very badly unless additional assumptions are made linking the different\u00a0entries in the table (for example, like in back-off or smoothed n-gram models,\u00a0Sec. 12.4.1).",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5182",
    "text": "\u2022 \u00a0\u00a0\u00a0Runtime: the cost of inference: Suppose we want to perform an inference\u00a0task where we use our model of the joint distribution P(x) to compute some\u00a0other distribution, such as the marginal distribution P(x!) or the conditional\u00a0distribution P(x2 | x!). Computing these distributions will require summing\u00a0across the entire table, so the runtime of these operations is as high as the\u00a0intractable memory cost of storing the model.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5183",
    "text": "\u2022 \u00a0\u00a0\u00a0Runtime: the cost of sampling: Likewise, suppose we want to draw a\u00a0sample from the model. The naive way to do this is to sample some value\u00a0u ~ U(0,1), then iterate through the table adding up the probability values\u00a0until they exceed u and return the outcome whose probability value was\u00a0added last. This requires reading through the whole table in the worst case,\u00a0so it has the same exponential cost as the other operations.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5184",
    "text": "The problem with the table-based approach is that we are explicitly modeling every possible kind of interaction between every possible subset of variables. The\u00a0probability distributions we encounter in real tasks are much simpler than this.\u00a0Usually, most variables influence each other only indirectly.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5185",
    "text": "For example, consider modeling the finishing times of a team in a relay race. Suppose the team consists of three runners: Alice, Bob and Carol. At the start of\u00a0the race, Alice carries a baton and begins running around a track. After completing\u00a0her lap around the track, she hands the baton to Bob. Bob then runs his own\u00a0lap and hands the baton to Carol, who runs the final lap. We can model each of\u00a0their finishing times as a continuous random variable. Alice\u2019s finishing time does\u00a0not depend on anyone else\u2019s, since she goes first. Bob\u2019s finishing time depends\u00a0on Alice\u2019s, because Bob does not have the opportunity to start his lap until Alice\u00a0has completed hers. If Alice finishes faster, Bob will finish faster, all else being\u00a0equal. Finally, Carol\u2019s finishing time depends on both her teammates. If Alice is\u00a0slow, Bob will probably finish late too. As a consequence, Carol will have quite a\u00a0late starting time and thus is likely to have a late finishing time as well. However,\u00a0Carol\u2019s finishing time depends only indirectly on Alice\u2019s finishing time via Bob\u2019s.\u00a0If we already know Bob\u2019s finishing time, we will not be able to estimate Carol\u2019s\u00a0finishing time better by finding out what Alice\u2019s finishing time was. This means\u00a0we can model the relay race using only two interactions: Alice\u2019s effect on Bob and\u00a0Bob\u2019s effect on Carol. We can omit the third, indirect interaction between Alice\u00a0and Carol from our model.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5186",
    "text": "Structured probabilistic models provide a formal framework for modeling only direct interactions between random variables. This allows the models to have\u00a0significantly fewer parameters which can in turn be estimated reliably from less\u00a0data. These smaller models also have dramatically reduced computational cost\u00a0in terms of storing the model, performing inference in the model, and drawing\u00a0samples from the model.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5187",
    "text": "Structured probabilistic models use graphs (in the graph theory sense of \u201cnodes\u201d or \u201cvertices\u201d connected by edges) to represent interactions between random variables.\u00a0Each node represents a random variable. Each edge represents a direct interaction.\u00a0These direct interactions imply other, indirect interactions, but only the direct\u00a0interactions need to be explicitly modeled.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5188",
    "text": "There is more than one way to describe the interactions in a probability distribution using a graph. In the following sections we describe some of the most\u00a0popular and useful approaches. Graphical models can be largely divided into\u00a0two categories: models based on directed acyclic graphs, and models based on\u00a0undirected graphs.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5189",
    "text": "One kind of structured probabilistic model is the directed graphical model, otherwise known as the belief network or Bayesian network2 (Pearl, 1985).",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5190",
    "text": "Directed graphical models are called \u201cdirected\u201d because their edges are directed,",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5191",
    "text": "Alice \u00a0\u00a0\u00a0Bob\u00a0\u00a0\u00a0\u00a0Carol",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5192",
    "text": "Figure 16.2: A directed graphical model depicting the relay race example. Alice\u2019s finishing time to influences Bob\u2019s finishing time t1, because Bob does not get to start running until\u00a0Alice finishes. Likewise, Carol only gets to start running after Bob finishes, so Bob\u2019s\u00a0finishing time t! directly influences Carol\u2019s finishing time t2-that is, they point from one vertex to another. This direction is represented in\u00a0the drawing with an arrow. The direction of the arrow indicates which variable\u2019s\u00a0probability distribution is defined in terms of the other\u2019s. Drawing an arrow from\u00a0a to b means that we define the probability distribution over b via a conditional\u00a0distribution, with a as one of the variables on the right side of the conditioning\u00a0bar. In other words, the distribution over b depends on the value of a.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5193",
    "text": "Continuing with the relay race example from Sec. 16.1, suppose we name Alice\u2019s finishing time to, Bob\u2019s finishing time t!, and Carol\u2019s finishing time t2. As we saw\u00a0earlier, our estimate of t! depends on to. Our estimate of t2 depends directly on t!\u00a0but only indirectly on to. We can draw this relationship in a directed graphical\u00a0model, illustrated in Fig. 16.2.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5194",
    "text": "Formally, a directed graphical model defined on variables x is defined by a directed acyclic graph G whose vertices are the random variables in the model, and\u00a0a set of local conditional probability distributions p(x^ | Pag(x^) where Pag(x^)\u00a0gives the parents of xi in G. The probability distribution over x is given by",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5195",
    "text": "p(x) = nip(xi | Pag(xi)). \u00a0\u00a0\u00a0(16.1)",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5196",
    "text": "In our relay race example, this means that, using the graph drawn in Fig. 16.2, p(t0, t1, t2) = p(t0)p(t! | t0)p(t2 | t!).\u00a0\u00a0\u00a0\u00a0(16.2)",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5197",
    "text": "This is our first time seeing a structured probabilistic model in action. We can examine the cost of using it, in order to observe how structured modeling has\u00a0many advantages relative to unstructured modeling.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5198",
    "text": "Suppose we represented time by discretizing time ranging from minute 0 to minute 10 into 6 second chunks. This would make to, t! and t2 each be discrete\u00a0variables with 100 possible values. If we attempted to represent p(t0, t!, t2) with a\u00a0table, it would need to store 999,999 values (100 values of to x 100 values oft 1 x\u00a0100 values of t2, minus 1, since the probability of one of the configurations is made\u00a0redundant by the constraint that the sum of the probabilities be 1). If instead, we\u00a0only make a table for each of the conditional probability distributions, then the\u00a0distribution over to requires 99 values, the table defining t! given to requires 9900\u00a0values, and so does the table defining t2 given t1. This comes to a total of 19,899\u00a0values. This means that using the directed graphical model reduced our number of\u00a0parameters by a factor of more than 50!",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5199",
    "text": "In general, to model n discrete variables each having k values, the cost of the single table approach scales like O(kn), as we have observed before. Now suppose\u00a0we build a directed graphical model over these variables. If m is the maximum\u00a0number of variables appearing (on either side of the conditioning bar) in a single\u00a0conditional probability distribution, then the cost of the tables for the directed\u00a0model scales like O(km). As long as we can design a model such that m << n, we\u00a0get very dramatic savings.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5200",
    "text": "In other words, so long as each variable has few parents in the graph, the distribution can be represented with very few parameters. Some restrictions on\u00a0the graph structure, such as requiring it to be a tree, can also guarantee that\u00a0operations like computing marginal or conditional distributions over subsets of\u00a0variables are efficient.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5201",
    "text": "It is important to realize what kinds of information can and cannot be encoded in the graph. The graph encodes only simplifying assumptions about which variables\u00a0are conditionally independent from each other. It is also possible to make other\u00a0kinds of simplifying assumptions. For example, suppose we assume Bob always\u00a0runs the same regardless of how Alice performed. (In reality, Alice\u2019s performance\u00a0probably influences Bob\u2019s performance\u2014depending on Bob\u2019s personality, if Alice\u00a0runs especially fast in a given race, this might encourage Bob to push hard and\u00a0match her exceptional performance, or it might make him overconfident and lazy).\u00a0Then the only effect Alice has on Bob\u2019s finishing time is that we must add Alice\u2019s\u00a0finishing time to the total amount of time we think Bob needs to run. This\u00a0observation allows us to define a model with O(k) parameters instead of O(k2).\u00a0However, note that to and t! are still directly dependent with this assumption,\u00a0because t! represents the absolute time at which Bob finishes, not the total time\u00a0he himself spends running. This means our graph must still contain an arrow from\u00a0to to t!. The assumption that Bob\u2019s personal running time is independent from\u00a0all other factors cannot be encoded in a graph over to, t!, and t2. Instead, we\u00a0encode this information in the definition of the conditional distribution itself. The\u00a0conditional distribution is no longer a k x k \u2014 1 element table indexed by to and t!\u00a0but is now a slightly more complicated formula using only k \u2014 1 parameters. The\u00a0directed graphical model syntax does not place any constraint on how we define\u00a0our conditional distributions. It only defines which variables they are allowed to\u00a0take in as arguments.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5202",
    "text": "Directed graphical models give us one language for describing structured probabilistic models. Another popular language is that of undirected models, otherwise known as Markov random fields (MRFs) or Markov networks (Kindermann, 1980).\u00a0As their name implies, undirected models use graphs whose edges are undirected.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5203",
    "text": "Directed models are most naturally applicable to situations where there is a clear reason to draw each arrow in one particular direction. Often these are\u00a0situations where we understand the causality and the causality only flows in one\u00a0direction. One such situation is the relay race example. Earlier runners affect the\u00a0finishing times of later runners; later runners do not affect the finishing times of\u00a0earlier runners.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5204",
    "text": "Not all situations we might want to model have such a clear direction to their interactions. When the interactions seem to have no intrinsic direction, or to\u00a0operate in both directions, it may be more appropriate to use an undirected model.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5205",
    "text": "As an example of such a situation, suppose we want to model a distribution over three binary variables: whether or not you are sick, whether or not your\u00a0coworker is sick, and whether or not your roommate is sick. As in the relay race\u00a0example, we can make simplifying assumptions about the kinds of interactions\u00a0that take place. Assuming that your coworker and your roommate do not know\u00a0each other, it is very unlikely that one of them will give the other a disease such as\u00a0a cold directly. This event can be seen as so rare that it is acceptable not to model\u00a0it. However, it is reasonably likely that either of them could give you a cold, and\u00a0that you could pass it on to the other. We can model the indirect transmission of\u00a0a cold from your coworker to your roommate by modeling the transmission of the\u00a0cold from your coworker to you and the transmission of the cold from you to your\u00a0roommate.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5206",
    "text": "In this case, it is just as easy for you to cause your roommate to get sick as it is for your roommate to make you sick, so there is not a clean, uni-directional\u00a0narrative on which to base the model. This motivates using an undirected model.\u00a0As with directed models, if two nodes in an undirected model are connected by an\u00a0edge, then the random variables corresponding to those nodes interact with each\u00a0other directly. Unlike directed models, the edge in an undirected model has no\u00a0arrow, and is not associated with a conditional probability distribution.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5207",
    "text": "We denote the random variable representing your health as hy, the random",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5208",
    "text": "\u00a9\u05be&)\u05be&",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5209",
    "text": "Figure 16.3: An undirected graph representing how your roommate\u2019s health hr, your health hy, and your work colleague\u2019s health h c affect each other. You and your roommate\u00a0might infect each other with a cold, and you and your work colleague might do the same,\u00a0but assuming that your roommate and your colleague do not know each other, they can\u00a0only infect each other indirectly via you.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5210",
    "text": "variable representing your roommate\u2019s health as hr, and the random variable representing your colleague\u2019s health as hc. See Fig. 16.3 for a drawing of the graph\u00a0representing this scenario.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5211",
    "text": "Formally, an undirected graphical model is a structured probabilistic model defined on an undirected graph Q. For each clique C in the graph,3 a factor rf>(C)\u00a0(also called a clique potential) measures the affinity of the variables in that clique\u00a0for being in each of their possible joint states. The factors are constrained to be\u00a0non-negative. Together they define an unnormalized probability distribution",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5212",
    "text": "-16.3",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5213",
    "text": "p(x) = nceG 0(C).",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5214",
    "text": "The unnormalized probability distribution is efficient to work with so long as all the cliques are small. It encodes the idea that states with higher affinity are\u00a0more likely. However, unlike in a Bayesian network, there is little structure to the\u00a0definition of the cliques, so there is nothing to guarantee that multiplying them\u00a0together will yield a valid probability distribution. See Fig. 16.4 for an example of\u00a0reading factorization information from an undirected graph.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5215",
    "text": "Our example of the cold spreading between you, your roommate, and your colleague contains two cliques. One clique contains hy and The factor for this\u00a0clique can be defined by a table, and might have values resembling these:",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5216",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5217",
    "text": "",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5218",
    "text": "o",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5219",
    "text": "II",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5220",
    "text": "hy = 1",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5221",
    "text": "hc",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5222",
    "text": "0",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5223",
    "text": "2",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5224",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5225",
    "text": "hc",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5226",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5227",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5228",
    "text": "10",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5229",
    "text": "A state of 1 indicates good health, while a state of 0 indicates poor health (having been infected with a cold). Both of you are usually healthy, so the",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5230",
    "text": "corresponding state has the highest affinity. The state where only one of you is sick has the lowest affinity, because this is a rare state. The state where both of\u00a0you are sick (because one of you has infected the other) is a higher affinity state,\u00a0though still not as common as the state where both are healthy.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5231",
    "text": "To complete the model, we would need to also define a similar factor for the clique containing hy and hr",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5232",
    "text": "While the unnormalized probability distribution is guaranteed to be non-negative everywhere, it is not guaranteed to sum or integrate to 1. To obtain a valid\u00a0probability distribution, we must use the corresponding normalized probability\u00a0distribution:4 5",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5233",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5234",
    "text": "P(x) = \u2014p(x) \u00a0\u00a0\u00a0(16.4)",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5235",
    "text": "where \u2014 is the value that results in the probability distribution summing or integrating to 1:",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5236",
    "text": "\u2014 = I p(x)dx. \u00a0\u00a0\u00a0(16.5)",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5237",
    "text": "You can think of \u2014 as a constant when the ^ functions are held constant. Note that if the ^ functions have parameters, then \u2014 is a function of those parameters.\u00a0It is common in the literature to write \u2014 with its arguments omitted to save space.\u00a0The normalizing constant \u2014 is known as the partition function, a term borrowed\u00a0from statistical physics.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5238",
    "text": "Since \u2014 is an integral or sum over all possible joint assignments of the state x it is often intractable to compute. In order to be able to obtain the normalized\u00a0probability distribution of an undirected model, the model structure and the\u00a0definitions of the ^ functions must be conducive to computing \u2014 efficiently. In\u00a0the context of deep learning, \u2014 is usually intractable. Due to the intractability\u00a0of computing \u2014 exactly, we must resort to approximations. Such approximate\u00a0algorithms are the topic of Chapter 18.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5239",
    "text": "One important consideration to keep in mind when designing undirected models is that it is possible to specify the factors in such a way that \u2014 does not exist.\u00a0This happens if some of the variables in the model are continuous and the integral\u00a0of p over their domain diverges. For example, suppose we want to model a single\u00a0scalar variable x G R with a single clique potential $(x) = x2. In this case,",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5240",
    "text": "Z = J x2dx. \u00a0\u00a0\u00a0(16.6)",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5241",
    "text": "Since this integral diverges, there is no probability distribution corresponding to this choice of ^ (x). Sometimes the choice of some parameter of the ^ functions\u00a0determines whether the probability distribution is defined. For example, for\u00a0^>(x; fi) = exp (-fix2), the fi parameter determines whether Z exists. Positive fi\u00a0results in a Gaussian distribution over x but all other values offi make ^ impossible\u00a0to normalize.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5242",
    "text": "One key difference between directed modeling and undirected modeling is that directed models are defined directly in terms of probability distributions from\u00a0the start, while undirected models are defined more loosely by ^ functions that\u00a0are then converted into probability distributions. This changes the intuitions one\u00a0must develop in order to work with these models. One key idea to keep in mind\u00a0while working with undirected models is that the domain of each of the variables\u00a0has dramatic effect on the kind of probability distribution that a given set of ^\u00a0functions corresponds to. For example, consider an n-dimensional vector-valued\u00a0random variable x and an undirected model parametrized by a vector of biases\u00a0b. Suppose we have one clique for each element of x, ^(i)(x^) =exp(b^). What\u00a0kind of probability distribution does this result in? The answer is that we do\u00a0not have enough information, because we have not yet specified the domain of x.\u00a0If x G Rn, then the integral defining Z diverges and no probability distribution\u00a0exists. If x G {0,1}n, then p(x) factorizes into n independent distributions, with\u00a0p(xi = 1) = sigmoid (bi). If the domain of x is the set of elementary basis vectors\u00a0({[1, 0,..., 0], [0,1,..., 0],..., [0,0,..., 1]} ) then p(x) = softmax(b), so a large\u00a0value of bi actually reduces p(xj = 1) for j = i. Often, it is possible to leverage\u00a0the effect of a carefully chosen domain of a variable in order to obtain complicated\u00a0behavior from a relatively simple set of ^ functions. We will explore a practical\u00a0application of this idea later, in Sec. 20.6.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5243",
    "text": "Many interesting theoretical results about undirected models depend on the assumption that Vx,p(x) > 0. A convenient way to enforce this condition is to use an energy-based model (EBM) where",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5244",
    "text": "p(x) = exp(-E (x)) \u00a0\u00a0\u00a0(16.7)",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5245",
    "text": "and E (x) is known as the energy function. Because exp(z) is positive for all z, this guarantees that no energy function will result in a probability of zero for any state x.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5246",
    "text": "Figure 16.4: \u00a0\u00a0\u00a0This graph implies that p(a, b, c, d, e, f) can be written as",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5247",
    "text": "Z ^a,b(a, b)$b,c(b, c)^a,d(a, d)^b,e(b, e)^e,f(e, f) for an appropriate choice of the ^ functions.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5248",
    "text": "Being completely free to choose the energy function makes learning simpler. If we learned the clique potentials directly, we would need to use constrained optimization\u00a0to arbitrarily impose some specific minimal probability value. By learning the\u00a0energy function, we can use unconstrained optimization.6 The probabilities in an\u00a0energy-based model can approach arbitrarily close to zero but never reach it.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5249",
    "text": "Any distribution of the form given by Eq. 16.7 is an example of a Boltzmann distribution. For this reason, many energy-based models are called Boltzmann\u00a0machines (Fahlman et al., 1983; Ackley et al., 1985; Hinton et al., 1984; Hinton\u00a0and Sejnowski, 1986). There is no accepted guideline for when to call a model an\u00a0energy-based model and when to call it a Boltzmann machine. The term Boltzmann\u00a0machine was first introduced to describe a model with exclusively binary variables,\u00a0but today many models such as the mean-covariance restricted Boltzmann machine\u00a0incorporate real-valued variables as well. While Boltzmann machines were originally\u00a0defined to encompass both models with and without latent variables, the term\u00a0Boltzmann machine is today most often used to designate models with latent\u00a0variables, while Boltzmann machines without latent variables are more often called\u00a0Markov random fields or log-linear models.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5250",
    "text": "Cliques in an undirected graph correspond to factors of the unnormalized probability function. Because exp(a) exp( b) = exp(a + b), this means that different\u00a0cliques in the undirected graph correspond to the different terms of the energy\u00a0function. In other words, an energy-based model is just a special kind of Markov\u00a0network: the exponentiation makes each term in the energy function correspond\u00a0to a factor for a different clique. See Fig. 16.5 for an example of how to read the\u00a0form of the energy function from an undirected graph structure. One can view an\u00a0energy-based model with multiple terms in its energy function as being a product\u00a0of experts (Hinton, 1999). Each term in the energy function corresponds to another\u00a0factor in the probability distribution. Each term of the energy function can be\u00a0thought of as an \u201cexpert\u201d that determines whether a particular soft constraint\u00a0is satisfied. Each expert may enforce only one constraint that concerns only\u00a0a low-dimensional projection of the random variables, but when combined by\u00a0multiplication of probabilities, the experts together enforce a complicated highdimensional constraint.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5251",
    "text": "One part of the definition of an energy-based model serves no functional purpose from a machine learning point of view: the \u2014 sign in Eq. 16.7. This\u00a0\u2014 sign could be incorporated into the definition of E, or for many functions E\u00a0the learning algorithm could simply learn parameters with opposite sign. The \u2014\u00a0sign is present primarily to preserve compatibility between the machine learning\u00a0literature and the physics literature. Many advances in probabilistic modeling\u00a0were originally developed by statistical physicists, for whom E refers to actual,\u00a0physical energy and does not have arbitrary sign. Terminology such as \u201cenergy\u201d\u00a0and \u201cpartition function\u201d remains associated with these techniques, even though\u00a0their mathematical applicability is broader than the physics context in which they\u00a0were developed. Some machine learning researchers (e.g., Smolensky (1986), who\u00a0referred to negative energy as harmony) have chosen to emit the negation, but this\u00a0is not the standard convention.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5252",
    "text": "Many algorithms that operate on probabilistic models do not need to compute pmodei (x) but only log pmode1(x). For energy-based models with latent variables h,\u00a0these algorithms are sometimes phrased in terms of the negative of this quantity,\u00a0called the free energy:",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5253",
    "text": "-16.8",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5254",
    "text": "Figure 16.5: This graph implies that E(a, b, c, d, e, f) can be written as Ea,b (a, b) + Eb,c(b, c) + Ea,d(a, d) + Eb,e(b, e) + Ee,f(e, f) for an appropriate choice of the per-clique\u00a0energy functions. Note that we can obtain the $ functions in Fig. 16.4 by setting each $\u00a0to the exponential of the corresponding negative energy, e.g., ^a,b( a, b) = exp(-E (a, b)).",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5255",
    "text": "F(x) = \u2014 log 5\u05be] exp (\u2014E(x, h)).",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5256",
    "text": "h",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5257",
    "text": "In this book, we usually prefer the more general log pmodei(x) formulation.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5258",
    "text": "(a) \u00a0\u00a0\u00a0(b)",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5259",
    "text": "Figure 16.6: (a) The path between random variablea and random variable b through s is active, because s is not observed. This means that a and b are not separated. (b) Here s\u00a0is shaded in, to indicate that it is observed. Because the only path between a and b is\u00a0through s, and that path is inactive, we can conclude that a and b are separated given s.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5260",
    "text": "The edges in a graphical model tell us which variables directly interact. We often need to know which variables indirectly interact. Some of these indirect interactions\u00a0can be enabled or disabled by observing other variables. More formally, we would\u00a0like to know which subsets of variables are conditionally independent from each\u00a0other, given the values of other subsets of variables.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5261",
    "text": "Identifying the conditional independences in a graph is very simple in the case of undirected models. In this case, conditional independence implied by the graph\u00a0is called separation. We say that a set of variables A is separated from another set\u00a0of variables B given a third set of variables S if the graph structure implies that A\u00a0is independent from B given S. If two variables a and b are connected by a path\u00a0involving only unobserved variables, then those variables are not separated. If no\u00a0path exists between them, or all paths contain an observed variable, then they are\u00a0separated. We refer to paths involving only unobserved variables as \u201cactive\u201d and\u00a0paths including an observed variable as \u201cinactive.\u201d",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5262",
    "text": "When we draw a graph, we can indicate observed variables by shading them in. See Fig. 16.6 for a depiction of how active and inactive paths in an undirected\u00a0model look when drawn in this way. See Fig. 16.7 for an example of reading\u00a0separation from an undirected graph.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5263",
    "text": "Similar concepts apply to directed models, except that in the context of directed models, these concepts are referred to as d-separation. The \u201cd\u201d stands for\u00a0\u201cdependence.\u201d D-separation for directed graphs is defined the same as separation\u00a0for undirected graphs: We say that a set of variables A is d-separated from another\u00a0set of variables B given a third set of variables S if the graph structure implies\u00a0that A is independent from B given S.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5264",
    "text": "As with undirected models, we can examine the independences implied by the graph by looking at what active paths exist in the graph. As before, two variables\u00a0are dependent if there is an active path between them, and d-separated if no such",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5265",
    "text": "Figure 16.7: An example of reading separation properties from an undirected graph. Here b is shaded to indicate that it is observed. Because observing b blocks the only path from\u00a0a to c, we say that a and c are separated from each other given b. The observation of b\u00a0also blocks one path between a and d, but there is a second, active path between them.\u00a0Therefore, a and d are not separated given b.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5266",
    "text": "path exists. In directed nets, determining whether a path is active is somewhat more complicated. See Fig. 16.8 for a guide to identifying active paths in a directed\u00a0model. See Fig. 16.9 for an example of reading some properties from a graph.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5267",
    "text": "It is important to remember that separation and d-separation tell us only about those conditional independences that are implied by the graph. There is no\u00a0requirement that the graph imply all independences that are present. In particular,\u00a0it is always legitimate to use the complete graph (the graph with all possible edges)\u00a0to represent any distribution. In fact, some distributions contain independences\u00a0that are not possible to represent with existing graphical notation. Context-specific\u00a0independences are independences that are present dependent on the value of some\u00a0variables in the network. For example, consider a model of three binary variables:\u00a0a, b and c. Suppose that when a is 0, b and c are independent, but when a is 1, b\u00a0is deterministically equal to c. Encoding the behavior when a = 1 requires an edge\u00a0connecting b and c. The graph then fails to indicate that b and c are independent\u00a0when a = 0.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5268",
    "text": "In general, a graph will never imply that an independence exists when it does not. However, a graph may fail to encode an independence.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5269",
    "text": "We often refer to a specific machine learning model as being undirected or directed. For example, we typically refer to RBMs as undirected and sparse coding as directed.\u00a0This choice of wording can be somewhat misleading, because no probabilistic\u00a0model is inherently directed or undirected. Instead, some models are most easily\u00a0described using a directed graph, or most easily described using an undirected\u00a0graph.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5270",
    "text": "Figure 16.8: All of the kinds of active paths of length two that can exist between random variables a and b. (a) Any path with arrows proceeding directly from a to b or vice versa.\u00a0This kind of path becomes blocked if s is observed. We have already seen this kind of\u00a0path in the relay race example. (b) a and b are connected by a common cause s. For\u00a0example, suppose s is a variable indicating whether or not there is a hurricane and a and\u00a0b measure the wind speed at two different nearby weather monitoring outposts. If we\u00a0observe very high winds at station a, we might expect to also see high winds at b. This\u00a0kind of path can be blocked by observing s. If we already know there is a hurricane, we\u00a0expect to see high winds at b, regardless of what is observed at a. A lower than expected\u00a0wind at a (for a hurricane) would not change our expectation of winds at b (knowing\u00a0there is a hurricane). However, if s is not observed, then a and b are dependent, i.e.,\u00a0the path is active. (c) a and b are both parents ofs. This is called a V-structure or the\u00a0collider case. The V-structure causes a and b to be related by the explaining away effect.\u00a0In this case, the path is actually active when s is observed. For example, suppose s is a\u00a0variable indicating that your colleague is not at work. The variable a represents her being\u00a0sick, while b represents her being on vacation. If you observe that she is not at work,\u00a0you can presume she is probably sick or on vacation, but it is not especially likely that\u00a0both have happened at the same time. If you find out that she is on vacation, this fact\u00a0is sufficient to explain her absence. You can infer that she is probably not also sick. (d)\u00a0The explaining away effect happens even if any descendant of s is observed! For example,\u00a0suppose that c is a variable representing whether you have received a report from your\u00a0colleague. If you notice that you have not received the report, this increases your estimate\u00a0of the probability that she is not at work today, which in turn makes it more likely that\u00a0she is either sick or on vacation. The only way to block a path through a V-structure is\u00a0to observe none of the descendants of the shared child.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5271",
    "text": "Figure 16.9: From this graph, we can read out several d-separation properties. Examples include:",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5272",
    "text": "\u2022 \u00a0\u00a0\u00a0a and b are d-separated given the empty set.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5273",
    "text": "\u2022 \u00a0\u00a0\u00a0a and e are d-separated given c.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5274",
    "text": "\u2022 \u00a0\u00a0\u00a0d and e are d-separated given c.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5275",
    "text": "We can also see that some variables are no longer d-separated when we observe some variables:",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5276",
    "text": "\u2022 \u00a0\u00a0\u00a0a and b are not d-separated given c.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5277",
    "text": "\u2022 \u00a0\u00a0\u00a0a and b are not d-separated given d.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5278",
    "text": "Figure 16.10: Examples of complete graphs, which can describe any probability distribution. Here we show examples with four random variables. (Left) The complete undirected graph.\u00a0In the undirected case, the complete graph is unique. (Right) A complete directed graph.\u00a0In the directed case, there is not a unique complete graph. We choose an ordering of the\u00a0variables and draw an arc from each variable to every variable that comes after it in the\u00a0ordering. There are thus a factorial number of complete graphs for every set of random\u00a0variables. In this example we order the variables from left to right, top to bottom.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5279",
    "text": "Directed models and undirected models both have their advantages and disadvantages. Neither approach is clearly superior and universally preferred. Instead, we should choose which language to use for each task. This choice will partially\u00a0depend on which probability distribution we wish to describe. We may choose to\u00a0use either directed modeling or undirected modeling based on which approach can\u00a0capture the most independences in the probability distribution or which approach\u00a0uses the fewest edges to describe the distribution. There are other factors that\u00a0can affect the decision of which language to use. Even while working with a single\u00a0probability distribution, we may sometimes switch between different modeling\u00a0languages. Sometimes a different language becomes more appropriate if we observe\u00a0a certain subset of variables, or if we wish to perform a different computational\u00a0task. For example, the directed model description often provides a straightforward\u00a0approach to efficiently draw samples from the model (described in Sec. 16.3) while\u00a0the undirected model formulation is often useful for deriving approximate inference\u00a0procedures (as we will see in Chapter 19, where the role of undirected models is\u00a0highlighted in Eq. 19.56).",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5280",
    "text": "Every probability distribution can be represented by either a directed model or by an undirected model. In the worst case, one can always represent any\u00a0distribution by using a \u201ccomplete graph.\u201d In the case of a directed model, the\u00a0complete graph is any directed acyclic graph where we impose some ordering on\u00a0the random variables, and each variable has all other variables that precede it in\u00a0the ordering as its ancestors in the graph. For an undirected model, the complete\u00a0graph is simply a graph containing a single clique encompassing all of the variables.\u00a0See Fig. 16.10 for an example.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5281",
    "text": "Of course, the utility of a graphical model is that the graph implies that some variables do not interact directly. The complete graph is not very useful because it\u00a0does not imply any independences.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5282",
    "text": "When we represent a probability distribution with a graph, we want to choose a graph that implies as many independences as possible, without implying any\u00a0independences that do not actually exist.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5283",
    "text": "From this point of view, some distributions can be represented more efficiently using directed models, while other distributions can be represented more efficiently\u00a0using undirected models. In other words, directed models can encode some\u00a0independences that undirected models cannot encode, and vice versa.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5284",
    "text": "Directed models are able to use one specific kind of substructure that undirected models cannot represent perfectly. This substructure is called an immorality. The\u00a0structure occurs when two random variables a and b are both parents of a third\u00a0random variable c, and there is no edge directly connecting a and b in either\u00a0direction. (The name \u201cimmorality\u201d may seem strange; it was coined in the graphical\u00a0models literature as a joke about unmarried parents.) To convert a directed model\u00a0with graph D into an undirected model, we need to create a new graph U. For\u00a0every pair of variables x and y, we add an undirected edge connecting x and y to\u00a0U if there is a directed edge (in either direction) connecting x and y in D or if x\u00a0and y are both parents in D of a third variable z. The resulting U is known as\u00a0a moralized graph. See Fig. 16.11 for examples of converting directed models to\u00a0undirected models via moralization.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5285",
    "text": "Likewise, undirected models can include substructures that no directed model can represent perfectly. Specifically, a directed graph D cannot capture all of the\u00a0conditional independences implied by an undirected graph U if U contains a loop\u00a0of length greater than three, unless that loop also contains a chord. A loop is\u00a0a sequence of variables connected by undirected edges, with the last variable in\u00a0the sequence connected back to the first variable in the sequence. A chord is a\u00a0connection between any two non-consecutive variables in the sequence defining a\u00a0loop. If U has loops of length four or greater and does not have chords for these\u00a0loops, we must add the chords before we can convert it to a directed model. Adding\u00a0these chords discards some of the independence information that was encoded in\u00a0U. The graph formed by adding chords to U is known as a chordal or triangulated\u00a0graph, because all the loops can now be described in terms of smaller, triangular\u00a0loops. To build a directed graph D from the chordal graph, we need to also assign\u00a0directions to the edges. When doing so, we must not create a directed cycle in\u00a0D, or the result does not define a valid directed probabilistic model. One way\u00a0to assign directions to the edges in D is to impose an ordering on the random",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5286",
    "text": "Figure 16.12: Converting an undirected model to a directed model. (Left) This undirected model cannot be converted directed to a directed model because it has a loop of length four\u00a0with no chords. Specifically, the undirected model encodes two different independences that\u00a0no directed model can capture simultaneously: aTc | {b, d} and bTd | {a, c}. (Center)\u00a0To convert the undirected model to a directed model, we must triangulate the graph,\u00a0by ensuring that all loops of greater than length three have a chord. To do so, we can\u00a0either add an edge connecting a and c or we can add an edge connecting b and d. In this\u00a0example, we choose to add the edge connecting a and c. (Right) To finish the conversion\u00a0process, we must assign a direction to each edge. When doing so, we must not create any\u00a0directed cycles. One way to avoid directed cycles is to impose an ordering over the nodes,\u00a0and always point each edge from the node that comes earlier in the ordering to the node\u00a0that comes later in the ordering. In this example, we use the variable names to impose\u00a0alphabetical order.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5287",
    "text": "variables, then point each edge from the node that comes earlier in the ordering to the node that comes later in the ordering. See Fig. 16.12 for a demonstration.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5288",
    "text": "Factor graphs are another way of drawing undirected models that resolve an ambiguity in the graphical representation of standard undirected model syntax.\u00a0In an undirected model, the scope of every ^ function must be a subset of some\u00a0clique in the graph. However, it is not necessary that there exist any ^ whose\u00a0scope contains the entirety of every clique. Factor graphs explicitly represent the\u00a0scope of each ^ function. Specifically, a factor graph is a graphical representation\u00a0of an undirected model that consists of a bipartite undirected graph. Some of the\u00a0nodes are drawn as circles. These nodes correspond to random variables as in a\u00a0standard undirected model. The rest of the nodes are drawn as squares. These\u00a0nodes correspond to the factors ^ of the unnormalized probability distribution.\u00a0Variables and factors may be connected with undirected edges. A variable and a\u00a0factor are connected in the graph if and only if the variable is one of the arguments\u00a0to the factor in the unnormalized probability distribution. No factor may be\u00a0connected to another factor in the graph, nor can a variable be connected to a",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5289",
    "text": "variable. See Fig. 16.13 for an example of how factor graphs can resolve ambiguity in the interpretation of undirected networks.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5290",
    "text": "Figure 16.13: An example of how a factor graph can resolve ambiguity in the interpretation of undirected networks. (Left) An undirected network with a clique involving three\u00a0variables: a, b and c. (Center) A factor graph corresponding to the same undirected\u00a0model. This factor graph has one factor over all three variables. (Right) Another valid\u00a0factor graph for the same undirected model. This factor graph has three factors, each\u00a0over only two variables. Representation, inference, and learning are all asymptotically\u00a0cheaper in this factor graph than in the factor graph depicted in the center, even though\u00a0both require the same undirected graph to represent.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5291",
    "text": "Graphical models also facilitate the task of drawing samples from a model.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5292",
    "text": "One advantage of directed graphical models is that a simple and efficient procedure called ancestral sampling can produce a sample from the joint distribution\u00a0represented by the model.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5293",
    "text": "The basic idea is to sort the variables x* in the graph into a topological ordering, so that for all i and j, j is greater than i if xi is a parent of xj. The variables\u00a0can then be sampled in this order. In other words, we first sample x! ~ P(x 1),\u00a0then sample P(x2 | Pag(x2)), and so on, until finally we sample P(xn | Pag(xn)).\u00a0So long as each conditional distribution p( x^ | Pag (xi)) is easy to sample from,\u00a0then the whole model is easy to sample from. The topological sorting operation\u00a0guarantees that we can read the conditional distributions in Eq.16.1 and sample\u00a0from them in order. Without the topological sorting, we might attempt to sample\u00a0a variable before its parents are available.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5294",
    "text": "For some graphs, more than one topological ordering is possible. Ancestral sampling may be used with any of these topological orderings.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5295",
    "text": "Ancestral sampling is generally very fast (assuming sampling from each conditional is easy) and convenient.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5296",
    "text": "One drawback to ancestral sampling is that it only applies to directed graphical models. Another drawback is that it does not support every conditional sampling\u00a0operation. When we wish to sample from a subset of the variables in a directed\u00a0graphical model, given some other variables, we often require that all the conditioning variables come earlier than the variables to be sampled in the ordered graph.\u00a0In this case, we can sample from the local conditional probability distributions\u00a0specified by the model distribution. Otherwise, the conditional distributions we\u00a0need to sample from are the posterior distributions given the observed variables.\u00a0These posterior distributions are usually not explicitly specified and parametrized\u00a0in the model. Inferring these posterior distributions can be costly. In models where\u00a0this is the case, ancestral sampling is no longer efficient.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5297",
    "text": "Unfortunately, ancestral sampling is applicable only to directed models. We can sample from undirected models by converting them to directed models, but this\u00a0often requires solving intractable inference problems (to determine the marginal\u00a0distribution over the root nodes of the new directed graph) or requires introducing\u00a0so many edges that the resulting directed model becomes intractable. Sampling\u00a0from an undirected model without first converting it to a directed model seems to\u00a0require resolving cyclical dependencies. Every variable interacts with every other\u00a0variable, so there is no clear beginning point for the sampling process. Unfortunately,\u00a0drawing samples from an undirected graphical model is an expensive, multi-pass\u00a0process. The conceptually simplest approach is Gibbs sampling. Suppose we\u00a0have a graphical model over an n-dimensional vector of random variables x. We\u00a0iteratively visit each variable xi and draw a sample conditioned on all of the other\u00a0variables, from p(xi | x-i). Due to the separation properties of the graphical\u00a0model, we can equivalently condition on only the neighbors ofxi. Unfortunately,\u00a0after we have made one pass through the graphical model and sampled all n\u00a0variables, we still do not have a fair sample from p(x). Instead, we must repeat the\u00a0process and resample all n variables using the updated values of their neighbors.\u00a0Asymptotically, after many repetitions, this process converges to sampling from\u00a0the correct distribution. It can be difficult to determine when the samples have\u00a0reached a sufficiently accurate approximation of the desired distribution. Sampling\u00a0techniques for undirected models are an advanced topic, covered in more detail in\u00a0Chapter 17.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5298",
    "text": "Figure 16.11: Examples of converting directed models (top row) to undirected models (bottom row) by constructing moralized graphs. (Left) This simple chain can be converted\u00a0to a moralized graph merely by replacing its directed edges with undirected edges. The\u00a0resulting undirected model implies exactly the same set of independences and conditional\u00a0independences. (Center) This graph is the simplest directed model that cannot be\u00a0converted to an undirected model without losing some independences. This graph consists\u00a0entirely of a single immorality. Because a and b are parents of c, they are connected by an\u00a0active path when c is observed. To capture this dependence, the undirected model must\u00a0include a clique encompassing all three variables. This clique fails to encode the fact that\u00a0aTb. (Right) In general, moralization may add many edges to the graph, thus losing many\u00a0implied independences. For example, this sparse coding graph requires adding moralizing\u00a0edges between every pair of hidden units, thus introducing a quadratic number of new\u00a0direct dependences.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5299",
    "text": "The primary advantage of using structured probabilistic models is that they allow us to dramatically reduce the cost of representing probability distributions as well\u00a0as learning and inference. Sampling is also accelerated in the case of directed\u00a0models, while the situation can be complicated with undirected models. The\u00a0primary mechanism that allows all of these operations to use less runtime and\u00a0memory is choosing to not model certain interactions. Graphical models convey\u00a0information by leaving edges out. Anywhere there is not an edge, the model\u00a0specifies the assumption that we do not need to model a direct interaction.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5300",
    "text": "A less quantifiable benefit of using structured probabilistic models is that they allow us to explicitly separate representation of knowledge from learning of\u00a0knowledge or inference given existing knowledge. This makes our models easier to\u00a0develop and debug. We can design, analyze, and evaluate learning algorithms and\u00a0inference algorithms that are applicable to broad classes of graphs. Independently,\u00a0we can design models that capture the relationships we believe are important in our\u00a0data. We can then combine these different algorithms and structures and obtain\u00a0a Cartesian product of different possibilities. It would be much more difficult to\u00a0design end-to-end algorithms for every possible situation.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5301",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5302",
    "text": " A natural image is an image that might be captured by a camera in a reasonably ordinary environment, as opposed to a synthetically rendered image, a screenshot of a web page, etc.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5303",
    "text": "2",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5304",
    "text": " Judea Pearl suggested using the term \u201cBayesian network\u201d when one wishes to \u201cemphasize the judgmental\u201d nature of the values computed by the network, i.e. to highlight that they usually\u00a0represent degrees of belief rather than frequencies of events.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5305",
    "text": "3",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5306",
    "text": " A clique of the graph is a subset of nodes that are all connected to each other by an edge of\u00a0the graph.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5307",
    "text": "4",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5308",
    "text": " A distribution defined by normalizing a product of clique potentials is also called a Gibbs",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5309",
    "text": "5",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5310",
    "text": "distribution.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5311",
    "text": "6",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5312",
    "text": " For some models, we may still need to use constrained optimization to make sure Z exists.",
    "chapter": "",
    "chapter_id": "main-30.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5313",
    "text": "A good generative model needs to accurately capture the distribution over the observed or \u201cvisible\u201d variables v. Often the different elements of v are highly\u00a0dependent on each other. In the context of deep learning, the approach most\u00a0commonly used to model these dependencies is to introduce several latent or\u00a0\u201chidden\u201d variables, h. The model can then capture dependencies between any pair\u00a0of variables v and vj indirectly, via direct dependencies between v and h, and\u00a0direct dependencies between h and vj.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5314",
    "text": "A good model of v which did not contain any latent variables would need to have very large numbers of parents per node in a Bayesian network or very large\u00a0cliques in a Markov network. Just representing these higher order interactions is\u00a0costly\u2014both in a computational sense, because the number of parameters that\u00a0must be stored in memory scales exponentially with the number of members in a\u00a0clique, but also in a statistical sense, because this exponential number of parameters\u00a0requires a wealth of data to estimate accurately.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5315",
    "text": "When the model is intended to capture dependencies between visible variables with direct connections, it is usually infeasible to connect all variables, so the graph\u00a0must be designed to connect those variables that are tightly coupled and omit\u00a0edges between other variables. An entire field of machine learning called structure\u00a0learning is devoted to this problem For a good reference on structure learning, see\u00a0(Koller and Friedman, 2009). Most structure learning techniques are a form of\u00a0greedy search. A structure is proposed, a model with that structure is trained,\u00a0then given a score. The score rewards high training set accuracy and penalizes\u00a0model complexity. Candidate structures with a small number of edges added or\u00a0removed are then proposed as the next step of the search. The search proceeds to\u00a0a new structure that is expected to increase the score.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5316",
    "text": "Using latent variables instead of adaptive structure avoids the need to perform discrete searches and multiple rounds of training. A fixed structure over visible\u00a0and hidden variables can use direct interactions between visible and hidden units\u00a0to impose indirect interactions between visible units. Using simple parameter\u00a0learning techniques we can learn a model with a fixed structure that imputes the\u00a0right structure on the marginal p(v).",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5317",
    "text": "Latent variables have advantages beyond their role in efficiently capturing p(v). The new variables h also provide an alternative representation for v. For example,\u00a0as discussed in Sec. 3.9.6, the mixture of Gaussians model learns a latent variable\u00a0that corresponds to which category of examples the input was drawn from. This\u00a0means that the latent variable in a mixture of Gaussians model can be used to do\u00a0classification. In Chapter 14 we saw how simple probabilistic models like sparse\u00a0coding learn latent variables that can be used as input features for a classifier,\u00a0or as coordinates along a manifold. Other models can be used in this same way,\u00a0but deeper models and models with different kinds of interactions can create even\u00a0richer descriptions of the input. Many approaches accomplish feature learning\u00a0by learning latent variables. Often, given some model of v and h, experimental\u00a0observations show that E[h | v] or argmax^p(h, v) is a good feature mapping for\u00a0v.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5318",
    "text": "One of the main ways we can use a probabilistic model is to ask questions about how variables are related to each other. Given a set of medical tests, we can ask\u00a0what disease a patient might have. In a latent variable model, we might want to\u00a0extract features E[h | v ] describing the observed variables v. Sometimes we need\u00a0to solve such problems in order to perform other tasks. We often train our models\u00a0using the principle of maximum likelihood. Because",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5319",
    "text": "logp(v) = Eh~p(h|v) [logP(h, v) - 10gP(h \\ v)] , \u00a0\u00a0\u00a0(16.9)",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5320",
    "text": "we often want to compute p(h | v) in order to implement a learning rule. All of these are examples of inference problems in which we must predict the value of\u00a0some variables given other variables, or predict the probability distribution over\u00a0some variables given the value of other variables.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5321",
    "text": "Unfortunately, for most interesting deep models, these inference problems are intractable, even when we use a structured graphical model to simplify them. The\u00a0graph structure allows us to represent complicated, high-dimensional distributions\u00a0with a reasonable number of parameters, but the graphs used for deep learning are\u00a0usually not restrictive enough to also allow efficient inference.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5322",
    "text": "It is straightforward to see that computing the marginal probability of a general graphical model is #P hard. The complexity class #P is a generalization of the\u00a0complexity class NP. Problems in NP require determining only whether a problem\u00a0has a solution and finding a solution if one exists. Problems in #P require counting\u00a0the number of solutions. To construct a worst-case graphical model, imagine that\u00a0we define a graphical model over the binary variables in a 3-SAT problem. We\u00a0can impose a uniform distribution over these variables. We can then add one\u00a0binary latent variable per clause that indicates whether each clause is satisfied.\u00a0We can then add another latent variable indicating whether all of the clauses are\u00a0satisfied. This can be done without making a large clique, by building a reduction\u00a0tree of latent variables, with each node in the tree reporting whether two other\u00a0variables are satisfied. The leaves of this tree are the variables for each clause.\u00a0The root of the tree reports whether the entire problem is satisfied. Due to the\u00a0uniform distribution over the literals, the marginal distribution over the root of the\u00a0reduction tree specifies what fraction of assignments satisfy the problem. While\u00a0this is a contrived worst-case example, NP hard graphs commonly arise in practical\u00a0real-world scenarios.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5323",
    "text": "This motivates the use of approximate inference. In the context of deep learning, this usually refers to variational inference, in which we approximate the\u00a0true distribution p(h | v) by seeking an approximate distribution q(h|v) that is as\u00a0close to the true one as possible. This and other techniques are described in depth\u00a0in Chapter 19.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5324",
    "text": "Deep learning practitioners generally use the same basic computational tools as other machine learning practitioners who work with structured probabilistic models.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5325",
    "text": "However, in the context of deep learning, we usually make different design decisions about how to combine these tools, resulting in overall algorithms and models that\u00a0have a very different flavor from more traditional graphical models.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5326",
    "text": "Deep learning does not always involve especially deep graphical models. In the context of graphical models, we can define the depth of a model in terms of the\u00a0graphical model graph rather than the computational graph. We can think of a\u00a0latent variable hi as being at depth j if the shortest path from hi to an observed\u00a0variable is j steps. We usually describe the depth of the model as being the greatest\u00a0depth of any such hi. This kind of depth is different from the depth induced by\u00a0the computational graph. Many generative models used for deep learning have no\u00a0latent variables or only one layer of latent variables, but use deep computational\u00a0graphs to define the conditional distributions within a model.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5327",
    "text": "Deep learning essentially always makes use of the idea of distributed representations. Even shallow models used for deep learning purposes (such as pretraining shallow models that will later be composed to form deep ones) nearly always\u00a0have a single, large layer of latent variables. Deep learning models typically have\u00a0more latent variables than observed variables. Complicated nonlinear interactions\u00a0between variables are accomplished via indirect connections that flow through\u00a0multiple latent variables.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5328",
    "text": "By contrast, traditional graphical models usually contain mostly variables that are at least occasionally observed, even if many of the variables are missing at\u00a0random from some training examples. Traditional models mostly use higher-order\u00a0terms and structure learning to capture complicated nonlinear interactions between\u00a0variables. If there are latent variables, they are usually few in number.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5329",
    "text": "The way that latent variables are designed also differs in deep learning. The deep learning practitioner typically does not intend for the latent variables to\u00a0take on any specific semantics ahead of time\u2014the training algorithm is free to\u00a0invent the concepts it needs to model a particular dataset. The latent variables are\u00a0usually not very easy for a human to interpret after the fact, though visualization\u00a0techniques may allow some rough characterization of what they represent. When\u00a0latent variables are used in the context of traditional graphical models, they are\u00a0often designed with some specific semantics in mind\u2014the topic of a document,\u00a0the intelligence of a student, the disease causing a patient\u2019s symptoms, etc. These\u00a0models are often much more interpretable by human practitioners and often have\u00a0more theoretical guarantees, yet are less able to scale to complex problems and are\u00a0not reusable in as many different contexts as deep models.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5330",
    "text": "Another obvious difference is the kind of connectivity typically used in the deep learning approach. Deep graphical models typically have large groups of units\u00a0that are all connected to other groups of units, so that the interactions between\u00a0two groups may be described by a single matrix. Traditional graphical models\u00a0have very few connections and the choice of connections for each variable may be\u00a0individually designed. The design of the model structure is tightly linked with\u00a0the choice of inference algorithm. Traditional approaches to graphical models\u00a0typically aim to maintain the tractability of exact inference. When this constraint\u00a0is too limiting, a popular approximate inference algorithm is an algorithm called\u00a0loopy belief propagation. Both of these approaches often work well with very\u00a0sparsely connected graphs. By comparison, models used in deep learning tend to\u00a0connect each visible unit v to very many hidden units hj, so that h can provide a\u00a0distributed representation of v (and probably several other observed variables too).\u00a0Distributed representations have many advantages, but from the point of view\u00a0of graphical models and computational complexity, distributed representations\u00a0have the disadvantage of usually yielding graphs that are not sparse enough for\u00a0the traditional techniques of exact inference and loopy belief propagation to be\u00a0relevant. As a consequence, one of the most striking differences between the larger\u00a0graphical models community and the deep graphical models community is that\u00a0loopy belief propagation is almost never used for deep learning. Most deep models\u00a0are instead designed to make Gibbs sampling or variational inference algorithms\u00a0efficient. Another consideration is that deep learning models contain a very large\u00a0number of latent variables, making efficient numerical code essential. This provides\u00a0an additional motivation, besides the choice of high-level inference algorithm, for\u00a0grouping the units into layers with a matrix describing the interaction between\u00a0two layers. This allows the individual steps of the algorithm to be implemented\u00a0with efficient matrix product operations, or sparsely connected generalizations, like\u00a0block diagonal matrix products or convolutions.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5331",
    "text": "Finally, the deep learning approach to graphical modeling is characterized by a marked tolerance of the unknown. Rather than simplifying the model until\u00a0all quantities we might want can be computed exactly, we increase the power of\u00a0the model until it is just barely possible to train or use. We often use models\u00a0whose marginal distributions cannot be computed, and are satisfied simply to draw\u00a0approximate samples from these models. We often train models with an intractable\u00a0objective function that we cannot even approximate in a reasonable amount of\u00a0time, but we are still able to approximately train the model if we can efficiently\u00a0obtain an estimate of the gradient of such a function. The deep learning approach\u00a0is often to figure out what the minimum amount of information we absolutely\u00a0need is, and then to figure out how to get a reasonable approximation of that\u00a0information as quickly as possible.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5332",
    "text": "Figure 16.14: An RBM drawn as a Markov network.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5333",
    "text": "The restricted Boltzmann machine (RBM) (Smolensky, 1986) or harmonium is the quintessential example of how graphical models are used for deep learning. The\u00a0RBM is not itself a deep model. Instead, it has a single layer of latent variables\u00a0that may be used to learn a representation for the input. In Chapter 20, we will\u00a0see how RBMs can be used to build many deeper models. Here, we show how the\u00a0RBM exemplifies many of the practices used in a wide variety of deep graphical\u00a0models: its units are organized into large groups called layers, the connectivity\u00a0between layers is described by a matrix, the connectivity is relatively dense, the\u00a0model is designed to allow efficient Gibbs sampling, and the emphasis of the model\u00a0design is on freeing the training algorithm to learn latent variables whose semantics\u00a0were not specified by the designer. Later, in Sec. 20.2, we will revisit the RBM in\u00a0more detail.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5334",
    "text": "The canonical RBM is an energy-based model with binary visible and hidden units. Its energy function is",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5335",
    "text": "E(v, h) = \u2014bv \u2014 cTh \u2014 v Wh, \u00a0\u00a0\u00a0(16.10)",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5336",
    "text": "where b, c, and W are unconstrained, real-valued, learnable parameters. We can see that the model is divided into two groups of units: v and h, and the interaction\u00a0between them is described by a matrix W. The model is depicted graphically\u00a0in Fig. 16.14. As this figure makes clear, an important aspect of this model is\u00a0that there are no direct interactions between any two visible units or between any\u00a0two hidden units (hence the \u201crestricted,\u201d a general Boltzmann machine may have\u00a0arbitrary connections).",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5337",
    "text": "The restrictions on the RBM structure yield the nice properties",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5338",
    "text": "p(h | v) = np(hi | v) \u00a0\u00a0\u00a0(16.11)",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5339",
    "text": "and",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5340",
    "text": "p(v 1 h) = nip(v i 1 h). \u00a0\u00a0\u00a0(16.12)",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5341",
    "text": "MiJ?\u05f37tunooutni \u05d2\u05d2?0)\u00a3->??\u05f4)??\u05d2?\u05e1?8\u05d2#)<&\u05d3\u00a0\u05d2 \u05d2 n Uq ? \u05be1 n \u05d2 uo8 \u05e6 u \u05dc",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5342",
    "text": "\u05d2\u05d2?>,)\u00a3\u05be)8*\u05f4) Uinonn^ \u05e6\u05d2\u05d9)\u05d9}?\u05be1 Uinon ntn?",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5343",
    "text": "Figure 16.15: Samples from a trained RBM, and its weights. Image reproduced with permission from LISA (2008). (Left) Samples from a model trained on MNIST, drawn\u00a0using Gibbs sampling. Each column is a separate Gibbs sampling process. Each row\u00a0represents the output of another 1,000 steps of Gibbs sampling. Successive samples are\u00a0highly correlated with one another. (Right) The corresponding weight vectors. Compare\u00a0this to the samples and weights of a linear factor model, shown in Fig. 13.2. The samples\u00a0here are much better because the RBM priorp(h) is not constrained to be factorial. The\u00a0RBM can learn which features should appear together when sampling. On the other hand,\u00a0the RBM posterior p(h | v) is factorial, while the sparse coding posterior p(h | v) is not,\u00a0so the sparse coding model may be better for feature extraction. Other models are able\u00a0to have both a non-factorial p(h) and a non-factorial p(h | v).",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5344",
    "text": "The individual conditionals are simple to compute as well. For the binary RBM we obtain:",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5345",
    "text": "-16.13",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5346",
    "text": "-16.14",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5347",
    "text": "Together these properties allow for efficient block Gibbs sampling, which alternates between sampling all of h simultaneously and sampling all of v simultaneously.\u00a0Samples generated by Gibbs sampling from an RBM model are shown in Fig.\u00a016.15.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5348",
    "text": "Since the energy function itself is just a linear function of the parameters, it is easy to take derivatives of the energy function. For example,",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5349",
    "text": "-16.15",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5350",
    "text": "P(hi = 1 | v) = a vTW,\u05be + b, ,",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5351",
    "text": "P(h, = 0 | v) = 1 - a vTW:,, + b, \u00a0\u00a0\u00a0.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5352",
    "text": "E(v, h) = \u2014v,hj.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5353",
    "text": "d",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5354",
    "text": "\u05e0,,",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5355",
    "text": "dWi",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5356",
    "text": "These two properties\u2014efficient Gibbs sampling and efficient derivatives\u2014make training convenient. In Chapter 18, we will see that undirected models may be\u00a0trained by computing such derivatives applied to samples from the model.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5357",
    "text": "Training the model induces a representation h of the data v. We can often use Eh~p(h|v) [h] as a set of features to describe v.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5358",
    "text": "Overall, the RBM demonstrates the typical deep learning approach to graphical models: representation learning accomplished via layers of latent variables, combined with efficient interactions between layers parametrized by matrices.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5359",
    "text": "The language of graphical models provides an elegant, flexible and clear language for describing probabilistic models. In the chapters ahead, we use this language,\u00a0among other perspectives, to describe a wide variety of deep probabilistic models.",
    "chapter": "",
    "chapter_id": "main-31.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5360",
    "text": "Randomized algorithms fall into two rough categories: Las Vegas algorithms and Monte Carlo algorithms. Las Vegas algorithms always return precisely the correct\u00a0answer (or report that they failed). These algorithms consume a random amount\u00a0of resources, usually memory or time. In contrast, Monte Carlo algorithms return\u00a0answers with a random amount of error. The amount of error can typically be\u00a0reduced by expending more resources (usually running time and memory). For any\u00a0fixed computational budget, a Monte Carlo algorithm can provide an approximate\u00a0answer.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5361",
    "text": "Many problems in machine learning are so difficult that we can never expect to obtain precise answers to them. This excludes precise deterministic algorithms and\u00a0Las Vegas algorithms. Instead, we must use deterministic approximate algorithms\u00a0or Monte Carlo approximations. Both approaches are ubiquitous in machine\u00a0learning. In this chapter, we focus on Monte Carlo methods.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5362",
    "text": "Many important technologies used to accomplish machine learning goals are based on drawing samples from some probability distribution and using these samples to\u00a0form a Monte Carlo estimate of some desired quantity.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5363",
    "text": "There are many reasons that we may wish to draw samples from a probability distribution. Sampling provides a flexible way to approximate many sums and\u00a0integrals at reduced cost. Sometimes we use this to provide a significant speedup to\u00a0a costly but tractable sum, as in the case when we subsample the full training cost\u00a0with minibatches. In other cases, our learning algorithm requires us to approximate\u00a0an intractable sum or integral, such as the gradient of the log partition function of\u00a0an undirected model. In many other cases, sampling is actually our goal, in the\u00a0sense that we want to train a model that can sample from the training distribution.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5364",
    "text": "When a sum or an integral cannot be computed exactly (for example the sum has an exponential number of terms and no exact simplification is known) it is\u00a0often possible to approximate it using Monte Carlo sampling. The idea is to view\u00a0the sum or integral as if it was an expectation under some distribution and to",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5365",
    "text": "approximate the expectation by a corresponding average. Let",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5366",
    "text": "s = ^ p(x)/(x) = ep [/ (x)] \u00a0\u00a0\u00a0(m)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5367",
    "text": "X",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5368",
    "text": "or",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5369",
    "text": "s = J p(x)/(x)dx = E p[/(x)] \u00a0\u00a0\u00a0(17.2)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5370",
    "text": "be the sum or integral to estimate, rewritten as an expectation, with the constraint that p is a probability distribution (for the sum) or a probability density (for the\u00a0integral) over random variable x.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5371",
    "text": "We can approximate s by drawing n samples x(1),..., x(n) from p and then forming the empirical average",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5372",
    "text": "1 n",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5373",
    "text": "Sn = \u00a0\u00a0\u00a0(x(i)).\u00a0\u00a0\u00a0\u00a0(17.3)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5374",
    "text": "i=1",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5375",
    "text": "This approximation is justified by a few different properties. The first trivial observation is that the estimator s is unbiased, since",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5376",
    "text": "nn",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5377",
    "text": "E[Sn ] =- \u00a0\u00a0\u00a0E[/(x(i))] = - s = s.\u00a0\u00a0\u00a0\u00a0(17.4)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5378",
    "text": "nn",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5379",
    "text": "i= 1 \u00a0\u00a0\u00a0i= 1",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5380",
    "text": "But in addition, the law of large numbers states that if the samples x(i) are i.i.d., then the average converges almost surely to the expected value:",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5381",
    "text": "lim sn = s, \u00a0\u00a0\u00a0(17.5)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5382",
    "text": "provided that the variance of the individual terms, Var [f (x(i))], is bounded. To see this more clearly, consider the variance of Sn as n increases. The variance Var[Sn]\u00a0decreases and converges to 0, so long as Var[f (x(i))] < to:",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5383",
    "text": "Var[Sn ]",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5384",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5385",
    "text": "n",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5386",
    "text": "J]Var[f (x)]",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5387",
    "text": "i=1",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5388",
    "text": "Var[f (x)]",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5389",
    "text": "n",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5390",
    "text": "-17.6",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5391",
    "text": "-17.7",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5392",
    "text": "This convenient result also tells us how to estimate the uncertainty in a Monte Carlo average or equivalently the amount of expected error of the Monte Carlo\u00a0approximation. We compute both the empirical average of the f (x(i)) and their\u00a0empirical variance,1 and then divide the estimated variance by the number of\u00a0samples n to obtain an estimator of Var[Sn]. The central limit theorem tells us that\u00a0the distribution of the average, Sn, converges to a normal distribution with mean s\u00a0and variance Var[f (x)]. This allows us to estimate confidence intervals around the",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5393",
    "text": "n",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5394",
    "text": "estimate Sn, using the cumulative distribution of the normal density.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5395",
    "text": "However, all this relies on our ability to easily sample from the base distribution p(x), but doing so is not always possible. When it is not feasible to sample from\u00a0p, an alternative is to use importance sampling, presented in Sec. 17.2. A more\u00a0general approach is to form a sequence of estimators that converge towards the\u00a0distribution of interest. That is the approach of Monte Carlo Markov chains\u00a0(Sec. 17.3).",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5396",
    "text": "An important step in the decomposition of the integrand (or summand) used by the Monte Carlo method in Eq. 17.2 is deciding which part of the integrand should\u00a0play the role the probability p(x) and which part of the integrand should play the\u00a0role of the quantity f (x) whose expected value (under that probability distribution)\u00a0is to be estimated. There is no unique decomposition because p(x)f (x) can always\u00a0be rewritten as",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5397",
    "text": "p(x)f (x) = q(x)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5398",
    "text": "-17.8",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5399",
    "text": "p(x)f (x)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5400",
    "text": "q(x) where we now sample from q and average pf. In many cases, we wish to compute\u00a0an expectation for a given p and an f, and the fact that the problem is specified\u00a0from the start as an expectation suggests that this p and f would be a natural\u00a0choice of decomposition. However, the original specification of the problem may\u00a0not be the the optimal choice in terms of the number of samples required to obtain\u00a0a given level of accuracy. Fortunately, the form of the optimal choice q* can be\u00a0derived easily. The optimal q* corresponds to what is called optimal importance\u00a0sampling.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5401",
    "text": "Because of the identity shown in Eq. 17.8, any Monte Carlo estimator",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5402",
    "text": "-17.9",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5403",
    "text": "Sp = n \u00a0\u00a0\u00a0f (x(i))",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5404",
    "text": "i=1,x",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5405",
    "text": "can be transformed into an importance sampling estimator",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5406",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5407",
    "text": "n",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5408",
    "text": "p(x(i))f (x(i))",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5409",
    "text": "q(x(i))",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5410",
    "text": "-17.1",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5411",
    "text": "q! xw 1",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5412",
    "text": "i=1,xW ~q",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5413",
    "text": "We see readily that the expected value of the estimator does not depend on q:",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5414",
    "text": "Eq [Sq] = Eq[Sp] = S. \u00a0\u00a0\u00a0(17.11)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5415",
    "text": "However, the variance of an importance sampling estimator can be greatly sensitive to the choice of q. The variance is given by",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5416",
    "text": "-17.12",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5417",
    "text": "-17.13",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5418",
    "text": "Var[Sq ] = Var[ p(x.)f(x)]/n.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5419",
    "text": "q(x)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5420",
    "text": "The minimum variance occurs when q is",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5421",
    "text": "q*(x) = hf,",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5422",
    "text": "where Z is the normalization constant, chosen so that q* (x) sums or integrates to 1 as appropriate. Better importance sampling distributions put more weight where\u00a0the integrand is larger. In fact, when f (x) does not change sign, Var [Sq*] = 0,\u00a0meaning that a single sample is sufficient when the optimal distribution is\u00a0used. Of course, this is only because the computation of q* has essentially solved\u00a0the original problem, so it is usually not practical to use this approach of drawing\u00a0a single sample from the optimal distribution.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5423",
    "text": "Any choice of sampling distribution q is valid (in the sense of yielding the correct expected value) and q* is the optimal one (in the sense of yielding minimum\u00a0variance). Sampling from q* is usually infeasible, but other choices of q can be\u00a0feasible while still reducing the variance somewhat.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5424",
    "text": "Another approach is to use biased importance sampling, which has the advantage of not requiring normalized p or q. In the case of discrete variables, the\u00a0biased importance sampling estimator is given by",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5425",
    "text": "En",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5426",
    "text": "i\u2014 1",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5427",
    "text": "sBIS =",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5428",
    "text": "p(x(i)) q(x(l))",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5429",
    "text": "n \u00a0\u00a0\u00a0p(x",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5430",
    "text": "i\u20141 q 1 x",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5431",
    "text": "f (*\u05f4>)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5432",
    "text": "n \u00a0\u00a0\u00a0p(x(i))",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5433",
    "text": "q(xW)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5434",
    "text": "En",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5435",
    "text": "i\u20141",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5436",
    "text": "-17.14",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5437",
    "text": "n p(x(l)) f (x(i))",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5438",
    "text": "i\u20141 q(X-i)) f (X )",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5439",
    "text": "En",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5440",
    "text": "i\u20141",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5441",
    "text": "p(x(l)) q(x W)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5442",
    "text": "n \u00a0\u00a0\u00a0p ( x",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5443",
    "text": "i\u20141 q 1 x",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5444",
    "text": "-17.15",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5445",
    "text": "-17.16",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5446",
    "text": "\\^n p(x(i)) f (x(i)) i\u20141 q(xil)) f (\u00a0\u00a0\u00a0\u00a0)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5447",
    "text": "En",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5448",
    "text": "i\u20141",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5449",
    "text": "n p(x(i)) i\u20141 q(x (i))",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5450",
    "text": "where p and q are the unnormalized forms ofp and q and the x(i) are the samples from q. This estimator is biased because E[sbis] = s, except asymptotically when\u00a0n \u2014\u2014 x and the denominator of Eq. 17.14 converges to 1. Hence this estimator is\u00a0called asymptotically unbiased.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5451",
    "text": "Although a good choice of q can greatly improve the efficiency of Monte Carlo estimation, a poor choice of q can make the efficiency much worse. Going back\u00a0to Eq. 17.12, we see that if there are samples of q for which\u00a0then the variance of the estimator can get very large. This may happen when\u00a0q(x) is tiny while neither p(x) nor f (x) are small enough to cancel it. The q\u00a0distribution is usually chosen to be a very simple distribution so that it is easy\u00a0to sample from. When x is high-dimensional, this simplicity in q causes it to\u00a0match p or p|f | poorly. When q(x(i) ) \u00bb p(x(i))|f( x(i)) |, importance sampling\u00a0collects useless samples (summing tiny numbers or zeros). On the other hand, when\u00a0q(x(i)) ^ p(x (i))lf ( x(i) )|, which will happen more rarely, the ratio can be huge.\u00a0Because these latter events are rare, they may not show up in a typical sample,\u00a0yielding typical underestimation of s, compensated rarely by gross overestimation.\u00a0Such very large or very small numbers are typical when x is high dimensional,\u00a0because in high dimension the dynamic range of joint probabilities can be very\u00a0large.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5452",
    "text": "In spite of this danger, importance sampling and its variants have been found very useful in many machine learning algorithms, including deep learning algorithms.\u00a0For example, see the use of importance sampling to accelerate training in neural\u00a0language models with a large vocabulary (Sec. 12.4.3.3) or other neural nets\u00a0with a large number of outputs. See also how importance sampling has been\u00a0used to estimate a partition function (the normalization constant of a probability\u00a0distribution) in Sec. 18.7, and to estimate the log-likelihood in deep directed models\u00a0such as the variational autoencoder, in Sec. 20.10.3. Importance sampling may\u00a0also be used to improve the estimate of the gradient of the cost function used to\u00a0train model parameters with stochastic gradient descent, particularly for models\u00a0such as classifiers where most of the total value of the cost function comes from a\u00a0small number of misclassified examples. Sampling more difficult examples more\u00a0frequently can reduce the variance of the gradient in such cases (Hinton, 2006).",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5453",
    "text": "In many cases, we wish to use a Monte Carlo technique but there is no tractable method for drawing exact samples from the distribution pmode1 (x) or from a good\u00a0(low variance) importance sampling distribution q (x). In the context of deep\u00a0learning, this most often happens when pmode1(x) is represented by an undirected\u00a0model. In these cases, we introduce a mathematical tool called a Markov chain to\u00a0approximately sample from pmode1(x). The family of algorithms that use Markov\u00a0chains to perform Monte Carlo estimates is called Markov chain Monte Carlo\u00a0methods (MCMC). Markov chain Monte Carlo methods for machine learning are\u00a0described at greater length in Koller and Friedman (2009). The most standard,\u00a0generic guarantees for MCMC techniques are only applicable when the model\u00a0does not assign zero probability to any state. Therefore, it is most convenient\u00a0to present these techniques as sampling from an energy-based model (EBM)\u00a0p(x) rc exp (\u2014E(x)) as described in Sec. 16.2.4. In the EBM formulation, every\u00a0state is guaranteed to have non-zero probability. MCMC methods are in fact\u00a0more broadly applicable and can be used with many probability distributions that\u00a0contain zero probability states. However, the theoretical guarantees concerning the\u00a0behavior of MCMC methods must be proven on a case-by-case basis for different\u00a0families of such distributions. In the context of deep learning, it is most common\u00a0to rely on the most general theoretical guarantees that naturally apply to all\u00a0energy-based models.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5454",
    "text": "To understand why drawing samples from an energy-based model is difficult, consider an EBM over just two variables, defining a distribution p(a, b). In order\u00a0to sample a, we must draw a from p(a | b), and in order to sample b, we must\u00a0draw it from p(b | a). It seems to be an intractable chicken-and-egg problem.\u00a0Directed models avoid this because their graph is directed and acyclic. To perform\u00a0ancestral sampling one simply samples each of the variables in topological order,\u00a0conditioning on each variable\u2019s parents, which are guaranteed to have already been\u00a0sampled (Sec. 16.3). Ancestral sampling defines an efficient, single-pass method of\u00a0obtaining a sample.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5455",
    "text": "In an EBM, we can avoid this chicken and egg problem by sampling using a Markov chain. The core idea of a Markov chain is to have a state x that begins\u00a0as an arbitrary value. Over time, we randomly update x repeatedly. Eventually\u00a0x becomes (very nearly) a fair sample from p( x). Formally, a Markov chain is\u00a0defined by a random state x and a transition distribution T(x' | x) specifying\u00a0the probability that a random update will go to state x' if it starts in state x.\u00a0Running the Markov chain means repeatedly updating the state x to a value x'\u00a0sampled from T(X | x).",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5456",
    "text": "To gain some theoretical understanding of how MCMC methods work, it is useful to reparametrize the problem. First, we restrict our attention to the case\u00a0where the random variable x has countably many states. In this case, we can\u00a0represent the state as just a positive integer x. Different integer values of x map\u00a0back to different states x in the original problem.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5457",
    "text": "Consider what happens when we run infinitely many Markov chains in parallel. All of the states of the different Markov chains are drawn from some distribution\u00a0q(t)(x), where t indicates the number of time steps that have elapsed. At the\u00a0beginning, q(0) is some distribution that we used to arbitrarily initialize x for each\u00a0Markov chain. Later, q(t) is influenced by all of the Markov chain steps that have\u00a0run so far. Our goal is for q(t) (x) to converge to p(x).",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5458",
    "text": "Because we have reparametrized the problem in terms of positive integer x, we can describe the probability distribution q using a vector v, with",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5459",
    "text": "q(x = i) = Vi. \u00a0\u00a0\u00a0(17.17)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5460",
    "text": "Consider what happens when we update a single Markov chain\u2019s state x to a new state x'. The probability of a single state landing in state 2/ is given by",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5461",
    "text": "q(t+1)(x') = \u00a0\u00a0\u00a0q(t) (x)T(x' | x).\u00a0\u00a0\u00a0\u00a0(17.18)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5462",
    "text": "X",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5463",
    "text": "Using our integer parametrization, we can represent the effect of the transition operator T using a matrix A. We define A so that",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5464",
    "text": "Ai,j = T(x' = i | x = j). \u00a0\u00a0\u00a0(17.19)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5465",
    "text": "Using this definition, we can now rewrite Eq. 17.18. Rather than writing it in terms of q and T to understand how a single state is updated, we may now use v\u00a0and A to describe how the entire distribution over all the different Markov chains\u00a0run in parallel shifts as we apply an update:",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5466",
    "text": "v(t) = Av(t-1). \u00a0\u00a0\u00a0(17.20)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5467",
    "text": "Applying the Markov chain update repeatedly corresponds to multiplying by the matrix A repeatedly. In other words, we can think of the process as exponentiating\u00a0the matrix A:",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5468",
    "text": "v(t) = Atv(0). \u00a0\u00a0\u00a0(17.21)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5469",
    "text": "The matrix A has special structure because each of its columns represents a probability distribution. Such matrices are called stochastic matrices. If there is\u00a0a non-zero probability of transitioning from any state x to any other state x' for\u00a0some power t, then the Perron-Frobenius theorem (Perron, 1907; Frobenius, 1908)\u00a0guarantees that the largest eigenvalue is real and equal to 1. Over time, we can\u00a0see that all of the eigenvalues are exponentiated:",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5470",
    "text": "v(t) = (Vdiag(A)V1\u05be^ v(0) = Vdiag(A)*V-1 v(0). \u00a0\u00a0\u00a0(17.22)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5471",
    "text": "This process causes all of the eigenvalues that are not equal to 1 to decay to zero. Under some additional mild conditions, A is guaranteed to have only\u00a0one eigenvector with eigenvalue 1. The process thus converges to a stationary\u00a0distribution, sometimes also called the equilibrium distribution. At convergence,",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5472",
    "text": "v' = Av = v, \u00a0\u00a0\u00a0(17.23)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5473",
    "text": "and this same condition holds for every additional step. This is an eigenvector equation. To be a stationary point, v must be an eigenvector with corresponding\u00a0eigenvalue 1. This condition guarantees that once we have reached the stationary\u00a0distribution, repeated applications of the transition sampling procedure do not\u00a0change the distribution over the states of all the various Markov chains (although\u00a0transition operator does change each individual state, of course).",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5474",
    "text": "If we have chosen T correctly, then the stationary distribution q will be equal to the distribution p we wish to sample from. We will describe how to choose T\u00a0shortly, in Sec. 17.4.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5475",
    "text": "Most properties of Markov Chains with countable states can be generalized to continuous variables. In this situation, some authors call the Markov Chain\u00a0a Harris chain but we use the term Markov Chain to describe both conditions.\u00a0In general, a Markov chain with transition operator T will converge, under mild\u00a0conditions, to a fixed point described by the equation",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5476",
    "text": "q'(x') = Ex^qT(x' | x), \u00a0\u00a0\u00a0(17.24)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5477",
    "text": "which in the discrete case is just rewriting Eq. 17.23. When x is discrete, the expectation corresponds to a sum, and when x is continuous, the expectation\u00a0corresponds to an integral.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5478",
    "text": "Regardless of whether the state is continuous or discrete, all Markov chain methods consist of repeatedly applying stochastic updates until eventually the state\u00a0begins to yield samples from the equilibrium distribution. Running the Markov\u00a0chain until it reaches its equilibrium distribution is called \u201c burning in\"\" the Markov\u00a0chain. After the chain has reached equilibrium, a sequence of infinitely many\u00a0samples may be drawn from from the equilibrium distribution. They are identically\u00a0distributed but any two successive samples will be highly correlated with each other.\u00a0A finite sequence of samples may thus not be very representative of the equilibrium\u00a0distribution. One way to mitigate this problem is to return only every n successive\u00a0samples, so that our estimate of the statistics of the equilibrium distribution is\u00a0not as biased by the correlation between an MCMC sample and the next several\u00a0samples. Markov chains are thus expensive to use because of the time required to\u00a0burn in to the equilibrium distribution and the time required to transition from\u00a0one sample to another reasonably decorrelated sample after reaching equilibrium.\u00a0If one desires truly independent samples, one can run multiple Markov chains\u00a0in parallel. This approach uses extra parallel computation to eliminate latency.\u00a0The strategy of using only a single Markov chain to generate all samples and the\u00a0strategy of using one Markov chain for each desired sample are two extremes; deep\u00a0learning practitioners usually use a number of chains that is similar to the number\u00a0of examples in a minibatch and then draw as many samples as are needed from\u00a0this fixed set of Markov chains. A commonly used number of Markov chains is 100.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5479",
    "text": "Another difficulty is that we do not know in advance how many steps the Markov chain must run before reaching its equilibrium distribution. This length of\u00a0time is called the mixing time. It is also very difficult to test whether a Markov\u00a0chain has reached equilibrium. We do not have a precise enough theory for guiding\u00a0us in answering this question. Theory tells us that the chain will converge, but not\u00a0much more. If we analyze the Markov chain from the point of view of a matrix A\u00a0acting on a vector of probabilities v, then we know that the chain mixes when A*\u00a0has effectively lost all of the eigenvalues from A besides the unique eigenvalue of 1.\u00a0This means that the magnitude of the second largest eigenvalue will determine the\u00a0mixing time. However, in practice, we cannot actually represent our Markov chain\u00a0in terms of a matrix. The number of states that our probabilistic model can visit\u00a0is exponentially large in the number of variables, so it is infeasible to represent\u00a0v, A, or the eigenvalues of A. Due to these and other obstacles, we usually do\u00a0not know whether a Markov chain has mixed. Instead, we simply run the Markov\u00a0chain for an amount of time that we roughly estimate to be sufficient, and use\u00a0heuristic methods to determine whether the chain has mixed. These heuristic\u00a0methods include manually inspecting samples or measuring correlations between\u00a0successive samples.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5480",
    "text": "So far we have described how to draw samples from a distribution q(x) by repeatedly updating x ^ x'\u00a0\u00a0\u00a0\u00a0T(x' | x). However, we have not described how to ensure that",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5481",
    "text": "q(x) is a useful distribution. Two basic approaches are considered in this book. The first one is to derive T from a given learned pmode1, described below with the\u00a0case of sampling from EBMs. The second one is to directly parametrize T and\u00a0learn it, so that its stationary distribution implicitly defines the pmode1 of interest.\u00a0Examples of this second approach are discussed in Sec. 20.12 and Sec. 20.13.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5482",
    "text": "In the context of deep learning, we commonly use Markov chains to draw samples from an energy-based model defining a distributionpmode1 (x). In this case,\u00a0we want the q(x) for the Markov chain to be pmode1 (x). To obtain the desired\u00a0q(x), we must choose an appropriate T(x' | x).",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5483",
    "text": "A conceptually simple and effective approach to building a Markov chain that samples from pmode1(x) is to use Gibbs sampling, in which sampling from\u00a0T(x' | x) is accomplished by selecting one variable x^ and sampling it from pmode1\u00a0conditioned on its neighbors in the undirected graph G defining the structure of\u00a0the energy-based model. It is also possible to sample several variables at the same\u00a0time so long as they are conditionally independent given all of their neighbors. As\u00a0shown in the RBM example in Sec. 16.7.1, all of the hidden units of an RBM may\u00a0be sampled simultaneously because they are conditionally independent from each\u00a0other given all of the visible units. Likewise, all of the visible units may be sampled\u00a0simultaneously because they are conditionally independent from each other given\u00a0all of the hidden units. Gibbs sampling approaches that update many variables\u00a0simultaneously in this way are called block Gibbs sampling.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5484",
    "text": "Alternate approaches to designing Markov chains to sample from p mode1 are possible. For example, the Metropolis-Hastings algorithm is widely used in other\u00a0disciplines. In the context of the deep learning approach to undirected modeling,\u00a0it is rare to use any approach other than Gibbs sampling. Improved sampling\u00a0techniques are one possible research frontier.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5485",
    "text": "The primary difficulty involved with MCMC methods is that they have a tendency to mix poorly. Ideally, successive samples from a Markov chain designed to sample\u00a0from p(x) would be completely independent from each other and would visit many\u00a0different regions in x space proportional to their probability. Instead, especially\u00a0in high dimensional cases, MCMC samples become very correlated. We refer",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5486",
    "text": "to such behavior as slow mixing or even failure to mix. MCMC methods with slow mixing can be seen as inadvertently performing something resembling noisy\u00a0gradient descent on the energy function, or equivalently noisy hill climbing on the\u00a0probability, with respect to the state of the chain (the random variables being\u00a0sampled). The chain tends to take small steps (in the space of the state of the\u00a0Markov chain), from a configuration x(t-1) to a configuration x(t), with the energy\u00a0E(x(t)) generally lower or approximately equal to the energy E(x(t-1)), with a\u00a0preference for moves that yield lower energy configurations. When starting from a\u00a0rather improbable configuration (higher energy than the typical ones from p (x)),\u00a0the chain tends to gradually reduce the energy of the state and only occasionally\u00a0move to another mode. Once the chain has found a region of low energy (for\u00a0example, if the variables are pixels in an image, a region of low energy might be\u00a0a connected manifold of images of the same object), which we call a mode, the\u00a0chain will tend to walk around that mode (following a kind of random walk). Once\u00a0in a while it will step out of that mode and generally return to it or (if it finds\u00a0an escape route) move towards another mode. The problem is that successful\u00a0escape routes are rare for many interesting distributions, so the Markov chain will\u00a0continue to sample the same mode longer than it should.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5487",
    "text": "This is very clear when we consider the Gibbs sampling algorithm (Sec. 17.4). In this context, consider the probability of going from one mode to a nearby\u00a0mode within a given number of steps. What will determine that probability is\u00a0the shape of the \u201cenergy barrier\u201d between these modes. Transitions between two\u00a0modes that are separated by a high energy barrier (a region of low probability)\u00a0are exponentially less likely (in terms of the height of the energy barrier). This is\u00a0illustrated in Fig. 17.1. The problem arises when there are multiple modes with\u00a0high probability that are separated by regions of low probability, especially when\u00a0each Gibbs sampling step must update only a small subset of variables whose\u00a0values are largely determined by the other variables.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5488",
    "text": "As a simple example, consider an energy-based model over two variables a and b, which are both binary with a sign, taking on values \u20141 and 1. If E(a, b) = \u2014wab\u00a0for some large positive number w, then the model expresses a strong belief that a\u00a0and b have the same sign. Consider updating b using a Gibbs sampling step with\u00a0a = 1. The conditional distribution over b is given by P( b = 1 | a = 1) = a (w).\u00a0If w is large, the sigmoid saturates, and the probability of also assigning b to be\u00a01 is close to 1. Likewise, if a = \u20141, the probability of assigning b to be \u20141 is\u00a0close to 1. According to Pmode1 (a, b), both signs of both variables are equally likely.\u00a0According to Pmodei (a | b), both variables should have the same sign. This means\u00a0that Gibbs sampling will only very rarely flip the signs of these variables.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5489",
    "text": "Figure 17.1: Paths followed by Gibbs sampling for three distributions, with the Markov chain initialized at the mode in both cases. (Left) A multivariate normal distribution\u00a0with two independent variables. Gibbs sampling mixes well because the variables are\u00a0independent. (Center) A multivariate normal distribution with highly correlated variables.\u00a0The correlation between variables makes it difficult for the Markov chain to mix. Because\u00a0each variable must be updated conditioned on the other, the correlation reduces the rate\u00a0at which the Markov chain can move away from the starting point. (Right) A mixture of\u00a0Gaussians with widely separated modes that are not axis-aligned. Gibbs sampling mixes\u00a0very slowly because it is difficult to change modes while altering only one variable at a\u00a0time.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5490",
    "text": "In more practical scenarios, the challenge is even greater because we care not only about making transitions between two modes but more generally between\u00a0all the many modes that a real model might contain. If several such transitions\u00a0are difficult because of the difficulty of mixing between modes, then it becomes\u00a0very expensive to obtain a reliable set of samples covering most of the modes, and\u00a0convergence of the chain to its stationary distribution is very slow.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5491",
    "text": "Sometimes this problem can be resolved by finding groups of highly dependent units and updating all of them simultaneously in a block. Unfortunately, when\u00a0the dependencies are complicated, it can be computationally intractable to draw a\u00a0sample from the group. After all, the problem that the Markov chain was originally\u00a0introduced to solve is this problem of sampling from a large group of variables.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5492",
    "text": "In the context of models with latent variables, which define a joint distribution pmodei(x, h), we often draw samples of x by alternating between sampling from\u00a0pmodei(x | h) and sampling frompmode1(h | x). From the point of view of mixing\u00a0rapidly, we would like pmode1 (h | x) to have very high entropy. However, from the\u00a0point of view of learning a useful representation of h, we would like h to encode",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5493",
    "text": "EDnane\u25a1\u25a1\u25a1!!",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5494",
    "text": "QDBDBQEIBBD",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5495",
    "text": "BBBEIBnQBBQ",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5496",
    "text": "BEIDBDQEIDDQ",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5497",
    "text": "BE1BBBBBBEI\u25a1",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5498",
    "text": "BQBQDBEIBD\u25a1",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5499",
    "text": "BBBBBBBSBB",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5500",
    "text": "BDBOBBBBBB",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5501",
    "text": "BBDBBBBBDB",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5502",
    "text": "Figure 17.2: An illustration of the slow mixing problem in deep probabilistic models. Each panel should be read left to right, top to bottom. (Left) Consecutive samples from\u00a0Gibbs sampling applied to a deep Boltzmann machine trained on the MNIST dataset.\u00a0Consecutive samples are similar to each other. Because the Gibbs sampling is performed\u00a0in a deep graphical model, this similarity is based more on semantic rather than raw visual\u00a0features, but it is still difficult for the Gibbs chain to transition from one mode of the\u00a0distribution to another, for example by changing the digit identity. (Right) Consecutive\u00a0ancestral samples from a generative adversarial network. Because ancestral sampling\u00a0generates each sample independently from the others, there is no mixing problem.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5503",
    "text": "enough information about x to reconstruct it well, which implies that h and x should have very high mutual information. These two goals are at odds with each\u00a0other. We often learn generative models that very precisely encode x into h but\u00a0are not able to mix very well. This situation arises frequently with Boltzmann\u00a0machines\u2014the sharper the distribution a Boltzmann machine learns, the harder\u00a0it is for a Markov chain sampling from the model distribution to mix well. This\u00a0problem is illustrated in Fig. 17.2.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5504",
    "text": "All this could make MCMC methods less useful when the distribution of interest has a manifold structure with a separate manifold for each class: the distribution\u00a0is concentrated around many modes and these modes are separated by vast regions\u00a0of high energy. This type of distribution is what we expect in many classification\u00a0problems and would make MCMC methods converge very slowly because of poor\u00a0mixing between modes.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5505",
    "text": "When a distribution has sharp peaks of high probability surrounded by regions of low probability, it is difficult to mix between the different modes of the distribution.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5506",
    "text": "Several techniques for faster mixing are based on constructing alternative versions of the target distribution in which the peaks are not as high and the surrounding\u00a0valleys are not as low. Energy-based models provide a particularly simple way to\u00a0do so. So far, we have described an energy-based model as defining a probability\u00a0distribution",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5507",
    "text": "p(x) rc exp (\u2014E(x)). \u00a0\u00a0\u00a0(17.25)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5508",
    "text": "Energy-based models may be augmented with an extra parameter 3 controlling how sharply peaked the distribution is:",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5509",
    "text": "p!3(x) rc exp(-3E(x)). \u00a0\u00a0\u00a0(17.26)",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5510",
    "text": "The 3 parameter is often described as being the reciprocal of the temperature, reflecting the origin of energy-based models in statistical physics. When the\u00a0temperature falls to zero and 3 rises to infinity, the energy-based model becomes\u00a0deterministic. When the temperature rises to infinity and 3 falls to zero, the\u00a0distribution (for discrete x) becomes uniform.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5511",
    "text": "Typically, a model is trained to be evaluated at 3 = 1. However, we can make use of other temperatures, particularly those where 3 < 1. Tempering is a general\u00a0strategy of mixing between modes of pi rapidly by drawing samples with 3 < 1.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5512",
    "text": "Markov chains based on tempered transitions (Neal, 1994) temporarily sample from higher-temperature distributions in order to mix to different modes, then\u00a0resume sampling from the unit temperature distribution. These techniques have\u00a0been applied to models such as RBMs (Salakhutdinov, 2010). Another approach is\u00a0to use parallel tempering (Iba, 2001), in which the Markov chain simulates many\u00a0different states in parallel, at different temperatures. The highest temperature\u00a0states mix slowly, while the lowest temperature states, at temperature 1, provide\u00a0accurate samples from the model. The transition operator includes stochastically\u00a0swapping states between two different temperature levels, so that a sufficiently high-probability sample from a high-temperature slot can jump into a lower temperature\u00a0slot. This approach has also been applied to RBMs (Desjardins et al., 2010; Cho\u00a0et al., 2010). Although tempering is a promising approach, at this point it has not\u00a0allowed researchers to make a strong advance in solving the challenge of sampling\u00a0from complex EBMs. One possible reason is that there are critical temperatures\u00a0around which the temperature transition must be very slow (as the temperature is\u00a0gradually reduced) in order for tempering to be effective.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5513",
    "text": "When drawing samples from a latent variable model p(h, x), we have seen that if p(h | x) encodes x too well, then sampling from p(x | h) will not change x very\u00a0much and mixing will be poor. One way to resolve this problem is to make h be a\u00a0deep representation, that encodes x into h in such a way that a Markov chain in\u00a0the space of h can mix more easily. Many representation learning algorithms, such\u00a0as autoencoders and RBMs, tend to yield a marginal distribution over h that is\u00a0more uniform and more unimodal than the original data distribution over x. It can\u00a0be argued that this arises from trying to minimize reconstruction error while using\u00a0all of the available representation space, because minimizing reconstruction error\u00a0over the training examples will be better achieved when different training examples\u00a0are easily distinguishable from each other in h-space, and thus well separated.\u00a0Bengio et al. (2013a) observed that deeper stacks of regularized autoencoders or\u00a0RBMs yield marginal distributions in the top-level h-space that appeared more\u00a0spread out and more uniform, with less of a gap between the regions corresponding\u00a0to different modes (categories, in the experiments). Training an RBM in that\u00a0higher-level space allowed Gibbs sampling to mix faster between modes. It remains\u00a0however unclear how to exploit this observation to help better train and sample\u00a0from deep generative models.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5514",
    "text": "Despite the difficulty of mixing, Monte Carlo techniques are useful and are often the best tool available. Indeed, they are the primary tool used to confront\u00a0the intractable partition function of undirected models, discussed next.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5515",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5516",
    "text": " The unbiased estimator of the variance is often preferred, in which the sum of squared differences is divided by n \u2014 1 instead of n.",
    "chapter": "",
    "chapter_id": "main-32.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5517",
    "text": "In Sec. 16.2.2 we saw that many probabilistic models (commonly known as undirected graphical models) are defined by an unnormalized probability distribution p(x; 9). We must normalize p by dividing by a partition function Z(6) in order to\u00a0obtain a valid probability distribution:",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5518",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5519",
    "text": "p(x;e) = Z(6)p(x; 6)18-1) \u00a0\u00a0\u00a0\u05be)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5520",
    "text": "The partition function is an integral (for continuous variables) or sum (for discrete variables) over the unnormalized probability of all states:",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5521",
    "text": "j p(x)dx \u00a0\u00a0\u00a0(18.2)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5522",
    "text": "or",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5523",
    "text": "-18.3",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5524",
    "text": "J2p(x)\u25a0",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5525",
    "text": "x",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5526",
    "text": "This operation is intractable for many interesting models.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5527",
    "text": "As we will see in Chapter 20, several deep learning models are designed to have a tractable normalizing constant, or are designed to be used in ways that do\u00a0not involve computing p(x) at all. However, other models directly confront the\u00a0challenge of intractable partition functions. In this chapter, we describe techniques\u00a0used for training and evaluating models that have intractable partition functions.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5528",
    "text": "What makes learning undirected models by maximum likelihood particularly difficult is that the partition function depends on the parameters. The gradient of\u00a0the log-likelihood with respect to the parameters has a term corresponding to the\u00a0gradient of the partition function:",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5529",
    "text": "-18.4",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5530",
    "text": "Ve logp(x; 6) _ Ve log p(x; 6) - Ve log Z(6).",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5531",
    "text": "This is a well-known decomposition into the positive phase and negative phase of learning.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5532",
    "text": "For most undirected models of interest, the negative phase is difficult. Models with no latent variables or with few interactions between latent variables typically\u00a0have a tractable positive phase. The quintessential example of a model with a\u00a0straightforward positive phase and difficult negative phase is the RBM, which has\u00a0hidden units that are conditionally independent from each other given the visible\u00a0units. The case where the positive phase is difficult, with complicated interactions\u00a0between latent variables, is primarily covered in Chapter 19. This chapter focuses\u00a0on the difficulties of the negative phase.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5533",
    "text": "Let us look more closely at the gradient of log Z:",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5534",
    "text": "Ve log Z",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5535",
    "text": "-18.5",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5536",
    "text": "\u05e0\u05d0",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5537",
    "text": "II",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5538",
    "text": "-18.6",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5539",
    "text": "Ve Ex p(x) _Z",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5540",
    "text": "-18.7",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5541",
    "text": "_ Ex V ep(x)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5542",
    "text": "_Z.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5543",
    "text": "-18.8",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5544",
    "text": "For models that guarantee p(x) > 0 for all x,",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5545",
    "text": "we can substitute exp (log p(x))",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5546",
    "text": "for p(x):",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5547",
    "text": "-18.9",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5548",
    "text": "-18.1",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5549",
    "text": "-18.11",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5550",
    "text": "-18.12",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5551",
    "text": "Ex V e exP (l\u00b0g p(x))",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5552",
    "text": "Z",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5553",
    "text": "Ex exP (log p(x)) Ve log p(x) Z",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5554",
    "text": "_ Ex p(x)Ve log p(x)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5555",
    "text": "Z",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5556",
    "text": "_5Z P(x)Ve tog p(x)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5557",
    "text": "#ERROR!",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5558",
    "text": "-18.13",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5559",
    "text": "This derivation made use of summation over discrete x, but a similar result applies using integration over continuous x. In the continuous version of the\u00a0derivation, we use Leibniz\u2019s rule for differentiation under the integral sign to obtain\u00a0the identity",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5560",
    "text": "Ve Jp(x)dx = J Vep(x)dx. \u00a0\u00a0\u00a0(18.14)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5561",
    "text": "This identity is applicable only under certain regularity conditions on p and Vep(x). In measure theoretic terms, the conditions are: (i) The unnormalized distributionp\u00a0must be a Lebesgue-integrable function of x for every value of 0; (ii) The gradient\u00a0Vep(x) must exist for all 0 and almost all x; (iii) There must exist an integrable\u00a0function R(x) that bounds V ep(x) in the sense that max* | dy p(x )| < R(x) for all\u00a00 and almost all x. Fortunately, most machine learning models of interest have\u00a0these properties.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5562",
    "text": "This identity",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5563",
    "text": "Ve log Z = Ex^(x) Ve log p(x) \u00a0\u00a0\u00a0(18.15)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5564",
    "text": "is the basis for a variety of Monte Carlo methods for approximately maximizing the likelihood of models with intractable partition functions.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5565",
    "text": "The Monte Carlo approach to learning undirected models provides an intuitive framework in which we can think of both the positive phase and the negative\u00a0phase. In the positive phase, we increase log p(x) for x drawn from the data. In\u00a0the negative phase, we decrease the partition function by decreasing log p(x) drawn\u00a0from the model distribution.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5566",
    "text": "In the deep learning literature, it is common to parametrize log p in terms of an energy function (Eq. 16.7). In this case, we can interpret the positive phase\u00a0as pushing down on the energy of training examples and the negative phase as\u00a0pushing up on the energy of samples drawn from the model, as illustrated in Fig.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5567",
    "text": "18.1.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5568",
    "text": "The naive way of implementing Eq. 18.15 is to compute it by burning in a set of Markov chains from a random initialization every time the gradient is needed.\u00a0When learning is performed using stochastic gradient descent, this means the\u00a0chains must be burned in once per gradient step. This approach leads to the\u00a0training procedure presented in Algorithm 18.1. The high cost of burning in the\u00a0Markov chains in the inner loop makes this procedure computationally infeasible,\u00a0but this procedure is the starting point that other more practical algorithms aim\u00a0to approximate.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5569",
    "text": "Algorithm 18.1 A naive MCMC algorithm for maximizing the log-likelihood with an intractable partition function using gradient ascent.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5570",
    "text": "Set e, the step size, to a small positive number.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5571",
    "text": "Set k, the number of Gibbs steps, high enough to allow burn in. Perhaps 100 to train an RBM on a small image patch.\u00a0while not converged do",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5572",
    "text": "Sample a minibatch of m examples {x(1),..., x(m)} from the training set. g ^ \u05f4E1\u05f4 V log p(x(i);6).",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5573",
    "text": "Initialize a set of m samples {X(1),..., X(m)} to random values (e.g., from a uniform or normal distribution, or possibly a distribution with marginals\u00a0matched to the model\u2019s marginals).\u00a0for i = 1 to k do\u00a0for j = 1 to m do",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5574",
    "text": "X(j) ^ gibbs_update(5i(j)). end for\u00a0end for",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5575",
    "text": "g ^ g - \u05f4 E1=\u05f4 V 1\u00b0g p(x (i); 1.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5576",
    "text": "6 ^ 6 + eg. end while",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5577",
    "text": "Figure 18.1: The view of Algorithm 18.1 as having a \u201cpositive phase\u201d and \u201cnegative phase.\u201d (Left) In the positive phase, we sample points from the data distribution, and push up on\u00a0their unnormalized probability. This means points that are likely in the data get pushed\u00a0up on more. (Right) In the negative phase, we sample points from the model distribution,\u00a0and push down on their unnormalized probability. This counteracts the positive phase\u2019s\u00a0tendency to just add a large constant to the unnormalized probability everywhere. When\u00a0the data distribution and the model distribution are equal, the positive phase has the\u00a0same chance to push up at a point as the negative phase has to push down. When this\u00a0occurs, there is no longer any gradient (in expectation) and training must terminate.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5578",
    "text": "for dreaming in humans and other animals (Crick and Mitchison, 1983), the idea being that the brain maintains a probabilistic model of the world and follows the\u00a0gradient of log p while experiencing real events while awake and follows the negative\u00a0gradient of log p to minimize log Z while sleeping and experiencing events sampled\u00a0from the current model. This view explains much of the language used to describe\u00a0algorithms with a positive and negative phase, but it has not been proven to be\u00a0correct with neuroscientific experiments. In machine learning models, it is usually\u00a0necessary to use the positive and negative phase simultaneously, rather than in\u00a0separate time periods of wakefulness and REM sleep. As we will see in Sec. 19.5,\u00a0other machine learning algorithms draw samples from the model distribution for\u00a0other purposes and such algorithms could also provide an account for the function\u00a0of dream sleep.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5579",
    "text": "Given this understanding of the role of the positive and negative phase of learning, we can attempt to design a less expensive alternative to Algorithm 18.1.\u00a0The main cost of the naive MCMC algorithm is the cost of burning in the Markov\u00a0chains from a random initialization at each step. A natural solution is to initialize\u00a0the Markov chains from a distribution that is very close to the model distribution,\u00a0so that the burn in operation does not take as many steps.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5580",
    "text": "The contrastive divergence (CD, or CD-k to indicate CD with k Gibbs steps) algorithm initializes the Markov chain at each step with samples from the data\u00a0distribution (Hinton, 2000, 2010). This approach is presented as Algorithm 18.2.\u00a0Obtaining samples from the data distribution is free, because they are already\u00a0available in the data set. Initially, the data distribution is not close to the model\u00a0distribution, so the negative phase is not very accurate. Fortunately, the positive\u00a0phase can still accurately increase the model\u2019s probability of the data. After the\u00a0positive phase has had some time to act, the model distribution is closer to the\u00a0data distribution, and the negative phase starts to become accurate.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5581",
    "text": "Algorithm 18.2 The contrastive divergence algorithm, using gradient ascent as the optimization procedure.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5582",
    "text": "Set e, the step size, to a small positive number.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5583",
    "text": "Set k, the number of Gibbs steps, high enough to allow a Markov chain sampling from p(x; 6) to mix when initialized from pdata. Perhaps 1-20 to train an RBM\u00a0on a small image patch.\u00a0while not converged do",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5584",
    "text": "x",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5585",
    "text": "(m)} from the training set.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5586",
    "text": "Sample a minibatch of m examples {x(1)-g ^ mE\u05f3=! v log p(x(i);6). for i = 1 to m do\u00a0x(i) ^ x(i).\u00a0end for",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5587",
    "text": "for i = 1 to k do for j = 1 to m do",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5588",
    "text": "x(j) ^ gibbs_update(5i(j)). end for\u00a0end for",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5589",
    "text": "g ^ g - mTdl 1 V l\u00b0g p(x(i); 6).",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5590",
    "text": "6 ^ 6 + eg. end while",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5591",
    "text": "Of course, CD is still an approximation to the correct negative phase. The main way that CD qualitatively fails to implement the correct negative phase\u00a0is that it fails to suppress regions of high probability that are far from actual\u00a0training examples. These regions that have high probability under the model but\u00a0low probability under the data generating distribution are called spurious modes.\u00a0Fig. 18.2 illustrates why this happens. Essentially, it is because modes in the\u00a0model distribution that are far from the data distribution will not be visited by",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5592",
    "text": "A spurious mode",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5593",
    "text": "Figure 18.2: An illustration of how the negative phase of contrastive divergence (Algorithm 18.2) can fail to suppress spurious modes. A spurious mode is a mode that is present in\u00a0the model distribution but absent in the data distribution. Because contrastive divergence\u00a0initializes its Markov chains from data points and runs the Markov chain for only a\u00a0few steps, it is unlikely to visit modes in the model that are far from the data points.\u00a0This means that when sampling from the model, we will sometimes get samples that do\u00a0not resemble the data. It also means that due to wasting some of its probability mass\u00a0on these modes, the model will struggle to place high probability mass on the correct\u00a0modes. For the purpose of visualization, this figure uses a somewhat simplified concept\u00a0of distance\u2014the spurious mode is far from the correct mode along the number line in\u00a0R. This corresponds to a Markov chain based on making local moves with a single x\u00a0variable in R. For most deep probabilistic models, the Markov chains are based on Gibbs\u00a0sampling and can make non-local moves of individual variables but cannot move all of\u00a0the variables simultaneously. For these problems, it is usually better to consider the edit\u00a0distance between modes, rather than the Euclidean distance. However, edit distance in a\u00a0high dimensional space is difficult to depict in a 2-D plot.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5594",
    "text": "Markov chains initialized at training points, unless k is very large.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5595",
    "text": "Carreira-Perpinan and Hinton (2005) showed experimentally that the CD estimator is biased for RBMs and fully visible Boltzmann machines, in that it\u00a0converges to different points than the maximum likelihood estimator. They argue\u00a0that because the bias is small, CD could be used as an inexpensive way to initialize\u00a0a model that could later be fine-tuned via more expensive MCMC methods. Bengio\u00a0and Delalleau (2009) showed that CD can be interpreted as discarding the smallest\u00a0terms of the correct MCMC update gradient, which explains the bias.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5596",
    "text": "CD is useful for training shallow models like RBMs. These can in turn be stacked to initialize deeper models like DBNs or DBMs. However, CD does not\u00a0provide much help for training deeper models directly. This is because it is difficult\u00a0to obtain samples of the hidden units given samples of the visible units. Since the\u00a0hidden units are not included in the data, initializing from training points cannot\u00a0solve the problem. Even if we initialize the visible units from the data, we will still\u00a0need to burn in a Markov chain sampling from the distribution over the hidden\u00a0units conditioned on those visible samples.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5597",
    "text": "The CD algorithm can be thought of as penalizing the model for having a Markov chain that changes the input rapidly when the input comes from the data.\u00a0This means training with CD somewhat resembles autoencoder training. Even\u00a0though CD is more biased than some of the other training methods, it can be\u00a0useful for pretraining shallow models that will later be stacked. This is because\u00a0the earliest models in the stack are encouraged to copy more information up to\u00a0their latent variables, thereby making it available to the later models. This should\u00a0be thought of more of as an often-exploitable side effect of CD training rather than\u00a0a principled design advantage.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5598",
    "text": "Sutskever and Tieleman (2010) showed that the CD update direction is not the gradient of any function. This allows for situations where CD could cycle forever,\u00a0but in practice this is not a serious problem.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5599",
    "text": "A different strategy that resolves many of the problems with CD is to initialize the Markov chains at each gradient step with their states from the previous gradient\u00a0step. This approach was first discovered under the name stochastic maximum\u00a0likelihood (SML) in the applied mathematics and statistics community (Younes,\u00a01998) and later independently rediscovered under the name persistent contrastive\u00a0divergence (PCD, or PCD-k to indicate the use of k Gibbs steps per update) in\u00a0the deep learning community (Tieleman, 2008). See Algorithm 18.3. The basic\u00a0idea of this approach is that, so long as the steps taken by the stochastic gradient\u00a0algorithm are small, then the model from the previous step will be similar to the\u00a0model from the current step. It follows that the samples from the previous model\u2019s\u00a0distribution will be very close to being fair samples from the current model\u2019s\u00a0distribution, so a Markov chain initialized with these samples will not require much\u00a0time to mix.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5600",
    "text": "Because each Markov chain is continually updated throughout the learning process, rather than restarted at each gradient step, the chains are free to wander\u00a0far enough to find all of the model\u2019s modes. SML is thus considerably more\u00a0resistant to forming models with spurious modes than CD is. Moreover, because\u00a0it is possible to store the state of all of the sampled variables, whether visible or\u00a0latent, SML provides an initialization point for both the hidden and visible units.\u00a0CD is only able to provide an initialization for the visible units, and therefore\u00a0requires burn-in for deep models. SML is able to train deep models efficiently.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5601",
    "text": "Marlin et al. (2010) compared SML to many of the other criteria presented in this chapter. They found that SML results in the best test set log-likelihood for\u00a0an RBM, and that if the RBM\u2019s hidden units are used as features for an SVM\u00a0classifier, SML results in the best classification accuracy.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5602",
    "text": "SML is vulnerable to becoming inaccurate if the stochastic gradient algorithm can move the model faster than the Markov chain can mix between steps. This\u00a0can happen if k is too small or e is too large. The permissible range of values is\u00a0unfortunately highly problem-dependent. There is no known way to test formally\u00a0whether the chain is successfully mixing between steps. Subjectively, if the learning\u00a0rate is too high for the number of Gibbs steps, the human operator will be able\u00a0to observe that there is much more variance in the negative phase samples across\u00a0gradient steps rather than across different Markov chains. For example, a model\u00a0trained on MNIST might sample exclusively 7s on one step. The learning process\u00a0will then push down strongly on the mode corresponding to 7s, and the model\u00a0might sample exclusively 9s on the next step.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5603",
    "text": "Algorithm 18.3 The stochastic maximum likelihood / persistent contrastive divergence algorithm using gradient ascent as the optimization procedure.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5604",
    "text": "Set e, the step size, to a small positive number.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5605",
    "text": "Set k, the number of Gibbs steps, high enough to allow a Markov chain sampling from p(x; 6 + eg) to burn in, starting from samples from p(x; 6). Perhaps 1 for\u00a0RBM on a small image patch, or 5-50 for a more complicated model like a DBM.\u00a0Initialize a set of m samples {X(1),..., X(m)} to random values (e.g., from a\u00a0uniform or normal distribution, or possibly a distribution with marginals matched\u00a0to the model\u2019s marginals).\u00a0while not converged do",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5606",
    "text": "Sample a minibatch of m examples {x(1),..., x(m)} from the training set.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5607",
    "text": "g ^ m Ei=1 v10g p(xW; 6).",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5608",
    "text": "for i = 1 to k do for j = 1 to m do",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5609",
    "text": "x(j) ^ gibbs_update(xj)). end for",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5610",
    "text": "end for",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5611",
    "text": "g ^ g - m YZL1 v910g p(x(i); 6).",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5612",
    "text": "6 ^ 6 + eg. end while",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5613",
    "text": "Care must be taken when evaluating the samples from a model trained with SML. It is necessary to draw the samples starting from a fresh Markov chain\u00a0initialized from a random starting point after the model is done training. The\u00a0samples present in the persistent negative chains used for training have been\u00a0influenced by several recent versions of the model, and thus can make the model\u00a0appear to have greater capacity than it actually does.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5614",
    "text": "Berglund and Raiko (2013) performed experiments to examine the bias and variance in the estimate of the gradient provided by CD and SML. CD proves to\u00a0have lower variance than the estimator based on exact sampling. SML has higher\u00a0variance. The cause of CD\u2019s low variance is its use of the same training points\u00a0in both the positive and negative phase. If the negative phase is initialized from\u00a0different training points, the variance rises above that of the estimator based on\u00a0exact sampling.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5615",
    "text": "All of these methods based on using MCMC to draw samples from the model can in principle be used with almost any variant of MCMC. This means that\u00a0techniques such as SML can be improved by using any of the enhanced MCMC\u00a0techniques described in Chapter 17, such as parallel tempering (Desjardins et al.,\u00a02010; Cho et al., 2010).",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5616",
    "text": "One approach to accelerating mixing during learning relies not on changing the Monte Carlo sampling technology but rather on changing the parametrization of\u00a0the model and the cost function. Fast PCD or FPCD (Tieleman and Hinton, 2009)\u00a0involves replacing the parameters 6 of a traditional model with an expression",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5617",
    "text": "6 = 6(slow) + 6(fast). \u00a0\u00a0\u00a0(18.16)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5618",
    "text": "There are now twice as many parameters as before, and they are added together element-wise to provide the parameters used by the original model definition. The\u00a0fast copy of the parameters is trained with a much larger learning rate, allowing\u00a0it to adapt rapidly in response to the negative phase of learning and push the\u00a0Markov chain to new territory. This forces the Markov chain to mix rapidly, though\u00a0this effect only occurs during learning while the fast weights are free to change.\u00a0Typically one also applies significant weight decay to the fast weights, encouraging\u00a0them to converge to small values, after only transiently taking on large values long\u00a0enough to encourage the Markov chain to change modes.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5619",
    "text": "One key benefit to the MCMC-based methods described in this section is that they provide an estimate of the gradient of log Z, and thus we can essentially\u00a0decompose the problem into the log p contribution and the log Z contribution.\u00a0We can then use any other method to tackle log p(x), and just add our negative\u00a0phase gradient onto the other method\u2019s gradient. In particular, this means that\u00a0our positive phase can make use of methods that provide only a lower bound on\u00a0p. Most of the other methods of dealing with log Z presented in this chapter are\u00a0incompatible with bound-based positive phase methods.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5620",
    "text": "Monte Carlo approximations to the partition function and its gradient directly confront the partition function. Other approaches sidestep the issue, by training\u00a0the model without computing the partition function. Most of these approaches are\u00a0based on the observation that it is easy to compute ratios of probabilities in an\u00a0undirected probabilistic model. This is because the partition function appears in\u00a0both the numerator and the denominator of the ratio and cancels out:",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5621",
    "text": "-18.17",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5622",
    "text": "p(x) = j p(x) = p(x) p(y)\u00a0\u00a0\u00a0\u00a0j p( y)\u00a0\u00a0\u00a0\u00a0P(y)'",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5623",
    "text": "The pseudolikelihood is based on the observation that conditional probabilities take this ratio-based form, and thus can be computed without knowledge of the\u00a0partition function. Suppose that we partition x into a, b and c, where a contains\u00a0the variables we want to find the conditional distribution over, b contains the\u00a0variables we want to condition on, and c contains the variables that are not part\u00a0of our query.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5624",
    "text": "P(a 1 b) =",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5625",
    "text": "p(a, b)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5626",
    "text": "p(a, b)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5627",
    "text": "p(a, b)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5628",
    "text": "P(b) \u00a0\u00a0\u00a0Ea,c P(a h, c)\u00a0\u00a0\u00a0\u00a0Ea,cp(a h, c)\u2019",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5629",
    "text": "-18.18",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5630",
    "text": "This quantity requires marginalizing out a, which can be a very efficient operation provided that a and c do not contain very many variables. In the extreme case, a\u00a0can be a single variable and c can be empty, making this operation require only as\u00a0many evaluations of p as there are values of a single random variable.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5631",
    "text": "Unfortunately, in order to compute the log-likelihood, we need to marginalize out large sets of variables. If there are n variables total, we must marginalize a set\u00a0of size n \u2014 1. By the chain rule of probability,",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5632",
    "text": "logp(x) = logp(x 1) + logp(x2 \\ xl) +-----+ p(xn 1 xl:n-l). \u00a0\u00a0\u00a0(18.19)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5633",
    "text": "In this case, we have made a maximally small, but c can be as large as x2:n . What if we simply move c into b to reduce the computational cost? This yields the\u00a0pseudolikelihood (Besag, 1975) objective function, based on predicting the value of\u00a0feature xi given all of the other features x-i:",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5634",
    "text": "n",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5635",
    "text": "5>gp(xi \\ x-i). \u00a0\u00a0\u00a0(18.20)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5636",
    "text": "i=1",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5637",
    "text": "If each random variable has k different values, this requires only k xn evaluations of p to compute, as opposed to the kn evaluations needed to compute the partition\u00a0function.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5638",
    "text": "This may look like an unprincipled hack, but it can be proven that estimation by maximizing the pseudolikelihood is asymptotically consistent (Mase, 1995).\u00a0Of course, in the case of datasets that do not approach the large sample limit,\u00a0pseudolikelihood may display different behavior from the maximum likelihood\u00a0estimator.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5639",
    "text": "It is possible to trade computational complexity for deviation from maximum likelihood behavior by using the generalized pseudolikelihood estimator (Huang and\u00a0Ogata, 2002). The generalized pseudolikelihood estimator uses m different sets\u00a0S(i), i = 1,..., m of indices of variables that appear together on the left side of the\u00a0conditioning bar. In the extreme case of m = 1 and S(1) = 1,..., n the generalized\u00a0pseudolikelihood recovers the log-likelihood. In the extreme case of m = n and\u00a0S(i) = {i}, the generalized pseudolikelihood recovers the pseudolikelihood. The\u00a0generalized pseudolikelihood objective function is given by",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5640",
    "text": "m",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5641",
    "text": "5^log P(x s(i) 1 x-s\u00ab). \u00a0\u00a0\u00a0(18.21)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5642",
    "text": "i=1",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5643",
    "text": "The performance of pseudolikelihood-based approaches depends largely on how the model will be used. Pseudolikelihood tends to perform poorly on tasks that\u00a0require a good model of the full joint p(x), such as density estimation and sampling.\u00a0However, it can perform better than maximum likelihood for tasks that require only\u00a0the conditional distributions used during training, such as filling in small amounts\u00a0of missing values. Generalized pseudolikelihood techniques are especially powerful if\u00a0the data has regular structure that allows the S index sets to be designed to capture\u00a0the most important correlations while leaving out groups of variables that only\u00a0have negligible correlation. For example, in natural images, pixels that are widely\u00a0separated in space also have weak correlation, so the generalized pseudolikelihood\u00a0can be applied with each S set being a small, spatially localized window.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5644",
    "text": "One weakness of the pseudolikelihood estimator is that it cannot be used with other approximations that provide only a lower bound on p(x), such as variational\u00a0inference, which will be covered in Chapter 19. This is because p appears in the\u00a0denominator. A lower bound on the denominator provides only an upper bound on\u00a0the expression as a whole, and there is no benefit to maximizing an upper bound.\u00a0This makes it difficult to apply pseudolikelihood approaches to deep models such\u00a0as deep Boltzmann machines, since variational methods are one of the dominant\u00a0approaches to approximately marginalizing out the many layers of hidden variables\u00a0that interact with each other. However, pseudolikelihood is still useful for deep\u00a0learning, because it can be used to train single layer models, or deep models using\u00a0approximate inference methods that are not based on lower bounds.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5645",
    "text": "Pseudolikelihood has a much greater cost per gradient step than SML, due to its explicit computation of all of the conditionals. However, generalized pseudolikelihood and similar criteria can still perform well if only one randomly selected\u00a0conditional is computed per example (Goodfellow et al., 2013b), thereby bringing\u00a0the computational cost down to match that of SML.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5646",
    "text": "Though the pseudolikelihood estimator does not explicitly minimize log Z, it can still be thought of as having something resembling a negative phase. The\u00a0denominators of each conditional distribution result in the learning algorithm\u00a0suppressing the probability of all states that have only one variable differing from\u00a0a training example.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5647",
    "text": "See Marlin and de Freitas (2011) for a theoretical analysis of the asymptotic efficiency of pseudolikelihood.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5648",
    "text": "Score matching (Hyvarinen, 2005) provides another consistent means of training a model without estimating Z or its derivatives. The name score matching comes\u00a0from terminology in which the derivatives of a log density with respect to its\u00a0argument, Vx logp(x), are called its score. The strategy used by score matching is\u00a0to minimize the expected squared difference between the derivatives of the model\u2019s\u00a0log density with respect to the input and the derivatives of the data\u2019s log density\u00a0with respect to the input:",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5649",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5650",
    "text": "L(x, 6) = ^ ||V x log Pmodel (x; 6) - V* log p data(x)||2 \u00a0\u00a0\u00a0(18.22)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5651",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5652",
    "text": "J (6) =2 EPdata (*) L(X, 6) \u00a0\u00a0\u00a0(18.23)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5653",
    "text": "6* = min J(6) \u00a0\u00a0\u00a0(18.24)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5654",
    "text": "This objective function avoids the difficulties associated with differentiating the partition function Z because Z is not a function of x and therefore Vx Z = 0.\u00a0Initially, score matching appears to have a new difficulty: computing the score\u00a0of the data distribution requires knowledge of the true distribution generating\u00a0the training data, pdata. Fortunately, minimizing the expected value of L(x, 6) is",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5655",
    "text": "equivalent to minimizing the expected value of",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5656",
    "text": "n \u00a0\u00a0\u00a0d2",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5657",
    "text": "L(x'0) = g( dxj",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5658",
    "text": "d2 \u00a0\u00a0\u00a01",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5659",
    "text": "logPmodel (x; 0) +",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5660",
    "text": "d",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5661",
    "text": "2 dx",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5662",
    "text": "log Pmodel (x",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5663",
    "text": "(\u05be(\u05f4",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5664",
    "text": "-18.25",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5665",
    "text": "where n is the dimensionality of x.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5666",
    "text": "Because score matching requires taking derivatives with respect to x, it is not applicable to models of discrete data. However, the latent variables in the model\u00a0may be discrete.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5667",
    "text": "Like the pseudolikelihood, score matching only works when we are able to evaluate log p(x) and its derivatives directly. It is not compatible with methods\u00a0that only provide a lower bound on log p(x), because score matching requires\u00a0the derivatives and second derivatives of log p(x) and a lower bound conveys no\u00a0information about its derivatives. This means that score matching cannot be\u00a0applied to estimating models with complicated interactions between the hidden\u00a0units, such as sparse coding models or deep Boltzmann machines. While score\u00a0matching can be used to pretrain the first hidden layer of a larger model, it has\u00a0not been applied as a pretraining strategy for the deeper layers of a larger model.\u00a0This is probably because the hidden layers of such models usually contain some\u00a0discrete variables.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5668",
    "text": "While score matching does not explicitly have a negative phase, it can be viewed as a version of contrastive divergence using a specific kind of Markov chain\u00a0(Hyvarinen, 2007a). The Markov chain in this case is not Gibbs sampling, but\u00a0rather a different approach that makes local moves guided by the gradient. Score\u00a0matching is equivalent to CD with this type of Markov chain when the size of the\u00a0local moves approaches zero.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5669",
    "text": "Lyu (2009) generalized score matching to the discrete case (but made an error in their derivation that was corrected by Marlin et al. (2010)). Marlin et al. (2010)\u00a0found that generalized score matching (GSM) does not work in high dimensional\u00a0discrete spaces where the observed probability of many events is 0.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5670",
    "text": "A more successful approach to extending the basic ideas of score matching to discrete data is ratio matching (Hyvarinen, 2007b). Ratio matching applies\u00a0specifically to binary data. Ratio matching consists of minimizing the average over\u00a0examples of the following objective function:",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5671",
    "text": "2",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5672",
    "text": "L(rm) (x, 0)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5673",
    "text": "j=1",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5674",
    "text": "1 +",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5675",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5676",
    "text": "x",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5677",
    "text": "-18.26",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5678",
    "text": "Pmodel(/(x),j );G)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5679",
    "text": "where f (x, j) returns x with the bit at position j flipped. Ratio matching avoids the partition function using the same trick as the pseudolikelihood estimator: in a\u00a0ratio of two probabilities, the partition function cancels out. Marlin et al. (2010)\u00a0found that ratio matching outperforms SML, pseudolikelihood and GSM in terms\u00a0of the ability of models trained with ratio matching to denoise test set images.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5680",
    "text": "Like the pseudolikelihood estimator, ratio matching requires n evaluations of p per data point, making its computational cost per update roughly n times higher\u00a0than that of SML.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5681",
    "text": "As with the pseudolikelihood estimator, ratio matching can be thought of as pushing down on all fantasy states that have only one variable different from a\u00a0training example. Since ratio matching applies specifically to binary data, this\u00a0means that it acts on all fantasy states within Hamming distance 1 of the data.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5682",
    "text": "Ratio matching can also be useful as the basis for dealing with high-dimensional sparse data, such as word count vectors. This kind of data poses a challenge for\u00a0MCMC-based methods because the data is extremely expensive to represent in\u00a0dense format, yet the MCMC sampler does not yield sparse values until the model\u00a0has learned to represent the sparsity in the data distribution. Dauphin and Bengio\u00a0(2013) overcame this issue by designing an unbiased stochastic approximation to\u00a0ratio matching. The approximation evaluates only a randomly selected subset of\u00a0the terms of the objective, and does not require the model to generate complete\u00a0fantasy samples.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5683",
    "text": "See Marlin and de Freitas (2011) for a theoretical analysis of the asymptotic efficiency of ratio matching.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5684",
    "text": "In some cases we may wish to regularize score matching, by fitting a distribution",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5685",
    "text": "Psmoothed(x) = J pdata(y)q(x | y)dy \u00a0\u00a0\u00a0(18.27)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5686",
    "text": "rather than the true pdata. The distribution q(x | y) is a corruption process, usually one that forms x by adding a small amount of noise to y.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5687",
    "text": "Denoising score matching is especially useful because in practice we usually do not have access to the true pdata but rather only an empirical distribution defined\u00a0by samples from it. Any consistent estimator will, given enough capacity, make\u00a0Pmodei into a set of Dirac distributions centered on the training points. Smoothing\u00a0by q helps to reduce this problem, at the loss of the asymptotic consistency property\u00a0described in Sec. 5.4.5. Kingma and LeCun (2010) introduced a procedure for\u00a0performing regularized score matching with the smoothing distribution q being\u00a0normally distributed noise.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5688",
    "text": "Recall from Sec. 14.5.1 that several autoencoder training algorithms are equivalent to score matching or denoising score matching. These autoencoder\u00a0training algorithms are therefore a way of overcoming the partition function\u00a0problem.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5689",
    "text": "Most techniques for estimating models with intractable partition functions do not provide an estimate of the partition function. SML and CD estimate only the\u00a0gradient of the log partition function, rather than the partition function itself.\u00a0Score matching and pseudolikelihood avoid computing quantities related to the\u00a0partition function altogether.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5690",
    "text": "Noise-contrastive estimation (NCE) (Gutmann and Hyvarinen, 2010) takes a different strategy. In this approach, the probability distribution estimated by the\u00a0model is represented explicitly as",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5691",
    "text": "logPmodel (x) = log pmodel (x; 6) + C, \u00a0\u00a0\u00a0(18.28)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5692",
    "text": "where c is explicitly introduced as an approximation of \u2014 log Z (6). Rather than estimating only 6, the noise contrastive estimation procedure treats c as just\u00a0another parameter and estimates 6 and c simultaneously, using the same algorithm\u00a0for both. The resulting logpmode1(x) thus may not correspond exactly to a valid\u00a0probability distribution, but will become closer and closer to being valid as the\u00a0estimate of c improves.2",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5693",
    "text": "Such an approach would not be possible using maximum likelihood as the criterion for the estimator. The maximum likelihood criterion would choose to set\u00a0c arbitrarily high, rather than setting c to create a valid probability distribution.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5694",
    "text": "NCE works by reducing the unsupervised learning problem of estimating p(x) to that of learning a probabilistic binary classifier in which one of the categories\u00a0corresponds to the data generated by the model. This supervised learning problem\u00a0is constructed in such a way that maximum likelihood estimation in this supervised\u00a0learning problem defines an asymptotically consistent estimator of the original\u00a0problem.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5695",
    "text": "Specifically, we introduce a second distribution, the noise distribution pnoise(x). The noise distribution should be tractable to evaluate and to sample from. We\u00a0can now construct a model over both x and a new, binary class variable y. In the\u00a0new joint model, we specify that",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5696",
    "text": "Pjoint(y = 1)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5697",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5698",
    "text": "2 \u2019",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5699",
    "text": "pjoint(x 1 y \u2014 1) \u2014 pmodel(x)\u05dc",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5700",
    "text": "-18.29",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5701",
    "text": "-18.3",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5702",
    "text": "and",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5703",
    "text": "-18.31",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5704",
    "text": "Pjoint(x 1 y \u2014 0) \u2014 pnoise(x).",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5705",
    "text": "In other words, y is a switch variable that determines whether we will generate x from the model or from the noise distribution.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5706",
    "text": "We can construct a similar joint model of training data. In this case, the switch variable determines whether we draw x from the data or from the noise\u00a0distribution. Formally, ptrain(y \u2014 1) \u2014 ^ , ptrain (x | y \u2014 1) \u2014 pdata(x), and",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5707",
    "text": "ptrain (x | y \u2014 0) \u2014 Pnoise(x).",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5708",
    "text": "We can now just use standard maximum likelihood learning on the supervised learning problem of fitting pjoint to ptrain:",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5709",
    "text": "6\u05dc c \u2014 arg max Ex",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5710",
    "text": "6,c",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5711",
    "text": ",y^Ptrain",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5712",
    "text": "in 1ogpjoint (y 1 x).",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5713",
    "text": "-18.32",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5714",
    "text": "The distribution pjoint is essentially a logistic regression model applied to the difference in log probabilities of the model and the noise distribution:",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5715",
    "text": "pjoint(y \u2014 1 | x) \u2014",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5716",
    "text": "pmodel (x)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5717",
    "text": "p model(x) + p noise (x)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5718",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5719",
    "text": "1 _1 pnoise(x) pmodel (x)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5720",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5721",
    "text": "1+exp (1og PmofilXj)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5722",
    "text": "pnoise(x)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5723",
    "text": "(",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5724",
    "text": "a - log",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5725",
    "text": ")",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5726",
    "text": "pmodel(x) \u05be",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5727",
    "text": "\u2014 a (logPmodel(x) - 1ogPnoise(x)) .",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5728",
    "text": "-18.33",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5729",
    "text": "-18.34",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5730",
    "text": "-18.35",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5731",
    "text": "-18.36",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5732",
    "text": "-18.37",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5733",
    "text": "NCE is thus simple to apply so long as log pmodei is easy to back-propagate through, and, as specified above, pnoise is easy to evaluate (in order to evaluate\u00a0Pjoint) and sample from (in order to generate the training data).",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5734",
    "text": "NCE is most successful when applied to problems with few random variables, but can work well even if those random variables can take on a high number of\u00a0values. For example, it has been successfully applied to modeling the conditional\u00a0distribution over a word given the context of the word (Mnih and Kavukcuoglu,\u00a02013). Though the word may be drawn from a large vocabulary, there is only one\u00a0word.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5735",
    "text": "When NCE is applied to problems with many random variables, it becomes less efficient. The logistic regression classifier can reject a noise sample by identifying\u00a0any one variable whose value is unlikely. This means that learning slows down\u00a0greatly after pmode1 has learned the basic marginal statistics. Imagine learning a\u00a0model of images of faces, using unstructured Gaussian noise as pnoise. If pmode1\u00a0learns about eyes, it can reject almost all unstructured noise samples without\u00a0having learned anything about other facial features, such as mouths.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5736",
    "text": "The constraint that pnoise must be easy to evaluate and easy to sample from can be overly restrictive. When pno-ise is simple, most samples are likely to be too\u00a0obviously distinct from the data to force pmode1 to improve noticeably.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5737",
    "text": "Like score matching and pseudolikelihood, NCE does not work if only a lower bound on p is available. Such a lower bound could be used to construct a lower\u00a0bound on pj0int(y = 1 | x), but it can only be used to construct an upper bound on\u00a0Pjoint(y = 0 | x), which appears in half the terms of the NCE objective. Likewise,\u00a0a lower bound on pnoise is not useful, because it provides only an upper bound on\u00a0Pjoint(y = 1 | x).",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5738",
    "text": "When the model distribution is copied to define a new noise distribution before each gradient step, NCE defines a procedure called self-contrastive estimation,\u00a0whose expected gradient is equivalent to the expected gradient of maximum\u00a0likelihood (Goodfellow, 2014). The special case of NCE where the noise samples\u00a0are those generated by the model suggests that maximum likelihood can be\u00a0interpreted as a procedure that forces a model to constantly learn to distinguish\u00a0reality from its own evolving beliefs, while noise contrastive estimation achieves\u00a0some reduced computational cost by only forcing the model to distinguish reality\u00a0from a fixed baseline (the noise model).",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5739",
    "text": "Using the supervised task of classifying between training samples and generated samples (with the model energy function used in defining the classifier) to provide\u00a0a gradient on the model was introduced earlier in various forms (Welling et al.,\u00a02003b; Bengio, 2009).",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5740",
    "text": "Noise contrastive estimation is based on the idea that a good generative model should be able to distinguish data from noise. A closely related idea is that\u00a0a good generative model should be able to generate samples that no classifier\u00a0can distinguish from data. This idea yields generative adversarial networks (Sec.\u00a020.10.4).",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5741",
    "text": "While much of this chapter is dedicated to describing methods that avoid needing to compute the intractable partition function Z(6) associated with an undirected\u00a0graphical model, in this section we discuss several methods for directly estimating\u00a0the partition function.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5742",
    "text": "Estimating the partition function can be important because we require it if we wish to compute the normalized likelihood of data. This is often important in\u00a0evaluating the model, monitoring training performance, and comparing models to\u00a0each other.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5743",
    "text": "For example, imagine we have two models: model Ma defining a probability distribution pa(x; 6a) = Z\"Pa (x; 6a) and model Mb defining a probability",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5744",
    "text": "distribution pb(x; 6b) = 1\u05be pB (x; 6b ). A common way to compare the models is to evaluate and compare the likelihood that both models assign to an i.i.d.\u00a0test dataset. Suppose the test set consists of m examples {x(1),..., X(m) }. jf\u00a0n. PA(x(i); 6a) > rX pb(x(.) ; 6b ) or equivalently if",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5745",
    "text": "-18.38",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5746",
    "text": "Y logPA (x(i); 6a) \u00a0\u00a0\u00a0lQgPB (x(i); 6b) > 0,",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5747",
    "text": "then we say that Ma is a better model than Mb (or, at least, it is a better model of the test set), in the sense that it has a better test log-likelihood. Unfortunately,\u00a0testing whether this condition holds requires knowledge of the partition function.\u00a0Unfortunately, Eq. 18.38 seems to require evaluating the log probability that\u00a0the model assigns to each point, which in turn requires evaluating the partition\u00a0function. We can simplify the situation slightly by re-arranging Eq. 18.38 into a\u00a0form where we need to know only the ratio of the two model\u2019s partition functions:",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5748",
    "text": "Y log PA (x(i); 6 a) \u2014 Y log PB (x(i); 6b ) = Y log . . .",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5749",
    "text": "Pa(x(.); 6a) Pb(x(.) ; 6b)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5750",
    "text": ")",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5751",
    "text": "\u2014m log",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5752",
    "text": "Z (6a )",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5753",
    "text": ",Z (6b )\u05be (18.39)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5754",
    "text": "We can thus determine whether Ma is a better model than Mb without knowing the partition function of either model but only their ratio. As we will see shortly,",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5755",
    "text": "we can estimate this ratio using importance sampling, provided that the two models are similar.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5756",
    "text": "If, however, we wanted to compute the actual probability of the test data under either Ma or Mb, we would need to compute the actual value of the partition\u00a0functions. That said, if we knew the ratio of two partition functions, r \u05be\u00a0\u00a0\u00a0\u00a0,",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5757",
    "text": "and we knew the actual value of just one of the two, say Z (6 a ), we could compute the value of the other:",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5758",
    "text": "Z (6b ) = rZ (6a)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5759",
    "text": "Z (6b ) Z (6a )",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5760",
    "text": "Z (6a).",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5761",
    "text": "-18.4",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5762",
    "text": "A simple way to estimate the partition function is to use a Monte Carlo method such as simple importance sampling. We present the approach in terms\u00a0of continuous variables using integrals, but it can be readily applied to discrete\u00a0variables by replacing the integrals with summation. We use a proposal distribution\u00a0po(x) \u05be ZqPo(x) which supports tractable sampling and tractable evaluation of\u00a0both the partition function Z0 and the unnormalized distribution po(x).",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5763",
    "text": "Z1 = J pi (x) dx",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5764",
    "text": "-18.41",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5765",
    "text": "\u05be W(x)p1(x) dx",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5766",
    "text": "-18.42",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5767",
    "text": "Z f ( vp1(x) d",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5768",
    "text": "\u05be Z 0 po (x) dx",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5769",
    "text": "J po(x)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5770",
    "text": "-18.43",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5771",
    "text": "Z Zo Pi (x(k> ) t (k>",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5772",
    "text": "Z1 \u05be (k>x s\u05bet\u2022 : x( > - po K k=1 p^o (x(k>)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5773",
    "text": "-18.44",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5774",
    "text": "In the last line, we make a Monte Carlo estimator, Z1, of the integral using samples drawn from p0(x) and then weight each sample with the ratio of the unnormalized\u00a0p 1 and the proposal po.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5775",
    "text": "We see also that this approach allows us to estimate the ratio between the partition functions as",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5776",
    "text": "1 \u00a0\u00a0\u00a0p1 (x(k>)",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5777",
    "text": "1 \u00a0\u00a0\u00a0s.t. : x(k> - po.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5778",
    "text": "K t=1 po(x",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5779",
    "text": "-18.45",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5780",
    "text": "This value can then be used directly to compare two models as described in Eq. 18.39.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5781",
    "text": "If the distribution po is close to p1, Eq. 18.44 can be an effective way of estimating the partition function (Minka, 2005). Unfortunately, most of the time",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5782",
    "text": "pi is both complicated (usually multimodal) and defined over a high dimensional space. It is difficult to find a tractable po that is simple enough to evaluate while\u00a0still being close enough to pi to result in a high quality approximation. If po and\u00a0pi are not close, most samples from po will have low probability under p 1 and\u00a0therefore make (relatively) negligible contribution to the sum in Eq. 18.44.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5783",
    "text": "Having few samples with significant weights in this sum will result in an estimator that is of poor quality due to high variance. This can be understood\u00a0quantitatively through an estimate of the variance of our estimate Z1:",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5784",
    "text": "(*) = K2",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5785",
    "text": "pi(x(",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5786",
    "text": "p 0(x(k))",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5787",
    "text": "-18.46",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5788",
    "text": "This quantity is largest when there is significant deviation in the values of the importance weights |\u05bejx(fcr).",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5789",
    "text": "We now turn to two related strategies developed to cope with the challenging task of estimating partition functions for complex distributions over highdimensional spaces: annealed importance sampling and bridge sampling. Both start with the simple importance sampling strategy introduced above and both\u00a0attempt to overcome the problem of the proposal po being too far from p 1 by\u00a0introducing intermediate distributions that attempt to bridge the gap between po\u00a0and pi.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5790",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5791",
    "text": "We can view the MCMC approach to maximum likelihood as trying to achieve balance between two forces, one pushing up on the model distribution where the\u00a0data occurs, and another pushing down on the model distribution where the model\u00a0samples occur. Fig. 18.1 illustrates this process. The two forces correspond to\u00a0maximizing log p and minimizing log Z. Several approximations to the negative\u00a0phase are possible. Each of these approximations can be understood as making\u00a0the negative phase computationally cheaper but also making it push down in the\u00a0wrong locations.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5792",
    "text": "Because the negative phase involves drawing samples from the model\u2019s distribution, we can think of it as finding points that the model believes in strongly. Because the negative phase acts to reduce the probability of those points, they\u00a0are generally considered to represent the model\u2019s incorrect beliefs about the world.\u00a0They are frequently referred to in the literature as \u201challucinations\u201d or \u201cfantasy\u00a0particles.\u201d In fact, the negative phase has been proposed as a possible explanation",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5793",
    "text": "2",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5794",
    "text": "NCE is also applicable to problems with a tractable partition function, where there is no need to introduce the extra parameter c. However, it has generated the most interest as a means\u00a0of estimating models with difficult partition functions.",
    "chapter": "",
    "chapter_id": "main-33.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5795",
    "text": "In situations where Dkl(poIIpi) is large (i.e., where there is little overlap between po and p 1), a strategy called annealed importance sampling (AIS) attempts to\u00a0bridge the gap by introducing intermediate distributions (Jarzynski, 1997; Neal,\u00a02001). Consider a sequence of distributions p^ ,... ,pVn, with 0 = no < ni < \u05be \u05be \u05be <\u00a0nn-1 < nn = 1 so that the first and last distributions in the sequence are po and pi\u00a0respectively.",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5796",
    "text": "This approach allows us to estimate the partition function of a multimodal distribution defined over a high-dimensional space (such as the distribution defined\u00a0by a trained RBM). We begin with a simpler model with a known partition function\u00a0(such as an RBM with zeroes for weights) and estimate the ratio between the two\u00a0model\u2019s partition functions. The estimate of this ratio is based on the estimate\u00a0of the ratios of a sequence of many similar distributions, such as the sequence of\u00a0RBMs with weights interpolating between zero and the learned weights.",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5797",
    "text": "sampling and then use these to obtain an estimate of Z .",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5798",
    "text": "Where do these intermediate distributions come from? Just as the original proposal distribution po is a design choice, so is the sequence of distributions\u00a0Pn 1.. \u2022Pn\u05f4_v That is, it can be specifically constructed to suit the problem domain.\u00a0One general-purpose and popular choice for the intermediate distributions is to\u00a0use the weighted geometric average of the target distribution pi and the starting\u00a0proposal distribution (for which the partition function is known) po:",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5799",
    "text": "Pn j",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5800",
    "text": "nj 1-n j rc pi Po",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5801",
    "text": "-18.5",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5802",
    "text": "In order to sample from these intermediate distributions, we define a series of Markov chain transition functionsTnJ(x/ | x) that define the conditional probability\u00a0distribution of transitioning to x' given we are currently at x. The transition\u00a0operator Tnj (x' | x) is defined to leave p^\u2022 (x) invariant:",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5803",
    "text": "pnj (x) = Jpnj(x')Tr1j (x | x') dx' \u00a0\u00a0\u00a0(18.51)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5804",
    "text": "These transitions may be constructed as any Markov chain Monte Carlo method (e.g., Metropolis-Hastings, Gibbs), including methods involving multiple passes\u00a0through all of the random variables or other kinds of iterations.",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5805",
    "text": "The AIS sampling strategy is then to generate samples from po and then use the transition operators to sequentially generate samples from the intermediate\u00a0distributions until we arrive at samples from the target distribution pi:",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5806",
    "text": "\u2022 for k = 1... K",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5807",
    "text": "- Sample xtf! ~ p0 (x)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5808",
    "text": "For sample k, we can derive the importance weight by chaining together the importance weights for the jumps between the intermediate distributions given in\u00a0Eq. 18.49:",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5809",
    "text": "(k)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5810",
    "text": "(k) _ K(x 7r) Pn2(x 772) \u00a0\u00a0\u00a0p (xifc))",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5811",
    "text": "-18.52",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5812",
    "text": "(k)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5813",
    "text": "w",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5814",
    "text": "\u2014 \u00a0\u00a0\u00a0Sample x^-",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5815",
    "text": "\u2014 \u00a0\u00a0\u00a0Sample x7k)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5816",
    "text": "end",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5817",
    "text": "(k)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5818",
    "text": "7n ^ T7n",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5819",
    "text": "^ t \u00a0\u00a0\u00a0(x7k) x7k) )",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5820",
    "text": "T7n-2(X 7n-1 1 x nn-2)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5821",
    "text": "t1 \u00a0\u00a0\u00a0(x7k)\u00a0\u00a0\u00a0\u00a0x7k) )",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5822",
    "text": "T7n-1 (X7n 1 xnn- 1 )",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5823",
    "text": "p0(x(k)) Pm(xm) \u00a0\u00a0\u00a0pn1-\u05f4(xS)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5824",
    "text": "To avoid numerical issues such as overflow, it is probably best to compute log w(k) by adding and subtracting log probabilities, rather than computing w(k) by multiplying\u00a0and dividing probabilities.",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5825",
    "text": "With the sampling procedure thus defined and the importance weights given in Eq. 18.52, the estimate of the ratio of partition functions is given by:",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5826",
    "text": "Z1",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5827",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5828",
    "text": "Z0 \u00a0\u00a0\u00a0K",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5829",
    "text": "K",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5830",
    "text": "k=1",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5831",
    "text": "w",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5832",
    "text": "(k)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5833",
    "text": "-18.53",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5834",
    "text": "In order to verify that this procedure defines a valid importance sampling scheme, we can show (Neal, 2001) that the AIS procedure corresponds to simple\u00a0importance sampling on an extended state space with points sampled over the\u00a0product space [xr]1,..., xnn-1, x!]. To do this, we define the distribution over the\u00a0extended space as:",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5835",
    "text": "P(xn1 ,\u2022\u2022\u2022, xnn-1 x1) \u00a0\u00a0\u00a0(18.54)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5836",
    "text": "_Pi(x1)T71-\u05f4(xnn-1 1 x1)Tnn-2(x7n-2 1 xnn-1) \u2022 \u2022 \u2022Tn 1 (xn1 1 xn2), \u00a0\u00a0\u00a0(18.55)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5837",
    "text": "where Ta is the reverse of the transition operator defined by Ta (via an application of Bayes\u2019 rule):",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5838",
    "text": "rp \u00a0\u00a0\u00a0Pa (x )\u00a0\u00a0\u00a0\u00a0pa (x )",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5839",
    "text": "Ta (x | x) _ \u00a0\u00a0\u00a0Ta(x | x ) _\u00a0\u00a0\u00a0\u00a0Ta (x | x )\u2022",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5840",
    "text": "Pa (x)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5841",
    "text": "pa (x)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5842",
    "text": "-18.56",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5843",
    "text": "Plugging the above into the expression for the joint distribution on the extended state space given in Eq. 18.55, we get:",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5844",
    "text": "-18.57",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5845",
    "text": "P(x71 , \u2022 \u2022 \u2022 , x7n-1 ,x 1 )",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5846",
    "text": "n\u20142",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5847",
    "text": "pr n-1(x rn-1)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5848",
    "text": "p1(x 1) \u00a0\u00a0\u00a0~\u00a0\u00a0\u00a0\u00a0(_ \u05e5\u00a0\u00a0\u00a0\u00a0Tr1-\u05f4(x 1 1 xrn-1)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5849",
    "text": "#7 n-1(x1 )",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5850",
    "text": "Pr/i (xni ) pm (x ri+1)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5851",
    "text": "T i(xm+1 1 xm)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5852",
    "text": "m.",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5853",
    "text": "-18.58",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5854",
    "text": "p1(x 1)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5855",
    "text": "n2",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5856",
    "text": "7^-1 (x1)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5857",
    "text": "x )Trn-1(x 1 1 xrn-1) pn1 (xn 1)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5858",
    "text": ".Pri+1 (xr;+1)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5859",
    "text": "Tr i(xr;+1 1 xr; )\u2022",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5860",
    "text": "i=",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5861",
    "text": "L p (x ) \u00a0\u00a0\u00a0^ri+1 1r",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5862",
    "text": "1 pni (xri+1)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5863",
    "text": "-18.59",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5864",
    "text": "We now have means of generating samples from the joint proposal distribution q over the extended sample via a sampling scheme given above, with the joint\u00a0distribution given by:",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5865",
    "text": "q(xn 1\u05d9 \u2022 \u2022 \u2022 \u05d9 xrn-1\u05d9x 1) _ p0(xr1 )Tr1(x r2 1 xn1 ) \u2022\u2022\u2022Trn-1 (x1 1 xrn-1)\u2022 \u00a0\u00a0\u00a0(18-60)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5866",
    "text": "We have a joint distribution on the extended space given by Eq. 18.59. Taking q(x^ , \u2022 \u2022 \u2022, xrn-1, x1) as the proposal distribution on the extended state space from\u00a0which we will draw samples, it remains to determine the importance weights:",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5867",
    "text": "w(k) _",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5868",
    "text": "p(xm1 \u05d9 \u2022 \u2022 \u2022 \u05d9 xrn-1,x 1) _ \u00a0\u00a0\u00a0,p1(x1",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5869",
    "text": "q(xr1 \u05d9 \u2022 \u2022 \u2022 \u05d9 xnn-1, x1)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5870",
    "text": "prn",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5871",
    "text": ".(k)",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5872",
    "text": "-18.61",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5873",
    "text": "These weights are the same as proposed for AIS. Thus we can interpret AIS as simple importance sampling applied to an extended state and its validity follows\u00a0immediately from the validity of importance sampling.",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5874",
    "text": "Annealed importance sampling (AIS) was first discovered by Jarzynski (1997) and then again, independently, by Neal (2001). It is currently the most common\u00a0way of estimating the partition function for undirected probabilistic models. The\u00a0reasons for this may have more to do with the publication of an influential paper\u00a0(Salakhutdinov and Murray, 2008) describing its application to estimating the\u00a0partition function of restricted Boltzmann machines and deep belief networks than\u00a0with any inherent advantage the method has over the other method described\u00a0below.",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5875",
    "text": "A discussion of the properties of the AIS estimator (e.g.. its variance and efficiency) can be found in Neal (2001).",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5876",
    "text": "Bridge sampling Bennett (1976) is another method that, like AIS, addresses the shortcomings of importance sampling. Rather than chaining together a series of\u00a0intermediate distributions, bridge sampling relies on a single distributionp*, known\u00a0as the bridge, to interpolate between a distribution with known partition function,\u00a0p0, and a distribution pi for which we are trying to estimate the partition function",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5877",
    "text": "Z1.",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5878",
    "text": "Bridge sampling estimates the ratio Z! /Z0 as the ratio of the expected importance weights between p and p* and between p and p*:",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5879",
    "text": "K \u00a0\u00a0\u00a0(k)\\",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5880",
    "text": "Z1 \u00a0\u00a0\u00a0p* (x0 )",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5881",
    "text": "Z0 ~ \u00a0\u00a0\u00a0(k)x",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5882",
    "text": "Z 0 \u00a0\u00a0\u00a0k=1 po (x0 )",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5883",
    "text": "/!:",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5884",
    "text": "p* (x!k)) =1 p1 (x!k))",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5885",
    "text": "-18.62",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5886",
    "text": "If the bridge distribution p* is chosen carefully to have a large overlap of support with both p0 and p1, then bridge sampling can allow the distance between two\u00a0distributions (or more formally, Dkl(p0||p 1)) to be much larger than with standard\u00a0importance sampling.",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5887",
    "text": "It can be shown that the optimal bridging distribution is given by p*opt) (x) x rpo(x)+ftX(x) where r = Z1/Z0. At first, this appears to be an unworkable solution\u00a0as it would seem to require the very quantity we are trying to estimate, Z1 /Zo.\u00a0However, it is possible to start with a coarse estimate of r and use the resulting\u00a0bridge distribution to refine our estimate iteratively (Neal, 2005). That is, we\u00a0iteratively re-estimate the ratio and use each iteration to update the value of r.",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5888",
    "text": "Linked importance sampling Both AIS and bridge sampling have their advantages. If Dkl (p 0|p1) is not too large (because po and p 1 are sufficiently close) bridge sampling can be a more effective means of estimating the ratio of partition\u00a0functions than AIS. If, however, the two distributions are too far apart for a single\u00a0distribution p* to bridge the gap then one can at least use AIS with potentially\u00a0many intermediate distributions to span the distance between po and p1. Neal\u00a0(2005) showed how his linked importance sampling method leveraged the power of\u00a0the bridge sampling strategy to bridge the intermediate distributions used in AIS\u00a0to significantly improve the overall partition function estimates.",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5889",
    "text": "Estimating the partition function while training While AIS has become accepted as the standard method for estimating the partition function for many\u00a0undirected models, it is sufficiently computationally intensive that it remains\u00a0infeasible to use during training. However, alternative strategies that have been\u00a0explored to maintain an estimate of the partition function throughout training",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5890",
    "text": "Using a combination of bridge sampling, short-chain AIS and parallel tempering, Desjardins et al. (2011) devised a scheme to track the partition function of an",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5891",
    "text": "RBM throughout the training process. The strategy is based on the maintenance of independent estimates of the partition functions of the RBM at every temperature\u00a0operating in the parallel tempering scheme. The authors combined bridge sampling\u00a0estimates of the ratios of partition functions of neighboring chains (i.e. from\u00a0parallel tempering) with AIS estimates across time to come up with a low variance\u00a0estimate of the partition functions at every iteration of learning.",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5892",
    "text": "The tools described in this chapter provide many different ways of overcoming the problem of intractable partition functions, but there can be several other\u00a0difficulties involved in training and using generative models. Foremost among these\u00a0is the problem of intractable inference, which we confront next.",
    "chapter": "",
    "chapter_id": "main-34.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5893",
    "text": "Many probabilistic models are difficult to train because it is difficult to perform inference in them. In the context of deep learning, we usually have a set of visible\u00a0variables v and a set of latent variables h. The challenge of inference usually\u00a0refers to the difficult problem of computing p(h | v) or taking expectations with\u00a0respect to it. Such operations are often necessary for tasks like maximum likelihood\u00a0learning.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5894",
    "text": "Many simple graphical models with only one hidden layer, such as restricted Boltzmann machines and probabilistic PCA, are defined in a way that makes\u00a0inference operations like computingp(h | v), or taking expectations with respect\u00a0to it, simple. Unfortunately, most graphical models with multiple layers of hidden\u00a0variables have intractable posterior distributions. Exact inference requires an\u00a0exponential amount of time in these models. Even some models with only a single\u00a0layer, such as sparse coding, have this problem.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5895",
    "text": "In this chapter, we introduce several of the techniques for confronting these intractable inference problems. Later, in Chapter 20, we will describe how to use\u00a0these techniques to train probabilistic models that would otherwise be intractable,\u00a0such as deep belief networks and deep Boltzmann machines.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5896",
    "text": "Intractable inference problems in deep learning usually arise from interactions between latent variables in a structured graphical model. See Fig. 19.1 for some\u00a0examples. These interactions may be due to direct interactions in undirected\u00a0models or \u201cexplaining away\u201d interactions between mutual ancestors of the same\u00a0visible unit in directed models.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5897",
    "text": "Figure 19.1: Intractable inference problems in deep learning are usually the result of interactions between latent variables in a structured graphical model. These can be due to\u00a0edges directly connecting one latent variable to another, or due to longer paths that are\u00a0activated when the child of a V-structure is observed. (Left) A semi-restricted Boltzmann\u00a0machine (Osindero and Hinton, 2008) with connections between hidden units. These\u00a0direct connections between latent variables make the posterior distribution intractable\u00a0due to large cliques of latent variables. (Center) A deep Boltzmann machine, organized\u00a0into layers of variables without intra-layer connections, still has an intractable posterior\u00a0distribution due to the connections between layers. (Right) This directed model has\u00a0interactions between latent variables when the visible variables are observed, because\u00a0every two latent variables are co-parents. Some probabilistic models are able to provide\u00a0tractable inference over the latent variables despite having one of the graph structures\u00a0depicted above. This is possible if the conditional probability distributions are chosen to\u00a0introduce additional independences beyond those described by the graph. For example,\u00a0probabilistic PCA has the graph structure shown in the right, yet still has simple inference\u00a0due to special properties of the specific conditional distributions it uses (linear-Gaussian\u00a0conditionals with mutually orthogonal basis vectors).",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5898",
    "text": "Many approaches to confronting the problem of difficult inference make use of the observation that exact inference can be described as an optimization problem.\u00a0Approximate inference algorithms may then be derived by approximating the\u00a0underlying optimization problem.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5899",
    "text": "To construct the optimization problem, assume we have a probabilistic model consisting of observed variables v and latent variables h. We would like to compute\u00a0the log probability of the observed data, logp(v; 6). Sometimes it is too difficult\u00a0to compute logp(v; 6) if it is costly to marginalize out h. Instead, we can compute\u00a0a lower bound L(v, 6, q) on logp(v; 6). This bound is called the evidence lower\u00a0bound (ELBO). Another commonly used name for this lower bound is the negative\u00a0variational free energy. Specifically, the evidence lower bound is defined to be",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5900",
    "text": "L(v, 6, q) = logp(v; 6) - Dkl (q(h | v)||p(h | v; 6)) \u00a0\u00a0\u00a0(19.1)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5901",
    "text": "where q is an arbitrary probability distribution over h.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5902",
    "text": "Because the difference between logp(v) and L(v, 6, q) is given by the KL divergence and because the KL divergence is always non-negative, we can see that\u00a0L always has at most the same value as the desired log probability. The two are\u00a0equal if and only if q is the same distribution as p(h | v).",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5903",
    "text": "Surprisingly, L can be considerably easier to compute for some distributions q. Simple algebra shows that we can rearrange L into a much more convenient form:",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5904",
    "text": "L(v, 6, q) = logp(v; 6) - DKL(q(h | v) ||p(h | v; 6)) \u00a0\u00a0\u00a0(19.2)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5905",
    "text": "#ERROR!",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5906",
    "text": "#ERROR!",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5907",
    "text": "p(v;0)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5908",
    "text": "#ERROR!",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5909",
    "text": "This yields the more canonical definition of the evidence lower bound,",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5910",
    "text": "L(v, 6, q) = Eh-q [logp(h, v)] + H(q). \u00a0\u00a0\u00a0(19.7)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5911",
    "text": "For an appropriate choice of q, L is tractable to compute. For any choice of q, L provides a lower bound on the likelihood. For q(h | v) that are better\u00a0approximations of p(h | v), the lower bound L will be tighter, in other words,\u00a0closer to logp( v). When q(h | v) = p (h | v), the approximation is perfect, and\u00a0L(v, 0,q) = logp(v; 6).",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5912",
    "text": "We can thus think of inference as the procedure for finding the q that maximizes L. Exact inference maximizes L perfectly by searching over a family of functions\u00a0q that includes p(h | v). Throughout this chapter, we will show how to derive\u00a0different forms of approximate inference by using approximate optimization to\u00a0find q. We can make the optimization procedure less expensive but approximate\u00a0by restricting the family of distributions q the optimization is allowed to search\u00a0over or by using an imperfect optimization procedure that may not completely\u00a0maximize L but merely increase it by a significant amount.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5913",
    "text": "No matter what choice of q we use, L is a lower bound. We can get tighter or looser bounds that are cheaper or more expensive to compute depending on\u00a0how we choose to approach this optimization problem. We can obtain a poorly\u00a0matched q but reduce the computational cost by using an imperfect optimization\u00a0procedure, or by using a perfect optimization procedure over a restricted family of\u00a0q distributions.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5914",
    "text": "The first algorithm we introduce based on maximizing a lower bound L is the expectation maximization (EM) algorithm, a popular training algorithm for models\u00a0with latent variables. We describe here a view on the EM algorithm developed by\u00a0Neal and Hinton (1999). Unlike most of the other algorithms we describe in this\u00a0chapter, EM is not an approach to approximate inference, but rather an approach\u00a0to learning with an approximate posterior.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5915",
    "text": "The EM algorithm consists of alternating between two steps until convergence:",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5916",
    "text": "The E-step (Expectation step): Let 6(0) denote the value of the parameters at the beginning of the step. Set q(h(i) | v) = p(h(i) | v(i); 6(0)) for all indices\u00a0i of the training examples v(i) we want to train on (both batch and minibatch\u00a0variants are valid). By this we mean q is defined in terms of the current\u00a0parameter value of 6^0); if we vary 6 thenp(h | v; 6) will change but q(h | v)\u00a0will remain equal to p(h | v; 6(0)).",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5917",
    "text": "The M-step (Maximization step): Completely or partially maximize",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5918",
    "text": "-19.8",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5919",
    "text": "E L(v(i). 6.4)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5920",
    "text": "with respect to 0 using your optimization algorithm of choice.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5921",
    "text": "This can be viewed as a coordinate ascent algorithm to maximize L. On one step, we maximize L with respect to q, and on the other, we maximize L with\u00a0respect to 0.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5922",
    "text": "Stochastic gradient ascent on latent variable models can be seen as a special case of the EM algorithm where the M step consists of taking a single gradient\u00a0step. Other variants of the EM algorithm can make much larger steps. For some\u00a0model families, the M step can even be performed analytically, jumping all the\u00a0way to the optimal solution for 0 given the current q.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5923",
    "text": "Even though the E-step involves exact inference, we can think of the EM algorithm as using approximate inference in some sense. Specifically, the M-step\u00a0assumes that the same value of q can be used for all values of 0. This will introduce\u00a0a gap between L and the true logp( v) as the M-step moves further and further\u00a0away from the value 0(0) used in the E-step. Fortunately, the E-step reduces the\u00a0gap to zero again as we enter the loop for the next time.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5924",
    "text": "The EM algorithm contains a few different insights. First, there is the basic structure of the learning process, in which we update the model parameters to\u00a0improve the likelihood of a completed dataset, where all missing variables have\u00a0their values provided by an estimate of the posterior distribution. This particular\u00a0insight is not unique to the EM algorithm. For example, using gradient descent to\u00a0maximize the log-likelihood also has this same property; the log-likelihood gradient\u00a0computations require taking expectations with respect to the posterior distribution\u00a0over the hidden units. Another key insight in the EM algorithm is that we can\u00a0continue to use one value of q even after we have moved to a different value of 0.\u00a0This particular insight is used throughout classical machine learning to derive large\u00a0M-step updates. In the context of deep learning, most models are too complex\u00a0to admit a tractable solution for an optimal large M-step update, so this second\u00a0insight which is more unique to the EM algorithm is rarely used.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5925",
    "text": "We usually use the term inference to refer to computing the probability distribution over one set of variables given another. When training probabilistic models with\u00a0latent variables, we are usually interested in computing p(h | v). An alternative\u00a0form of inference is to compute the single most likely value of the missing variables,\u00a0rather than to infer the entire distribution over their possible values. In the context\u00a0of latent variable models, this means computing",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5926",
    "text": "h* = argmaxp(h | v). \u00a0\u00a0\u00a0(19.9)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5927",
    "text": "h",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5928",
    "text": "This is known as maximum a posteriori inference, abbreviated MAP inference.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5929",
    "text": "MAP inference is usually not thought of as approximate inference\u2014it does compute the exact most likely value of h*. However, if we wish to develop a\u00a0learning process based on maximizing L( v, h, q), then it is helpful to think of MAP\u00a0inference as a procedure that provides a value of q. In this sense, we can think of\u00a0MAP inference as approximate inference, because it does not provide the optimal",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5930",
    "text": "q.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5931",
    "text": "Recall from Sec. 19.1 that exact inference consists of maximizing",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5932",
    "text": "L(v, Q, q) = Eh^q [logp(h, v)] + H(q) \u00a0\u00a0\u00a0(19.10)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5933",
    "text": "with respect to q over an unrestricted family of probability distributions, using an exact optimization algorithm. We can derive MAP inference as a form of\u00a0approximate inference by restricting the family of distributions q may be drawn\u00a0from. Specifically, we require q to take on a Dirac distribution:",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5934",
    "text": "q(h | v) = 5(h \u2014 p). \u00a0\u00a0\u00a0(19.11)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5935",
    "text": "This means that we can now control q entirely via p. Dropping terms of L that do not vary with p, we are left with the optimization problem",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5936",
    "text": "p* = argmaxlogp(h = p, v), \u00a0\u00a0\u00a0(19.12)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5937",
    "text": "which is equivalent to the MAP inference problem",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5938",
    "text": "h* = argmaxp(h | v). \u00a0\u00a0\u00a0(19.13)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5939",
    "text": "h",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5940",
    "text": "We can thus justify a learning procedure similar to EM, in which we alternate between performing MAP inference to infer h * and then update Q to increase\u00a0logp(h*, v). As with EM, this is a form of coordinate ascent on L, where we\u00a0alternate between using inference to optimize L with respect to q and using\u00a0parameter updates to optimize L with respect to Q. The procedure as a whole can\u00a0be justified by the fact that L is a lower bound on logp(v). In the case of MAP\u00a0inference, this justification is rather vacuous, because the bound is infinitely loose,\u00a0due to the Dirac distribution\u2019s differential entropy of negative infinity. However,\u00a0adding noise to p would make the bound meaningful again.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5941",
    "text": "MAP inference is commonly used in deep learning as both a feature extractor and a learning mechanism. It is primarily used for sparse coding models.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5942",
    "text": "Recall from Sec. 13.4 that sparse coding is a linear factor model that imposes a sparsity-inducing prior on its hidden units. A common choice is a factorial Laplace\u00a0prior, with",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5943",
    "text": "p(hi) = ^e-A|h 1. \u00a0\u00a0\u00a0(1R14)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5944",
    "text": "The visible units are then generated by performing a linear transformation and adding noise:",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5945",
    "text": "p(x | h) = N(v; Wh + b, 0-1I). \u00a0\u00a0\u00a0(19.15)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5946",
    "text": "Computing or even representing p(h | v) is difficult. Every pair of variables hi and hj are both parents of v. This means that when v is observed, the graphical\u00a0model contains an active path connecting hi and hj. All of the hidden units thus\u00a0participate in one massive clique in p (h | v). If the model were Gaussian then\u00a0these interactions could be modeled efficiently via the covariance matrix, but the\u00a0sparse prior makes these interactions non-Gaussian.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5947",
    "text": "Because p(h | v) is intractable, so is the computation of the log-likelihood and its gradient. We thus cannot use exact maximum likelihood learning. Instead, we\u00a0use MAP inference and learn the parameters by maximizing the ELBO defined by\u00a0the Dirac distribution around the MAP estimate of h.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5948",
    "text": "If we concatenate all of the h vectors in the training set into a matrix H, and concatenate all of the v vectors into a matrix V, then the sparse coding learning\u00a0process consists of minimizing",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5949",
    "text": "J(H, W) = \u00a3 |Hi,j | +\u00a3 (V",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5950",
    "text": "i,j \u00a0\u00a0\u00a0i,j",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5951",
    "text": "HW",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5952",
    "text": "T",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5953",
    "text": ")2.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5954",
    "text": "i,j",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5955",
    "text": "-19.16",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5956",
    "text": "Most applications of sparse coding also involve weight decay or a constraint on the norms of the columns of W, in order to prevent the pathological solution with\u00a0extremely small H and large W.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5957",
    "text": "We can minimize J by alternating between minimization with respect to H and minimization with respect to W. Both sub-problems are convex. In fact,\u00a0the minimization with respect to W is just a linear regression problem. However,\u00a0minimization of J with respect to both arguments is usually not a convex problem.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5958",
    "text": "Minimization with respect to H requires specialized algorithms such as the feature-sign search algorithm (Lee et al., 2007).",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5959",
    "text": "We have seen how the evidence lower bound L (v, 0,q) is a lower bound on log p(v; 0), how inference can be viewed as maximizing L with respect to q, and\u00a0how learning can be viewed as maximizing L with respect to 0. We have seen\u00a0that the EM algorithm allows us to make large learning steps with a fixed q and\u00a0that learning algorithms based on MAP inference allow us to learn using a point\u00a0estimate of p(h | v) rather than inferring the entire distribution. Now we develop\u00a0the more general approach to variational learning.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5960",
    "text": "The core idea behind variational learning is that we can maximize L over a restricted family of distributions q. This family should be chosen so that it is easy\u00a0to compute Eq log p(h, v). A typical way to do this is to introduce assumptions\u00a0about how q factorizes.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5961",
    "text": "A common approach to variational learning is to impose the restriction that q is a factorial distribution:",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5962",
    "text": "q(h 1 v) = IJ q(hi1 v). \u00a0\u00a0\u00a0(19T7)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5963",
    "text": "i",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5964",
    "text": "This is called the mean field approach. More generally, we can impose any graphical model structure we choose on q, to flexibly determine how many interactions we\u00a0want our approximation to capture. This fully general graphical model approach\u00a0is called structured variational inference (Saul and Jordan, 1996).",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5965",
    "text": "The beauty of the variational approach is that we do not need to specify a specific parametric form for q. We specify how it should factorize, but then the\u00a0optimization problem determines the optimal probability distribution within those\u00a0factorization constraints. For discrete latent variables, this just means that we\u00a0use traditional optimization techniques to optimize a finite number of variables\u00a0describing the q distribution. For continuous latent variables, this means that we\u00a0use a branch of mathematics called calculus of variations to perform optimization\u00a0over a space of functions, and actually determine which function should be used\u00a0to represent q. Calculus of variations is the origin of the names \u201cvariational\u00a0learning\u201d and \u201cvariational inference,\u201d though these names apply even when the\u00a0latent variables are discrete and calculus of variations is not needed. In the case\u00a0of continuous latent variables, calculus of variations is a powerful technique that\u00a0removes much of the responsibility from the human designer of the model, who\u00a0now must specify only how q factorizes, rather than needing to guess how to design\u00a0a specific q that can accurately approximate the posterior.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5966",
    "text": "Because L(v, 0,q) is defined to be logp( v; 0) \u2014 DKL (q(h | v)||p(h | v; 0)), we can think of maximizing L with respect to q as minimizing DKL(q(h | v)||p(h | v)).",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5967",
    "text": "In this sense, we are fitting q to p. However, we are doing so with the opposite direction of the KL divergence than we are used to using for fitting an approximation.\u00a0When we use maximum likelihood learning to fit a model to data, we minimize\u00a0DKL(pdata ||pmodei)\u2022 As illustrated in Fig. 3.6, this means that maximum likelihood\u00a0encourages the model to have high probability everywhere that the data has high\u00a0probability, while our optimization-based inference procedure encourages q to\u00a0have low probability everywhere the true posterior has low probability. Both\u00a0directions of the KL divergence can have desirable and undesirable properties. The\u00a0choice of which to use depends on which properties are the highest priority for\u00a0each application. In the case of the inference optimization problem, we choose\u00a0to use Dkl(q(h | v)||p(h | v)) for computational reasons. Specifically, computing\u00a0DKL(q(h | v) ||p(h | v)) involves evaluating expectations with respect to q, so by\u00a0designing q to be simple, we can simplify the required expectations. The opposite\u00a0direction of the KL divergence would require computing expectations with respect\u00a0to the true posterior. Because the form of the true posterior is determined by\u00a0the choice of model, we cannot design a reduced-cost approach to computing\u00a0DKL(p(h | v)||q(h | v)) exactly.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5968",
    "text": "Variational inference with discrete latent variables is relatively straightforward. We define a distribution q, typically one where each factor of q is just defined\u00a0by a lookup table over discrete states. In the simplest case, h is binary and we\u00a0make the mean field assumption that q factorizes over each individual hi. In this\u00a0case we can parametrize q with a vector h whose entries are probabilities. Then",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5969",
    "text": "q(hi = 1 | v) = hj.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5970",
    "text": "After determining how to represent q, we simply optimize its parameters. In the case of discrete latent variables, this is just a standard optimization problem.\u00a0In principle the selection of q could be done with any optimization algorithm, such\u00a0as gradient descent.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5971",
    "text": "Because this optimization must occur in the inner loop of a learning algorithm, it must be very fast. To achieve this speed, we typically use special optimization\u00a0algorithms that are designed to solve comparatively small and simple problems in\u00a0very few iterations. A popular choice is to iterate fixed point equations, in other\u00a0words, to solve",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5972",
    "text": "d",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5973",
    "text": "L = 0 \u00a0\u00a0\u00a0(19.18)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5974",
    "text": "dhj",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5975",
    "text": "for hj. We repeatedly update different elements of h until we satisfy a convergence",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5976",
    "text": "criterion.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5977",
    "text": "To make this more concrete, we show how to apply variational inference to the binary sparse coding model (we present here the model developed by Henniges et al.\u00a0(2010) but demonstrate traditional, generic mean field applied to the model, while\u00a0they introduce a specialized algorithm). This derivation goes into considerable\u00a0mathematical detail and is intended for the reader who wishes to fully resolve\u00a0any ambiguity in the high-level conceptual description of variational inference and\u00a0learning we have presented so far. Readers who do not plan to derive or implement\u00a0variational learning algorithms may safely skip to the next section without missing\u00a0any new high-level concepts. Readers who proceed with the binary sparse coding\u00a0example are encouraged to review the list of useful properties of functions that\u00a0commonly arise in probabilistic models in Sec. 3.10. We use these properties\u00a0liberally throughout the following derivations without highlighting exactly where\u00a0we use each one.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5978",
    "text": "In the binary sparse coding model, the input v \u00a3 Rn is generated from the model by adding Gaussian noise to the sum of m different components which\u00a0can each be present or absent. Each component is switched on or off by the\u00a0corresponding hidden unit in h \u00a3 {0,1}m:",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5979",
    "text": "-19.19",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5980",
    "text": "-19.2",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5981",
    "text": "P(hi = 1) = ^(bi)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5982",
    "text": "p(v | h) = N(v; Wh, 3 *)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5983",
    "text": "where b is a learnable set of biases, W is a learnable weight matrix, and 3 is a learnable, diagonal precision matrix.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5984",
    "text": "Training this model with maximum likelihood requires taking the derivative with respect to the parameters. Consider the derivative with respect to one of the\u00a0biases:",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5985",
    "text": "-19.21",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5986",
    "text": "-19.22",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5987",
    "text": "-19.23",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5988",
    "text": "-19.24",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5989",
    "text": "di lQg p(v)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5990",
    "text": ". at iP(v) p(v)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5991",
    "text": "Wi \u00a0\u00a0\u00a0h p(h v)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5992",
    "text": "p(v)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5993",
    "text": "Wi ^h p(h)p(v I h) p(v)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5994",
    "text": "Figure 19.2: The graph structure of a binary sparse coding model with four hidden units. (Left) The graph structure of p( h, v). Note that the edges are directed, and that every two\u00a0hidden units are co-parents of every visible unit. (Right) The graph structure ofp(h | v).\u00a0In order to account for the active paths between co-parents, the posterior distribution\u00a0needs an edge between all of the hidden units.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5995",
    "text": "Eh P(v 1 h) 6b i P(h)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5996",
    "text": "P(v)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5997",
    "text": "\u00a3 p(h 1 \u05f4) *p(h)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5998",
    "text": "h",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "5999",
    "text": "d",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6000",
    "text": "P(h)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6001",
    "text": "Eh~p(h|v) db- 10gp(h)\u05be",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6002",
    "text": "-19.25",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6003",
    "text": "-19.26",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6004",
    "text": "-19.27",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6005",
    "text": "This requires computing expectations with respect to p(h | v). Unfortunately, p(h | v) is a complicated distribution. See Fig. 19.2 for the graph structure of\u00a0p(h, v) andp(h | v). The posterior distribution corresponds to the complete graph\u00a0over the hidden units, so variable elimination algorithms do not help us to compute\u00a0the required expectations any faster than brute force.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6006",
    "text": "We can resolve this difficulty by using variational inference and variational learning instead.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6007",
    "text": "We can make a mean field approximation:",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6008",
    "text": "q(h | v) = Y[q(hi | v). \u00a0\u00a0\u00a0(19.28)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6009",
    "text": "i",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6010",
    "text": "The latent variables of the binary sparse coding model are binary, so to represent a factorial q we simply need to model m Bernoulli distributions q( hi | v). A natural\u00a0way to represent the means of the Bernoulli distributions is with a vector h of\u00a0probabilities, with q(hi =1 | v) = h. We impose a restriction that hi is never\u00a0equal to 0 or to 1, in order to avoid errors when computing, for example, log hi.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6011",
    "text": "We will see that the variational inference equations never assign 0 or 1 to hi analytically. However, in a software implementation, machine rounding error could\u00a0result in 0 or 1 values. In software, we may wish to implement binary sparse\u00a0coding using an unrestricted vector of variational parameters z and obtain h via\u00a0the relation h = a (z). We can thus safely compute log h on a computer by using\u00a0the identity log a(z) = \u2014Z(\u2014zi) relating the sigmoid and the softplus.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6012",
    "text": "To begin our derivation of variational learning in the binary sparse coding model, we show that the use of this mean field approximation makes learning\u00a0tractable.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6013",
    "text": "The evidence lower bound is given by",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6014",
    "text": "L(v, 0,q)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6015",
    "text": "#ERROR!",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6016",
    "text": "#ERROR!",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6017",
    "text": "Y log p(hi) +Y logp(vi I h) \u2014 Y log q(hi I v)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6018",
    "text": ".i=1 \u00a0\u00a0\u00a0i=1\u00a0\u00a0\u00a0\u00a0i=1",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6019",
    "text": "#ERROR!",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6020",
    "text": "\u2014^ (vi \u2014 Wi'h)2)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6021",
    "text": "Y [hi(log a(bi) \u2014 log hi) + (1 \u2014 hi)(log a(\u2014bi) \u2014 log(1 \u2014 hi))",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6022",
    "text": "#NAME?",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6023",
    "text": "i=1",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6024",
    "text": "+ Eh",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6025",
    "text": "-19.29",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6026",
    "text": "-19.3",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6027",
    "text": "-19.31",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6028",
    "text": "-19.32",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6029",
    "text": "-19.33",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6030",
    "text": "-19.34",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6031",
    "text": "-19.35",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6032",
    "text": "i=1",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6033",
    "text": "i=1",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6034",
    "text": "log\u05be^ \u2014 \u00a0\u00a0\u00a0(v2 \u2014 2viWi: h + Y",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6035",
    "text": "^ j",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6036",
    "text": "wZfy + \u00a0\u00a0\u00a0Wi,j Wi,k hjhk",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6037",
    "text": "k=j",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6038",
    "text": "J J",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6039",
    "text": "-19.36",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6040",
    "text": "While these equations are somewhat unappealing aesthetically, they show that L can be expressed in a small number of simple arithmetic operations. The evidence\u00a0lower bound L is therefore tractable. We can use L as a replacement for the\u00a0intractable log-likelihood.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6041",
    "text": "In principle, we could simply run gradient ascent on both v and h and this would make a perfectly acceptable combined inference and training algorithm.\u00a0Usually, however, we do not do this, for two reasons. First, this would require\u00a0storing h for each v. We typically prefer algorithms that do not require per-example memory. It is difficult to scale learning algorithms to billions of examples\u00a0if we must remember a dynamically updated vector associated with each example.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6042",
    "text": "Second, we would like to be able to extract the features h very quickly, in order to recognize the content of v. In a realistic deployed setting, we would need to be\u00a0able to compute h in real time.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6043",
    "text": "For both these reasons, we typically do not use gradient descent to compute the mean field parameters h. Instead, we rapidly estimate them with fixed point\u00a0equations.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6044",
    "text": "The idea behind fixed point equations is that we are seeking a local maximum with respect to h, where VhL(v, 6, h) = 0. We cannot efficiently solve this\u00a0equation with respect to all of h simultaneously. However, we can solve for a single\u00a0variable:",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6045",
    "text": "d",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6046",
    "text": "d hi",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6047",
    "text": "-19.37",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6048",
    "text": "L(v, 6, h) = 0.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6049",
    "text": "We can then iteratively apply the solution to the equation for i = 1,..., m, and repeat the cycle until we satisfy a converge criterion. Common convergence\u00a0criteria include stopping when a full cycle of updates does not improve L by more\u00a0than some tolerance amount, or when the cycle does not change h by more than\u00a0some amount.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6050",
    "text": "Iterating mean field fixed point equations is a general technique that can provide fast variational inference in a broad variety of models. To make this more\u00a0concrete, we show how to derive the updates for the binary sparse coding model in\u00a0particular.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6051",
    "text": "First, we must write an expression for the derivatives with respect to hi. To do so, we substitute Eq. 19.36 into the left side of Eq. 19.37:",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6052",
    "text": "d",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6053",
    "text": "dhi",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6054",
    "text": "d",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6055",
    "text": "dhi",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6056",
    "text": "-19.38",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6057",
    "text": "L(v, 6, h)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6058",
    "text": "m",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6059",
    "text": "Y [hj (log a(bj) - loghj) + (1 - hj )(log a(-bj) - log(1 - hj)) \u00a0\u00a0\u00a0(19.39)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6060",
    "text": "j=1",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6061",
    "text": "j=1",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6062",
    "text": "P3",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6063",
    "text": "^g \u00a0\u00a0\u00a0- p j 1 yjj- 2v 3W3h+Y",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6064",
    "text": "Wj,khk + \u00a0\u00a0\u00a0Wj,kWj,l hkhl",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6065",
    "text": "l=k",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6066",
    "text": "#ERROR!",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6067",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6068",
    "text": "+",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6069",
    "text": "j = l",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6070",
    "text": "Pj I VjWji - 2 Wji - \u00a3 WjkWji hk",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6071",
    "text": "k=i",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6072",
    "text": "-19.4",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6073",
    "text": "-19.41",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6074",
    "text": "-19.42",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6075",
    "text": "b - log hi + log(1 - hi) + vTpW,i - \u05f4WT0W:,i -Y, W.T0W:Jf1j. (19.43)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6076",
    "text": "To apply the fixed point update inference rule, we solve for the hi that sets Eq. 19.43 to 0:",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6077",
    "text": "i",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6078",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6079",
    "text": "#ERROR!",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6080",
    "text": "T",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6081",
    "text": "i",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6082",
    "text": "i",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6083",
    "text": "2",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6084",
    "text": "i",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6085",
    "text": ",i j",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6086",
    "text": "-19.44",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6087",
    "text": "At this point, we can see that there is a close connection between recurrent neural networks and inference in graphical models. Specifically, the mean field\u00a0fixed point equations defined a recurrent neural network. The task of this network\u00a0is to perform inference. We have described how to derive this network from a\u00a0model description, but it is also possible to train the inference network directly.\u00a0Several ideas based on this theme are described in Chapter 20.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6088",
    "text": "In the case of binary sparse coding, we can see that the recurrent network connection specified by Eq. 19.44 consists of repeatedly updating the hidden\u00a0units based on the changing values of the neighboring hidden units. The input\u00a0always sends a fixed message of vT^ W to the hidden units, but the hidden units\u00a0constantly update the message they send to each other. Specifically, two units hi\u00a0and hj inhibit each other when their weight vectors are aligned. This is a form of\u00a0competition\u2014between two hidden units that both explain the input, only the one\u00a0that explains the input best will be allowed to remain active. This competition is\u00a0the mean field approximation\u2019s attempt to capture the explaining away interactions\u00a0in the binary sparse coding posterior. The explaining away effect actually should\u00a0cause a multi-modal posterior, so that if we draw samples from the posterior,\u00a0some samples will have one unit active, other samples will have the other unit\u00a0active, but very few samples have both active. Unfortunately, explaining away\u00a0interactions cannot be modeled by the factorial q used for mean field, so the mean\u00a0field approximation is forced to choose one mode to model. This is an instance of\u00a0the behavior illustrated in Fig. 3.6.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6089",
    "text": "We can rewrite Eq. 19.44 into an equivalent form that reveals some further insights:",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6090",
    "text": "hi = a bi + | v -Y, W: j hj | PW:,i - 1W.,i PW:,i",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6091",
    "text": "j=i",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6092",
    "text": "/ \\T",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6093",
    "text": "-19.45",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6094",
    "text": "In this reformulation, we see the input at each step as consisting of v - ^j= W:jhj rather than v. We can thus think of unit i as attempting to encode the residual\u00a0error in v given the code of the other units. We can thus think of sparse coding as\u00a0an iterative autoencoder, that repeatedly encodes and decodes its input, attempting\u00a0to fix mistakes in the reconstruction after each iteration.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6095",
    "text": "In this example, we have derived an update rule that updates a single unit at a time. It would be advantageous to be able to update more units simultaneously.\u00a0Some graphical models, such as deep Boltzmann machines, are structured in such a\u00a0way that we can solve for many entries of h simultaneously. Unfortunately, binary\u00a0sparse coding does not admit such block updates. Instead, we can use a heuristic\u00a0technique called damping to perform block updates. In the damping approach, we\u00a0solve for the individually optimal values of every element of h, then move all of\u00a0the values in a small step in that direction. This approach is no longer guaranteed\u00a0to increase L at each step, but works well in practice for many models. See Koller\u00a0and Friedman (2009) for more information about choosing the degree of synchrony\u00a0and damping strategies in message passing algorithms.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6096",
    "text": "Before continuing with our presentation of variational learning, we must briefly introduce an important set of mathematical tools used in variational learning:",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6097",
    "text": "calculus of variations.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6098",
    "text": "Many machine learning techniques are based on minimizing a function J(6) by finding the input vector 6 E Rn for which it takes on its minimal value. This can\u00a0be accomplished with multivariate calculus and linear algebra, by solving for the\u00a0critical points where VqJ(6) = 0. In some cases, we actually want to solve for a\u00a0function f (x), such as when we want to find the probability density function over\u00a0some random variable. This is what calculus of variations enables us to do.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6099",
    "text": "Sf (x)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6100",
    "text": "A complete formal development of functional derivatives is beyond the scope of this book. For our purposes, it is sufficient to state that for differentiable functions\u00a0f (x) and differentiable functions g(y, x) with continuous derivatives, that",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6101",
    "text": "A function of a function f is known as a functional J [f]. Much as we can take partial derivatives of a function with respect to elements of its vector-valued\u00a0argument, we can take functional derivatives, also known as variational derivatives,\u00a0of a functional J[f ] with respect to individual values of the function f (x) at any\u00a0specific value of x. The functional derivative of the functional J with respect to\u00a0the value of the function f at point x is denoted",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6102",
    "text": "-19.46",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6103",
    "text": "$ \u00a0\u00a0\u00a0d",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6104",
    "text": "spx) g(f(x)\u05f3x) dx=dyg(f(x)x)\u05f3",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6105",
    "text": "To gain some intuition for this identity, one can think of f (x) as being a vector with uncountably many elements, indexed by a real vector x. In this (somewhat\u00a0incomplete view), the identity providing the functional derivatives is the same as\u00a0we would obtain for a vector 6 E Rn indexed by positive integers:",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6106",
    "text": "J^ gA A\u25a0 \u00a0\u00a0\u00a0(19-47)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6107",
    "text": "Many results in other machine learning publications are presented using the more general Euler-Lagrange equation which allows g to depend on the derivatives of f\u00a0as well as the value of f, but we do not need this fully general form for the results\u00a0presented in this book.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6108",
    "text": "To optimize a function with respect to a vector, we take the gradient of the function with respect to the vector and solve for the point where every element of\u00a0the gradient is equal to zero. Likewise, we can optimize a functional by solving for\u00a0the function where the functional derivative at every point is equal to zero.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6109",
    "text": "As an example of how this process works, consider the problem of finding the probability distribution function over x E R that has maximal differential entropy.\u00a0Recall that the entropy of a probability distribution p(x) is defined as",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6110",
    "text": "-19.48",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6111",
    "text": "H [p] = -Ex log p(x).",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6112",
    "text": "For continuous values, the expectation is an integral:",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6113",
    "text": "H [p] = ~!p(x)log p(x)dx\u25a0 \u00a0\u00a0\u00a0(1949\u05f3)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6114",
    "text": "We cannot simply maximize H[p] with respect to the function p(x), because the result might not be a probability distribution. Instead, we need to use Lagrange\u00a0multipliers to add a constraint that p(x) integrates to 1. Also, the entropy\u00a0increases without bound as the variance increases. This makes the question of\u00a0which distribution has the greatest entropy uninteresting. Instead, we ask which\u00a0distribution has maximal entropy for fixed variance a 2. Finally, the problem\u00a0is underdetermined because the distribution can be shifted arbitrarily without\u00a0changing the entropy. To impose a unique solution, we add a constraint that the\u00a0mean of the distribution be p. The Lagrangian functional for this optimization\u00a0problem is",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6115",
    "text": "p(x)dx \u2014 1 + A2 (E[x] \u2014 p) + A3 (E[(x \u2014 p)2] \u2014 a2) + H[p] (19.50)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6116",
    "text": "L[P] = A! ^",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6117",
    "text": "#ERROR!",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6118",
    "text": "-19.51",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6119",
    "text": "To minimize the Lagrangian with respect to p, we set the functional derivatives equal to 0:",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6120",
    "text": "Vx,",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6121",
    "text": "S",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6122",
    "text": "Sp(x)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6123",
    "text": "L = A! + A2x + A3(x - p)2 - 1 - logp(x) = 0.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6124",
    "text": "-19.52",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6125",
    "text": "This condition now tells us the functional form of p (x). By algebraically re-arranging the equation, we obtain",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6126",
    "text": "-19.53",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6127",
    "text": "p(x) = exp (A! + A2x + A3(x - p)2 - 1) .",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6128",
    "text": "We never assumed directly that p(x) would take this functional form; we obtained the expression itself by analytically minimizing a functional. To finish\u00a0the minimization problem, we must choose the A values to ensure that all of our\u00a0constraints are satisfied. We are free to choose any A values, because the gradient\u00a0of the Lagrangian with respect to the A variables is zero so long as the constraints\u00a0are satisfied. To satisfy all of the constraints, we may set A! = 1 - log a 2/\u05e5n,\u00a0A2 = 0, and A3 = -^ to obtain",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6129",
    "text": "-19.54",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6130",
    "text": "p(x) = N(x; p, a2).",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6131",
    "text": "This is one reason for using the normal distribution when we do not know the true distribution. Because the normal distribution has the maximum entropy, we\u00a0impose the least possible amount of structure by making this assumption.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6132",
    "text": "While examining the critical points of the Lagrangian functional for the entropy, we found only one critical point, corresponding to maximizing the entropy for\u00a0fixed variance. What about the probability distribution function that minimizes\u00a0the entropy? Why did we not find a second critical point corresponding to the\u00a0minimum? The reason is that there is no specific function that achieves minimal\u00a0entropy. As functions place more probability density on the two points x = p + a\u00a0and x = p - a, and place less probability density on all other values of x, they lose\u00a0entropy while maintaining the desired variance. However, any function placing\u00a0exactly zero mass on all but two points does not integrate to one, and is not a\u00a0valid probability distribution. There thus is no single minimal entropy probability\u00a0distribution function, much as there is no single minimal positive real number.\u00a0Instead, we can say that there is a sequence of probability distributions converging\u00a0toward putting mass only on these two points. This degenerate scenario may be\u00a0described as a mixture of Dirac distributions. Because Dirac distributions are\u00a0not described by a single probability distribution function, no Dirac or mixture of\u00a0Dirac distribution corresponds to a single specific point in function space. These\u00a0distributions are thus invisible to our method of solving for a specific point where\u00a0the functional derivatives are zero. This is a limitation of the method. Distributions\u00a0such as the Dirac must be found by other methods, such as guessing the solution\u00a0and then proving that it is correct.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6133",
    "text": "When our graphical model contains continuous latent variables, we may still perform variational inference and learning by maximizing L. However, we must\u00a0now use calculus of variations when maximizing L with respect to q(h | v).",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6134",
    "text": "In most cases, practitioners need not solve any calculus of variations problems themselves. Instead, there is a general equation for the mean field fixed point\u00a0updates. If we make the mean field approximation",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6135",
    "text": "q(h | v) = \u00a0\u00a0\u00a0q(hi | v),\u00a0\u00a0\u00a0\u00a0(19.55)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6136",
    "text": "i",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6137",
    "text": "v) may be obtained by",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6138",
    "text": "and fix q(hj | v) for all j = i, then the optimal q(hi | normalizing the unnormalized distribution",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6139",
    "text": "q(hi 1 v) = exp (Eh_^q(h_\u00bb 10g ^, h)) \u00a0\u00a0\u00a0(19.56)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6140",
    "text": "so long as p does not assign 0 probability to any joint configuration of variables. Carrying out the expectation inside the equation will yield the correct functional\u00a0form of q (hi | v). It is only necessary to derive functional forms of q directly using\u00a0calculus of variations if one wishes to develop a new form of variational learning;\u00a0Eq. 19.56 yields the mean field approximation for any probabilistic model.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6141",
    "text": "Eq. 19.56 is a fixed point equation, designed to be iteratively applied for each value of i repeatedly until convergence. However, it also tells us more than that. It\u00a0tells us the functional form that the optimal solution will take, whether we arrive\u00a0there by fixed point equations or not. This means we can take the functional form\u00a0from that equation but regard some of the values that appear in it as parameters,\u00a0that we can optimize with any optimization algorithm we like.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6142",
    "text": "As an example, consider a very simple probabilistic model, with latent variables h e R2 and just one visible variable, v. Suppose that p(h) = N(h; 0, I) and\u00a0p(v | h) = N (v; wTh; 1). We could actually simplify this model by integrating\u00a0out h; the result is just a Gaussian distribution over v. The model itself is not\u00a0interesting; we have constructed it only to provide a simple demonstration of how\u00a0calculus of variations may be applied to probabilistic modeling.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6143",
    "text": "The true posterior is given, up to a normalizing constant, by",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6144",
    "text": "-19.57",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6145",
    "text": "-19.58",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6146",
    "text": "-19.59",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6147",
    "text": "-19.6",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6148",
    "text": "p(h | v)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6149",
    "text": "(xp(h, v)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6150",
    "text": "#ERROR!",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6151",
    "text": "( exp",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6152",
    "text": "^- 1 [h? + h2 + (v \u2014 h 1 w 1 \u2014 h2 w2 )2]",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6153",
    "text": "exp ^ ^ [h? + h| + v2 + h?w? + W \u2014 2vh ?w? \u2014 2vh2w2 + 2h? w? h2w2] ^ .",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6154",
    "text": "-19.61",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6155",
    "text": "Due to the presence of the terms multiplying h? and h2 together, we can see that the true posterior does not factorize over h1 and h2.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6156",
    "text": "Applying Eq. 19.56, we find that",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6157",
    "text": "q(h? 1 v)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6158",
    "text": ":exP (Eh2~q(h2 |v) 10g p(v, h)) 1",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6159",
    "text": "2E",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6160",
    "text": "exp ( \u2014 -1 Eh2^q(h2|v) [h2 + h2 + v2 + h2w2 + h2w2 \u20142vh?w? \u2014 2vh2w2 + 2h ?w?h2w2]^ .",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6161",
    "text": "-19.62",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6162",
    "text": "-19.63",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6163",
    "text": "-19.64",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6164",
    "text": "-19.65",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6165",
    "text": "From this, we can see that there are effectively only two values we need to obtain from q(h2 | v): Eh2^g(h|v)[h2] and Eh2^q(h|v)[h|]. Writing these as (h2) and (h2),\u00a0we obtain",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6166",
    "text": "q\u05f3(h1 | v) = exp^ \u2014 2\u05be [h? + (h2) + v2 + h2w2 + (h2)w2 \u00a0\u00a0\u00a0(19.66)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6167",
    "text": "\u20142vh?w? \u2014 2v(h2)w2 + 2h?w?(h2)w2]^ . \u00a0\u00a0\u00a0(19.67)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6168",
    "text": "From this, we can see that g has the functional form of a Gaussian. We can thus conclude q (h | v) = N(h; p, ft-1) where p and diagonal ft are variational\u00a0parameters that we can optimize using any technique we choose. It is important\u00a0to recall that we did not ever assume that q would be Gaussian; its Gaussian\u00a0form was derived automatically by using calculus of variations to maximize q with\u00a0respect to L. Using the same approach on a different model could yield a different\u00a0functional form of q.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6169",
    "text": "This was of course, just a small case constructed for demonstration purposes. For examples of real applications of variational learning with continuous variables\u00a0in the context of deep learning, see Goodfellow et al. (2013d).",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6170",
    "text": "Using approximate inference as part of a learning algorithm affects the learning process, and this in turn affects the accuracy of the inference algorithm.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6171",
    "text": "Specifically, the training algorithm tends to adapt the model in a way that makes the approximating assumptions underlying the approximate inference algorithm\u00a0become more true. When training the parameters, variational learning increases",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6172",
    "text": "Eh~q logp(v, h). \u00a0\u00a0\u00a0(19.68)",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6173",
    "text": "For a specific v, this increases p(h | v) for values of h that have high probability under q(h | v) and decreases p(h | v) for values of h that have low probability\u00a0under q(h | v).",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6174",
    "text": "This behavior causes our approximating assumptions to become self-fulfilling prophecies. If we train the model with a unimodal approximate posterior, we will\u00a0obtain a model with a true posterior that is far closer to unimodal than we would\u00a0have obtained by training the model with exact inference.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6175",
    "text": "Computing the true amount of harm imposed on a model by a variational approximation is thus very difficult. There exist several methods for estimating\u00a0logp(v). We often estimate logp(v; 0) after training the model, and find that\u00a0the gap with L(v, 0, q) is small. From this, we can conclude that our variational\u00a0approximation is accurate for the specific value of 0 that we obtained from the\u00a0learning process. We should not conclude that our variational approximation is\u00a0accurate in general or that the variational approximation did little harm to the\u00a0learning process. To measure the true amount of harm induced by the variational\u00a0approximation, we would need to know 0* = max# logp( v; 0). It is possible for\u00a0L(v, 0, q)\u00a0\u00a0\u00a0\u00a0logp(v; 0) and logp (v; 0) ^ logp(v; 0*) to hold simultaneously. If",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6176",
    "text": "maxqL(v, 0* ,q) ^ logp(v; 0*), because 0* induces too complicated of a posterior distribution for our q family to capture, then the learning process will never\u00a0approach 0*. Such a problem is very difficult to detect, because we can only know\u00a0for sure that it happened if we have a superior learning algorithm that can find 0*\u00a0for comparison.",
    "chapter": "",
    "chapter_id": "main-35.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6177",
    "text": "We have seen that inference can be thought of as an optimization procedure that increases the value of a function L. Explicitly performing optimization via\u00a0iterative procedures such as fixed point equations or gradient-based optimization\u00a0is often very expensive and time-consuming. Many approaches to inference avoid\u00a0this expense by learning to perform approximate inference. Specifically, we can\u00a0think of the optimization process as a function f that maps an input v to an\u00a0approximate distribution q* = argmax^ L(v, q). Once we think of the multi-step\u00a0iterative optimization process as just being a function, we can approximate it with\u00a0a neural network that implements an approximation f(v; 6).",
    "chapter": "",
    "chapter_id": "main-36.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6178",
    "text": "One of the main difficulties with training a model to infer h from v is that we do not have a supervised training set with which to train the model. Given a v,\u00a0we do not know the appropriate h. The mapping from v to h depends on the\u00a0choice of model family, and evolves throughout the learning process as 6 changes.\u00a0The wake-sleep algorithm (Hinton et al., 1995b; Frey et al., 1996) resolves this\u00a0problem by drawing samples of both h and v from the model distribution. For\u00a0example, in a directed model, this can be done cheaply by performing ancestral\u00a0sampling beginning at h and ending at v. The inference network can then be\u00a0trained to perform the reverse mapping: predicting which h caused the present\u00a0v. The main drawback to this approach is that we will only be able to train the\u00a0inference network on values of v that have high probability under the model. Early\u00a0in learning, the model distribution will not resemble the data distribution, so the\u00a0inference network will not have an opportunity to learn on samples that resemble\u00a0data.",
    "chapter": "",
    "chapter_id": "main-36.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6179",
    "text": "In Sec. 18.2 we saw that one possible explanation for the role of dream sleep in human beings and animals is that dreams could provide the negative phase samples\u00a0that Monte Carlo training algorithms use to approximate the negative gradient of\u00a0the log partition function of undirected models. Another possible explanation for\u00a0biological dreaming is that it is providing samples from p( h, v) which can be used\u00a0to train an inference network to predict h given v. In some senses, this explanation\u00a0is more satisfying than the partition function explanation. Monte Carlo algorithms\u00a0generally do not perform well if they are run using only the positive phase of the\u00a0gradient for several steps then with only the negative phase of the gradient for\u00a0several steps. Human beings and animals are usually awake for several consecutive\u00a0hours then asleep for several consecutive hours. It is not readily apparent how this\u00a0schedule could support Monte Carlo training of an undirected model. Learning\u00a0algorithms based on maximizing L can be run with prolonged periods of improving\u00a0q and prolonged periods of improving 6, however. If the role of biological dreaming\u00a0is to train networks for predicting q, then this explains how animals are able to\u00a0remain awake for several hours (the longer they are awake, the greater the gap\u00a0between L and logp(v), but L will remain a lower bound) and to remain asleep\u00a0for several hours (the generative model itself is not modified during sleep) without\u00a0damaging their internal models. Of course, these ideas are purely speculative, and\u00a0there is no hard evidence to suggest that dreaming accomplishes either of these\u00a0goals. Dreaming may also serve reinforcement learning rather than probabilistic\u00a0modeling, by sampling synthetic experiences from the animal\u2019s transition model,\u00a0on which to train the animal\u2019s policy. Or sleep may serve some other purpose not\u00a0yet anticipated by the machine learning community.",
    "chapter": "",
    "chapter_id": "main-36.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6180",
    "text": "This strategy of learned approximate inference has also been applied to other models. Salakhutdinov and Larochelle (2010) showed that a single pass in a\u00a0learned inference network could yield faster inference than iterating the mean field\u00a0fixed point equations in a DBM. The training procedure is based on running the\u00a0inference network, then applying one step of mean field to improve its estimates,\u00a0and training the inference network to output this refined estimate instead of its\u00a0original estimate.",
    "chapter": "",
    "chapter_id": "main-36.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6181",
    "text": "We have already seen in Sec. 14.8 that the predictive sparse decomposition model trains a shallow encoder network to predict a sparse code for the input.\u00a0This can be seen as a hybrid between an autoencoder and sparse coding. It is\u00a0possible to devise probabilistic semantics for the model, under which the encoder\u00a0may be viewed as performing learned approximate MAP inference. Due to its\u00a0shallow encoder, PSD is not able to implement the kind of competition between\u00a0units that we have seen in mean field inference. However, that problem can be\u00a0remedied by training a deep encoder to perform learned approximate inference, as\u00a0in the ISTA technique (Gregor and LeCun, 2010b).",
    "chapter": "",
    "chapter_id": "main-36.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6182",
    "text": "Learned approximate inference has recently become one of the dominant approaches to generative modeling, in the form of the variational autoencoder\u00a0(Kingma, 2013; Rezende et al., 2014). In this elegant approach, there is no need to\u00a0construct explicit targets for the inference network. Instead, the inference network\u00a0is simply used to define Lelegant approach, there is no need the inference network\u00a0are adapted to increase L. This model is described in depth later, in Sec. 20.10.3.",
    "chapter": "",
    "chapter_id": "main-36.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6183",
    "text": "Using approximate inference, it is possible to train and use a wide variety of models. Many of these models are described in the next chapter.",
    "chapter": "",
    "chapter_id": "main-36.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6184",
    "text": "In this chapter, we present several of the specific kinds of generative models that can be built and trained using the techniques presented in Chapters 16, 17, 18 and\u00a019. All of these models represent probability distributions over multiple variables\u00a0in some way. Some allow the probability distribution function to be evaluated\u00a0explicitly. Others do not allow the evaluation of the probability distribution\u00a0function, but support operations that implicitly require knowledge of it, such\u00a0as drawing samples from the distribution. Some of these models are structured\u00a0probabilistic models described in terms of graphs and factors, using the language\u00a0of graphical models presented in Chapter 16. Others can not easily be described\u00a0in terms of factors, but represent probability distributions nonetheless.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6185",
    "text": "Boltzmann machines were originally introduced as a general \u201cconnectionist\u201d approach to learning arbitrary probability distributions over binary vectors (Fahlman et al., 1983; Ackley et al., 1985; Hinton et al., 1984; Hinton and Sejnowski, 1986).\u00a0Variants of the Boltzmann machine that include other kinds of variables have long\u00a0ago surpassed the popularity of the original. In this section we briefly introduce\u00a0the binary Boltzmann machine and discuss the issues that come up when trying to\u00a0train and perform inference in the model.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6186",
    "text": "We define the Boltzmann machine over a d-dimensional binary random vector x \u00a3 {0,1 }d. The Boltzmann machine is an energy-based model (Sec. 16.2.4),",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6187",
    "text": "meaning we define the joint probability distribution using an energy function:",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6188",
    "text": "P (x) = exp(\u05beE (x\u00bb, \u00a0\u00a0\u00a0(20.1)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6189",
    "text": "where E (x) is the energy function and Z is the partition function that ensures that ^x P(x) = 1. The energy function of the Boltzmann machine is given by",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6190",
    "text": "E(x) = -xTUx - bx, \u00a0\u00a0\u00a0(20.2)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6191",
    "text": "where U is the \u201cweight\u201d matrix of model parameters and b is the vector of bias parameters.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6192",
    "text": "In the general setting of the Boltzmann machine, we are given a set of training examples, each of which are n-dimensional. Eq. 20.1 describes the joint probability\u00a0distribution over the observed variables. While this scenario is certainly viable,\u00a0it does limit the kinds of interactions between the observed variables to those\u00a0described by the weight matrix. Specifically, it means that the probability of one\u00a0unit being on is given by a linear model (logistic regression) from the values of the\u00a0other units.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6193",
    "text": "The Boltzmann machine becomes more powerful when not all the variables are observed. In this case, the non-observed variables, or latent variables, can\u00a0act similarly to hidden units in a multi-layer perceptron and model higher-order\u00a0interactions among the visible units. Just as the addition of hidden units to\u00a0convert logistic regression into an MLP results in the MLP being a universal\u00a0approximator of functions, a Boltzmann machine with hidden units is no longer\u00a0limited to modeling linear relationships between variables. Instead, the Boltzmann\u00a0machine becomes a universal approximator of probability mass functions over\u00a0discrete variables (Le Roux and Bengio, 2008).",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6194",
    "text": "Formally, we decompose the units x into two subsets: the visible units v and the latent (or hidden) units h. The energy function becomes",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6195",
    "text": "E(v, h) = -vTRv - vT Wh - hTSh - bTv - cTh. \u00a0\u00a0\u00a0(20.3)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6196",
    "text": "Boltzmann Machine Learning Learning algorithms for Boltzmann machines are usually based on maximum likelihood. All Boltzmann machines have an\u00a0intractable partition function, so the maximum likelihood gradient must be approximated using the techniques described in Chapter 18.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6197",
    "text": "One interesting property of Boltzmann machines when trained with learning rules based on maximum likelihood is that the update for a particular weight\u00a0connecting two units depends only the statistics of those two units, collected",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6198",
    "text": "under different distributions: Pmode](v) and Pdata(v)Pmode1 (h | v). The rest of the network participates in shaping those statistics, but the weight can be updated\u00a0without knowing anything about the rest of the network or how those statistics were\u00a0produced. This means that the learning rule is \u201clocal,\u201d which makes Boltzmann\u00a0machine learning somewhat biologically plausible. It is conceivable that if each\u00a0neuron were a random variable in a Boltzmann machine, then the axons and\u00a0dendrites connecting two random variables could learn only by observing the firing\u00a0pattern of the cells that they actually physically touch. In particular, in the\u00a0positive phase, two units that frequently activate together have their connection\u00a0strengthened. This is an example of a Hebbian learning rule (Hebb, 1949) often\u00a0summarized with the mnemonic \u201cfire together, wire together.\u201d Hebbian learning\u00a0rules are among the oldest hypothesized explanations for learning in biological\u00a0systems and remain relevant today (Giudice et al., 2009).",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6199",
    "text": "Other learning algorithms that use more information than local statistics seem to require us to hypothesize the existence of more machinery than this. For\u00a0example, for the brain to implement back-propagation in a multilayer perceptron,\u00a0it seems necessary for the brain to maintain a secondary communication network for\u00a0transmitting gradient information backwards through the network. Proposals for\u00a0biologically plausible implementations (and approximations) of back-propagation\u00a0have been made (Hinton, 2007a; Bengio, 2015) but remain to be validated, and\u00a0Bengio (2015) links back-propagation of gradients to inference in energy-based\u00a0models similar to the Boltzmann machine (but with continuous latent variables).",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6200",
    "text": "The negative phase of Boltzmann machine learning is somewhat harder to explain from a biological point of view. As argued in Sec. 18.2, dream sleep may\u00a0be a form of negative phase sampling. This idea is more speculative though.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6201",
    "text": "Invented under the name harmonium (Smolensky, 1986), restricted Boltzmann machines are some of the most common building blocks of deep probabilistic models.\u00a0We have briefly described RBMs previously, in Sec. 16.7.1. Here we review the\u00a0previous information and go into more detail. RBMs are undirected probabilistic\u00a0graphical models containing a layer of observable variables and a single layer of\u00a0latent variables. RBMs may be stacked (one on top of the other) to form deeper\u00a0models. See Fig. 20.1 for some examples. In particular, Fig. 20.1a shows the graph\u00a0structure of the RBM itself. It is a bipartite graph, with no connections permitted\u00a0between any variables in the observed layer or between any units in the latent\u00a0layer.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6202",
    "text": "a",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6203",
    "text": "b",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6204",
    "text": "c",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6205",
    "text": "Figure 20.1: Examples of models that may be built with restricted Boltzmann machines. (a) The restricted Boltzmann machine itself is an undirected graphical model based on\u00a0a bipartite graph, with visible units in one part of the graph and hidden units in the\u00a0other part. There are no connections among the visible units, nor any connections among\u00a0the hidden units. Typically every visible unit is connected to every hidden unit but it\u00a0is possible to construct sparsely connected RBMs such as convolutional RBMs. (b) A\u00a0deep belief network is a hybrid graphical model involving both directed and undirected\u00a0connections. Like an RBM, it has no intra-layer connections. However, a DBN has\u00a0multiple hidden layers, and thus there are connections between hidden units that are in\u00a0separate layers. All of the local conditional probability distributions needed by the deep\u00a0belief network are copied directly from the local conditional probability distributions of\u00a0its constituent RBMs. Alternatively, we could also represent the deep belief network with\u00a0a completely undirected graph, but it would need intra-layer connections to capture the\u00a0dependencies between parents. (c) A deep Boltzmann machine is an undirected graphical\u00a0model with several layers of latent variables. Like RBMs and DBNs, DBMs lack intra-layer\u00a0connections. DBMs are less closely tied to RBMs than DBNs are. When initializing a\u00a0DBM from a stack of RBMs, it is necessary to modify the RBM parameters slightly. Some\u00a0kinds of DBMs may be trained without first training a set of RBMs.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6206",
    "text": "We begin with the binary version of the restricted Boltzmann machine, but as we see later there are extensions to other types of visible and hidden units.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6207",
    "text": "More formally, let the observed layer consist of a set of n v binary random variables which we refer to collectively with the vector v. We refer to the latent or\u00a0hidden layer of n^ binary random variables as h.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6208",
    "text": "Like the general Boltzmann machine, the restricted Boltzmann machine is an energy-based model with the joint probability distribution specified by its energy\u00a0function:",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6209",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6210",
    "text": "P(v = v, h = h) = \u2014 exp (-E(v, h)).",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6211",
    "text": "The energy function for an RBM is given by",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6212",
    "text": "E(v, h) = -b v - cTh - v Wh, and Z is the normalizing constant known as the partition function:",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6213",
    "text": "Z = \u00a0\u00a0\u00a0exP {-E(^ h)} .",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6214",
    "text": "v h",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6215",
    "text": "-20.4",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6216",
    "text": "(20.5) (20.6)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6217",
    "text": "It is apparent from the definition of the partition function Z that the naive method of computing Z (exhaustively summing over all states) could be computationally\u00a0intractable, unless a cleverly designed algorithm could exploit regularities in the\u00a0probability distribution to compute Z faster. In the case of restricted Boltzmann\u00a0machines, Long and Servedio (2010) formally proved that the partition function Z\u00a0is intractable. The intractable partition function Z implies that the normalized\u00a0joint probability distribution P(v) is also intractable to evaluate.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6218",
    "text": "Though P (v) is intractable, the bipartite graph structure of the RBM has the very special property that its conditional distributions P(h | v) and P(v | h) are\u00a0factorial and relatively simple to compute and to sample from.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6219",
    "text": "Deriving the conditional distributions from the joint distribution is straightforward:",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6220",
    "text": "P(h | v) =",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6221",
    "text": "P(h, v) P(v)\u00a011",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6222",
    "text": "exp",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6223",
    "text": "|bTv + c h + vTWh|",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6224",
    "text": "P(v) Z 1",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6225",
    "text": "- exp j ch + vT Wh|",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6226",
    "text": "Z",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6227",
    "text": "-20.7",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6228",
    "text": "(20.8) (20.9)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6229",
    "text": "nh",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6230",
    "text": "nh",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6231",
    "text": "z, exp \u00a0\u00a0\u00a0c h3 +J2vT W-J h",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6232",
    "text": "Z",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6233",
    "text": "-20.1",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6234",
    "text": "j=1",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6235",
    "text": "j=1",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6236",
    "text": "1 nh",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6237",
    "text": "#ERROR!",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6238",
    "text": "-20.11",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6239",
    "text": "j=l",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6240",
    "text": "Since we are conditioning on the visible units v, we can treat these as constant with respect to the distribution P (h | v). The factorial nature of the conditional\u00a0P(h | v) follows immediately from our ability to write the joint probability over\u00a0the vector h as the product of (unnormalized) distributions over the individual\u00a0elements, hj. It is now a simple matter of normalizing the distributions over the\u00a0individual binary hj.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6241",
    "text": "P(hj = 1 | v) =",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6242",
    "text": "P(hj = 1 1 v)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6243",
    "text": "/5(hj = 0 | v) + P(hj = 1 | v) exp \\cj + vT Wj\u00a0exp {0} + exp {cj + vT W:,j }",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6244",
    "text": "#ERROR!",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6245",
    "text": "\u05e0,",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6246",
    "text": "-20.12",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6247",
    "text": "-20.13",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6248",
    "text": "-20.14",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6249",
    "text": "We can now express the full conditional over the hidden layer as the factorial distribution:",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6250",
    "text": "nh",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6251",
    "text": "-20.15",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6252",
    "text": "j=1",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6253",
    "text": "P(h | v) = \u00a0\u00a0\u00a0a((2h - 1) 0 (c + WTv)\u00a0\u00a0\u00a0\u00a0.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6254",
    "text": "A similar derivation will show that the other condition of interest to us, P(v | h), is also a factorial distribution:",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6255",
    "text": "nv",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6256",
    "text": "P(v | h) = \u00a0\u00a0\u00a0a ((2v - 1) 0 (b + Wh))i.\u00a0\u00a0\u00a0\u00a0(20.16)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6257",
    "text": "i= 1",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6258",
    "text": "Because the RBM admits efficient evaluation and differentiation of PP(v) and efficient MCMC sampling in the form of block Gibbs sampling, it can readily be\u00a0trained with any of the techniques described in Chapter 18 for training models\u00a0that have intractable partition functions. This includes CD, SML (PCD), ratio\u00a0matching and so on. Compared to other undirected models used in deep learning,\u00a0the RBM is relatively straightforward to train because we can compute P(h | v)\u00a0exactly in closed form. Some other deep models, such as the deep Boltzmann\u00a0machine, combine both the difficulty of an intractable partition function and the\u00a0difficulty of intractable inference.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6259",
    "text": "Deep belief networks (DBNs) were one of the first non-convolutional models to successfully admit training of deep architectures (Hinton et al., 2006; Hinton,\u00a02007b). The introduction of deep belief networks in 2006 began the current deep\u00a0learning renaissance. Prior to the introduction of deep belief networks, deep models\u00a0were considered too difficult to optimize. Kernel machines with convex objective\u00a0functions dominated the research landscape. Deep belief networks demonstrated\u00a0that deep architectures can be successful, by outperforming kernelized support\u00a0vector machines on the MNIST dataset (Hinton et al., 2006). Today, deep belief\u00a0networks have mostly fallen out of favor and are rarely used, even compared to\u00a0other unsupervised or generative learning algorithms, but they are still deservedly\u00a0recognized for their important role in deep learning history.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6260",
    "text": "Deep belief networks are generative models with several layers of latent variables. The latent variables are typically binary, while the visible units may be binary\u00a0or real. There are no intra-layer connections. Usually, every unit in each layer is\u00a0connected to every unit in each neighboring layer, though it is possible to construct\u00a0more sparsely connected DBNs. The connections between the top two layers are\u00a0undirected. The connections between all other layers are directed, with the arrows\u00a0pointed toward the layer that is closest to the data. See Fig. 20.1b for an example.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6261",
    "text": "A DBN with l hidden layers contains l weight matrices: W(1),..., W(l). It also contains l+ 1 bias vectors: b(0),..., b(l), with providing the biases for the\u00a0visible layer. The probability distribution represented by the DBN is given by",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6262",
    "text": "P(h(l), h(l-1)) a exp (b(l)Th(l) + b(l-1)Th(l-1) + h(l-1)TW(l)h(l)) , \u00a0\u00a0\u00a0(20.17)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6263",
    "text": "P (h(k) = 1 | h(k+1)) = \u00a0\u00a0\u00a0+ w(k+1)T h(k+1^ Vi, Vk e 1,...,l - 2,\u00a0\u00a0\u00a0\u00a0(20.18)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6264",
    "text": "P(v{ = 1 | h(1)) = a (\\(0) + W;(iL)Th(1^ Vi. \u00a0\u00a0\u00a0(20.19)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6265",
    "text": "In the case of real-valued visible units, substitute",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6266",
    "text": "v \u00a0\u00a0\u00a0(v; b(0) + W(1)T h(1), 0-1)\u00a0\u00a0\u00a0\u00a0(20.20)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6267",
    "text": "with diagonal for tractability. Generalizations to other exponential family visible units are straightforward, at least in theory. A DBN with only one hidden layer is\u00a0just an RBM.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6268",
    "text": "To generate a sample from a DBN, we first run several steps of Gibbs sampling on the top two hidden layers. This stage is essentially drawing a sample from\u00a0the RBM defined by the top two hidden layers. We can then use a single pass of\u00a0ancestral sampling through the rest of the model to draw a sample from the visible\u00a0units.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6269",
    "text": "Deep belief networks incur many of the problems associated with both directed models and undirected models.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6270",
    "text": "Inference in a deep belief network is intractable due to the explaining away effect within each directed layer, and due to the interaction between the two hidden\u00a0layers that have undirected connections. Evaluating or maximizing the standard\u00a0evidence lower bound on the log-likelihood is also intractable, because the evidence\u00a0lower bound takes the expectation of cliques whose size is equal to the network\u00a0width.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6271",
    "text": "Evaluating or maximizing the log-likelihood requires not just confronting the problem of intractable inference to marginalize out the latent variables, but also\u00a0the problem of an intractable partition function within the undirected model of\u00a0the top two layers.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6272",
    "text": "To train a deep belief network, one begins by training an RBM to maximize Ev~pdata logp(v) using contrastive divergence or stochastic maximum likelihood.\u00a0The parameters of the RBM then define the parameters of the first layer of the\u00a0DBN. Next, a second RBM is trained to approximately maximize",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6273",
    "text": "E-v^pdataEh(1)~p(1)(h(1) |v)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6274",
    "text": "log p(2)(h(1))",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6275",
    "text": "-20.21",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6276",
    "text": "where p(1) is the probability distribution represented by the first RBM and p(2) is the probability distribution represented by the second RBM. In other words,\u00a0the second RBM is trained to model the distribution defined by sampling the\u00a0hidden units of the first RBM, when the first RBM is driven by the data. This\u00a0procedure can be repeated indefinitely, to add as many layers to the DBN as\u00a0desired, with each new RBM modeling the samples of the previous one. Each RBM\u00a0defines another layer of the DBN. This procedure can be justified as increasing a\u00a0variational lower bound on the log-likelihood of the data under the DBN (Hinton\u00a0et al., 2006).",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6277",
    "text": "In most applications, no effort is made to jointly train the DBN after the greedy layer-wise procedure is complete. However, it is possible to perform generative\u00a0fine-tuning using the wake-sleep algorithm.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6278",
    "text": "The trained DBN may be used directly as a generative model, but most of the interest in DBNs arose from their ability to improve classification models. We can\u00a0take the weights from the DBN and use them to define an MLP:",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6279",
    "text": "h(1) = a(b(1) + vTW(1)) . \u00a0\u00a0\u00a0(20.22)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6280",
    "text": "h(1) = a (b(\u00b0 + h(1-1)TW(1)) V/ e 2,..., m, \u00a0\u00a0\u00a0(20.23)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6281",
    "text": "After initializing this MLP with the weights and biases learned via generative training of the DBN, we may train the MLP to perform a classification task. This\u00a0additional training of the MLP is an example of discriminative fine-tuning.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6282",
    "text": "This specific choice of MLP is somewhat arbitrary, compared to many of the inference equations in Chapter 19 that are derived from first principles. This MLP\u00a0is a heuristic choice that seems to work well in practice and is used consistently\u00a0in the literature. Many approximate inference techniques are motivated by their\u00a0ability to find a maximally tight variational lower bound on the log-likelihood\u00a0under some set of constraints. One can construct a variational lower bound on the\u00a0log-likelihood using the hidden unit expectations defined by the DBN\u2019s MLP, but\u00a0this is true of any probability distribution over the hidden units, and there is no\u00a0reason to believe that this MLP provides a particularly tight bound. In particular,\u00a0the MLP ignores many important interactions in the DBN graphical model. The\u00a0MLP propagates information upward from the visible units to the deepest hidden\u00a0units, but does not propagate any information downward or sideways. The DBN\u00a0graphical model has explaining away interactions between all of the hidden units\u00a0within the same layer as well as top-down interactions between layers.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6283",
    "text": "While the log-likelihood of a DBN is intractable, it may be approximated with AIS (Salakhutdinov and Murray, 2008). This permits evaluating its quality as a\u00a0generative model.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6284",
    "text": "The term \u201cdeep belief network\u201d is commonly used incorrectly to refer to any kind of deep neural network, even networks without latent variable semantics.\u00a0The term \u201cdeep belief network\u201d should refer specifically to models with undirected\u00a0connections in the deepest layer and directed connections pointing downward\u00a0between all other pairs of consecutive layers.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6285",
    "text": "The term \u201cdeep belief network\u201d may also cause some confusion because the term \u201cbelief network\u201d is sometimes used to refer to purely directed models, while\u00a0deep belief networks contain an undirected layer. Deep belief networks also share\u00a0the acronym DBN with dynamic Bayesian networks (Dean and Kanazawa, 1989),\u00a0which are Bayesian networks for representing Markov chains.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6286",
    "text": "Figure 20.2: The graphical model for a deep Boltzmann machine with one visible layer (bottom) and two hidden layers. Connections are only between units in neighboring layers.\u00a0There are no intra-layer layer connections.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6287",
    "text": "A deep Boltzmann machine or DBM (Salakhutdinov and Hinton, 2009a) is another kind of deep, generative model. Unlike the deep belief network (DBN), it is an\u00a0entirely undirected model. Unlike the RBM, the DBM has several layers of latent\u00a0variables (RBMs have just one). But like the RBM, within each layer, each of the\u00a0variables are mutually independent, conditioned on the variables in the neighboring\u00a0layers. See Fig. 20.2 for the graph structure. Deep Boltzmann machines have been\u00a0applied to a variety of tasks including document modeling (Srivastava et al., 2013).",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6288",
    "text": "Like RBMs and DBNs, DBMs typically contain only binary units\u2014as we assume for simplicity of our presentation of the model\u2014but it is straightforward\u00a0to include real-valued visible units.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6289",
    "text": "A DBM is an energy-based model, meaning that the the joint probability distribution over the model variables is parametrized by an energy function E. In\u00a0the case of a deep Boltzmann machine with one visible layer, v, and three hidden\u00a0layers, h(1), h(2) and h(3), the joint probability is given by:",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6290",
    "text": "P (v, h(1), h(2), h(3)) = Z^exp (-E (v, h(1), h(2), h(3); 0}) . \u00a0\u00a0\u00a0(20.24)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6291",
    "text": "To simplify our presentation, we omit the bias parameters below. The DBM energy function is then defined as follows:",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6292",
    "text": "E(v, h(1), h(2), h(3); 0} = -vT W(1)h(1) - h(1)TW(2)h(2) - h(2)TW(3)h(3).",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6293",
    "text": "-20.25",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6294",
    "text": "Figure 20.3: A deep Boltzmann machine, re-arranged to reveal its bipartite graph structure.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6295",
    "text": "In comparison to the RBM energy function (Eq. 20.5), the DBM energy function includes connections between the hidden units (latent variables) in the\u00a0form of the weight matrices (W(2) and W(3)). As we will see, these connections\u00a0have significant consequences for both the model behavior as well as how we go\u00a0about performing inference in the model.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6296",
    "text": "In comparison to fully connected Boltzmann machines (with every unit connected to every other unit), the DBM offers some advantages that are similar to those offered by the RBM. Specifically, as illustrated in Fig. 20.3, the DBM layers\u00a0can be organized into a bipartite graph, with odd layers on one side and even layers\u00a0on the other. This immediately implies that when we condition on the variables in\u00a0the even layer, the variables in the odd layers become conditionally independent.\u00a0Of course, when we condition on the variables in the odd layers, the variables in\u00a0the even layers also become conditionally independent.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6297",
    "text": "The bipartite structure of the DBM means that we can apply the same equations we have previously used for the conditional distributions of an RBM to determine the conditional distributions in a DBM. The units within a layer are\u00a0conditionally independent from each other given the values of the neighboring\u00a0layers, so the distributions over binary variables can be fully described by the\u00a0Bernoulli parameters giving the probability of each unit being active. In our\u00a0example with two hidden layers, the activation probabilities are given by:",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6298",
    "text": "P(vi = 1 | h(1)) = a (W1^) \u2019 \u00a0\u00a0\u00a0(20.26)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6299",
    "text": "P(h(1) = 1 | v,h(2)) = a(vTW^ + WV?h(2)) \u00a0\u00a0\u00a0(20.27)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6300",
    "text": "and",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6301",
    "text": "P(hk2) = 1 | h(1)) = a (h(1)TW\u2122) . \u00a0\u00a0\u00a0(20.28)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6302",
    "text": "The bipartite structure makes Gibbs sampling in a deep Boltzmann machine efficient. The naive approach to Gibbs sampling is to update only one variable\u00a0at a time. RBMs allow all of the visible units to be updated in one block and all\u00a0of the hidden units to be updated in a second block. One might naively assume\u00a0that a DBM with l layers requires l + 1 updates, with each iteration updating a\u00a0block consisting of one layer of units. Instead, it is possible to update all of the\u00a0units in only two iterations. Gibbs sampling can be divided into two blocks of\u00a0updates, one including all even layers (including the visible layer) and the other\u00a0including all odd layers. Due to the bipartite DBM connection pattern, given\u00a0the even layers, the distribution over the odd layers is factorial and thus can be\u00a0sampled simultaneously and independently as a block. Likewise, given the odd\u00a0layers, the even layers can be sampled simultaneously and independently as a\u00a0block. Efficient sampling is especially important for training with the stochastic\u00a0maximum likelihood algorithm.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6303",
    "text": "Deep Boltzmann machines have many interesting properties.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6304",
    "text": "DBMs were developed after DBNs. Compared to DBNs, the posterior distribution P(h | v) is simpler for DBMs. Somewhat counterintuitively, the simplicity of this posterior distribution allows richer approximations of the posterior. In the case\u00a0of the DBN, we perform classification using a heuristically motivated approximate\u00a0inference procedure, in which we guess that a reasonable value for the mean field\u00a0expectation of the hidden units can be provided by an upward pass through the\u00a0network in an MLP that uses sigmoid activation functions and the same weights\u00a0as the original DBN. Any distribution Q(h) may be used to obtain a variational\u00a0lower bound on the log-likelihood. This heuristic procedure therefore allows us to\u00a0obtain such a bound. However, the bound is not explicitly optimized in any way, so\u00a0the bound may be far from tight. In particular, the heuristic estimate of Q ignores\u00a0interactions between hidden units within the same layer as well as the top-down\u00a0feedback influence of hidden units in deeper layers on hidden units that are closer\u00a0to the input. Because the heuristic MLP-based inference procedure in the DBN\u00a0is not able to account for these interactions, the resulting Q is presumably far\u00a0from optimal. In DBMs, all of the hidden units within a layer are conditionally\u00a0independent given the other layers. This lack of intra-layer interaction makes it\u00a0possible to use fixed point equations to actually optimize the variational lower\u00a0bound and find the true optimal mean field expectations (to within some numerical\u00a0tolerance).",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6305",
    "text": "The use of proper mean field allows the approximate inference procedure for DBMs to capture the influence of top-down feedback interactions. This makes\u00a0DBMs interesting from the point of view of neuroscience, because the human brain\u00a0is known to use many top-down feedback connections. Because of this property,\u00a0DBMs have been used as computational models of real neuroscientific phenomena\u00a0(Series et al., 2010; Reichert et al., 2011).",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6306",
    "text": "One unfortunate property of DBMs is that sampling from them is relatively difficult. DBNs only need to use MCMC sampling in their top pair of layers. The\u00a0other layers are used only at the end of the sampling process, in one efficient\u00a0ancestral sampling pass. To generate a sample from a DBM, it is necessary to\u00a0use MCMC across all layers, with every layer of the model participating in every\u00a0Markov chain transition.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6307",
    "text": "The conditional distribution over one DBM layer given the neighboring layers is factorial. In the example of the DBM with two hidden layers, these distributions\u00a0are P(v | h(1)), P(h(1) | v, h(2)) and P(h(2) | h(1)). The distribution over all\u00a0hidden layers generally does not factorize because of interactions between layers.\u00a0In the example with two hidden layers, P(h(1), h(2) | v) does not factorize due due\u00a0to the interaction weights W(2) between h(1) and h(2) which render these variables\u00a0mutually dependent.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6308",
    "text": "As was the case with the DBN, we are left to seek out methods to approximate the DBM posterior distribution. However, unlike the DBN, the DBM posterior\u00a0distribution over their hidden units\u2014while complicated\u2014is easy to approximate\u00a0with a variational approximation (as discussed in Sec. 19.4), specifically a mean\u00a0field approximation. The mean field approximation is a simple form of variational\u00a0inference, where we restrict the approximating distribution to fully factorial distributions. In the context of DBMs, the mean field equations capture the bidirectional\u00a0interactions between layers. In this section we derive the iterative approximate\u00a0inference procedure originally introduced in Salakhutdinov and Hinton (2009a).",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6309",
    "text": "In variational approximations to inference, we approach the task of approximating a particular target distribution\u2014in our case, the posterior distribution over the hidden units given the visible units\u2014by some reasonably simple family of distributions. In the case of the mean field approximation, the approximating family\u00a0is the set of distributions where the hidden units are conditionally independent.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6310",
    "text": "We now develop the mean field approach for the example with two hidden layers. Let Q (h(1), h<2) | v) be the approximation of P(h(1), h<2) | v). The mean\u00a0field assumption implies that",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6311",
    "text": "Q(h(1), h<2) | v) =JJ Q(hj1) | v )JJ Q(hf2 | v). \u00a0\u00a0\u00a0(20.29)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6312",
    "text": "j \u00a0\u00a0\u00a0k",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6313",
    "text": "The mean field approximation attempts to find a member of this family of distributions that best fits the true posterior P(h(1), h<2) | v). Importantly, the\u00a0inference process must be run again to find a different distribution Q every time\u00a0we use a new value of v.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6314",
    "text": "One can conceive of many ways of measuring how well Q(h | v) fits P(h | v). The mean field approach is to minimize",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6315",
    "text": "KL(QIIP) = EQ(h<1)'h(2)\u05d5 v)1\u05f4g (^<1(h<2) |vj) . \u00a0\u00a0\u00a0(203\u00b0\u05f3)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6316",
    "text": "In general, we do not have to provide a parametric form of the approximating distribution beyond enforcing the independence assumptions. The variational\u00a0approximation procedure is generally able to recover a functional form of the\u00a0approximate distribution. However, in the case of a mean field assumption on\u00a0binary hidden units (the case we are developing here) there is no loss of generality\u00a0resulting from fixing a parametrization of the model in advance.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6317",
    "text": "We parametrize Q as a product of Bernoulli distributions, that is we associate the probability of each element of h(1) with a parameter. Specifically, for each j,",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6318",
    "text": "hj1 = Q(hj1) = 1 | v), where hj1 \u00a3 [0,1] and for each k, hk2) = Q(h\u05f3k2) = 1 | v), (2)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6319",
    "text": "where hk ' \u00a3 [0,1]. Thus we have the following approximation to the posterior:",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6320",
    "text": "-20.31",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6321",
    "text": "h <2) 1 v) \u00a0\u00a0\u00a0Q(h j1) 1 v) jj Q(h k2) 1 v)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6322",
    "text": "(1 - hj1) )<I-hj\u2019) x \u00a0\u00a0\u00a0(hk2))hk2) (1 - hk2))<1-hk2').",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6323",
    "text": "jk",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6324",
    "text": "-20.32",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6325",
    "text": "Of course, for DBMs with more layers the approximate posterior parametrization can be extended in the obvious way, exploiting the bipartite structure of the graph\u00a0to update all of the even layers simultaneously and then to update all of the odd\u00a0layers simultaneously, following the same schedule as Gibbs sampling.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6326",
    "text": "Now that we have specified our family of approximating distributions Q, it remains to specify a procedure for choosing the member of this family that best\u00a0fits P. The most straightforward way to do this is to use the mean field equations\u00a0specified by Eq. 19.56. These equations were derived by solving for where the\u00a0derivatives of the variational lower bound are zero. They describe in an abstract\u00a0manner how to optimize the variational lower bound for any model, simply by\u00a0taking expectations with respect to Q.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6327",
    "text": "Applying these general equations, we obtain the update rules (again, ignoring bias terms):",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6328",
    "text": "a",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6329",
    "text": "fe \u05f4 *T,j + E W2 \u05f3T)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6330",
    "text": "i \u00a0\u00a0\u00a0k\u05f3",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6331",
    "text": "Vj",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6332",
    "text": "-20.33",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6333",
    "text": "hk = a (E jk\u05f3j1 I , Vk. \u00a0\u00a0\u00a0(20.34)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6334",
    "text": "At a fixed point of this system of equations, we have a local maximum of the variational lower bound L (Q). Thus these fixed point update equations define\u00a0an iterative algorithm where we alternate updates of hj1 (using Eq. 20.33) and",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6335",
    "text": "updates of \u05f3\u05f3k2) (using Eq. 20.34). On small problems such as MNIST, as few as ten iterations can be sufficient to find an approximate positive phase gradient\u00a0for learning, and fifty usually suffice to obtain a high quality representation of\u00a0a single specific example to be used for high-accuracy classification. Extending\u00a0approximate variational inference to deeper DBMs is straightforward.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6336",
    "text": "Learning in the DBM must confront both the challenge of an intractable partition function, using the techniques from Chapter 18, and the challenge of an\u00a0intractable posterior distribution, using the techniques from Chapter 19.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6337",
    "text": "As described in Sec. 20.4.2, variational inference allows the construction of a distribution Q( h | v) that approximates the intractable P(h | v). Learning then\u00a0proceeds by maximizing L (v, Q, 6), the variational lower bound on the intractable\u00a0log-likelihood, log P(v; 6).",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6338",
    "text": "For a deep Boltzmann machine with two hidden layers, L is given by",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6339",
    "text": "L(Q, 6) = EE v W; j > + E E h(1 \u2019wfk\u05f3 h21 - log Z (6) + H(Q). (20.35)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6340",
    "text": "i j\u05f3 \u00a0\u00a0\u00a0j\u05f3 k\u05f3",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6341",
    "text": "This expression still contains the log partition function, log Z( 6). Because a deep Boltzmann machine contains restricted Boltzmann machines as components, the\u00a0hardness results for computing the partition function and sampling that apply to\u00a0restricted Boltzmann machines also apply to deep Boltzmann machines. This means\u00a0that evaluating the probability mass function of a Boltzmann machine requires\u00a0approximate methods such as annealed importance sampling. Likewise, training\u00a0the model requires approximations to the gradient of the log partition function. See\u00a0Chapter 18 for a general description of these methods. DBMs are typically trained\u00a0using stochastic maximum likelihood. Many of the other techniques described in\u00a0Chapter 18 are not applicable. Techniques such as pseudolikelihood require the\u00a0ability to evaluate the unnormalized probabilities, rather than merely obtain a\u00a0variational lower bound on them. Contrastive divergence is slow for deep Boltzmann\u00a0machines because they do not allow efficient sampling of the hidden units given the\u00a0visible units\u2014instead, contrastive divergence would require burning in a Markov\u00a0chain every time a new negative phase sample is needed.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6342",
    "text": "The non-variational version of stochastic maximum likelihood algorithm was discussed earlier, in Sec. 18.2. Variational stochastic maximum likelihood as applied\u00a0to the DBM is given in Algorithm 20.1. Recall that we describe a simplified varient\u00a0of the DBM that lacks bias parameters; including them is trivial.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6343",
    "text": "Unfortunately, training a DBM using stochastic maximum likelihood (as described above) from a random initialization usually results in failure. In some cases, the\u00a0model fails to learn to represent the distribution adequately. In other cases, the\u00a0DBM may represent the distribution well, but with no higher likelihood than could\u00a0be obtained with just an RBM. A DBM with very small weights in all but the first\u00a0layer represents approximately the same distribution as an RBM.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6344",
    "text": "Various techniques that permit joint training have been developed and are described in Sec. 20.4.5. However, the original and most popular method for\u00a0overcoming the joint training problem of DBMs is greedy layer-wise pretraining.\u00a0In this method, each layer of the DBM is trained in isolation as an RBM. The\u00a0first layer is trained to model the input data. Each subsequent RBM is trained to\u00a0model samples from the previous RBM\u2019s posterior distribution. After all of the",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6345",
    "text": "Algorithm 20.1 The variational stochastic maximum likelihood algorithm for training a DBM with two hidden layers.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6346",
    "text": "Set e, the step size, to a small positive number",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6347",
    "text": "Set k, the number of Gibbs steps, high enough to allow a Markov chain of p( v, h(1), h(2); 0 + eA0) to burn in, starting from samples fromp(v, h(1), h(2); 0).\u00a0Initialize three matrices, V, H(1) and H(2) each with m rows set to random\u00a0values (e.g., from Bernoulli distributions, possibly with marginals matched to\u00a0the model\u2019s marginals).\u00a0while not converged (learning loop) do",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6348",
    "text": "Sample a minibatch of m examples from the training data and arrange them as the rows of a design matrix V.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6349",
    "text": "Initialize matrices H(1) and H(2), possibly to the model\u2019s marginals. while not converged (mean field inference loop) do",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6350",
    "text": "H (1) a (VW(1) + H(2) W(2)T",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6351",
    "text": "(h (1)w (2))",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6352",
    "text": "H(2) ^ a",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6353",
    "text": "end while",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6354",
    "text": "aw o ^ m v TH (1)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6355",
    "text": "Aw (2) ^ m H{1) T H2)\u05be)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6356",
    "text": "for l = 1 to k (Gibbs sampling) do Gibbs block 1:",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6357",
    "text": "Vi, j, Vij sampled from P(Vij = 1) = a \u00a0\u00a0\u00a0.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6358",
    "text": "Vi, j, \u00a0\u00a0\u00a0sampled from P( h(2)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6359",
    "text": "Gibbs block 2:",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6360",
    "text": "i,j",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6361",
    "text": "Vi, j, pj sampled from P(.P(1)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6362",
    "text": "\u2022,j",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6363",
    "text": "end for",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6364",
    "text": "j,",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6365",
    "text": "H(1)w \u05bej2)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6366",
    "text": "#ERROR!",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6367",
    "text": "#ERROR!",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6368",
    "text": "a",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6369",
    "text": "J + i^i(2)WJ(2)T",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6370",
    "text": "Aw (!) ^ A w(!) - m VTH(1)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6371",
    "text": "Aw (2) ^ a w(2) - m H(1)tHi(2)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6372",
    "text": "W(1) ^ W(1) + e Aw(1) (this is a cartoon illustration, in practice use a more effective algorithm, such as momentum with a decaying learning rate)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6373",
    "text": "W(2) ^ W(2) + eAW(2) end while",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6374",
    "text": "RBMs have been trained in this way, they can be combined to form a DBM. The DBM may then be trained with PCD. Typically PCD training will make only a\u00a0small change in the model\u2019s parameters and its performance as measured by the\u00a0log-likelihood it assigns to the data, or its ability to classify inputs. See Fig. 20.4\u00a0for an illustration of the training procedure.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6375",
    "text": "This greedy layer-wise training procedure is not just coordinate ascent. It bears some passing resemblance to coordinate ascent because we optimize one subset of\u00a0the parameters at each step. However, in the case of the greedy layer-wise training\u00a0procedure, we actually use a different objective function at each step.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6376",
    "text": "Greedy layer-wise pretraining of a DBM differs from greedy layer-wise pretraining of a DBN. The parameters of each individual RBM may be copied to the corresponding DBN directly. In the case of the DBM, the RBM parameters\u00a0must be modified before inclusion in the DBM. A layer in the middle of the stack\u00a0of RBMs is trained with only bottom-up input, but after the stack is combined\u00a0to form the DBM, the layer will have both bottom-up and top-down input. To\u00a0account for this effect, Salakhutdinov and Hinton (2009a) advocate dividing the\u00a0weights of all but the top and bottom RBM in half before inserting them into the\u00a0DBM. Additionally, the bottom RBM must be trained using two \u201ccopies\u201d of each\u00a0visible unit and the weights tied to be equal between the two copies. This means\u00a0that the weights are effectively doubled during the upward pass. Similarly, the top\u00a0RBM should be trained with two copies of the topmost layer.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6377",
    "text": "Obtaining the state of the art results with the deep Boltzmann machine requires a modification of the standard SML algorithm, which is to use a small amount of\u00a0mean field during the negative phase of the joint PCD training step (Salakhutdinov\u00a0and Hinton, 2009a). Specifically, the expectation of the energy gradient should\u00a0be computed with respect to the mean field distribution in which all of the units\u00a0are independent from each other. The parameters of this mean field distribution\u00a0should be obtained by running the mean field fixed point equations for just one\u00a0step. See Goodfellow et al. (2013b) for a comparison of the performance of centered\u00a0DBMs with and without the use of partial mean field in the negative phase.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6378",
    "text": "Classic DBMs require greedy unsupervised pretraining, and to perform classification well, require a separate MLP-based classifier on top of the hidden features they\u00a0extract. This has some undesirable properties. It is hard to track performance\u00a0during training because we cannot evaluate properties of the full DBM while\u00a0training the first RBM. Thus, it is hard to tell how well our hyperparameters",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6379",
    "text": "Figure 20.4: The deep Boltzmann machine training procedure used to classify the MNIST dataset (Salakhutdinov and Hinton, 2009a; Srivastava et al., 2014). (a) Train an RBM\u00a0by using CD to approximately maximize log P (v). (b) Train a second RBM that models\u00a0h(1) and target class y by using CD-k to approximately maximize log P(h(1), y) where\u00a0is drawn from the first RBM\u2019s posterior conditioned on the data. Increasek from 1\u00a0to 20 during learning. (c) Combine the two RBMs into a DBM. Train it to approximately\u00a0maximize log P( v, y) using stochastic maximum likelihood withk = 5. (d) Delete y from\u00a0the model. Define a new set of features h(1) and h(2) that are obtained by running mean\u00a0field inference in the model lacking y. Use these features as input to an MLP whose\u00a0structure is the same as an additional pass of mean field, with an additional output layer\u00a0for the estimate of y. Initialize the MLP\u2019s weights to be the same as the DBM\u2019s weights.\u00a0Train the MLP to approximately maximize log P(y | v) using stochastic gradient descent\u00a0and dropout. Figure reprinted from (Goodfellow et al., 2013b).",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6380",
    "text": "are working until quite late in the training process. Software implementations of DBMs need to have many different components for CD training of individual\u00a0RBMs, PCD training of the full DBM, and training based on back-propagation\u00a0through the MLP. Finally, the MLP on top of the Boltzmann machine loses many\u00a0of the advantages of the Boltzmann machine probabilistic model, such as being\u00a0able to perform inference when some input values are missing.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6381",
    "text": "There are two main ways to resolve the joint training problem of the deep Boltzmann machine. The first is the centered deep Boltzmann machine (Montavon\u00a0and Muller, 2012), which reparametrizes the model in order to make the Hessian of\u00a0the cost function better-conditioned at the beginning of the learning process. This\u00a0yields a model that can be trained without a greedy layer-wise pretraining stage.\u00a0The resulting model obtains excellent test set log-likelihood and produces high\u00a0quality samples. Unfortunately, it remains unable to compete with appropriately\u00a0regularized MLPs as a classifier. The second way to jointly train a deep Boltzmann\u00a0machine is to use a multi-prediction deep Boltzmann machine (Goodfellow et al.,\u00a02013b). This model uses an alternative training criterion that allows the use\u00a0of the back-propagation algorithm in order to avoid the problems with MCMC\u00a0estimates of the gradient. Unfortunately, the new criterion does not lead to good\u00a0likelihood or samples, but, compared to the MCMC approach, it does lead to\u00a0superior classification performance and ability to reason well about missing inputs.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6382",
    "text": "The centering trick for the Boltzmann machine is easiest to describe if we return to the general view of a Boltzmann machine as consisting of a set of units x\u00a0with a weight matrix U and biases b. Recall from Eq. 20.2 that he energy function\u00a0is given by",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6383",
    "text": "E(x) = -xTUx - b x. \u00a0\u00a0\u00a0(20.36)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6384",
    "text": "Using different sparsity patterns in the weight matrix U, we can implement structures of Boltzmann machines, such as RBMs, or DBMs with different numbers\u00a0of layers. This is accomplished by partitioning x into visible and hidden units and\u00a0zeroing out elements of U for units that do not interact. The centered Boltzmann\u00a0machine introduces a vector fi that is subtracted from all of the states:",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6385",
    "text": "E(x; U, b) = \u2014(x \u2014 1)TU(x \u2014 i) \u2014 (x \u2014 1) b. \u00a0\u00a0\u00a0(20.37)",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6386",
    "text": "Typically i is a hyperparameter fixed at the beginning of training. It is usually chosen to make sure that x \u2014 i \u00ab 0 when the model is initialized. This reparametrization does not change the set of probability distributions that the\u00a0model can represent, but it does change the dynamics of stochastic gradient descent\u00a0applied to the likelihood. Specifically, in many cases, this reparametrization results\u00a0in a Hessian matrix that is better conditioned. Melchior et al. (2013) experimentally\u00a0confirmed that the conditioning of the Hessian matrix improves, and observed\u00a0that the centering trick is equivalent to another Boltzmann machine learning\u00a0technique, the enhanced gradient (Cho et al., 2011). The improved conditioning of\u00a0the Hessian matrix allows learning to succeed, even in difficult cases like training a\u00a0deep Boltzmann machine with multiple layers.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6387",
    "text": "The other approach to jointly training deep Boltzmann machines is the multiprediction deep Boltzmann machine (MP-DBM) which works by viewing the mean field equations as defining a family of recurrent networks for approximately solving\u00a0every possible inference problem (Goodfellow et al., 2013b). Rather than training\u00a0the model to maximize the likelihood, the model is trained to make each recurrent\u00a0network obtain an accurate answer to the corresponding inference problem. The\u00a0training process is illustrated in Fig. 20.5. It consists of randomly sampling a\u00a0training example, randomly sampling a subset of inputs to the inference network,\u00a0and then training the inference network to predict the values of the remaining\u00a0units.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6388",
    "text": "This general principle of back-propagating through the computational graph for approximate inference has been applied to other models (Stoyanov et al., 2011;\u00a0Brakel et al., 2013). In these models and in the MP-DBM, the final loss is not\u00a0the lower bound on the likelihood. Instead, the final loss is typically based on\u00a0the approximate conditional distribution that the approximate inference network\u00a0imposes over the missing values. This means that the training of these models\u00a0is somewhat heuristically motivated. If we inspect the p(v) represented by the\u00a0Boltzmann machine learned by the MP-DBM, it tends to be somewhat defective,\u00a0in the sense that Gibbs sampling yields poor samples.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6389",
    "text": "Back-propagation through the inference graph has two main advantages. First, it trains the model as it is really used\u2014with approximate inference. This means\u00a0that approximate inference, for example, to fill in missing inputs, or to perform\u00a0classification despite the presence of missing inputs, is more accurate in the MP-DBM than in the original DBM. The original DBM does not make an accurate\u00a0classifier on its own; the best classification results with the original DBM were\u00a0based on training a separate classifier to use features extracted by the DBM,\u00a0rather than by using inference in the DBM to compute the distribution over the\u00a0class labels. Mean field inference in the MP-DBM performs well as a classifier\u00a0without special modifications. The other advantage of back-propagating through\u00a0approximate inference is that back-propagation computes the exact gradient of\u00a0the loss. This is better for optimization than the approximate gradients of SML\u00a0training, which suffer from both bias and variance. This probably explains why MP-DBMs may be trained jointly while DBMs require a greedy layer-wise pretraining.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6390",
    "text": "Figure 20.5: An illustration of the multi-prediction training process for a deep Boltzmann machine. Each row indicates a different example within a minibatch for the same training\u00a0step. Each column represents a time step within the mean field inference process. For\u00a0each example, we sample a subset of the data variables to serve as inputs to the inference\u00a0process. These variables are shaded black to indicate conditioning. We then run the\u00a0mean field inference process, with arrows indicating which variables influence which other\u00a0variables in the process. In practical applications, we unroll mean field for several steps.\u00a0In this illustration, we unroll for only two steps. Dashed arrows indicate how the process\u00a0could be unrolled for more steps. The data variables that were not used as inputs to the\u00a0inference process become targets, shaded in gray. We can view the inference process for\u00a0each example as a recurrent network. We use gradient descent and back-propagation to\u00a0train these recurrent networks to produce the correct targets given their inputs. This\u00a0trains the mean field process for the MP-DBM to produce accurate estimates. Figure\u00a0adapted from Goodfellow et al. (2013b).",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6391",
    "text": "The disadvantage of back-propagating through the approximate inference graph is that it does not provide a way to optimize the log-likelihood, but rather a heuristic\u00a0approximation of the generalized pseudolikelihood.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6392",
    "text": "The MP-DBM inspired the NADE-k (Raiko et al., 2014) extension to the NADE framework, which is described in Sec. 20.10.10.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6393",
    "text": "The MP-DBM has some connections to dropout. Dropout shares the same parameters among many different computational graphs, with the difference between each graph being whether it includes or excludes each unit. The MP-DBM also\u00a0shares parameters across many computational graphs. In the case of the MP-DBM,\u00a0the difference between the graphs is whether each input unit is observed or not.\u00a0When a unit is not observed, the MP-DBM does not delete it entirely as in the\u00a0case of dropout. Instead, the MP-DBM treats it as a latent variable to be inferred.\u00a0One could imagine applying dropout to the MP-DBM by additionally removing\u00a0some units rather than making them latent.",
    "chapter": "",
    "chapter_id": "main-37.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6394",
    "text": "While Boltzmann machines were originally developed for use with binary data, many applications such as image and audio modeling seem to require the ability\u00a0to represent probability distributions over real values. In some cases, it is possible\u00a0to treat real-valued data in the interval [0, 1] as representing the expectation of a\u00a0binary variable. For example, Hinton (2000) treats grayscale images in the training\u00a0set as defining [0,1] probability values. Each pixel defines the probability of a\u00a0binary value being 1, and the binary pixels are all sampled independently from\u00a0each other. This is a common procedure for evaluating binary models on grayscale\u00a0image datasets. However, it is not a particularly theoretically satisfying approach,\u00a0and binary images sampled independently in this way have a noisy appearance. In\u00a0this section, we present Boltzmann machines that define a probability density over\u00a0real-valued data.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6395",
    "text": "Restricted Boltzmann machines may be developed for many exponential family conditional distributions (Welling et al., 2005). Of these, the most common is the\u00a0RBM with binary hidden units and real-valued visible units, with the conditional\u00a0distribution over the visible units being a Gaussian distribution whose mean is a\u00a0function of the hidden units.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6396",
    "text": "There are many ways of parametrizing Gaussian-Bernoulli RBMs. First, we may choose whether to use a covariance matrix or a precision matrix for the Gaussian\u00a0distribution. Here we present the precision formulation. The modification to obtain\u00a0the covariance formulation is straightforward. We wish to have the conditional\u00a0distribution",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6397",
    "text": "p(v | h) = N(v; Wh, 0-1). \u00a0\u00a0\u00a0(20.38)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6398",
    "text": "We can find the terms we need to add to the energy function by expanding the unnormalized log conditional distribution:",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6399",
    "text": "logN(v; Wh, 0-1) = - - (v - Wh)T 0 (v - Wh) + f (0). \u00a0\u00a0\u00a0(20.39)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6400",
    "text": "\u2014",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6401",
    "text": "Here f encapsulates all the terms that are a function only of the parameters and not the random variables in the model. We can discard f because its only\u00a0role is to normalize the distribution, and the partition function of whatever energy\u00a0function we choose will carry out that role.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6402",
    "text": "If we include all of the terms (with their sign flipped) involving v from Eq. 20.39 in our energy function and do not add any other terms involving v, then our energy\u00a0function will represent the desired conditional p(v | h).",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6403",
    "text": "We have some freedom regarding the other conditional distribution, p(h | v). Note that Eq. 20.39 contains a term",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6404",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6405",
    "text": "\u2014hTW 0Wh. \u00a0\u00a0\u00a0(20.40)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6406",
    "text": "\u2014",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6407",
    "text": "This term cannot be included in its entirety because it includes hhj terms. These correspond to edges between the hidden units. If we included these terms, we\u00a0would have a linear factor model instead of a restricted Boltzmann machine.\u00a0When designing our Boltzmann machine, we simply omit these hih j cross terms.\u00a0Omitting them does not change the conditional p(v | h) so Eq. 20.39 is still\u00a0respected. However, we still have a choice about whether to include the terms\u00a0involving only a single hi. If we assume a diagonal precision matrix, we find that\u00a0for each hidden unit hi we have a term",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6408",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6409",
    "text": "- hi\u00a3 j Wj. \u00a0\u00a0\u00a0(20.41)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6410",
    "text": "j",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6411",
    "text": "In the above, we used the fact that hj = hi because hi \u00a3 {0,1}. If we include this term (with its sign flipped) in the energy function, then it will naturally bias hi\u00a0to be turned off when the weights for that unit are large and connected to visible\u00a0units with high precision. The choice of whether or not to include this bias term\u00a0does not affect the family of distributions the model can represent (assuming that\u00a0we include bias parameters for the hidden units) but it does affect the learning\u00a0dynamics of the model. Including the term may help the hidden unit activations\u00a0remain reasonable even when the weights rapidly increase in magnitude.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6412",
    "text": "One way to define the energy function on a Gaussian-Bernoulli RBM is thus",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6413",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6414",
    "text": "E(v, h) = 2 vT(3 \u00a9 v) - (v \u00a9 3)T Wh - bTh \u00a0\u00a0\u00a0(20.42)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6415",
    "text": "2",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6416",
    "text": "but we may also add extra terms or parametrize the energy in terms of the variance rather than precision if we choose.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6417",
    "text": "In this derivation, we have not included a bias term on the visible units, but one could easily be added. One final source of variability in the parametrization of a\u00a0Gaussian-Bernoulli RBM is the choice of how to treat the precision matrix. It may\u00a0either be fixed to a constant (perhaps estimated based on the marginal precision\u00a0of the data) or learned. It may also be a scalar times the identity matrix, or it\u00a0may be a diagonal matrix. Typically we do not allow the precision matrix to be\u00a0non-diagonal in this context, because some operations would then require inverting\u00a0the matrix. In the sections ahead, we will see that other forms of Boltzmann\u00a0machines permit modeling the covariance structure, using various techniques to\u00a0avoid inverting the precision matrix.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6418",
    "text": "While the Gaussian RBM has been the canonical energy model for real-valued data, Ranzato et al. (2010a) argue that the Gaussian RBM inductive bias is not\u00a0well suited to the statistical variations present in some types of real-valued data,\u00a0especially natural images. The problem is that much of the information content\u00a0present in natural images is embedded in the covariance between pixels rather than\u00a0in the raw pixel values. In other words, it is the relationships between pixels and\u00a0not their absolute values where most of the useful information in images resides.\u00a0Since the Gaussian RBM only models the conditional mean of the input given the\u00a0hidden units, it cannot capture conditional covariance information. In response\u00a0to these criticisms, alternative models have been proposed that attempt to better\u00a0account for the covariance of real-valued data. These models include the mean and\u00a0covariance RBM (mcRBM1), the mean-product of f-distribution (mPoT) model\u00a0and the spike and slab RBM (ssRBM).",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6419",
    "text": "Mean and Covariance RBM The mcRBM uses its hidden units to independently encode the conditional mean and covariance of all observed units. The mcRBM hidden layer is divided into two groups of units: mean units and covariance\u00a0units. The group that models the conditional mean is simply a Gaussian RBM.\u00a0The other half is a covariance RBM (Ranzato et al., 2010a), also called a cRBM,\u00a0whose components model the conditional covariance structure, as described below.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6420",
    "text": "Specifically, with binary mean units h(m) and binary covariance units h(c), the mcRBM model is defined as the combination of two energy functions:",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6421",
    "text": "Emc(x, h<m>, h<c>) = Em(x, h<m>) + Ec(x, \u00a0\u00a0\u00a0),\u00a0\u00a0\u00a0\u00a0(20.43)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6422",
    "text": "where Em is the standard Gaussian-Bernoulli RBM energy function:2",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6423",
    "text": "Em(x, h(m)) = 2xTx - ^ xT W:jhjm) - ^ \u00a0\u00a0\u00a0hjm),\u00a0\u00a0\u00a0\u00a0(20.44)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6424",
    "text": "2",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6425",
    "text": "and Ec is the cRBM energy function that models the conditional covariance information:",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6426",
    "text": "-20.45",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6427",
    "text": "Ec(x, h( c)) =2 \u00a0\u00a0\u00a0hjc) ^xTr -\u00a0\u00a0\u00a0\u00a0bjc) hjc).",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6428",
    "text": "The parameter r(j) corresponds to the covariance weight vector associated with hjc) and b( c) is a vector of covariance offsets. The combined energy function defines\u00a0a joint distribution:",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6429",
    "text": "\u05da",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6430",
    "text": "Pmc(x, h(m), h(c)) = Z exp{ Emc(x, h(m), h(c)) j, \u00a0\u00a0\u00a0(20.46)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6431",
    "text": "and a corresponding conditional distribution over the observations given h(m) and h(c) as a multivariate Gaussian distribution:",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6432",
    "text": "pmc(x | h<m>, h<c>) = N I x; cmh I \u00a3 \u00a0\u00a0\u00a0I , I .\u00a0\u00a0\u00a0\u00a0(20.47)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6433",
    "text": "Note that the covariance matrix C^jh = \u00a0\u00a0\u00a0hjc)rr(j)T + 71 is non-diagonal",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6434",
    "text": "and that W is the weight matrix associated with the Gaussian RBM modeling the",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6435",
    "text": "conditional means. It is difficult to train the mcRBM via contrastive divergence or persistent contrastive divergence because of its non-diagonal conditional covariance\u00a0structure. CD and PCD require sampling from the joint distribution of x, h(m), h(c)\u00a0which, in a standard RBM, is accomplished by Gibbs sampling over the conditionals.\u00a0However, in the mcRBM, sampling frompmc(x | h(m), h(c)) requires computing\u00a0(Cmc)-1 at every iteration of learning. This can be an impractical computational\u00a0burden for larger observations. Ranzato and Hinton (2010) avoid direct sampling\u00a0from the conditional pmc( x | h(m), h(c)) by sampling directly from the marginal\u00a0p(x) using Hamiltonian (hybrid) Monte Carlo (Neal, 1993) on the mcRBM free\u00a0energy.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6436",
    "text": "Mean-Product of Student\u2019s t-distributions The mean-product of Student\u2019s t-distribution (mPoT) model (Ranzato et al., 2010b) extends the PoT model (Welling\u00a0et al., 2003a) in a manner similar to how the mcRBM extends the cRBM. This\u00a0is achieved by including nonzero Gaussian means by the addition of Gaussian\u00a0RBM-like hidden units. Like the mcRBM, the PoT conditional distribution over the\u00a0observation is a multivariate Gaussian (with non-diagonal covariance) distribution;\u00a0however, unlike the mcRBM, the complementary conditional distribution over the\u00a0hidden variables is given by conditionally independent Gamma distributions. The\u00a0Gamma distribution G(k, 9) is a probability distribution over positive real numbers,\u00a0with mean k9. It is not necessary to have a more detailed understanding of the\u00a0Gamma distribution to understand the basic ideas underlying the mPoT model.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6437",
    "text": "The mPoT energy function is:",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6438",
    "text": "-20.48",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6439",
    "text": "EmPoT(x, h(m) , h(c) )",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6440",
    "text": "- Yj )l0g h",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6441",
    "text": "(c)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6442",
    "text": "3",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6443",
    "text": "-20.49",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6444",
    "text": "where r(3) is the covariance weight vector associated with unit h jc) and Em(x, h( is as defined in Eq. 20.44.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6445",
    "text": "Just as with the mcRBM, the mPoT model energy function specifies a multivariate Gaussian, with a conditional distribution over x that has non-diagonal covariance. Learning in the mPoT model\u2014again, like the mcRBM\u2014is complicated by the inability to sample from the non-diagonal Gaussian conditional\u00a0PmPoT(x 1 h(m), h(c) ), so Ranzato et al. (2010b) also advocate direct sampling of\u00a0p(x) via Hamiltonian (hybrid) Monte Carlo.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6446",
    "text": "Spike and Slab Restricted Boltzmann Machines Spike and slab restricted Boltzmann machines (Courville et al., 2011) or ssRBMs provide another means\u00a0of modeling the covariance structure of real-valued data. Compared to mcRBMs,\u00a0ssRBMs have the advantage of requiring neither matrix inversion nor Hamiltonian\u00a0Monte Carlo methods. As a model of natural images, the ssRBM is interesting\u00a0in that, like the mcRBM and the mPoT model, its binary hidden units encode\u00a0the conditional covariance across pixels through the use of auxiliary real-valued\u00a0variables.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6447",
    "text": "The spike and slab RBM has two sets of hidden units: binary spike units h, and real-valued slab units s. The mean of the visible units conditioned on the\u00a0hidden units is given by (h 0 s)WT. In other words, each column W:;i defines a\u00a0component that can appear in the input when hi = 1. The corresponding spike\u00a0variable hi determines whether that component is present at all. The corresponding\u00a0slab variable si determines the intensity of that component, if it is present. When\u00a0a spike variable is active, the corresponding slab variable adds variance to the\u00a0input along the axis defined by W:;i. This allows us to model the covariance of the\u00a0inputs. Fortunately, contrastive divergence and persistent contrastive divergence\u00a0with Gibbs sampling are still applicable. There is no need to invert any matrix.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6448",
    "text": "Formally, the ssRBM model is defined via its energy function:",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6449",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6450",
    "text": "E ss(x, s, h) = \u2014 ^ x TW :,iSihi + 2 xT",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6451",
    "text": "(a. + \u00a3 $ihij",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6452",
    "text": "x",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6453",
    "text": "-20.5",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6454",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6455",
    "text": "+ 2$^ as? -X} aiEi'Sihi -^2 bihi +5Z ai$hi, \u00a0\u00a0\u00a0(20.51)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6456",
    "text": "where bi is the offset of the spike hi and A is a diagonal precision matrix on the observations x. The parameter ai > 0 is a scalar precision parameter for the\u00a0real-valued slab variable si. The parameter $i is a non-negative diagonal matrix\u00a0that defines an h-modulated quadratic penalty on x. Each * is a mean parameter\u00a0for the slab variable si.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6457",
    "text": "With the joint distribution defined via the energy function, it is relatively straightforward to derive the ssRBM conditional distributions. For example,\u00a0by marginalizing out the slab variables s, the conditional distribution over the\u00a0observations given the binary spike variables h is given by:",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6458",
    "text": "Pss(x 1 h)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6459",
    "text": "J exp {\u2014E(x, s, h)} ds",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6460",
    "text": "#ERROR!",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6461",
    "text": "11",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6462",
    "text": "P(h) Z",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6463",
    "text": "-20.52",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6464",
    "text": "-20.53",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6465",
    "text": "where C\u05be^ = (A +\u00a3 , * ,hi - \u00a3, a-'h WW) 1. The last equality holds only if the covariance matrix C^h is positive definite.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6466",
    "text": "Gating by the spike variables means that the true marginal distribution over h 0 s is sparse. This is different from sparse coding, where samples from the model\u00a0\u201calmost never\u201d (in the measure theoretic sense) contain zeros in the code, and MAP\u00a0inference is required to impose sparsity.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6467",
    "text": "Comparing the ssRBM to the mcRBM and the mPoT models, the ssRBM parametrizes the conditional covariance of the observation in a significantly different\u00a0way. The mcRBM and mPoT both model the covariance structure of the observation",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6468",
    "text": "as ^ Ylj h jcV(j) r(j)T + \u00a0\u00a0\u00a0, using the activation of the hidden units hj > 0 to",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6469",
    "text": "enforce constraints on the conditional covariance in the direction r(j). In contrast, the ssRBM specifies the conditional covariance of the observations using the hidden\u00a0spike activations hi = 1 to pinch the precision matrix along the direction specified\u00a0by the corresponding weight vector. The ssRBM conditional covariance is very\u00a0similar to that given by a different model: the product of probabilistic principal\u00a0components analysis (PoPPCA) (Williams and Agakov, 2002). In the overcomplete\u00a0setting, sparse activations with the ssRBM parametrization permit significant\u00a0variance (above the nominal variance given by A-1) only in the selected directions\u00a0of the sparsely activated hi. In the mcRBM or mPoT models, an overcomplete\u00a0representation would mean that to capture variation in a particular direction in\u00a0the observation space requires removing potentially all constraints with positive\u00a0projection in that direction. This would suggest that these models are less well\u00a0suited to the overcomplete setting.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6470",
    "text": "The primary disadvantage of the spike and slab restricted Boltzmann machine is that some settings of the parameters can correspond to a covariance matrix\u00a0that is not positive definite. Such a covariance matrix places more unnormalized\u00a0probability on values that are farther from the mean, causing the integral over\u00a0all possible outcomes to diverge. Generally this issue can be avoided with simple\u00a0heuristic tricks. There is not yet any theoretically satisfying solution. Using\u00a0constrained optimization to explicitly avoid the regions where the probability is\u00a0undefined is difficult to do without being overly conservative and also preventing\u00a0the model from accessing high-performing regions of parameter space.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6471",
    "text": "Qualitatively, convolutional variants of the ssRBM produce excellent samples of natural images. Some examples are shown in Fig. 16.1.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6472",
    "text": "The ssRBM allows for several extensions. Including higher-order interactions and average-pooling of the slab variables (Courville et al., 2014) enables the model\u00a0to learn excellent features for a classifier when labeled data is scarce. Adding a\u00a0term to the energy function that prevents the partition function from becoming\u00a0undefined results in a sparse coding model, spike and slab sparse coding (Goodfellow\u00a0et al., 2013d), also known as S3C.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6473",
    "text": "As seen in Chapter 9, extremely high dimensional inputs such as images place great strain on the computation, memory and statistical requirements of machine\u00a0learning models. Replacing matrix multiplication by discrete convolution with a\u00a0small kernel is the standard way of solving these problems for inputs that have\u00a0translation invariant spatial or temporal structure. Desjardins and Bengio (2008)\u00a0showed that this approach works well when applied to RBMs.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6474",
    "text": "Deep convolutional networks usually require a pooling operation so that the spatial size of each successive layer decreases. Feedforward convolutional networks\u00a0often use a pooling function such as the maximum of the elements to be pooled.\u00a0It is unclear how to generalize this to the setting of energy-based models. We\u00a0could introduce a binary pooling unit p over n binary detector units d and enforce\u00a0p = maxi di by setting the energy function to be to whenever that constraint is\u00a0violated. This does not scale well though, as it requires evaluating 2 different\u00a0energy configurations to compute the normalization constant. For a small 3 x 3\u00a0pooling region this requires 29 = 512 energy function evaluations per pooling unit!",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6475",
    "text": "Lee et al. (2009) developed a solution to this problem called probabilistic max pooling (not to be confused with \u201cstochastic pooling,\u201d which is a technique for\u00a0implicitly constructing ensembles of convolutional feedforward networks). The\u00a0strategy behind probabilistic max pooling is to constrain the detector units so\u00a0at most one may be active at a time. This means there are only n + 1 total\u00a0states (one state for each of the n detector units being on, and an additional state\u00a0corresponding to all of the detector units being off). The pooling unit is on if\u00a0and only if one of the detector units is on. The state with all units off is assigned\u00a0energy zero. We can think of this as describing a model with a single variable that\u00a0has n + 1 states, or equivalently as a model that has n + 1 variables that assigns\u00a0energy to to all but n + 1 joint assignments of variables.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6476",
    "text": "While efficient, probabilistic max pooling does force the detector units to be mutually exclusive, which may be a useful regularizing constraint in some contexts\u00a0or a harmful limit on model capacity in other contexts. It also does not support\u00a0overlapping pooling regions. Overlapping pooling regions are usually required\u00a0to obtain the best performance from feedforward convolutional networks, so this\u00a0constraint probably greatly reduces the performance of convolutional Boltzmann",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6477",
    "text": "machines.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6478",
    "text": "Lee et al. (2009) demonstrated that probabilistic max pooling could be used to build convolutional deep Boltzmann machines.3 This model is able to perform\u00a0operations such as filling in missing portions of its input. While intellectually\u00a0appealing, this model is challenging to make work in practice, and usually does\u00a0not perform as well as a classifier as traditional convolutional networks trained\u00a0with supervised learning.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6479",
    "text": "Many convolutional models work equally well with inputs of many different spatial sizes. For Boltzmann machines, it is difficult to change the input size\u00a0for a variety of reasons. The partition function changes as the size of the input\u00a0changes. Moreover, many convolutional networks achieve size invariance by scaling\u00a0up the size of their pooling regions proportional to the size of the input, but scaling\u00a0Boltzmann machine pooling regions is awkward. Traditional convolutional neural\u00a0networks can use a fixed number of pooling units and dynamically increase the\u00a0size of their pooling regions in order to obtain a fixed-size representation of a\u00a0variable-sized input. For Boltzmann machines, large pooling regions become too\u00a0expensive for the naive approach. The approach of Lee et al. (2009) of making\u00a0each of the detector units in the same pooling region mutually exclusive solves\u00a0the computational problems, but still does not allow variable-size pooling regions.\u00a0For example, suppose we learn a model with 2 x 2 probabilistic max pooling over\u00a0detector units that learn edge detectors. This enforces the constraint that only\u00a0one of these edges may appear in each 2 x 2 region. If we then increase the size of\u00a0the input image by 50% in each direction, we would expect the number of edges to\u00a0increase correspondingly. Instead, if we increase the size of the pooling regions by\u00a050% in each direction to 3 x 3, then the mutual exclusivity constraint now specifies\u00a0that each of these edges may only appear once in a 3 x 3 region. As we grow\u00a0a model\u2019s input image in this way, the model generates edges with less density.\u00a0Of course, these issues only arise when the model must use variable amounts of\u00a0pooling in order to emit a fixed-size output vector. Models that use probabilistic\u00a0max pooling may still accept variable-sized input images so long as the output of\u00a0the model is a feature map that can scale in size proportional to the input image.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6480",
    "text": "Pixels at the boundary of the image also pose some difficulty, which is exacerbated by the fact that connections in a Boltzmann machine are symmetric. If we do not implicitly zero-pad the input, then there are fewer hidden units than\u00a0visible units, and the visible units at the boundary of the image are not modeled\u00a0well because they lie in the receptive field of fewer hidden units. However, if we do\u00a0implicitly zero-pad the input, then the hidden units at the boundary are driven by\u00a0fewer input pixels, and may fail to activate when needed.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6481",
    "text": "In the structured output scenario, we wish to train a model that can map from some input x to some output y, and the different entries of y are related to each\u00a0other and must obey some constraints. For example, in the speech synthesis task,\u00a0y is a waveform, and the entire waveform must sound like a coherent utterance.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6482",
    "text": "A natural way to represent the relationships between the entries in y is to use a probability distribution p(y | x). Boltzmann machines, extended to model\u00a0conditional distributions, can supply this probabilistic model.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6483",
    "text": "The same tool of conditional modeling with a Boltzmann machine can be used not just for structured output tasks, but also for sequence modeling. In the latter\u00a0case, rather than mapping an input x to an output y, the model must estimate a\u00a0probability distribution over a sequence of variables,p(x(1),..., x(t)). Conditional\u00a0Boltzmann machines can represent factors of the form p(x(t) | x(1),..., x(t-1)) in\u00a0order to accomplish this task.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6484",
    "text": "An important sequence modeling task for the video game and film industry is modeling sequences of joint angles of skeletons used to render 3-D characters.\u00a0These sequences are often collected using motion capture systems to record the\u00a0movements of actors. A probabilistic model of a character\u2019s movement allows\u00a0the generation of new, previously unseen, but realistic animations. To solve\u00a0this sequence modeling task, Taylor et al. (2007) introduced a conditional RBM\u00a0modelingp(x(t) | x(t-1),...,x(t-m)) for small m. The model is an RBM over\u00a0p(x(t)) whose bias parameters are a linear function of the preceding m values of x.\u00a0When we condition on different values of x(t-1) and earlier variables, we get a new\u00a0RBM over x. The weights in the RBM over x never change, but by conditioning on\u00a0different past values, we can change the probability of different hidden units in the\u00a0RBM being active. By activating and deactivating different subsets of hidden units,\u00a0we can make large changes to the probability distribution induced on x. Other\u00a0variants of conditional RBM (Mnih et al., 2011) and other variants of sequence\u00a0modeling using conditional RBMs are possible (Taylor and Hinton, 2009; Sutskever\u00a0et al., 2009; Boulanger-Lewandowski et al., 2012).",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6485",
    "text": "Another sequence modeling task is to model the distribution over sequences of musical notes used to compose songs. Boulanger-Lewandowski et al. (2012)\u00a0introduced the RNN-RBM sequence model and applied it to this task. The RNN-RBM is a generative model of a sequence of frames consisting of an RNN\u00a0that emits the RBM parameters for each time step. Unlike the model described\u00a0above, the RNN emits all of the parameters of the RBM, including the weights.\u00a0To train the model, we need to be able to back-propagate the gradient of the\u00a0loss function through the RNN. The loss function is not applied directly to the\u00a0RNN outputs. Instead, it is applied to the RBM. This means that we must\u00a0approximately differentiate the loss with respect to the RBM parameters using\u00a0contrastive divergence or a related algorithm. This approximate gradient may then\u00a0be back-propagated through the RNN using the usual back-propagation through\u00a0time algorithm.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6486",
    "text": "Many other variants of Boltzmann machines are possible.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6487",
    "text": "Boltzmann machines may be extended with different training criteria. We have focused on Boltzmann machines trained to approximately maximize the generative\u00a0criterion logp(v). It is also possible to train discriminative RBMs that aim to\u00a0maximize logp(y | v) instead (Larochelle and Bengio, 2008). This approach often\u00a0performs the best when using a linear combination of both the generative and\u00a0the discriminative criteria. Unfortunately, RBMs do not seem to be as powerful\u00a0supervised learners as MLPs, at least using existing methodology.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6488",
    "text": "Most Boltzmann machines used in practice have only second-order interactions in their energy functions, meaning that their energy functions are the sum of many\u00a0terms and each individual term only includes the product between two random\u00a0variables. An example of such a term is viWi,jhj . It is also possible to train\u00a0higher-order Boltzmann machines (Sejnowski, 1987) whose energy function terms\u00a0involve the products between many variables. Three-way interactions between a\u00a0hidden unit and two different images can model spatial transformations from one\u00a0frame of video to the next (Memisevic and Hinton, 2007, 2010). Multiplication by a\u00a0one-hot class variable can change the relationship between visible and hidden units\u00a0depending on which class is present (Nair and Hinton, 2009). One recent example\u00a0of the use of higher-order interactions is a Boltzmann machine with two groups of\u00a0hidden units, with one group of hidden units that interact with both the visible\u00a0units v and the class label y, and another group of hidden units that interact only\u00a0with the v input values (Luo et al., 2011). This can be interpreted as encouraging\u00a0some hidden units to learn to model the input using features that are relevant to\u00a0the class but also to learn extra hidden units that explain nuisance details that\u00a0are necessary for the samples of v to be realistic but do not determine the class\u00a0of the example. Another use of higher-order interactions is to gate some features.\u00a0Sohn et al. (2013) introduced a Boltzmann machine with third-order interactions\u00a0with binary mask variables associated with each visible unit. When these masking\u00a0variables are set to zero, they remove the influence of a visible unit on the hidden\u00a0units. This allows visible units that are not relevant to the classification problem\u00a0to be removed from the inference pathway that estimates the class.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6489",
    "text": "More generally, the Boltzmann machine framework is a rich space of models permitting many more model structures than have been explored so far. Developing\u00a0a new form of Boltzmann machine requires some more care and creativity than\u00a0developing a new neural network layer, because it is often difficult to find an energy\u00a0function that maintains tractability of all of the different conditional distributions\u00a0needed to use the Boltzmann machine, but despite this required effort the field\u00a0remains open to innovation.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6490",
    "text": "Traditional neural networks implement a deterministic transformation of some input variables x. When developing generative models, we often wish to extend\u00a0neural networks to implement stochastic transformations of x. One straightforward\u00a0way to do this is to augment the neural network with extra inputs z that are\u00a0sampled from some simple probability distribution, such as a uniform or Gaussian\u00a0distribution. The neural network can then continue to perform deterministic\u00a0computation internally, but the function f (x, z) will appear stochastic to an\u00a0observer who does not have access to z. Provided that f is continuous and\u00a0differentiable, we can then compute the gradients necessary for training using\u00a0back-propagation as usual.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6491",
    "text": "As an example, let us consider the operation consisting of drawing samples y from a Gaussian distribution with mean ! and variance a2:",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6492",
    "text": "y ~N(!,a2 ). \u00a0\u00a0\u00a0(20.54)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6493",
    "text": "Because an individual sample of y is not produced by a function, but rather by a sampling process whose output changes every time we query it, it may seem\u00a0counterintuitive to take the derivatives of y with respect to the parameters of\u00a0its distribution, ! and a2. However, we can rewrite the sampling process as\u00a0transforming an underlying random value z ~ N(z; 0, 1) to obtain a sample from",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6494",
    "text": "the desired distribution:",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6495",
    "text": "y = p + az \u00a0\u00a0\u00a0(20.55)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6496",
    "text": "We are now able to back-propagate through the sampling operation, by regarding it as a deterministic operation with an extra input z. Crucially, the extra input is a random variable whose distribution is not a function of any of the variables\u00a0whose derivatives we want to calculate. The result tells us how an infinitesimal\u00a0change in p or a would change the output if we could repeat the sampling operation\u00a0again with the same value of z.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6497",
    "text": "Being able to back-propagate through this sampling operation allows us to incorporate it into a larger graph. We can build elements of the graph on top of the\u00a0output of the sampling distribution. For example, we can compute the derivatives\u00a0of some loss function J(y). We can also build elements of the graph whose outputs\u00a0are the inputs or the parameters of the sampling operation. For example, we could\u00a0build a larger graph with p = f(x; 6) and a = g(x; 6). In this augmented graph,\u00a0we can use back-propagation through these functions to derive V qJ(y).",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6498",
    "text": "The principle used in this Gaussian sampling example is more generally applicable. We can express any probability distribution of the formp(y; 6) or p (y | x; 6) as p(y | u), where u is a variable containing both parameters 6, and if applicable,\u00a0the inputs x. Given a value y sampled from distribution p(y | u), where u may in\u00a0turn be a function of other variables, we can rewrite",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6499",
    "text": "y ~ p(y | u) \u00a0\u00a0\u00a0(20.56)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6500",
    "text": "as",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6501",
    "text": "y = f (z; u), \u00a0\u00a0\u00a0(20.57)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6502",
    "text": "where z is a source of randomness. We may then compute the derivatives of y with respect to u using traditional tools such as the back-propagation algorithm applied\u00a0to f, so long as f is continuous and differentiable almost everywhere. Crucially, u\u00a0must not be a function of z, and z must not be a function of u. This technique is\u00a0often called the reparametrization trick, stochastic back-propagation or perturbation\u00a0analysis.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6503",
    "text": "The requirement that f be continuous and differentiable of course requires y to be continuous. If we wish to back-propagate through a sampling process that\u00a0produces discrete-valued samples, it may still be possible to estimate a gradient on\u00a0u, using reinforcement learning algorithms such as variants of the REINFORCE\u00a0algorithm (Williams, 1992), discussed in Sec. 20.9.1.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6504",
    "text": "In neural network applications, we typically choose z to be drawn from some simple distribution, such as a unit uniform or unit Gaussian distribution, and\u00a0achieve more complex distributions by allowing the deterministic portion of the\u00a0network to reshape its input.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6505",
    "text": "The idea of propagating gradients or optimizing through stochastic operations dates back to the mid-twentieth century (Price, 1958; Bonnet, 1964) and was\u00a0first used for machine learning in the context of reinforcement learning (Williams,\u00a01992). More recently, it has been applied to variational approximations (Opper\u00a0and Archambeau, 2009) and stochastic or generative neural networks (Bengio\u00a0et al., 2013b; Kingma, 2013; Kingma and Welling, 2014b,a; Rezende et al., 2014;\u00a0Goodfellow et al., 2014c). Many networks, such as denoising autoencoders or\u00a0networks regularized with dropout, are also naturally designed to take noise\u00a0as an input without requiring any special reparametrization to make the noise\u00a0independent from the model.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6506",
    "text": "When a model emits a discrete variable y, the reparametrization trick is not applicable. Suppose that the model takes inputs x and parameters 6, both\u00a0encapsulated in the vector u, and combines them with random noise z to produce",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6507",
    "text": "y:",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6508",
    "text": "y = f (z; u). \u00a0\u00a0\u00a0(20.58)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6509",
    "text": "Because y is discrete, f must be a step function. The derivatives of a step function are not useful at any point. Right at each step boundary, the derivatives are\u00a0undefined, but that is a small problem. The large problem is that the derivatives\u00a0are zero almost everywhere, on the regions between step boundaries. The derivatives\u00a0of any cost function J(y) therefore do not give any information for how to update\u00a0the model parameters 6.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6510",
    "text": "The REINFORCE algorithm (REward Increment = Non-negative Factor x Offset Reinforcement x Characteristic Eligibility) provides a framework defining a\u00a0family of simple but powerful solutions (Williams, 1992). The core idea is that\u00a0even though J(f (z; u)) is a step function with useless derivatives, the expected\u00a0cost Ez~P(z)J (f (z; u)) is often a smooth function amenable to gradient descent.\u00a0Although that expectation is typically not tractable when y is high-dimensional\u00a0(or is the result of the composition of many discrete stochastic decisions), it can be\u00a0estimated without bias using a Monte Carlo average. The stochastic estimate of\u00a0the gradient can be used with SGD or other stochastic gradient-based optimization\u00a0techniques.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6511",
    "text": "The simplest version of REINFORCE can be derived by simply differentiating",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6512",
    "text": "the expected cost:",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6513",
    "text": "E z[J (y)] _Y^J (y)p(y)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6514",
    "text": "-20.59",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6515",
    "text": "y",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6516",
    "text": "\u05f4 EJ\u00ab\u00bb_ E J <\u00bb> t\u05f4\u2019",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6517",
    "text": "y",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6518",
    "text": "-20.6",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6519",
    "text": "_ E J (y)p(y)d",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6520",
    "text": "y",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6521",
    "text": "-20.61",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6522",
    "text": "\u00ab 1 E J (y(i) f 1og p(y,<)).",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6523",
    "text": "m du",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6524",
    "text": "y(i)~p(y), i= 1",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6525",
    "text": "-20.62",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6526",
    "text": "d logp(y) _ \u00a0\u00a0\u00a01 dp(y)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6527",
    "text": "Eq. 20.60 relies on the assumption that J does not reference u directly. It is trivial to extend the approach to relax this assumption. Eq. 20.61 exploits the derivative",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6528",
    "text": "Eq. 20.62 gives an unbiased Monte",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6529",
    "text": "p(y) du",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6530",
    "text": "rule for the logarithm,",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6531",
    "text": "Carlo estimator of the gradient.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6532",
    "text": "Anywhere we write p( y) in this section, one could equally write p(y | x). This is because p(y) is parametrized by u, and u contains both 6 and x, if x is present.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6533",
    "text": "One issue with the above simple REINFORCE estimator is that it has a very high variance, so that many samples of y need to be drawn to obtain a good\u00a0estimator of the gradient, or equivalently, if only one sample is drawn, SGD will\u00a0converge very slowly and will require a smaller learning rate. It is possible to\u00a0considerably reduce the variance of that estimator by using variance reduction\u00a0methods (Wilson, 1984; L\u2019Ecuyer, 1994). The idea is to modify the estimator so\u00a0that its expected value remains unchanged but its variance get reduced. In the\u00a0context of REINFORCE, the proposed variance reduction methods involve the\u00a0computation of a baseline that is used to offset J (y). Note that any offset b(u)\u00a0that does not depend on y would not change the expectation of the estimated\u00a0gradient because",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6534",
    "text": "Ep(y)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6535",
    "text": "d log p(y) d u",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6536",
    "text": "d tog p(y) _\u00a0\u00a0\u00a0\u00a0p(y)\u00a0\u00a0\u00a0\u00a0du",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6537",
    "text": "y",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6538",
    "text": "dp(y) d u",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6539",
    "text": "dW E p(y) _ dW1",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6540",
    "text": "0,",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6541",
    "text": "-20.63",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6542",
    "text": "-20.64",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6543",
    "text": "-20.65",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6544",
    "text": "y",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6545",
    "text": "which means that",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6546",
    "text": "Ep(y)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6547",
    "text": "(J(y) - b(u))",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6548",
    "text": "d log p(y) d u",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6549",
    "text": "\u2014 Ep(y)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6550",
    "text": "\u2014 E",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6551",
    "text": "p(y)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6552",
    "text": "J (y)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6553",
    "text": "J (y)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6554",
    "text": "d log p(y) d u",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6555",
    "text": "d log p(y) d u",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6556",
    "text": "b(u)Ep(y)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6557",
    "text": "d log p(y) d u",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6558",
    "text": "-20.66",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6559",
    "text": "-20.67",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6560",
    "text": "Furthermore, we can obtain the optimal b(u) by computing the variance of (J(y) \u2014 b(u))d 1\u00b0g<P(y) under p(y) and minimizing with respect to b (u). What we find is\u00a0that this optimal baseline b (u)i is different for each element cvi of the vector u:",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6561",
    "text": "b *(u)i \u2014",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6562",
    "text": "Ep(y)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6563",
    "text": "r \u05e1 n",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6564",
    "text": "J (y)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6565",
    "text": "Ep(y)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6566",
    "text": "d log p(y) 2",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6567",
    "text": "Owi",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6568",
    "text": "",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6569",
    "text": "-20.68",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6570",
    "text": "The gradient estimator with respect to wi then becomes",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6571",
    "text": "-20.69",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6572",
    "text": "(J (y) \u2014 b(u) i)-",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6573",
    "text": "d logp(y)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6574",
    "text": "dui",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6575",
    "text": "where b(u) estimates the above b*(u )i. The estimate b is usually obtained by adding extra outputs to the neural network and training the new outputs to estimate",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6576",
    "text": "C\\-",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6577",
    "text": "d1\u00b0gpy)2",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6578",
    "text": "dwi",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6579",
    "text": "outputs can be trained with the mean squared error objective, using respectively",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6580",
    "text": "J(y)d 10g?\u25a0^ and d 1OgJ^ as targets when y is sampled from p(y), for a given u. The estimate b may then be recovered by substituting these estimates into Eq.\u00a020.68. Mnih and Gregor (2014) preferred to use a single shared output (across all\u00a0elements i of u) trained with the target J(y), using as baseline b(u)\u00a0\u00a0\u00a0\u00a0Ep(y) [J (y)].",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6581",
    "text": "Ep",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6582",
    "text": "p(y)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6583",
    "text": "(\u05be>",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6584",
    "text": "[J(y) ^VpM ] and",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6585",
    "text": "E",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6586",
    "text": "p(y)",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6587",
    "text": "for each element of u. These extra",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6588",
    "text": "Variance reduction methods have been introduced in the reinforcement learning context (Sutton et al., 2000; Weaver and Tao, 2001), generalizing previous work\u00a0on the case of binary reward by Dayan (1990). See Bengio et al. (2013b), Mnih\u00a0and Gregor (2014), Ba et al. (2014), Mnih et al. (2014), or Xu et al. (2015) for\u00a0examples of modern uses of the REINFORCE algorithm with reduced variance in\u00a0the context of deep learning. In addition to the use of an input-dependent baseline\u00a0b(u), Mnih and Gregor (2014) found that the scale of (J(y) \u2014 b(u)) could be\u00a0adjusted during training by dividing it by its standard deviation estimated by a\u00a0moving average during training, as a kind of adaptive learning rate, to counter\u00a0the effect of important variations that occur during the course of training in the\u00a0magnitude of this quantity. Mnih and Gregor (2014) called this heuristic variance\u00a0normalization.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6589",
    "text": "REINFORCE-based estimators can be understood as estimating the gradient by correlating choices of y with corresponding values of J (y). If a good value of y\u00a0is unlikely under the current parametrization, it might take a long time to obtain it\u00a0by chance, and get the required signal that this configuration should be reinforced.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6590",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6591",
    "text": "The term \u201cmcRBM\u201d is pronounced by saying the name of the letters M-C-R-B-M; the \u201cmc\u201d is not pronounced like the \u201cMc\u201d in \u201cMcDonald\u2019s.\u201d",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6592",
    "text": "2",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6593",
    "text": "This version of the Gaussian-Bernoulli RBM energy function assumes the image data has zero mean, per pixel. Pixel offsets can easily be added to the model to account for nonzero pixel\u00a0means.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6594",
    "text": "3",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6595",
    "text": "The publication describes the model as a \u201cdeep belief network\u201d but because it can be described as a purely undirected model with tractable layer-wise mean field fixed point updates, it best fits\u00a0the definition of a deep Boltzmann machine.",
    "chapter": "",
    "chapter_id": "main-38.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6596",
    "text": "As discussed in Chapter 16, directed graphical models make up a prominent class of graphical models. While directed graphical models have been very popular\u00a0within the greater machine learning community, within the smaller deep learning\u00a0community they have until roughly 2013 been overshadowed by undirected models\u00a0such as the RBM.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6597",
    "text": "In this section we review some of the standard directed graphical models that have traditionally been associated with the deep learning community.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6598",
    "text": "We have already described deep belief networks, which are a partially directed model. We have also already described sparse coding models, which can be thought\u00a0of as shallow directed generative models. They are often used as feature learners\u00a0in the context of deep learning, though they tend to perform poorly at sample\u00a0generation and density estimation. We now describe a variety of deep, fully directed\u00a0models.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6599",
    "text": "Sigmoid belief networks (Neal, 1990) are a simple form of directed graphical model with a specific kind of conditional probability distribution. In general, we can\u00a0think of a sigmoid belief network as having a vector of binary states s, with each\u00a0element of the state influenced by its ancestors:",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6600",
    "text": "p(si) = a \u00a0\u00a0\u00a0Wj,isj + bi J .\u00a0\u00a0\u00a0\u00a0(20.70)",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6601",
    "text": "The most common structure of sigmoid belief network is one that is divided into many layers, with ancestral sampling proceeding through a series of many\u00a0hidden layers and then ultimately generating the visible layer. This structure is\u00a0very similar to the deep belief network, except that the units at the beginning of\u00a0the sampling process are independent from each other, rather than sampled from\u00a0a restricted Boltzmann machine. Such a structure is interesting for a variety of\u00a0reasons. One reason is that the structure is a universal approximator of probability\u00a0distributions over the visible units, in the sense that it can approximate any\u00a0probability distribution over binary variables arbitrarily well, given enough depth,\u00a0even if the width of the individual layers is restricted to the dimensionality of the\u00a0visible layer (Sutskever and Hinton, 2008).",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6602",
    "text": "While generating a sample of the visible units is very efficient in a sigmoid belief network, most other operations are not. Inference over the hidden units given\u00a0the visible units is intractable. Mean field inference is also intractable because the\u00a0variational lower bound involves taking expectations of cliques that encompass\u00a0entire layers. This problem has remained difficult enough to restrict the popularity\u00a0of directed discrete networks.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6603",
    "text": "One approach for performing inference in a sigmoid belief network is to construct a different lower bound that is specialized for sigmoid belief networks (Saul et al.,\u00a01996). This approach has only been applied to very small networks. Another\u00a0approach is to use learned inference mechanisms as described in Sec. 19.5. The\u00a0Helmholtz machine (Dayan et al., 1995; Dayan and Hinton, 1996) is a sigmoid belief\u00a0network combined with an inference network that predicts the parameters of the\u00a0mean field distribution over the hidden units. Modern approaches (Gregor et al.,\u00a02014; Mnih and Gregor, 2014) to sigmoid belief networks still use this inference\u00a0network approach. These techniques remain difficult due to the discrete nature of\u00a0the latent variables. One cannot simply back-propagate through the output of the\u00a0inference network, but instead must use the relatively unreliable machinery for back-propagating through discrete sampling processes, described in Sec. 20.9.1. Recent\u00a0approaches based on importance sampling, reweighted wake-sleep (Bornschein\u00a0and Bengio, 2015) and bidirectional Helmholtz machines (Bornschein et al., 2015)\u00a0make it possible to quickly train sigmoid belief networks and reach state-of-the-art\u00a0performance on benchmark tasks.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6604",
    "text": "A special case of sigmoid belief networks is the case where there are no latent variables. Learning in this case is efficient, because there is no need to marginalize\u00a0latent variables out of the likelihood. A family of models called auto-regressive\u00a0networks generalize this fully visible belief network to other kinds of variables\u00a0besides binary variables and other structures of conditional distributions besides log-linear relationships. Auto-regressive networks are described later, in Sec. 20.10.7.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6605",
    "text": "Many generative models are based on the idea of using a differentiable generator network. The model transforms samples of latent variables z to samples x or\u00a0to distributions over samples x using a differentiable function g(z; 0(g)) which is\u00a0typically represented by a neural network. This model class includes variational\u00a0autoencoders, which pair the generator net with an inference net, generative\u00a0adversarial networks, which pair the generator network with a discriminator\u00a0network, and techniques that train generator networks in isolation.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6606",
    "text": "Generator networks are essentially just parametrized computational procedures for generating samples, where the architecture provides the family of possible\u00a0distributions to sample from and the parameters select a distribution from within\u00a0that family.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6607",
    "text": "As an example, the standard procedure for drawing samples from a normal distribution with mean fi and covariance \u00a3 is to feed samples z from a normal\u00a0distribution with zero mean and identity covariance into a very simple generator\u00a0network. This generator network contains just one affine layer:",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6608",
    "text": "x",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6609",
    "text": "g(z) = p + Lz",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6610",
    "text": "-20.71",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6611",
    "text": "where L is given by the Cholesky decomposition of \u00a3.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6612",
    "text": "Pseudorandom number generators can also use nonlinear transformations of simple distributions. For example, inverse transform sampling (Devroye, 2013)\u00a0draws a scalar z from U(0, 1) and applies a nonlinear transformation to a scalar\u00a0x. In this case g(z) is given by the inverse of the cumulative distribution function\u00a0F(x) = /* p(v)dv. If we are able to specify p(x), integrate over x, and invert the\u00a0resulting function, we can sample from p(x) without using machine learning.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6613",
    "text": "To generate samples from more complicated distributions that are difficult to specify directly, difficult to integrate over, or whose resulting integrals are\u00a0difficult to invert, we use a feedforward network to represent a parametric family\u00a0of nonlinear functions g, and use training data to infer the parameters selecting\u00a0the desired function.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6614",
    "text": "We can think of g as providing a nonlinear change of variables that transforms the distribution over z into the desired distribution over x.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6615",
    "text": "Recall from Eq. 3.47 that, for invertible, differentiable, continuous g,",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6616",
    "text": "Pz(z) = Px(g(z))",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6617",
    "text": "det( dZ \u05d9",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6618",
    "text": "-20.72",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6619",
    "text": "This implicitly imposes a probability distribution over x:",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6620",
    "text": "-20.73",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6621",
    "text": "Px(x) = PZ -I(X))",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6622",
    "text": "Of course, this formula may be difficult to evaluate, depending on the choice of g, so we often use indirect means of learning g, rather than trying to maximize\u00a0logp(x) directly.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6623",
    "text": "In some cases, rather than using g to provide a sample of x directly, we use g to define a conditional distribution over x. For example, we could use a generator\u00a0net whose final layer consists of sigmoid outputs to provide the mean parameters\u00a0of Bernoulli distributions:",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6624",
    "text": "p(xi = 1 | z) = g(z)i. \u00a0\u00a0\u00a0(20.74)",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6625",
    "text": "In this case, when we use g to define p(x | z), we impose a distribution over x by marginalizing z:",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6626",
    "text": "p(x) = Ezp(x | z). \u00a0\u00a0\u00a0(20.75)",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6627",
    "text": "Both approaches define a distribution pg (x) and allow us to train various criteria of pg using the reparametrization trick of Sec. 20.9.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6628",
    "text": "The two different approaches to formulating generator nets\u2014emitting the parameters of a conditional distribution versus directly emitting samples\u2014have\u00a0complementary strengths and weaknesses. When the generator net defines a\u00a0conditional distribution over x, it is capable of generating discrete data as well\u00a0as continuous data. When the generator net provides samples directly, it is\u00a0capable of generating only continuous data (we could introduce discretization in\u00a0the forward propagation, but this would lose the ability to learn the model using\u00a0back-propagation). The advantage to direct sampling is that we are no longer\u00a0forced to use conditional distributions whose form can be easily written down and\u00a0algebraically manipulated by a human designer.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6629",
    "text": "Approaches based on differentiable generator networks are motivated by the success of gradient descent applied to differentiable feedforward networks for\u00a0classification. In the context of supervised learning, deep feedforward networks\u00a0trained with gradient-based learning seem practically guaranteed to succeed given\u00a0enough hidden units and enough training data. Can this same recipe for success\u00a0transfer to generative modeling?",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6630",
    "text": "Generative modeling seems to be more difficult than classification or regression because the learning process requires optimizing intractable criteria. In the context\u00a0of differentiable generator nets, the criteria are intractable because the data does\u00a0not specify both the inputs z and the outputs x of the generator net. In the case\u00a0of supervised learning, both the inputs x and the outputs y were given, and the\u00a0optimization procedure needs only to learn how to produce the specified mapping.\u00a0In the case of generative modeling, the learning procedure needs to determine how\u00a0to arrange z space in a useful way and additionally how to map from z to x.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6631",
    "text": "Dosovitskiy et al. (2015) studied a simplified problem, where the correspondence between z and x is given. Specifically, the training data is computer-rendered\u00a0imagery of chairs. The latent variables z are parameters given to the rendering\u00a0engine describing the choice of which chair model to use, the position of the chair,\u00a0and other configuration details that affect the rendering of the image. Using this\u00a0synthetically generated data, a convolutional network is able to learn to map z\u00a0descriptions of the content of an image to x approximations of rendered images.\u00a0This suggests that contemporary differentiable generator networks have sufficient\u00a0model capacity to be good generative models, and that contemporary optimization\u00a0algorithms have the ability to fit them. The difficulty lies in determining how to\u00a0train generator networks when the value of z for each x is not fixed and known\u00a0ahead of each time.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6632",
    "text": "The following sections describe several approaches to training differentiable generator nets given only training samples of x.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6633",
    "text": "The variational autoencoder or VAE (Kingma, 2013; Rezende et al., 2014) is a directed model that uses learned approximate inference and can be trained purely\u00a0with gradient-based methods.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6634",
    "text": "To generate a sample from the model, the VAE first draws a sample z from the code distribution pmode1( z). The sample is then run through a differentiable\u00a0generator networkg(z). Finally, x is sampled from a distribution pmode1(x; g(z)) =\u00a0pmode1 (x | z). However, during training, the approximate inference network (or\u00a0encoder) q(z | x) is used to obtain z and pmode1 (x | z) is then viewed as a decoder\u00a0network.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6635",
    "text": "The key insight behind variational autoencoders is that they may be trained by maximizing the variational lower bound L(q) associated with data point x:",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6636",
    "text": "L(q) = E\u05be~q(z|*) 10gPmodel(z\u05dc x) + H(q(z 1 x)) \u00a0\u00a0\u00a0(20.76)",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6637",
    "text": "Ez~q(z|\u00ae) 10gpmode1(x 1 z) \u00a0\u00a0\u00a0DKL(q(z 1 x) 1|pmode1(z))\u00a0\u00a0\u00a0\u00a0(2\u00b0.77)",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6638",
    "text": "< logPmode1 (x). \u00a0\u00a0\u00a0(20.78)",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6639",
    "text": "In Eq. 20.76, we recognize the first term as the joint log-likelihood of the visible and hidden variables under the approximate posterior over the latent variables (just\u00a0like with EM, except that we use an approximate rather than the exact posterior).\u00a0We recognize also a second term, the entropy of the approximate posterior. When\u00a0q is chosen to be a Gaussian distribution, with noise added to a predicted mean\u00a0value, maximizing this entropy term encourages increasing the standard deviation\u00a0of this noise. More generally, this entropy term encourages the variational posterior\u00a0to place high probability mass on many z values that could have generated x,\u00a0rather than collapsing to a single point estimate of the most likely value. In Eq.\u00a020.77, we recognize the first term as the reconstruction log-likelihood found in\u00a0other autoencoders. The second term tries to make the approximate posterior\u00a0distribution q(z | x) and the model prior pmode1 (z) approach each other.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6640",
    "text": "Traditional approaches to variational inference and learning infer q via an optimization algorithm, typically iterated fixed point equations (Sec. 19.4). These\u00a0approaches are slow and often require the ability to compute Ez^q logpmode1(z, x)\u00a0in closed form. The main idea behind the variational autoencoder is to train a\u00a0parametric encoder (also sometimes called an inference network or recognition\u00a0model) that produces the parameters of q. So long as z is a continuous variable, we\u00a0can then back-propagate through samples of z drawn from q(z | x) = q(z; f (x; 6))\u00a0in order to obtain a gradient with respect to d. Learning then consists solely of\u00a0maximizing L with respect to the parameters of the encoder and decoder. All of\u00a0the expectations in L may be approximated by Monte Carlo sampling.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6641",
    "text": "The variational autoencoder approach is elegant, theoretically pleasing, and simple to implement. It also obtains excellent results and is among the state of\u00a0the art approaches to generative modeling. Its main drawback is that samples\u00a0from variational autoencoders trained on images tend to be somewhat blurry. The\u00a0causes of this phenomenon are not yet known. One possibility is that the blurriness\u00a0is an intrinsic effect of maximum likelihood, which minimizes Dkl (pdata||pmodei).\u00a0As illustrated in Fig. 3.6, this means that the model will assign high probability to\u00a0points that occur in the training set, but may also assign high probability to other\u00a0points. These other points may include blurry images. Part of the reason that the\u00a0model would choose to put probability mass on blurry images rather than some\u00a0other part of the space is that the variational autoencoders used in practice usually\u00a0have a Gaussian distribution for pmode1(x; g(z)). Maximizing a lower bound on\u00a0the likelihood of such a distribution is similar to training a traditional autoencoder\u00a0with mean squared error, in the sense that it has a tendency to ignore features\u00a0of the input that occupy few pixels or that cause only a small change in the\u00a0brightness of the pixels that they occupy. This issue is not specific to VAEs and\u00a0is shared with generative models that optimize a log-likelihood, or equivalently,\u00a0Dkl (pdata||pmodei), as argued by Theis et al. (2015) and by Huszar (2015). Another\u00a0troubling issue with contemporary VAE models is that they tend to use only a small\u00a0subset of the dimensions of z, as if the encoder was not able to transform enough\u00a0of the local directions in input space to a space where the marginal distribution\u00a0matches the factorized prior.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6642",
    "text": "The VAE framework is very straightforward to extend to a wide range of model architectures. This is a key advantage over Boltzmann machines, which require\u00a0extremely careful model design to maintain tractability. VAEs work very well\u00a0with a diverse family of differentiable operators. One particularly sophisticated\u00a0VAE is the deep recurrent attention writer or DRAW model (Gregor et al., 2015).\u00a0DRAW uses a recurrent encoder and recurrent decoder combined with an attention\u00a0mechanism. The generation process for the DRAW model consists of sequentially\u00a0visiting different small image patches and drawing the values of the pixels at those\u00a0points. VAEs can also be extended to generate sequences by defining variational\u00a0RNNs (Chung et al., 2015b) by using a recurrent encoder and decoder within\u00a0the VAE framework. Generating a sample from a traditional RNN involves only\u00a0non-deterministic operations at the output space. Variational RNNs also have\u00a0random variability at the potentially more abstract level captured by the VAE\u00a0latent variables.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6643",
    "text": "The VAE framework has been extended to maximize not just the traditional variational lower bound, but instead the importance weighted autoencoder (Burda\u00a0et al., 2015) objective:",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6644",
    "text": "Lk(x, q) = Ez(1) \u00a0\u00a0\u00a0~g(z|x) l\u00b0g k",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6645",
    "text": "Pmodel (x, Z(i) )",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6646",
    "text": "k \u00a0\u00a0\u00a0q(z W | x)",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6647",
    "text": "i=1",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6648",
    "text": "-20.79",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6649",
    "text": "This new objective is equivalent to the traditional lower bound L when k = 1. However, it may also be interpreted as forming an estimate of the true logpmodei(x)\u00a0using importance sampling of z from proposal distribution q(z | x). The importance\u00a0weighted autoencoder objective is also a lower bound on logpmode1 (x) and becomes\u00a0tighter as k increases.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6650",
    "text": "Variational autoencoders have some interesting connections to the MP-DBM and other approaches that involve back-propagation through the approximate\u00a0inference graph (Goodfellow et al., 2013b; Stoyanov et al., 2011; Brakel et al., 2013).\u00a0These previous approaches required an inference procedure such as mean field fixed\u00a0point equations to provide the computational graph. The variational autoencoder\u00a0is defined for arbitrary computational graphs, which makes it applicable to a wider\u00a0range of probabilistic model families because there is no need to restrict the choice\u00a0of models to those with tractable mean field fixed point equations. The variational\u00a0autoencoder also has the advantage that it increases a bound on the log-likelihood\u00a0of the model, while the criteria for the MP-DBM and related models are more\u00a0heuristic and have little probabilistic interpretation beyond making the results of\u00a0approximate inference accurate. One disadvantage of the variational autoencoder\u00a0is that it learns an inference network for only one problem, inferring z given x.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6651",
    "text": "The older methods are able to perform approximate inference over any subset of variables given any other subset of variables, because the mean field fixed point\u00a0equations specify how to share parameters between the computational graphs for\u00a0all of these different problems.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6652",
    "text": "One very nice property of the variational autoencoder is that simultaneously training a parametric encoder in combination with the generator network forces\u00a0the model to learn a predictable coordinate system that the encoder can capture.\u00a0This makes it an excellent manifold learning algorithm. See Fig. 20.6 for examples\u00a0of low-dimensional manifolds learned by the variational autoencoder. In one of the\u00a0cases demonstrated in the figure, the algorithm discovered two independent factors\u00a0of variation present in images of faces: angle of rotation and emotional expression.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6653",
    "text": "** *\u00ab\u2022I\u00ab\u2022I*\u20221\u2022 \u20221\u2022 \u00a0\u00a0\u00a0\u2022\u05df\u2022 % U U 6 6 2",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6654",
    "text": "i J i i",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6655",
    "text": "* \u20224* \u2022l\u00ab \u00a0\u00a0\u00a0M 2 2 2 2",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6656",
    "text": "it m m m \u00a0\u00a0\u00a0*\u05d2\u05d2\u05d2\u05d9\u05d9\u05d9",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6657",
    "text": ".\u00bb\u00ab4**1**1**1\u00ab*1*\u00bb4**1*%(*%1\u25a0* \u2018I 3 3 2 2",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6658",
    "text": "ii\u20181\u20181\u2018\u05d2\u05d9 \u05f3",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6659",
    "text": "\u05e3\u05f4(* !J ^ ^ \u05e3",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6660",
    "text": "\u05d3 H \u05e8 \u05d5\u05d9 \u05d9",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6661",
    "text": "**f**f**fa*f**V**V*M**f**l>* \u05e3 \u05e3 \u05e3 \u05e3 \u05e3",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6662",
    "text": "\u2022 \u00a0\u00a0\u00a0*1# *1\u00a0\u00a0\u00a0\u00a0\u20221* \u00ab\u05d5*\u00ab\u05df h h 9 <?",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6663",
    "text": "\u05d3",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6664",
    "text": "7 .\u00bb\u2022\u05df*\u20221**1* \u20221\u2022\u00bb\u05d5* \u20221\u2022 \u2022\u05d5* \u2022 v v H 9",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6665",
    "text": "^ > w.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6666",
    "text": "\u2022 \u00a0\u00a0\u00a0V y V \u00ab 9",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6667",
    "text": "\u05d9\u05be y y y 9 7",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6668",
    "text": "U1w*v\u00ab\u00abf*\u00bbb \u20181\u2022 *I* - {\u2022\u2022C\u2022(** 7 9 7 7 1",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6669",
    "text": "7 7 7 7 7",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6670",
    "text": "i&OOO 2 2 2 0 0\u00a02 2 2 2 5\u00a02 2 2 2 3\u00a02 2 2 2 3\u00a022233",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6671",
    "text": "2 \u00a0\u00a0\u00a02 2 3 3",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6672",
    "text": "3 \u00a0\u00a0\u00a02 3 3 3\u00a03 3 3 3 3",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6673",
    "text": "2 8",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6674",
    "text": "\u05df 9\u00a09\u00a09\u00a01",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6675",
    "text": "8 8\u00a09\u00a09\u00a08\u00a09\u00a09\u00a09",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6676",
    "text": "\u05d5",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6677",
    "text": "1 \u05d5",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6678",
    "text": "3 3 8 8\u00a08 S\u00a08 8",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6679",
    "text": "OOO OOO\u00a05 5 0\u00a05 5 5\u00a03 3 5\u00a03 3 3\u00a03 3 3\u00a03 3 3\u00a03 3 3\u00a03 3 3\u00a08 3 3\u00a0S S 6\u00a06\u00a06\u00a06\u00a04",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6680",
    "text": "1 1 \u05d5 1\u00a0\u05d5",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6681",
    "text": "1 \\ \\",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6682",
    "text": "4 4 4 I\u00a0t I",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6683",
    "text": "I I",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6684",
    "text": "OOO",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6685",
    "text": "OOO",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6686",
    "text": "000 6 0 0\u00a03 3 0\u00a03 3S\u00a03 5S\u00a03 3S\u00a03 3 8",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6687",
    "text": "3 \u00a0\u00a0\u00a08 8\u00a08 8 8\u00a08 8 6\u00a06 6 6\u00a06 6 6\u00a06 6 6",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6688",
    "text": "1 \u00a0\u00a0\u00a06 6",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6689",
    "text": "4 \u00a0\u00a0\u00a0l i\u00a0I I l\u00a0I i I\u00a0I I I",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6690",
    "text": "0 003 0 0 0 3\u00a00 0 0 3\u00a00 6 3 3\u00a0S 3 3 3\u00a0S S J J\u00a0S S S 7\u00a0S S f /",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6691",
    "text": "8 r r ?",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6692",
    "text": "8 ? r 7",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6693",
    "text": "8 f r r",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6694",
    "text": "s s r s s r\u00a06 s f\u00a0i",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6695",
    "text": "Figure 20.6: Examples of two-dimensional coordinate systems for high-dimensional manifolds, learned by a variational autoencoder (Kingma and Welling, 2014a). Two dimensions may be plotted directly on the page for visualization, so we can gain an understanding of\u00a0how the model works by training a model with a 2-D latent code, even if we believe the\u00a0intrinsic dimensionality of the data manifold is much higher. The images shown are not\u00a0examples from the training set but images x actually generated by the model p(x | z),\u00a0simply by changing the 2-D \u201ccode\u201d z (each image corresponds to a different choice of \u201ccode\u201d\u00a0z on a 2-D uniform grid). (Left) The two-dimensional map of the Frey faces manifold.\u00a0One dimension that has been discovered (horizontal) mostly corresponds to a rotation of\u00a0the face, while the other (vertical) corresponds to the emotional expression. (Right) The\u00a0two-dimensional map of the MNIST manifold.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6696",
    "text": "Generative adversarial networks or GANs (Goodfellow et al2014c) are another generative modeling approach based on differentiable generator networks.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6697",
    "text": "Generative adversarial networks are based on a game theoretic scenario in which the generator network must compete against an adversary. The generator\u00a0network directly produces samples x = g(z; 0(g)). Its adversary, the discriminator\u00a0network, attempts to distinguish between samples drawn from the training data\u00a0and samples drawn from the generator. The discriminator emits a probability value\u00a0given by d(x; 0(d)), indicating the probability that x is a real training example\u00a0rather than a fake sample drawn from the model.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6698",
    "text": "The simplest way to formulate learning in generative adversarial networks is as a zero-sum game, in which a function v(0(g), 0(d)) determines the payoff of the\u00a0discriminator. The generator receives \u2014 v(d(g), 0(d)) as its own payoff. During\u00a0learning, each player attempts to maximize its own payoff, so that at convergence",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6699",
    "text": "g* = argminmax v(g,d). \u00a0\u00a0\u00a0(20.80)",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6700",
    "text": "g \u00a0\u00a0\u00a0d",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6701",
    "text": "The default choice for v is",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6702",
    "text": "v(0 (g) 0(d) ) = Ex^pdata 10g d(x) + E \u00a0\u00a0\u00a0odel 10g(l \u2014 d(x)) .\u00a0\u00a0\u00a0\u00a0(2\u00b0.81)",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6703",
    "text": "This drives the discriminator to attempt to learn to correctly classify samples as real or fake. Simultaneously, the generator attempts to fool the classifier into believing\u00a0its samples are real. At convergence, the generator\u2019s samples are indistinguishable\u00a0from real data, and the discriminator outputs | everywhere. The discriminator\u00a0may then be discarded.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6704",
    "text": "The main motivation for the design of GANs is that the learning process requires neither approximate inference nor approximation of a partition function\u00a0gradient. In the case where maxd v(g, d) is convex in 0(g) (such as the case where\u00a0optimization is performed directly in the space of probability density functions)\u00a0then the procedure is guaranteed to converge and is asymptotically consistent.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6705",
    "text": "Unfortunately, learning in GANs can be difficult in practice when g and d are represented by neural networks and maxd v(g,d) is not convex. Goodfellow",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6706",
    "text": "(2014) identified non-convergence as an issue that may cause GANs to underfit.\u00a0In general, simultaneous gradient descent on two players\u2019 costs is not guaranteed\u00a0to reach an equilibrium. Consider for example the value function v(a, b) = ab,\u00a0where one player controls a and incurs cost ab, while the other player controls b\u00a0and receives a cost \u2014ab. If we model each player as making infinitesimally small\u00a0gradient steps, each player reducing their own cost at the expense of the other\u00a0player, then a and b go into a stable, circular orbit, rather than arriving at the\u00a0equilibrium point at the origin. Note that the equilibria for a minimax game are\u00a0not local minima of v. Instead, they are points that are simultaneously minima\u00a0for both players\u2019 costs. This means that they are saddle points of v that are local\u00a0minima with respect to the first player\u2019s parameters and local maxima with respect\u00a0to the second player\u2019s parameters. It is possible for the two players to take turns\u00a0increasing then decreasing v forever, rather than landing exactly on the saddle\u00a0point where neither player is capable of reducing their cost. It is not known to\u00a0what extent this non-convergence problem affects GANs.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6707",
    "text": "Goodfellow (2014) identified an alternative formulation of the payoffs, in which the game is no longer zero-sum, that has the same expected gradient\u00a0as maximum likelihood learning whenever the discriminator is optimal. Because\u00a0maximum likelihood training converges, this reformulation of the GAN game should\u00a0also converge, given enough samples. Unfortunatley, this alternative formulation\u00a0does not seem to perform well in practice, possibly due to suboptimality of the\u00a0discriminator, or possibly due to high variance around the expected gradient.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6708",
    "text": "In practice, the best-performing formulation of the GAN game is a different formulation that is neither zero-sum nor equivalent to maximum likelihood, introduced by Goodfellow et al. (2014c) with a heuristic motivation. In this best-performing\u00a0formulation, the generator aims to increase the log probability that the discriminator makes a mistake, rather than aiming to decrease the log probability that the\u00a0discriminator makes the correct prediction. This reformulation is motivated solely\u00a0by the observation that it causes the derivative of the generator\u2019s cost function\u00a0with respect to the discriminator\u2019s logits to remain large even in the situation\u00a0where the discriminator confidently rejects all generator samples.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6709",
    "text": "Stabilization of GAN learning remains an open problem. Fortunately, GAN learning performs well when the model architecture and hyperparameters are carefully selected. Radford et al. (2015) crafted a deep convolutional GAN (DCGAN)\u00a0that performs very well for image synthesis tasks, and showed that its latent\u00a0representation space captures important factors of variation, as shown in Fig. 15.9.\u00a0See Fig. 20.7 for examples of images generated by a DCGAN generator.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6710",
    "text": "The GAN learning problem can also be simplified by breaking the generation process into many levels of detail. It is possible to train conditional GANs (Mirza\u00a0and Osindero, 2014) that learn to sample from a distribution p(x | y) rather\u00a0than simply sampling from a marginal distribution p(x). Denton et al. (2015)\u00a0showed that a series of conditional GANs can be trained to first generate a very\u00a0low-resolution version of an image, then incrementally add details to the image.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6711",
    "text": "Figure 20.7: Images generated by GANs trained on the LSUN dataset. (Left) Images of bedrooms generated by a DCGAN model, reproduced with permission from Radford\u00a0et al. (2015). (Right) Images of churches generated by a LAPGAN model, reproduced\u00a0with permission from Denton et al. (2015).",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6712",
    "text": "This technique is called the LAPGAN model, due to the use of a Laplacian pyramid to generate the images containing varying levels of detail. LAPGAN generators\u00a0are able to fool not only discriminator networks but also human observers, with\u00a0experimental subjects identifying up to 40% of the outputs of the network as being\u00a0real data. See Fig. 20.7 for examples of images generated by a LAPGAN generator.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6713",
    "text": "One unusual capability of the GAN training procedure is that it can fit probability distributions that assign zero probability to the training points. Rather than maximizing the log probability of specific points, the generator net learns to trace\u00a0out a manifold whose points resemble training points in some way. Somewhat paradoxically, this means that the model may assign a log-likelihood of negative infinity\u00a0to the test set, while still representing a manifold that a human observer judges\u00a0to capture the essence of the generation task. This is not clearly an advantage or\u00a0a disadvantage, and one may also guarantee that the generator network assigns\u00a0non-zero probability to all points simply by making the last layer of the generator\u00a0network add Gaussian noise to all of the generated values. Generator networks\u00a0that add Gaussian noise in this manner sample from the same distribution that one\u00a0obtains by using the generator network to parametrize the mean of a conditional\u00a0Gaussian distribution.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6714",
    "text": "Dropout seems to be important in the discriminator network. In particular, units should be stochastically dropped while computing the gradient for the\u00a0generator network to follow. Following the gradient of the deterministic version of\u00a0the discriminator with its weights divided by two does not seem to be as effective.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6715",
    "text": "Likewise, never using dropout seems to yield poor results.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6716",
    "text": "While the GAN framework is designed for differentiable generator networks, similar principles can be used to train other kinds of models. For example, self-supervised boosting can be used to train an RBM generator to fool a logistic\u00a0regression discriminator (Welling et al., 2002).",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6717",
    "text": "Generative moment matching networks (Li et al., 2015; Dziugaite et al., 2015) are another form of generative model based on differentiable generator networks.\u00a0Unlike VAEs and GANs, they do not need to pair the generator network with any\u00a0other network\u2014neither an inference network as used with VAEs nor a discriminator\u00a0network as used with GANs.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6718",
    "text": "These networks are trained with a technique called moment matching. The basic idea behind moment matching is to train the generator in such a way that\u00a0many of the statistics of samples generated by the model are as similar as possible\u00a0to those of the statistics of the examples in the training set. In this context, a\u00a0moment is an expectation of different powers of a random variable. For example,\u00a0the first moment is the mean, the second moment is the mean of the squared\u00a0values, and so on. In multiple dimensions, each element of the random vector may\u00a0be raised to different powers, so that a moment may be any quantity of the form",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6719",
    "text": "Ex n x\"\u25a0 \u00a0\u00a0\u00a0(20.82)",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6720",
    "text": "where n = [n 1, n2,..., nd]T is a vector of non-negative integers.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6721",
    "text": "Upon first examination, this approach seems to be computationally infeasible. For example, if we want to match all the moments of the form x^x j, then we need\u00a0to minimize the difference between a number of values that is quadratic in the\u00a0dimension of x. Moreover, even matching all of the first and second moments\u00a0would only be sufficient to fit a multivariate Gaussian distribution, which captures\u00a0only linear relationships between values. Our ambitions for neural networks are to\u00a0capture complex nonlinear relationships, which would require far more moments.\u00a0GANs avoid this problem of exhaustively enumerating all moments by using a\u00a0dynamically updated discriminator, that automatically focuses its attention on\u00a0whichever statistic the generator network is matching the least effectively.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6722",
    "text": "Instead, generative moment matching networks can be trained by minimizing a cost function called maximum mean discrepancy (Scholkopf and Smola, 2002;\u00a0Gretton et al., 2012) or MMD. This cost function measures the error in the first\u00a0moments in an infinite-dimensional space, using an implicit mapping to feature\u00a0space defined by a kernel function in order to make computations on infinitedimensional vectors tractable. The MMD cost is zero if and only if the two\u00a0distributions being compared are equal.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6723",
    "text": "Visually, the samples from generative moment matching networks are somewhat disappointing. Fortunately, they can be improved by combining the generator\u00a0network with an autoencoder. First, an autoencoder is trained to reconstruct the\u00a0training set. Next, the encoder of the autoencoder is used to transform the entire\u00a0training set into code space. The generator network is then trained to generate\u00a0code samples, which may be mapped to visually pleasing samples via the decoder.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6724",
    "text": "Unlike GANs, the cost function is defined only with respect to a batch of examples from both the training set and the generator network. It is not possible\u00a0to make a training update as a function of only one training example or only\u00a0one sample from the generator network. This is because the moments must be\u00a0computed as an empirical average across many samples. When the batch size is too\u00a0small, MMD can underestimate the true amount of variation in the distributions\u00a0being sampled. No finite batch size is sufficiently large to eliminate this problem\u00a0entirely, but larger batches reduce the amount of underestimation. When the batch\u00a0size is too large, the training procedure becomes infeasibly slow, because many\u00a0examples must be processed in order to compute a single small gradient step.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6725",
    "text": "As with GANs, it is possible to train a generator net using MMD even if that generator net assigns zero probability to the training points.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6726",
    "text": "When generating images, it is often useful to use a generator network that includes a convolutional structure (see for example Goodfellow et al. (2014c) or Dosovitskiy\u00a0et al. (2015)). To do so, we use the \u201ctranspose\u201d of the convolution operator,\u00a0described in Sec. 9.5. This approach often yields more realistic images and does\u00a0so using fewer parameters than using fully connected layers without parameter\u00a0sharing.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6727",
    "text": "Convolutional networks for recognition tasks have information flow from the image to some summarization layer at the top of the network, often a class label.\u00a0As this image flows upward through the network, information is discarded as the\u00a0representation of the image becomes more invariant to nuisance transformations.\u00a0In a generator network, the opposite is true. Rich details must be added as\u00a0the representation of the image to be generated propagates through the network,\u00a0culminating in the final representation of the image, which is of course the image\u00a0itself, in all of its detailed glory, with object positions and poses and textures and\u00a0lighting. The primary mechanism for discarding information in a convolutional\u00a0recognition network is the pooling layer. The generator network seems to need to\u00a0add information. We cannot put the inverse of a pooling layer into the generator\u00a0network because most pooling functions are not invertible. A simpler operation is\u00a0to merely increase the spatial size of the representation. An approach that seems\u00a0to perform acceptably is to use an \u201cun-pooling\u201d as introduced by Dosovitskiy et al.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6728",
    "text": "(2015). This layer corresponds to the inverse of the max-pooling operation under certain simplifying conditions. First, the stride of the max-pooling operation is\u00a0constrained to be equal to the width of the pooling region. Second, the maximum\u00a0input within each pooling region is assumed to be the input in the upper-left\u00a0corner. Finally, all non-maximal inputs within each pooling region are assumed to\u00a0be zero. These are very strong and unrealistic assumptions, but they do allow the\u00a0max-pooling operator to be inverted. The inverse un-pooling operation allocates\u00a0a tensor of zeros, then copies each value from spatial coordinate i of the input\u00a0to spatial coordinate i x k of the output. The integer value k defines the size\u00a0of the pooling region. Even though the assumptions motivating the definition of\u00a0the un-pooling operator are unrealistic, the subsequent layers are able to learn to\u00a0compensate for its unusual output, so the samples generated by the model as a\u00a0whole are visually pleasing.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6729",
    "text": "Auto-regressive networks are directed probabilistic models with no latent random variables. The conditional probability distributions in these models are represented\u00a0by neural networks (sometimes extremely simple neural networks such as logistic\u00a0regression). The graph structure of these models is the complete graph. They\u00a0decompose a joint probability over the observed variables using the chain rule of\u00a0probability to obtain a product of conditionals of the form P(x d | ad-1,... , x 1).\u00a0Such models have been called fully-visible Bayes networks (FVBNs) and used\u00a0successfully in many forms, first with logistic regression for each conditional\u00a0distribution (Frey, 1998) and then with neural networks with hidden units (Bengio\u00a0and Bengio, 2000b; Larochelle and Murray, 2011). In some forms of autoregressive networks, such as NADE (Larochelle and Murray, 2011), described in\u00a0Sec. 20.10.10 below, we can introduce a form of parameter sharing that brings both\u00a0a statistical advantage (fewer unique parameters) and a computational advantage\u00a0(less computation). This is one more instance of the recurring deep learning motif\u00a0of reuse of features.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6730",
    "text": "Figure 20.8: A fully visible belief network predicts the i-th variable from the i \u2014 1 previous ones. (Top) The directed graphical model for an FVBN. (Bottom) Corresponding\u00a0computational graph, in the case of the logistic FVBN, where each prediction is made by\u00a0a linear predictor.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6731",
    "text": "The simplest form of auto-regressive network has no hidden units and no sharing of parameters or features. Each P (xi | xi-1,..., x1) is parametrized as a linear\u00a0model (linear regression for real-valued data, logistic regression for binary data,\u00a0softmax regression for discrete data). This model was introduced by Frey (1998)\u00a0and has O(d2) parameters when there are d variables to model. It is illustrated in\u00a0Fig. 20.8.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6732",
    "text": "If the variables are continuous, a linear auto-regressive model is merely another way to formulate a multivariate Gaussian distribution, capturing linear pairwise\u00a0interactions between the observed variables.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6733",
    "text": "Linear auto-regressive networks are essentially the generalization of linear classification methods to generative modeling. They therefore have the same\u00a0advantages and disadvantages as linear classifiers. Like linear classifiers, they may\u00a0be trained with convex loss functions, and sometimes admit closed form solutions\u00a0(as in the Gaussian case). Like linear classifiers, the model itself does not offer\u00a0a way of increasing its capacity, so capacity must be raised using techniques like\u00a0basis expansions of the input or the kernel trick.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6734",
    "text": "Figure 20.9: A neural auto-regressive network predicts thei-th variable xi from the i \u2014 1 previous ones, but is parametrized so that features (groups of hidden units denotedhi)\u00a0that are functions of x1,..., xi can be reused in predicting all of the subsequent variables",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6735",
    "text": "x i+1, xi+2 , \u2022 \u2022 \u2022 , xd\u2022",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6736",
    "text": "Neural auto-regressive networks (Bengio and Bengio, 2000a,b) have the same left-to-right graphical model as logistic auto-regressive networks (Fig. 20.8) but\u00a0employ a different parametrization of the conditional distributions within that\u00a0graphical model structure. The new parametrization is more powerful in the sense\u00a0that its capacity can be increased as much as needed, allowing approximation of\u00a0any joint distribution. The new parametrization can also improve generalization\u00a0by introducing a parameter sharing and feature sharing principle common to deep\u00a0learning in general. The models were motivated by the objective of avoiding the\u00a0curse of dimensionality arising out of traditional tabular graphical models, sharing\u00a0the same structure as Fig. 20.8. In tabular discrete probabilistic models, each\u00a0conditional distribution is represented by a table of probabilities, with one entry\u00a0and one parameter for each possible configuration of the variables involved. By\u00a0using a neural network instead, two advantages are obtained:",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6737",
    "text": "1. The parametrization of each P(x^ | xi-1,..., xi) by a neural network with (i \u2014 1) x k inputs and k outputs (if the variables are discrete and take k\u00a0values, encoded one-hot) allows one to estimate the conditional probability\u00a0without requiring an exponential number of parameters (and examples), yet\u00a0still is able to capture high-order dependencies between the random variables.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6738",
    "text": "2. \u00a0\u00a0\u00a0Instead of having a different neural network for the prediction of each x^,\u00a0a left-to-right connectivity illustrated in Fig. 20.9 allows one to merge all\u00a0the neural networks into one. Equivalently, it means that the hidden layer\u00a0features computed for predicting xi can be reused for predicting xi+k (k > 0).\u00a0The hidden units are thus organized in groups that have the particularity\u00a0that all the units in the i-th group only depend on the input values x 1,..., xi.\u00a0The parameters used to compute these hidden units are jointly optimized\u00a0to improve the prediction of all the variables in the sequence. This is\u00a0an instance of the reuse principle that recurs throughout deep learning in\u00a0scenarios ranging from recurrent and convolutional network architectures to\u00a0multi-task and transfer learning.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6739",
    "text": "Each P( xi | xi-1,..., x1) can represent a conditional distribution by having outputs of the neural network predict parameters of the conditional distribution\u00a0of xi, as discussed in Sec. 6.2.1.1. Although the original neural auto-regressive\u00a0networks were initially evaluated in the context of purely discrete multivariate\u00a0data (with a sigmoid output for a Bernoulli variable or softmax output for a\u00a0multinoulli variable) it is natural to extend such models to continuous variables or\u00a0joint distributions involving both discrete and continuous variables.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6740",
    "text": "The neural autoregressive density estimator (NADE) is a very successful recent form of neural auto-regressive network (Larochelle and Murray, 2011). The connectivity\u00a0is the same as for the original neural auto-regressive network of Bengio and\u00a0Bengio (2000b) but NADE introduces an additional parameter sharing scheme, as\u00a0illustrated in Fig. 20.10. The parameters of the hidden units of different groups j\u00a0are shared.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6741",
    "text": "The weights W' k \u2022 from the i-th input xi to the k-th element of the j-th group",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6742",
    "text": "3 ,k,i",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6743",
    "text": "of hidden unit hk3) (j > i) are shared among the groups:",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6744",
    "text": "Wj , k ,i = Wk ,i. \u00a0\u00a0\u00a0(20.83)",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6745",
    "text": "The remaining weights, where j < i, are zero.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6746",
    "text": "Larochelle and Murray (2011) chose this sharing scheme so that forward propagation in a NADE model loosely resembles the computations performed in\u00a0mean field inference to fill in missing inputs in an RBM. This mean field inference\u00a0corresponds to running a recurrent network with shared weights and the first step\u00a0of that inference is the same as in NADE. The only difference is that with NADE,\u00a0the output weights connecting the hidden units to the output are parametrized",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6747",
    "text": "Figure 20.10: An illustration of the neural autoregressive density estimator (NADE). The hidden units are organized in groups h(j) so that only the inputs x1,... , xi participate\u00a0in computing h(i) and predicting P (xj | xj-1,..., x1), for j > i. NADE is differentiated\u00a0from earlier neural auto-regressive networks by the use of a particular weight sharing\u00a0pattern: Wjk i = Wk,i is shared (indicated in the figure by the use of the same line pattern\u00a0for every instance of a replicated weight) for all the weights going out fromx i to the k-th\u00a0unit of any group j > i. Recall that the vector (W i, W2 i5. .., Wn i) is denoted W: i.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6748",
    "text": "independently from the weights connecting the input units to the hidden units. In the RBM, the hidden-to-output weights are the transpose of the input-to-hidden\u00a0weights. The NADE architecture can be extended to mimic not just one time step\u00a0of the mean field recurrent inference but to mimic k steps. This approach is called\u00a0NADE-k (Raiko et al., 2014).",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6749",
    "text": "As mentioned previously, auto-regressive networks may be extend to process continuous-valued data. A particularly powerful and generic way of parametrizing a\u00a0continuous density is as a Gaussian mixture (introduced in Sec. 3.9.6) with mixture\u00a0weights a (the coefficient or prior probability for component i), per-component\u00a0conditional mean ^ and per-component conditional variance a?. A model called\u00a0RNADE (Uria et al., 2013) uses this parametrization to extend NADE to real\u00a0values. As with other mixture density networks, the parameters of this distribution\u00a0are outputs of the network, with the mixture weight probabilities produced by a\u00a0softmax unit, and the variances parametrized so that they are positive. Stochastic\u00a0gradient descent can be numerically ill-behaved due to the interactions between the\u00a0conditional means ^ and the conditional variances a?. To reduce this difficulty,\u00a0Uria et al. (2013) use a pseudo-gradient that replaces the gradient on the mean, in\u00a0the back-propagation phase.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6750",
    "text": "Another very interesting extension of the neural auto-regressive architectures gets rid of the need to choose an arbitrary order for the observed variables (Murray\u00a0and Larochelle, 2014). In auto-regressive networks, the idea is to train the network\u00a0to be able to cope with any order by randomly sampling orders and providing the\u00a0information to hidden units specifying which of the inputs are observed (on the\u00a0right side of the conditioning bar) and which are to be predicted and are thus\u00a0considered missing (on the left side of the conditioning bar). This is nice because\u00a0it allows one to use a trained auto-regressive network to perform any inference\u00a0problem (i.e. predict or sample from the probability distribution over any subset\u00a0of variables given any subset) extremely efficiently. Finally, since many orders of\u00a0variables are possible (n! for n variables) and each order o of variables yields a\u00a0different p(x | o), we can form an ensemble of models for many values of o:",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6751",
    "text": "1 k",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6752",
    "text": "P3nsemble(x) = \u05be \u00a0\u00a0\u00a0p(x | 0111).\u00a0\u00a0\u00a0\u00a0(20.84)",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6753",
    "text": "i= 1",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6754",
    "text": "This ensemble model usually generalizes better and assigns higher probability to the test set than does an individual model defined by a single ordering.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6755",
    "text": "In the same paper, the authors propose deep versions of the architecture, but unfortunately that immediately makes computation as expensive as in the original\u00a0neural auto-regressive neural network (Bengio and Bengio, 2000b). The first layer\u00a0and the output layer can still be computed in O(nh) multiply-add operations,\u00a0as in the regular NADE, where h is the number of hidden units (the size of the\u00a0groups hi, in Fig. 20.10 and Fig. 20.9), whereas it is O(n2h) in Bengio and Bengio\u00a0(2000b). However, for the other hidden layers, the computation is O(n2h2) if every\u00a0\u201cprevious\u201d group at layer l participates in predicting the \u201cnext\u201d group at layer l + 1,\u00a0assuming n groups of h hidden units at each layer. Making the i-th group at layer\u00a0l + 1 only depend on the i-th group, as in Murray and Larochelle (2014) at layer l\u00a0reduces it to O(nh2), which is still h times worse than the regular NADE.",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6756",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6757",
    "text": " \u00a0\u00a0\u00a0Starting from the previous state x, inject corruption noise, sampling X from\u00a0C(X | x).",
    "chapter": "",
    "chapter_id": "main-39.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6758",
    "text": "In Chapter 14, we saw that many kinds of autoencoders learn the data distribution. There are close connections between score matching, denoising autoencoders, and\u00a0contractive autoencoders. These connections demonstrate that some kinds of\u00a0autoencoders learn the data distribution in some way. We have not yet seen how\u00a0to draw samples from such models.",
    "chapter": "",
    "chapter_id": "main-40.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6759",
    "text": "Some kinds of autoencoders, such as the variational autoencoder, explicitly represent a probability distribution and admit straightforward ancestral sampling.\u00a0Most other kinds of autoencoders require MCMC sampling.",
    "chapter": "",
    "chapter_id": "main-40.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6760",
    "text": "Contractive autoencoders are designed to recover an estimate of the tangent plane of the data manifold. This means that repeated encoding and decoding with\u00a0injected noise will induce a random walk along the surface of the manifold (Rifai\u00a0et al., 2012; Mesnil et al., 2012). This manifold diffusion technique is a kind of\u00a0Markov chain.",
    "chapter": "",
    "chapter_id": "main-40.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6761",
    "text": "There is also a more general Markov chain that can sample from any denoising autoencoder.",
    "chapter": "",
    "chapter_id": "main-40.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6762",
    "text": "The above discussion left open the question of what noise to inject and where, in order to obtain a Markov chain that would generate from the distribution estimated\u00a0by the autoencoder. Bengio et al. (2013c) showed how to construct such a Markov\u00a0chain for generalized denoising autoencoders. Generalized denoising autoencoders\u00a0are specified by a denoising distribution for sampling an estimate of the clean input\u00a0given the corrupted input.",
    "chapter": "",
    "chapter_id": "main-40.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6763",
    "text": "Each step of the Markov chain that generates from the estimated distribution consists of the following sub-steps, illustrated in Fig. 20.11: 1 2 3 4",
    "chapter": "",
    "chapter_id": "main-40.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6764",
    "text": "Figure 20.11: Each step of the Markov chain associated with a trained denoising autoencoder, that generates the samples from the probabilistic model implicitly trained by the denoising log-likelihood criterion. Each step consists in (a) injecting noise via corruption\u00a0process C in state x, yielding x, (b) encoding it with function f, yielding h = f (x),\u00a0(c) decoding the result with function g, yielding parameters u for the reconstruction\u00a0distribution, and (d) given u, sampling a new state from the reconstruction distribution\u00a0p(x | u = g(f (X))). In the typical squared reconstruction error case, g (h) = X, which\u00a0estimates E[x | X], corruption consists in adding Gaussian noise and sampling from\u00a0p(x | u) consists in adding Gaussian noise, a second time, to the reconstruction x. The\u00a0latter noise level should correspond to the mean squared error of reconstructions, whereas\u00a0the injected noise is a hyperparameter that controls the mixing speed as well as the\u00a0extent to which the estimator smooths the empirical distribution (Vincent, 2011). In the\u00a0example illustrated here, only the C and p conditionals are stochastic steps (f and g are\u00a0deterministic computations), although noise can also be injected inside the autoencoder,\u00a0as in generative stochastic networks (Bengio et al., 2014).",
    "chapter": "",
    "chapter_id": "main-40.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6765",
    "text": "consistent stationary\u00a0(albeit an",
    "chapter": "",
    "chapter_id": "main-40.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6766",
    "text": "the free units xo given xf and the sampled latent variables (if any). For example, MP-DBMs can be interpreted as a form of denoising autoencoder, and are able\u00a0to sample missing inputs. GSNs later generalized some of the ideas present in\u00a0MP-DBMs to perform the same operation (Bengio et al., 2014). Alain et al. (2015)\u00a0identified a missing condition from Proposition 1 of Bengio et al. (2014), which is\u00a0that the transition operator (defined by the stochastic mapping going from one\u00a0state of the chain to the next) should satisfy a property called detailed balance,\u00a0which specifies that a Markov Chain at equilibrium will remain in equilibrium\u00a0whether the transition operator is run in forward or reverse.",
    "chapter": "",
    "chapter_id": "main-40.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6767",
    "text": "An experiment in clamping half of the pixels (the right part of the image) and running the Markov chain on the other half is shown in Fig. 20.12.",
    "chapter": "",
    "chapter_id": "main-40.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6768",
    "text": "1",
    "chapter": "",
    "chapter_id": "main-40.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6769",
    "text": " \u00a0\u00a0\u00a0Starting from the previous state x, inject corruption noise, sampling X from\u00a0C(X | x).",
    "chapter": "",
    "chapter_id": "main-40.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6770",
    "text": "2",
    "chapter": "",
    "chapter_id": "main-40.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6771",
    "text": " \u00a0\u00a0\u00a0Encode X into h = f (X).",
    "chapter": "",
    "chapter_id": "main-40.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6772",
    "text": "3",
    "chapter": "",
    "chapter_id": "main-40.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6773",
    "text": " Decode h to obtain the parameters w = g(h) of p(x | w = g(h)) = p(x | X).",
    "chapter": "",
    "chapter_id": "main-40.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6774",
    "text": "4",
    "chapter": "",
    "chapter_id": "main-40.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6775",
    "text": " Sample the next state x from p(x | w = g(h)) = p(x | X).",
    "chapter": "",
    "chapter_id": "main-40.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6776",
    "text": "Bengio et al. ( 01\u05f3 ) showed that if the autoencoder p( x | x) forms a estimator of the corresponding true conditional distribution, then the\u00a0distribution of the above Markov chain forms a consistent estimator\u00a0implicit one) of the data generating distribution of x.",
    "chapter": "",
    "chapter_id": "main-40.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6777",
    "text": "20.11.2 \u00a0\u00a0\u00a0Clamping and Conditional Sampling",
    "chapter": "",
    "chapter_id": "main-40.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6778",
    "text": "Similarly to Boltzmann machines, denoising autoencoders and their generalizations (such as GSNs, described below) can be used to sample from a conditional distribution p(xf | xo), simply by clamping the observed units xf and only resampling",
    "chapter": "",
    "chapter_id": "main-40.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6779",
    "text": "r trrtrrrrrrtr lamuum",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6780",
    "text": "\u05d1\u05d1\u05d1\u05d1\u05d1\u05d1\u05d1\u05d1\u05d1\u05d1\u05d1(p",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6781",
    "text": "0 (f (j (\u00bb (\u00bb u to \u05dc \u05dc \u05dc Ir i",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6782",
    "text": "7 77777777777 7 W",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6783",
    "text": "\u05d7\u05d7\u05d7\u05d7\u05d7\u05d4\u05df",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6784",
    "text": "I mnn 3 3 3 3 3",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6785",
    "text": "Figure 20.12: Illustration of clamping the right half of the image and running the Markov Chain by resampling only the left half at each step. These samples come from a GSN\u00a0trained to reconstruct MNIST digits at each time step using the walkback procedure.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6786",
    "text": "The walk-back training procedure was proposed by Bengio et al. (2013c) as a way to accelerate the convergence of generative training of denoising autoencoders.\u00a0Instead of performing a one-step encode-decode reconstruction, this procedure\u00a0consists in alternative multiple stochastic encode-decode steps (as in the generative",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6787",
    "text": "Markov chain) initialized at a training example (just like with the contrastive divergence algorithm, described in Sec. 18.2) and penalizing the last probabilistic\u00a0reconstructions (or all of the reconstructions along the way).",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6788",
    "text": "Training with k steps is equivalent (in the sense of achieving the same stationary distribution) as training with one step, but practically has the advantage that\u00a0spurious modes farther from the data can be removed more efficiently.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6789",
    "text": "Generative stochastic networks or GSNs (Bengio et al., 2014) are generalizations of denoising autoencoders that include latent variables h in the generative Markov\u00a0chain, in addition to the visible variables (usually denoted x).",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6790",
    "text": "A GSN is parametrized by two conditional probability distributions which specify one step of the Markov chain:",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6791",
    "text": "1. \u00a0\u00a0\u00a0p (x(k) | h(k)) tells how to generate the next visible variable given the current\u00a0latent state. Such a \u201creconstruction distribution\u201d is also found in denoising\u00a0autoencoders, RBMs, DBNs and DBMs.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6792",
    "text": "2. \u00a0\u00a0\u00a0p(h(k) | h(k-1), x(k-1)) tells how to update the latent state variable, given\u00a0the previous latent state and visible variable.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6793",
    "text": "Denoising autoencoders and GSNs differ from classical probabilistic models (directed or undirected) in that they parametrize the generative process itself rather\u00a0than the mathematical specification of the joint distribution of visible and latent\u00a0variables. Instead, the latter is defined implicitly, if it exists, as the stationary\u00a0distribution of the generative Markov chain. The conditions for existence of the\u00a0stationary distribution are mild and are the same conditions required by standard\u00a0MCMC methods (see Sec. 17.3). These conditions are necessary to guarantee\u00a0that the chain mixes, but they can be violated by some choices of the transition\u00a0distributions (for example, if they were deterministic).",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6794",
    "text": "One could imagine different training criteria for GSNs. The one proposed and evaluated by Bengio et al. (2014) is simply reconstruction log-probability on the\u00a0visible units, just like for denoising autoencoders. This is achieved by clamping\u00a0x(0) = x to the observed example and maximizing the probability of generating x\u00a0at some subsequent time steps, i.e., maximizing logp(x(k) = x | h(k)), where h(k)\u00a0is sampled from the chain, given x(0) = x. In order to estimate the gradient of\u00a0logp(x(k) = x | h(k)) with respect to the other pieces of the model, Bengio et al.\u00a0(2014) use the reparametrization trick, introduced in Sec. 20.9.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6795",
    "text": "The walk-back training protocol (described in Sec. 20.11.3) was used (Bengio et al., 2014) to improve training convergence of GSNs.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6796",
    "text": "The original formulation of GSNs (Bengio et al., 2014) was meant for unsupervised learning and implicitly modeling p(x) for observed data x, but it is possible to\u00a0modify the framework to optimize p(y | x).",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6797",
    "text": "For example, Zhou and Troyanskaya (2014) generalize GSNs in this way, by only back-propagating the reconstruction log-probability over the output variables, keeping the input variables fixed. They applied this successfully to model sequences\u00a0(protein secondary structure) and introduced a (one-dimensional) convolutional\u00a0structure in the transition operator of the Markov chain. It is important to remember that, for each step of the Markov chain, one generates a new sequence for\u00a0each layer, and that sequence is the input for computing other layer values (say\u00a0the one below and the one above) at the next time step.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6798",
    "text": "Hence the Markov chain is really over the output variable (and associated higher-level hidden layers), and the input sequence only serves to condition that\u00a0chain, with back-propagation allowing to learn how the input sequence can condition\u00a0the output distribution implicitly represented by the Markov chain. It is therefore\u00a0a case of using the GSN in the context of structured outputs, where p(y | x)\u00a0does not have a simple parametric form but instead the components of y are\u00a0statistically dependent of each other, given x, in complicated ways.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6799",
    "text": "Zohrer and Pernkopf (2014) introduced a hybrid model that combines a supervised objective (as in the above work) and an unsupervised objective (as in the original GSN work), by simply adding (with a different weight) the supervised and\u00a0unsupervised costs i.e., the reconstruction log-probabilities of y and x respectively.\u00a0Such a hybrid criterion had previously been introduced for RBMs by Larochelle\u00a0and Bengio (2008). They show improved classification performance using this\u00a0scheme.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6800",
    "text": "The methods we have described so far use either MCMC sampling, ancestral sampling, or some mixture of the two to generate samples. While these are the\u00a0most popular approaches to generative modeling, they are by no means the only\u00a0approaches.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6801",
    "text": "Sohl-Dickstein et al. (2015) developed a diffusion inversion training scheme for learning a generative model, based on non-equilibrium thermodynamics. The\u00a0approach is based on the idea that the probability distributions we wish to sample\u00a0from have structure. This structure can gradually be destroyed by a diffusion\u00a0process that incrementally changes the probability distribution to have more\u00a0entropy. To form a generative model, we can run the process in reverse, by training\u00a0a model that gradually restores the structure to an unstructured distribution. By\u00a0iteratively applying a process that brings a distribution closer to the target one, we\u00a0can gradually approach that target distribution. This approach resembles MCMC\u00a0methods in the sense that it involves many iterations to produce a sample. However,\u00a0the model is defined to be the probability distribution produced by the final step\u00a0of the chain. In this sense, there is no approximation induced by the iterative\u00a0procedure. The approach introduced by Sohl-Dickstein et al. (2015) is also very\u00a0close to the generative interpretation of the denoising autoencoder (Sec. 20.11.1).\u00a0Like with the denoising autoencoder, the training objective trains a transition\u00a0operator which attempts to probabilistically undo the effect of adding some noise,\u00a0trying to undo one step of the diffusion process. If we compare with the walkback\u00a0training procedure (Sec. 20.11.3) for denoising autoencoders and GSNs, the main\u00a0difference is that instead of reconstructing only towards the observed training point\u00a0x, the objective function only tries to reconstruct towards the previous point in\u00a0the diffusion trajectory that started at x (which should be easier). This addresses\u00a0the following dilemma present with the ordinary reconstruction log-likelihood\u00a0objective of denoising autoencoders: with small levels of noise the learner only sees\u00a0configurations near the data points, while with large levels of noise it is asked to do\u00a0an almost impossible job (because the denoising distribution is going to be highly\u00a0complex and multi-modal). With the diffusion inversion objective, the learner can\u00a0learn more precisely the shape of the density around the data points as well as\u00a0remove spurious modes that could show up far from the data points.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6802",
    "text": "Another approach to sample generation is the approximate Bayesian computation (ABC) framework (Rubin et al., 1984). In this approach, samples are rejected or modified in order to make the moments of selected functions of the samples\u00a0match those of the desired distribution. While this idea uses the moments of the\u00a0samples like in moment matching, it is different from moment matching because it\u00a0modifies the samples themselves, rather than training the model to automatically\u00a0emit samples with the correct moments. Bachman and Precup (2015) showed how\u00a0to use ideas from ABC in the context of deep learning, by using ABC to shape the\u00a0MCMC trajectories of GSNs.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6803",
    "text": "We expect that many other possible approaches to generative modeling await discovery.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6804",
    "text": "Researchers studying generative models often need to compare one generative model to another, usually in order to demonstrate that a newly invented generative\u00a0model is better at capturing some distribution than the pre-existing models.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6805",
    "text": "This can be a difficult and subtle task. In many cases, we can not actually evaluate the log probability of the data under the model, but only an approximation.\u00a0In these cases, it is important to think and communicate clearly about exactly what\u00a0is being measured. For example, suppose we can evaluate a stochastic estimate of\u00a0the log-likelihood for model A, and a deterministic lower bound on the log-likelihood\u00a0for model B. If model A gets a higher score than model B, which is better? If we\u00a0care about determining which model has a better internal representation of the\u00a0distribution, we actually cannot tell, unless we have some way of determining how\u00a0loose the bound for model B is. However, if we care about how well we can use\u00a0the model in practice, for example to perform anomaly detection, then it is fair to\u00a0say that a model is preferable based on a criterion specific to the practical task of\u00a0interest, e.g., based on ranking test examples and ranking criteria such as precision\u00a0and recall.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6806",
    "text": "Another subtlety of evaluating generative models is that the evaluation metrics are often hard research problems in and of themselves. It can be very difficult\u00a0to establish that models are being compared fairly. For example, suppose we use\u00a0AIS to estimate log Z in order to compute log p(x) \u2014 log Z for a new model we\u00a0have just invented. A computationally economical implementation of AIS may fail\u00a0to find several modes of the model distribution and underestimate Z, which will\u00a0result in us overestimating logp(x). It can thus be difficult to tell whether a high\u00a0likelihood estimate is due to a good model or a bad AIS implementation.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6807",
    "text": "Other fields of machine learning usually allow for some variation in the preprocessing of the data. For example, when comparing the accuracy of object recognition algorithms, it is usually acceptable to preprocess the input images\u00a0slightly differently for each algorithm based on what kind of input requirements\u00a0it has. Generative modeling is different because changes in preprocessing, even\u00a0very small and subtle ones, are completely unacceptable. Any change to the input\u00a0data changes the distribution to be captured and fundamentally alters the task.\u00a0For example, multiplying the input by 0.1 will artificially increase likelihood by a\u00a0factor of 10.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6808",
    "text": "Issues with preprocessing commonly arise when benchmarking generative models on the MNIST dataset, one of the more popular generative modeling benchmarks.\u00a0MNIST consists of grayscale images. Some models treat MNIST images as points\u00a0in a real vector space, while others treat them as binary. Yet others treat the\u00a0grayscale values as probabilities for a binary samples. It is essential to compare\u00a0real-valued models only to other real-valued models and binary-valued models only\u00a0to other binary-valued models. Otherwise the likelihoods measured are not on the\u00a0same space. For binary-valued models, the log-likelihood can be at most zero, while\u00a0for real-valued models it can be arbitrarily high, since it is the measurement of a\u00a0density. Among binary models, it is important to compare models using exactly\u00a0the same kind of binarization. For example, we might binarize a gray pixel to 0 or 1\u00a0by thresholding at 0.5, or by drawing a random sample whose probability of being\u00a01 is given by the gray pixel intensity. If we use the random binarization, we might\u00a0binarize the whole dataset once, or we might draw a different random example for\u00a0each step of training and then draw multiple samples for evaluation. Each of these\u00a0three schemes yields wildly different likelihood numbers, and when comparing\u00a0different models it is important that both models use the same binarization scheme\u00a0for training and for evaluation. In fact, researchers who apply a single random\u00a0binarization step share a file containing the results of the random binarization, so\u00a0that there is no difference in results based on different outcomes of the binarization\u00a0step.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6809",
    "text": "Because being able to generate realistic samples from the data distribution is one of the goals of a generative model, practitioners often evaluate generative\u00a0models by visually inspecting the samples. In the best case, this is done not by the\u00a0researchers themselves, but by experimental subjects who do not know the source\u00a0of the samples (Denton et al., 2015). Unfortunately, it is possible for a very poor\u00a0probabilistic model to produce very good samples. A common practice to verify\u00a0if the model only copies some of the training examples is illustrated in Fig. 16.1.\u00a0The idea is to show for some of the generated samples their nearest neighbor in\u00a0the training set, according to Euclidean distance in the space of x. This test is\u00a0intended to detect the case where the model overfits the training set and just\u00a0reproduces training instances. It is even possible to simultaneously underfit and\u00a0overfit yet still produce samples that individually look good. Imagine a generative\u00a0model trained on images of dogs and cats that simply learns to reproduce the\u00a0training images of dogs. Such a model has clearly overfit, because it does not\u00a0produces images that were not in the training set, but it has also underfit, because\u00a0it assigns no probability to the training images of cats. Yet a human observer\u00a0would judge each individual image of a dog to be high quality. In this simple\u00a0example, it would be easy for a human observer who can inspect many samples to\u00a0determine that the cats are absent. In more realistic settings, a generative model\u00a0trained on data with tens of thousands of modes may ignore a small number of\u00a0modes, and a human observer would not easily be able to inspect or remember\u00a0enough images to detect the missing variation.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6810",
    "text": "Since the visual quality of samples is not a reliable guide, we often also evaluate the log-likelihood that the model assigns to the test data, when this is\u00a0computationally feasible. Unfortunately, in some cases the likelihood seems not\u00a0to measure any attribute of the model that we really care about. For example,\u00a0real-valued models of MNIST can obtain arbitrarily high likelihood by assigning\u00a0arbitrarily low variance to background pixels that never change. Models and\u00a0algorithms that detect these constant features can reap unlimited rewards, even\u00a0though this is not a very useful thing to do. The potential to achieve a cost\u00a0approaching negative infinity is present for any kind of maximum likelihood\u00a0problem with real values, but it is especially problematic for generative models of\u00a0MNIST because so many of the output values are trivial to predict. This strongly\u00a0suggests a need for developing other ways of evaluating generative models.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6811",
    "text": "Theis et al. (2015) review many of the issues involved in evaluating generative models, including many of the ideas described above. They highlight the fact\u00a0that there are many different uses of generative models and that the choice of\u00a0metric must match the intended use of the model. For example, some generative\u00a0models are better at assigning high probability to most realistic points while other\u00a0generative models are better at rarely assigning high probability to unrealistic\u00a0points. These differences can result from whether a generative model is designed\u00a0to minimize Dkl(pdata||pmode1) or Dkl(Pmodei llpdata), as illustrated in Fig. 3.6.\u00a0Unfortunately, even when we restrict the use of each metric to the task it is most\u00a0suited for, all of the metrics currently in use continue to have serious weaknesses.\u00a0One of the most important research topics in generative modeling is therefore not\u00a0just how to improve generative models, but in fact, designing new techniques to\u00a0measure our progress.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6812",
    "text": "Training generative models with hidden units is a powerful way to make models understand the world represented in the given training data. By learning a model\u00a0pmode1 (x) and a representation pmode1 (h | x ),a generative model can provide\u00a0answers to many inference problems about the relationships between input variables\u00a0in x and can provide many different ways of representing x by taking expectations\u00a0of h at different layers of the hierarchy. Generative models hold the promise to\u00a0provide AI systems with a framework for all of the many different intuitive concepts\u00a0they need to understand, and the ability to reason about these concepts in the\u00a0face of uncertainty. We hope that our readers will find new ways to make these",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6813",
    "text": "approaches more powerful and continue the journey to understanding the principles that underlie learning and intelligence.",
    "chapter": "",
    "chapter_id": "main-41.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6814",
    "text": "Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M., Ghemawat, S., Goodfehow, I., Harp, A., Irving, G., Isard, M.,\u00a0Jia, Y., Jozefowicz, R., Kaiser, L., Kudlur, M., Levenberg, J., Mane, D., Monga, R.,\u00a0Moore, S., Murray, D., Olah, C., Schuster, M., Shlens, J., Steiner, B., Sutskever, I.,\u00a0Talwar, K., Tucker, P., Vanhoucke, V., Vasudevan, V., Viegas, F., Vinyals, O., Warden,\u00a0P., Wattenberg, M., Wicke, M., Yu, Y., and Zheng, X. (2015). TensorFlow: Large-scale\u00a0machine learning on heterogeneous systems. Software available from tensorflow.org. 25,\u00a0212, 448",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6815",
    "text": "Ackley, D. H., Hinton, G. E., and Sejnowski, T. J. (1985). A learning algorithm for Boltzmann machines. Cognitive Science, 9, 147-169. 572, 656",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6816",
    "text": "Alain, G. and Bengio, Y. (2013). What regularized auto-encoders learn from the data generating distribution. In ICLR\u20192013, arXiv:1211.4246. 509, 515, 523",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6817",
    "text": "Alain, G., Bengio, Y., Yao, L., Eric Thibodeau-Laufer, Yosinski, J., and Vincent, P. (2015). GSNs: Generative stochastic networks. arXiv:1503.05571. 512, 715",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6818",
    "text": "Anderson, E. (1935). The Irises of the Gaspe Peninsula. Bulletin of the American Iris Society, 59, 2-5. 21",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6819",
    "text": "Ba, J., Mnih, V., and Kavukcuoglu, K. (2014). Multiple object recognition with visual attention. arXiv:1412.7755. 693",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6820",
    "text": "Bachman, P. and Precup, D. (2015). Variational generative stochastic networks with collaborative shaping. In Proceedings of the 32nd International Conference on Machine\u00a0Learning, ICML 2015, Lille, France, 6-11 July 2015, pages 1964-1972. 718",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6821",
    "text": "Bacon, P.-L., Bengio, E., Pineau, J., and Precup, D. (2015). Conditional computation in neural networks using a decision-theoretic approach. In 2nd Multidisciplinary Conference\u00a0on Reinforcement Learning and Decision Making (RLDM 2015). 452",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6822",
    "text": "Bagnell, J. A. and Bradley, D. M. (2009). Differentiable sparse coding. In D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, Advances in Neural Information\u00a0Processing Systems 21 (NIPS\u201908), pages 113-120. 500",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6823",
    "text": "Bahdanau, D., Cho, K., and Bengio, Y. (2015). Neural machine translation by jointly learning to align and translate. In ICLR\u20192015, arXiv:1f09.0473. 25, 101, 398, 420, 421,\u00a0467, 477",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6824",
    "text": "Bahl, L. R., Brown, P., de Souza, P. V., and Mercer, R. L. (1987). Speech recognition with continuous-parameter hidden Markov models. Computer, Speech and Language,2,\u00a0219-234. 460",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6825",
    "text": "Baldi, P. and Hornik, K. (1989). Neural networks and principal component analysis: Learning from examples without local minima. Neural Networks, 2, 53-58. 286",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6826",
    "text": "Baldi, P., Brunak, S., Frasconi, P., Soda, G., and Pollastri, G. (1999). Exploiting the past and the future in protein secondary structure prediction. Bioinformatics, 15(11),\u00a0937-946. 395",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6827",
    "text": "Baldi, P., Sadowski, P., and Whiteson, D. (2014). Searching for exotic particles in high-energy physics with deep learning. Nature communications, 5. 26",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6828",
    "text": "Ballard, D. H., Hinton, G. E., and Sejnowski, T. J. (1983). Parallel vision computation.",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6829",
    "text": "Nature. 454",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6830",
    "text": "Barlow, H. B. (1989). Unsupervised learning. Neural Computation, 1, 295-311. 146",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6831",
    "text": "Barron, A. E. (1993). Universal approximation bounds for superpositions of a sigmoidal function. IEEE Trans. on Information Theory, 39, 930-945. 198",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6832",
    "text": "Bartholomew, D. J. (1987). Latent variable models and factor analysis. Oxford University Press. 492",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6833",
    "text": "Basilevsky, A. (1994). Statistical Factor Analysis and Related Methods: Theory and Applications. Wiley. 492",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6834",
    "text": "Bastien, F., Lamblin, P., Pascanu, R., Bergstra, J., Goodfellow, I. J., Bergeron, A., Bouchard, N., and Bengio, Y. (2012). Theano: new features and speed improvements.\u00a0Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop. 25, 82, 212,\u00a0222, 448",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6835",
    "text": "Basu, S. and Christensen, J. (2013). Teaching classification boundaries to humans. In AAAI\u20192013. 328",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6836",
    "text": "Baxter, J. (1995). Learning internal representations. In Proceedings of the 8th International Conference on Computational Learning Theory (COLT\u201995), pages 311-320, Santa Cruz,\u00a0California. ACM Press. 246",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6837",
    "text": "Bayer, J. and Osendorfer, C. (2014). Learning stochastic recurrent networks. ArXiv e-prints. 265",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6838",
    "text": "Becker, S. and Hinton, G. (1992). A self-organizing neural network that discovers surfaces in random-dot stereograms. Nature, 355, 161-163. 543",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6839",
    "text": "Behnke, S. (2001). Learning iterative image reconstruction in the neural abstraction pyramid. Int. J. Computational Intelligence and Applications, 1(4), 427-438. 517",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6840",
    "text": "Beiu, V., Quintana, J. M., and Avedillo, M. J. (2003). VLSI implementations of threshold logic-a comprehensive survey. Neural Networks, IEEE Transactions on, 14(5), 12171243. 453",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6841",
    "text": "Belkin, M. and Niyogi, P. (2002). Laplacian eigenmaps and spectral techniques for embedding and clustering. In T. Dietterich, S. Becker, and Z. Ghahramani, editors,\u00a0Advances in Neural Information Processing Systems 14 (NIPS\u201901), Cambridge, MA.\u00a0MIT Press. 244",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6842",
    "text": "Belkin, M. and Niyogi, P. (2003). Laplacian eigenmaps for dimensionality reduction and data representation. Neural Computation, 15(6), 1373-1396. 163, 520",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6843",
    "text": "Bengio, E., Bacon, P.-L., Pineau, J., and Precup, D. (2015a). Conditional computation in neural networks for faster models. arXiv:1511.06297. 452",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6844",
    "text": "Bengio, S. and Bengio, Y. (2000a). Taking on the curse of dimensionality in joint distributions using neural networks. IEEE Transactions on Neural Networks, special\u00a0issue on Data Mining and Knowledge Discovery, 11(3), 550-557. 709",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6845",
    "text": "Bengio, S., Vinyals, O., Jaitly, N., and Shazeer, N. (2015b). Scheduled sampling for sequence prediction with recurrent neural networks. Technical report, arXiv:1506.03099.\u00a0384",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6846",
    "text": "Bengio, Y. (1991). Artificial Neural Networks and their Application to Sequence Recognition. Ph.D. thesis, McGill University, (Computer Science), Montreal, Canada. 408",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6847",
    "text": "Bengio, Y. (2000). Gradient-based optimization of hyperparameters. Neural Computation, 12(8), 1889-1900. 437",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6848",
    "text": "Bengio, Y. (2002). New distributed probabilistic language models. Technical Report 1215, Dept. IRO, Universite de Montreal. 469",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6849",
    "text": "Bengio, Y. (2009). Learning deep architectures for AI. Now Publishers. 200, 624",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6850",
    "text": "Bengio, Y. (2013). Deep learning of representations: looking forward. In Statistical Language and Speech Processing, volume 7978 of Lecture Notes in Computer Science,\u00a0pages 1-37. Springer, also in arXiv at http://arxiv.org/abs/1305.0445. 450",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6851",
    "text": "Bengio, Y. (2015). Early inference in energy-based models approximates back-propagation. Technical Report arXiv:1510.02777, Universite de Montreal. 658",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6852",
    "text": "Bengio, Y. and Bengio, S. (2000b). Modeling high-dimensional discrete data with multilayer neural networks. In NIPS 12, pages 400-406. MIT Press. 707, 709, 710, 712",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6853",
    "text": "Bengio, Y. and Delalleau, O. (2009). Justifying and generalizing contrastive divergence. Neural Computation, 21(6), 1601-1621. 515, 613",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6854",
    "text": "Bengio, Y. and Grandvalet, Y. (2004). No unbiased estimator of the variance of k-fold cross-validation. In S. Thrun, L. Saul, and B. Scholkopf, editors, Advances in Neural\u00a0Information Processing Systems 16 (NIPS\u201903), Cambridge, MA. MIT Press, Cambridge.\u00a0122",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6855",
    "text": "Bengio, Y. and LeCun, Y. (2007). Scaling learning algorithms towards AI. In Large Scale Kernel Machines. 19",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6856",
    "text": "Bengio, Y. and Monperrus, M. (2005). Non-local manifold tangent learning. In L. Saul, Y. Weiss, and L. Bottou, editors, Advances in Neural Information Processing Systems\u00a017 (NIPS\u201904), pages 129-136. MIT Press. 159, 521",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6857",
    "text": "Bengio, Y. and Senecal, J.-S. (2003). Quick training of probabilistic neural nets by importance sampling. In Proceedings of AISTATS 2003. 472",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6858",
    "text": "Bengio, Y. and Senecal, J.-S. (2008). Adaptive importance sampling to accelerate training of a neural probabilistic language model. IEEE Trans. Neural Networks,19 (4), 713-722.\u00a0472",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6859",
    "text": "Bengio, Y., De Mori, R., Flammia, G., and Kompe, R. (1991). Phonetically motivated acoustic parameters for continuous speech recognition using artificial neural networks.\u00a0In Proceedings of EuroSpeech\u201991. 27, 461",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6860",
    "text": "Bengio, Y., De Mori, R., Flammia, G., and Kompe, R. (1992). Neural network-Gaussian mixture hybrid for speech recognition or density estimation. In NIPS 4, pages 175-182.\u00a0Morgan Kaufmann. 461",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6861",
    "text": "Bengio, Y., Frasconi, P., and Simard, P. (1993). The problem of learning long-term dependencies in recurrent networks. In IEEE International Conference on Neural\u00a0Networks, pages 1183-1195, San Francisco. IEEE Press. (invited paper). 404",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6862",
    "text": "Bengio, Y., Simard, P., and Frasconi, P. (1994). Learning long-term dependencies with gradient descent is difficult. IEEE Tr. Neural Nets. 18, 402, 404, 405, 413",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6863",
    "text": "Bengio, Y., Latendresse, S., and Dugas, C. (1999). Gradient-based learning of hyperparameters. Learning Conference, Snowbird. 437",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6864",
    "text": "Bengio, Y., Ducharme, R., and Vincent, P. (2001). A neural probabilistic language model. In T. K. Leen, T. G. Dietterich, and V. Tresp, editors, NIPS\u20192000, pages 932-938. MIT\u00a0Press. 18, 449, 465, 468, 474, 479, 484",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6865",
    "text": "Bengio, Y., Ducharme, R., Vincent, P., and Jauvin, C. (2003). A neural probabilistic language model. JMLR, 3, 1137-1155. 468, 474",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6866",
    "text": "Bengio, Y., Le Roux, N., Vincent, P., Delalleau, O., and Marcotte, P. (2006a). Convex neural networks. In NIPS\u20192005, pages 123-130. 258",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6867",
    "text": "Bengio, Y., Delalleau, O., and Le Roux, N. (2006b). The curse of highly variable functions for local kernel machines. In NIPS\u20192005. 157",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6868",
    "text": "Bengio, Y., Larochelle, H., and Vincent, P. (2006c). Non-local manifold Parzen windows. In NIPS\u20192005. MIT Press. 159, 522",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6869",
    "text": "Bengio, Y., Lamblin, P., Popovici, D., and Larochelle, H. (2007). Greedy layer-wise training of deep networks. In NIPS\u20192006. 14, 19, 200, 323, 324, 530, 532",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6870",
    "text": "Bengio, Y., Louradour, J., Collobert, R., and Weston, J. (2009). Curriculum learning. In ICML\u201909. 328",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6871",
    "text": "Bengio, Y., Mesnil, G., Dauphin, Y., and Rifai, S. (2013a). Better mixing via deep representations. In ICML\u20192013. 606",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6872",
    "text": "Bengio, Y., Leonard, N., and Courville, A. (2013b). Estimating or propagating gradients through stochastic neurons for conditional computation. arXiv:1308.3432. 450, 452,\u00a0691, 693",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6873",
    "text": "Bengio, Y., Yao, L., Alain, G., and Vincent, P. (2013c). Generalized denoising autoencoders as generative models. In NIPS\u20192013. 509, 713, 715",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6874",
    "text": "Bengio, Y., Courville, A., and Vincent, P. (2013d). Representation learning: A review and new perspectives. IEEE Trans. Pattern Analysis and Machine Intelligence (PAMI),\u00a035(8), 1798-1828. 557",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6875",
    "text": "Bengio, Y., Thibodeau-Laufer, E., Alain, G., and Yosinski, J. (2014). Deep generative stochastic networks trainable by backprop. In ICML\u20192014. 713, 714, 715, 716, 717",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6876",
    "text": "Bennett, C. (1976). Efficient estimation of free energy differences from Monte Carlo data. Journal of Computational Physics, 22(2), 245-268. 630",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6877",
    "text": "Bennett, J. and Lanning, S. (2007). The Netflix prize. 481",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6878",
    "text": "Berger, A. L., Della Pietra, V. J., and Della Pietra, S. A. (1996). A maximum entropy approach to natural language processing. Computational Linguistics, 22, 39-71. 475",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6879",
    "text": "Berglund, M. and Raiko, T. (2013). Stochastic gradient estimate variance in contrastive divergence and persistent contrastive divergence. CoRR, abs/1312.6002. 616",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6880",
    "text": "Bergstra, J. (2011). Incorporating Complex Cells into Neural Networks for Pattern Classification. Ph.D. thesis, Universite de Montreal. 255",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6881",
    "text": "Bergstra, J. and Bengio, Y. (2009). Slow, decorrelated features for pretraining complex cell-like networks. In NIPS\u20192009. 496",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6882",
    "text": "Bergstra, J. and Bengio, Y. (2012). Random search for hyper-parameter optimization. J. Machine Learning Res., 13, 281-305. 436, 437",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6883",
    "text": "Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J., Warde-Farley, D., and Bengio, Y. (2010). Theano: a CPU and GPU math expression\u00a0compiler. In Proc. SciPy. 25, 82, 212, 222, 448",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6884",
    "text": "Bergstra, J., Bardenet, R., Bengio, Y., and Kegl, B. (2011). Algorithms for hyper-parameter optimization. In NIPS\u20192011. 438",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6885",
    "text": "Berkes, P. and Wiskott, L. (2005). Slow feature analysis yields a rich repertoire of complex cell properties. Journal of Vision, 5(6), 579-602. 497",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6886",
    "text": "Bertsekas, D. P. and Tsitsiklis, J. (1996). Neuro-Dynamic Programming. Athena Scientific. 106",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6887",
    "text": "Besag, J. (1975). Statistical analysis of non-lattice data. The Statistician, 24(3), 179-195. 617",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6888",
    "text": "Bishop, C. M. (1994). Mixture density networks. 188",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6889",
    "text": "Bishop, C. M. (1995a). Regularization and complexity control in feed-forward networks. In Proceedings International Conference on Artificial Neural Networks ICANN\u201995,\u00a0volume 1, page 141-148. 242, 250",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6890",
    "text": "Bishop, C. M. (1995b). Training with noise is equivalent to Tikhonov regularization. Neural Computation, 7(1), 108-116. 242",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6891",
    "text": "Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer. 98, 145",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6892",
    "text": "Blum, A. L. and Rivest, R. L. (1992). Training a 3-node neural network is NP-complete. 293",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6893",
    "text": "Blumer, A., Ehrenfeucht, A., Haussler, D., and Warmuth, M. K. (1989). Learnability and the Vapnik-Chervonenkis dimension. Journal of the ACM, 36(4), 929\u2014865. 114",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6894",
    "text": "Bonnet, G. (1964). Transformations des signaux aleatoires a travers les systemes non lineaires sans memoire. Annales des Telecommunications, 19(9-10), 203-220. 691",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6895",
    "text": "Bordes, A., Weston, J., Collobert, R., and Bengio, Y. (2011). Learning structured embeddings of knowledge bases. In AAAI 2011. 486",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6896",
    "text": "Bordes, A., Glorot, X., Weston, J., and Bengio, Y. (2012). Joint learning of words and meaning representations for open-text semantic parsing. AISTATS\u20192012. 402, 486",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6897",
    "text": "Bordes, A., Glorot, X., Weston, J., and Bengio, Y. (2013a). A semantic matching energy function for learning with multi-relational data. Machine Learning: Special Issue on\u00a0Learning Semantics. 485",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6898",
    "text": "Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., and Yakhnenko, O. (2013b). Translating embeddings for modeling multi-relational data. In C. Burges, L. Bottou,\u00a0M. Welling, Z. Ghahramani, and K. Weinberger, editors, Advances in Neural Information\u00a0Processing Systems 26, pages 2787-2795. Curran Associates, Inc. 486",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6899",
    "text": "Bornschein, J. and Bengio, Y. (2015). Reweighted wake-sleep. In ICLR\u20192015, arXiv:1406.2751. 695",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6900",
    "text": "Bornschein, J., Shabanian, S., Fischer, A., and Bengio, Y. (2015). Training bidirectional Helmholtz machines. Technical report, arXiv:1506.03877. 695",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6901",
    "text": "Boser, B. E., Guyon, I. M., and Vapnik, V. N. (1992). A training algorithm for optimal margin classifiers. In COLT \u201992: Proceedings of the fifth annual workshop on Computational learning theory, pages 144-152, New York, NY, USA. ACM. 18, 140",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6902",
    "text": "Bottou, L. (1998). Online algorithms and stochastic approximations. In D. Saad, editor, Online Learning in Neural Networks. Cambridge University Press, Cambridge, UK. 296",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6903",
    "text": "Bottou, L. (2011). From machine learning to machine reasoning. Technical report, arXiv.1102.1808. 400, 402",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6904",
    "text": "Bottou, L. (2015). Multilayer neural networks. Deep Learning Summer School. 442",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6905",
    "text": "Bottou, L. and Bousquet, O. (2008). The tradeoffs of large scale learning. In NIPS\u20192008. 282, 295",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6906",
    "text": "Boulanger-Lewandowski, N., Bengio, Y., and Vincent, P. (2012). Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation\u00a0and transcription. In ICML\u201912. 687, 688",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6907",
    "text": "Boureau, Y., Ponce, J., and LeCun, Y. (2010). A theoretical analysis of feature pooling in vision algorithms. In Proc. International Conference on Machine learning (ICML\u201910).\u00a0345",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6908",
    "text": "Boureau, Y., Le Roux, N., Bach, F., Ponce, J., and LeCun, Y. (2011). Ask the locals: multi-way local pooling for image recognition. In Proc. International Conference on\u00a0Computer Vision (ICCV\u201911). IEEE. 345",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6909",
    "text": "Bourlard, H. and Kamp, Y. (1988). Auto-association by multilayer perceptrons and singular value decomposition. Biological Cybernetics, 59, 291-294. 504",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6910",
    "text": "Bourlard, H. and Wellekens, C. (1989). Speech pattern discrimination and multi-layered perceptrons. Computer Speech and Language, 3, 1-19. 461",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6911",
    "text": "Boyd, S. and Vandenberghe, L. (2004). Convex Optimization. Cambridge University Press, New York, NY, USA. 93",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6912",
    "text": "Brady, M. L., Raghavan, R., and Slawny, J. (1989). Back-propagation fails to separate where perceptrons succeed. IEEE Transactions on Circuits and Systems, 36, 665-674.\u00a0284",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6913",
    "text": "Brakel, P., Stroobandt, D., and Schrauwen, B. (2013). Training energy-based models for time-series imputation. Journal of Machine Learning Research, 14, 2771-2797. 676,\u00a0700",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6914",
    "text": "Brand, M. (2003). Charting a manifold. In NIPS\u20192002, pages 961-968. MIT Press. 163, 520",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6915",
    "text": "Breiman, L. (1994). Bagging predictors. Machine Learning, 24(2), 123-140. 256",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6916",
    "text": "Breiman, L., Friedman, J. H., Olshen, R. A., and Stone, C. J. (1984). Classification and Regression Trees. Wadsworth International Group, Belmont, CA. 145",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6917",
    "text": "Bridle, J. S. (1990). Alphanets: a recurrent \u2018neural\u2019 network architecture with a hidden Markov model interpretation. Speech Communication, 9(1), 83-92. 185",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6918",
    "text": "Briggman, K., Denk, W., Seung, S., Helmstaedter, M. N., and Turaga, S. C. (2009). Maximin affinity learning of image segmentation. In NIPS\u20192009, pages 1865-1873. 359",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6919",
    "text": "Brown, P. F., Cocke, J., Pietra, S. A. D., Pietra, V. J. D., Jelinek, F., Lafferty, J. D., Mercer, R. L., and Roossin, P. S. (1990). A statistical approach to machine translation.\u00a0Computational linguistics, 16(2), 79-85. 21",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6920",
    "text": "Brown, P. F., Pietra, V. J. D., DeSouza, P. V., Lai, J. C., and Mercer, R. L. (1992). Class-based n-gram models of natural language. Computational Linguistics, 18, 467-479. 465",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6921",
    "text": "Bryson, A. and Ho, Y. (1969). Applied optimal control: optimization, estimation, and control. Blaisdell Pub. Co. 224",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6922",
    "text": "Bryson, Jr., A. E. and Denham, W. F. (1961). A steepest-ascent method for solving optimum programming problems. Technical Report BR-1303, Raytheon Company,\u00a0Missle and Space Division. 224",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6923",
    "text": "Bucilua, C., Caruana, R., and Niculescu-Mizil, A. (2006). Model compression. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery\u00a0and data mining, pages 535-541. ACM. 450",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6924",
    "text": "Burda, Y., Grosse, R., and Salakhutdinov, R. (2015). Importance weighted autoencoders. arXiv preprint arXiv:1509.00519. 700",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6925",
    "text": "Cai, M., Shi, Y., and Liu, J. (2013). Deep maxout neural networks for speech recognition. In Automatic Speech Recognition and Understanding (ASRU), 2013 IEEE Workshop\u00a0on, pages 291-296. IEEE. 193",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6926",
    "text": "Carreira-Perpinan, M. A. and Hinton, G. E. (2005). On contrastive divergence learning. In R. G. Cowell and Z. Ghahramani, editors, Proceedings of the Tenth International\u00a0Workshop on Artificial Intelligence and Statistics (AISTATS\u201905), pages 33-40. Society\u00a0for Artificial Intelligence and Statistics. 613",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6927",
    "text": "Caruana, R. (1993). Multitask connectionist learning. In Proc. 1993 Connectionist Models Summer School, pages 372-379. 244",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6928",
    "text": "Cauchy, A. (1847). Methode generale pour la resolution de systemes d\u2019equations simul-tanees. In Compte rendu des seances de l\u2019academie des sciences, pages 536-538. 83, 224",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6929",
    "text": "Cayton, L. (2005). Algorithms for manifold learning. Technical Report CS2008-0923, UCSD. 163",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6930",
    "text": "Chandola, V., Banerjee, A., and Kumar, V. (2009). Anomaly detection: A survey. ACM computing surveys (CSUR), 41(3), 15. 102",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6931",
    "text": "Chapelle, O., Weston, J., and Scholkopf, B. (2003). Cluster kernels for semi-supervised learning. In S. Becker, S. Thrun, and K. Obermayer, editors, Advances in Neural\u00a0Information Processing Systems 15 (NIPS\u201902), pages 585-592, Cambridge, MA. MIT\u00a0Press. 244",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6932",
    "text": "Chapelle, O., Scholkopf, B., and Zien, A., editors (2006). Semi-Supervised Learning. MIT Press, Cambridge, MA. 244, 543",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6933",
    "text": "Chellapilla, K., Puri, S., and Simard, P. (2006). High Performance Convolutional Neural Networks for Document Processing. In Guy Lorette, editor, Tenth International\u00a0Workshop on Frontiers in Handwriting Recognition, La Baule (France). Universite de\u00a0Rennes 1, Suvisoft. http://www.suvisoft.com. 24, 27, 447",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6934",
    "text": "Chen, B., Ting, J.-A., Marlin, B. M., and de Freitas, N. (2010). Deep learning of invariant spatio-temporal features from video. NIPS*2010 Deep Learning and Unsupervised\u00a0Feature Learning Workshop. 360",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6935",
    "text": "Chen, S. F. and Goodman, J. T. (1999). An empirical study of smoothing techniques for language modeling. Computer, Speech and Language, 13(4), 359-393. 464, 475",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6936",
    "text": "Chen, T., Du, Z., Sun, N., Wang, J., Wu, C., Chen, Y., and Temam, O. (2014a). DianNao: A small-footprint high-throughput accelerator for ubiquitous machine-learning. In Proceedings of the 19th international conference on Architectural support for programming\u00a0languages and operating systems, pages 269-284. ACM. 453",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6937",
    "text": "Chen, T., Li, M., Li, Y., Lin, M., Wang, N., Wang, M., Xiao, T., Xu, B., Zhang, C., and Zhang, Z. (2015). MXNet: A flexible and efficient machine learning library for\u00a0heterogeneous distributed systems. arXiv preprint arXiv:1512.01274. 25",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6938",
    "text": "Chen, Y., Luo, T., Liu, S., Zhang, S., He, L., Wang, J., Li, L., Chen, T., Xu, Z., Sun, N., et al. (2014b). DaDianNao: A machine-learning supercomputer. In Microarchitecture\u00a0(MICRO), 2014 47th Annual IEEE/ACM International Symposium on, pages 609-622.\u00a0IEEE. 453",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6939",
    "text": "Chilimbi, T., Suzue, Y., Apacible, J., and Kalyanaraman, K. (2014). Project Adam: Building an efficient and scalable deep learning training system. In 11th USENIX\u00a0Symposium on Operating Systems Design and Implementation (OSDI\u201914). 449",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6940",
    "text": "Cho, K., Raiko, T., and Ilin, A. (2010). Parallel tempering is efficient for learning restricted Boltzmann machines. In IJCNN\u20192010. 605, 616",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6941",
    "text": "Cho, K., Raiko, T., and Ilin, A. (2011). Enhanced gradient and adaptive learning rate for training restricted Boltzmann machines. In ICML\u20192011, pages 105-112. 676",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6942",
    "text": "Cho, K., van Merrienboer, B., Gulcehre, C., Bougares, F., Schwenk, H., and Bengio, Y. (2014a). Learning phrase representations using RNN encoder-decoder for statistical\u00a0machine translation. In Proceedings of the Empiricial Methods in Natural Language\u00a0Processing (EMNLP 2014). 396, 476, 477",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6943",
    "text": "Cho, K., Van Merrienboer, B., Bahdanau, D., and Bengio, Y. (2014b). On the properties of neural machine translation: Encoder-decoder approaches. ArXiv e-prints, abs/1409.1259. 413",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6944",
    "text": "Choromanska, A., Henaff, M., Mathieu, M., Arous, G. B., and LeCun, Y. (2014). The loss surface of multilayer networks. 285, 286",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6945",
    "text": "Chorowski, J., Bahdanau, D., Cho, K., and Bengio, Y. (2014). End-to-end continuous speech recognition using attention-based recurrent NN: First results. arXiv:1412.1602.\u00a0462",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6946",
    "text": "Christianson, B. (1992). Automatic Hessians by reverse accumulation. IMA Journal of Numerical Analysis, 12(2), 135-150. 224",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6947",
    "text": "Chrupala, G., Kadar, A., and Alishahi, A. (2015). Learning language through pictures. arXiv 1506.03694. 413",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6948",
    "text": "Chung, J., Gulcehre, C., Cho, K., and Bengio, Y. (2014). Empirical evaluation of gated recurrent neural networks on sequence modeling. NIPS\u20192014 Deep Learning workshop,\u00a0arXiv 1412.3555. 413, 462",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6949",
    "text": "Chung, J., Gulgehre, Q., Cho, K., and Bengio, Y. (2015a). Gated feedback recurrent neural networks. In ICML\u201915. 413",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6950",
    "text": "Chung, J., Kastner, K., Dinh, L., Goel, K., Courville, A., and Bengio, Y. (2015b). A recurrent latent variable model for sequential data. In NIPS\u20192015. 700",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6951",
    "text": "Ciresan, D., Meier, U., Masci, J., and Schmidhuber, J. (2012). Multi-column deep neural network for traffic sign classification. Neural Networks, 32, 333-338. 23, 200",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6952",
    "text": "Ciresan, D. C., Meier, U., Gambardella, L. M., and Schmidhuber, J. (2010). Deep big simple neural nets for handwritten digit recognition. Neural Computation, 22, 1-14.\u00a024, 27, 448",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6953",
    "text": "Coates, A. and Ng, A. Y. (2011). The importance of encoding versus training with sparse coding and vector quantization. In ICML\u20192011. 27, 256, 500",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6954",
    "text": "Coates, A., Lee, H., and Ng, A. Y. (2011). An analysis of single-layer networks in unsupervised feature learning. In Proceedings of the Thirteenth International Conference\u00a0on Artificial Intelligence and Statistics (AISTATS 2011). 363, 364, 457",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6955",
    "text": "Coates, A., Huval, B., Wang, T., Wu, D., Catanzaro, B., and Andrew, N. (2013). Deep learning with COTS HPC systems. In S. Dasgupta and D. McAllester, editors,\u00a0Proceedings of the 30th International Conference on Machine Learning (ICML-13),\u00a0volume 28 (3), pages 1337-1345. JMLR Workshop and Conference Proceedings. 24, 27,\u00a0364, 449",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6956",
    "text": "Cohen, N., Sharir, O., and Shashua, A. (2015). On the expressive power of deep learning: A tensor analysis. arXiv:1509.05009. 556",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6957",
    "text": "Collobert, R. (2004). Large Scale Machine Learning. Ph.D. thesis, Universite de Paris VI, LIP6. 196",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6958",
    "text": "Collobert, R. (2011). Deep learning for efficient discriminative parsing. In AISTATS\u20192011. 101, 479",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6959",
    "text": "Collobert, R. and Weston, J. (2008a). A unified architecture for natural language processing: Deep neural networks with multitask learning. In ICML\u20192008. 473, 479",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6960",
    "text": "Collobert, R. and Weston, J. (2008b). A unified architecture for natural language processing: Deep neural networks with multitask learning. In ICML\u20192008. 537",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6961",
    "text": "Collobert, R., Bengio, S., and Bengio, Y. (2001). A parallel mixture of SVMs for very large scale problems. Technical Report IDIAP-RR-01-12, IDIAP. 452",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6962",
    "text": "Collobert, R., Bengio, S., and Bengio, Y. (2002). Parallel mixture of SVMs for very large scale problems. Neural Computation, 14(5), 1105-1114. 452",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6963",
    "text": "Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., and Kuksa, P. (2011a). Natural language processing (almost) from scratch. The Journal of Machine Learning\u00a0Research, 12, 2493-2537. 328, 479, 537, 538",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6964",
    "text": "Collobert, R., Kavukcuoglu, K., and Farabet, C. (2011b). Torch7: A Matlab-like environment for machine learning. In BigLearn, NIPS Workshop. 25, 210, 448",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6965",
    "text": "Comon, P. (1994). Independent component analysis - a new concept? Signal Processing, 36, 287-314. 493",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6966",
    "text": "Cortes, C. and Vapnik, V. (1995). Support vector networks. Machine Learning, 20, 273-297. 18, 140",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6967",
    "text": "Couprie, C., Farabet, C., Najman, L., and LeCun, Y. (2013). Indoor semantic segmentation using depth information. In International Conference on Learning Representations\u00a0(ICLR2013). 23, 200",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6968",
    "text": "Courbariaux, M., Bengio, Y., and David, J.-P. (2015). Low precision arithmetic for deep learning. In Arxiv:1f12.7024, ICLR\u20192015 Workshop. 454",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6969",
    "text": "Courville, A., Bergstra, J., and Bengio, Y. (2011). Unsupervised models of images by spike-and-slab RBMs. In ICML\u201911. 563, 683",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6970",
    "text": "Courville, A., Desjardins, G., Bergstra, J., and Bengio, Y. (2014). The spike-and-slab RBM and extensions to discrete and sparse data distributions. Pattern Analysis and\u00a0Machine Intelligence, IEEE Transactions on, 36(9), 1874-1887. 684",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6971",
    "text": "Cover, T. M. and Thomas, J. A. (2006). Elements of Information Theory, 2nd Edition. Wiley-Interscience. 73",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6972",
    "text": "Cox, D. and Pinto, N. (2011). Beyond simple features: A large-scale feature search approach to unconstrained face recognition. In Automatic Face & Gesture Recognition\u00a0and Workshops (FG 2011), 2011 IEEE International Conference on, pages 8-15. IEEE.\u00a0363",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6973",
    "text": "Cramer, H. (1946). Mathematical methods of statistics. Princeton University Press. 135, 295",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6974",
    "text": "Crick, F. H. C. and Mitchison, G. (1983). The function of dream sleep. Nature,304, 111-114. 611",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6975",
    "text": "Cybenko, G. (1989). Approximation by superpositions of a sigmoidal function. Mathematics of Control, Signals, and Systems, 2, 303-314. 197",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6976",
    "text": "Dahl, G. E., Ranzato, M., Mohamed, A., and Hinton, G. E. (2010). Phone recognition with the mean-covariance restricted Boltzmann machine. In NIPS\u20192010. 23",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6977",
    "text": "Dahl, G. E., Yu, D., Deng, L., and Acero, A. (2012). Context-dependent pre-trained deep neural networks for large vocabulary speech recognition. IEEE Transactions on Audio,\u00a0Speech, and Language Processing, 20(1), 33-42. 461",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6978",
    "text": "Dahl, G. E., Sainath, T. N., and Hinton, G. E. (2013). Improving deep neural networks for LVCSR using rectified linear units and dropout. In ICASSP\u20192013. 461",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6979",
    "text": "Dahl, G. E., Jaitly, N., and Salakhutdinov, R. (2014). Multi-task neural networks for QSAR predictions. arXiv:1406.1231. 26",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6980",
    "text": "Dauphin, Y. and Bengio, Y. (2013). Stochastic ratio matching of RBMs for sparse high-dimensional inputs. In NIPS26. NIPS Foundation. 621",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6981",
    "text": "Dauphin, Y., Glorot, X., and Bengio, Y. (2011). Large-scale learning of embeddings with reconstruction sampling. In ICML\u20192011. 473",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6982",
    "text": "Dauphin, Y., Pascanu, R., Gulcehre, C., Cho, K., Ganguli, S., and Bengio, Y. (2014). Identifying and attacking the saddle point problem in high-dimensional non-convex\u00a0optimization. In NIPS\u20192014. 285, 286, 288",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6983",
    "text": "Davis, A., Rubinstein, M., Wadhwa, N., Mysore, G., Durand, F., and Freeman, W. T. (2014). The visual microphone: Passive recovery of sound from video. ACM Transactions\u00a0on Graphics (Proc. SIGGRAPH), 33(4), 79:1-79:10. 454",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6984",
    "text": "Dayan, P. (1990). Reinforcement comparison. In Connectionist Models: Proceedings of the 1990 Connectionist Summer School, San Mateo, CA. 693",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6985",
    "text": "Dayan, P. and Hinton, G. E. (1996). Varieties of Helmholtz machine. Neural Networks, 9(8), 1385-1403. 695",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6986",
    "text": "Dayan, P., Hinton, G. E., Neal, R. M., and Zemel, R. S. (1995). The Helmholtz machine. Neural computation, 7(5), 889-904. 695",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6987",
    "text": "Dean, J., Corrado, G., Monga, R., Chen, K., Devin, M., Le, Q., Mao, M., Ranzato, M., Senior, A., Tucker, P., Yang, K., and Ng, A. Y. (2012). Large scale distributed deep\u00a0networks. In NIPS\u20192012. 25, 449",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6988",
    "text": "Dean, T. and Kanazawa, K. (1989). A model for reasoning about persistence and causation. Computational Intelligence, 5(3), 142-150. 664",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6989",
    "text": "Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., and Harshman, R. (1990). Indexing by latent semantic analysis. Journal of the American Society for Information\u00a0Science, 41(6), 391-407. 478, 484",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6990",
    "text": "Delalleau, O. and Bengio, Y. (2011). Shallow vs. deep sum-product networks. In NIPS. 19, 556",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6991",
    "text": "Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L. (2009). ImageNet: A Large-Scale Hierarchical Image Database. In CVPR09. 21",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6992",
    "text": "Deng, J., Berg, A. C., Li, K., and Fei-Fei, L. (2010a). What does classifying more than 10,000 image categories tell us? In Proceedings of the 11th European Conference on\u00a0Computer Vision: Part V, ECCV\u201910, pages 71-84, Berlin, Heidelberg. Springer-Verlag.\u00a021",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6993",
    "text": "Deng, L. and Yu, D. (2014). Deep learning - methods and applications. Foundations and Trends in Signal Processing. 462",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6994",
    "text": "Deng, L., Seltzer, M., Yu, D., Acero, A., Mohamed, A., and Hinton, G. (2010b). Binary coding of speech spectrograms using a deep auto-encoder. In Interspeech 2010, Makuhari,\u00a0Chiba, Japan. 23",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6995",
    "text": "Denil, M., Bazzani, L., Larochelle, H., and de Freitas, N. (2012). Learning where to attend with deep architectures for image tracking. Neural Computation,24(8), 2151-2184. 367",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6996",
    "text": "Denton, E., Chintala, S., Szlam, A., and Fergus, R. (2015). Deep generative image models using a Laplacian pyramid of adversarial networks. NIPS. 703, 704, 720",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6997",
    "text": "Desjardins, G. and Bengio, Y. (2008). Empirical evaluation of convolutional RBMs for vision. Technical Report 1327, Departement d\u2019Informatique et de Recherche Opera-tionnelle, Universite de Montreal. 685",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6998",
    "text": "Desjardins, G., Courville, A. C., Bengio, Y., Vincent, P., and Delalleau, O. (2010). Tempered Markov chain Monte Carlo for training of restricted Boltzmann machines. In\u00a0International Conference on Artificial Intelligence and Statistics, pages 145-152. 605,\u00a0616",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "6999",
    "text": "Desjardins, G., Courville, A., and Bengio, Y. (2011). On tracking the partition function. In NIPS\u20192011. 631",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7000",
    "text": "Desjardins, G., Simonyan, K., Pascanu, R., et al. (2015). Natural neural networks. In Advances in Neural Information Processing Systems, pages 2062-2070. 320",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7001",
    "text": "Devlin, J., Zbib, R., Huang, Z., Lamar, T., Schwartz, R., and Makhoul, J. (2014). Fast and robust neural network joint models for statistical machine translation. In Proc.\u00a0ACL\u20192014. 475",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7002",
    "text": "Devroye, L. (2013). Non-Uniform Random Variate Generation. SpringerLink : Bucher. Springer New York. 696",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7003",
    "text": "DiCarlo, J. J. (2013). Mechanisms underlying visual object recognition: Humans vs. neurons vs. machines. NIPS Tutorial. 26, 366",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7004",
    "text": "Dinh, L., Krueger, D., and Bengio, Y. (2014). NICE: Non-linear independent components estimation. arXiv:1410.8516. 495",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7005",
    "text": "Donahue, J., Hendricks, L. A., Guadarrama, S., Rohrbach, M., Venugopalan, S., Saenko, K., and Darrell, T. (2014). Long-term recurrent convolutional networks for visual\u00a0recognition and description. arXiv:1411.4389. 102",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7006",
    "text": "Donoho, D. L. and Grimes, C. (2003). Hessian eigenmaps: new locally linear embedding techniques for high-dimensional data. Technical Report 2003-08, Dept. Statistics,\u00a0Stanford University. 163, 521",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7007",
    "text": "Dosovitskiy, A., Springenberg, J. T., and Brox, T. (2015). Learning to generate chairs with convolutional neural networks. In Proceedings of the IEEE Conference on Computer\u00a0Vision and Pattern Recognition, pages 1538-1546. 697, 706, 707",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7008",
    "text": "Doya, K. (1993). Bifurcations of recurrent neural networks in gradient descent learning. IEEE Transactions on Neural Networks, 1, 75-80. 402, 405",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7009",
    "text": "Dreyfus, S. E. (1962). The numerical solution of variational problems. Journal of Mathematical Analysis and Applications, 5(1), 30-45. 224",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7010",
    "text": "Dreyfus, S. E. (1973). The computational solution of optimal control problems with time lag. IEEE Transactions on Automatic Control, 18(4), 383-385. 224",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7011",
    "text": "Drucker, H. and LeCun, Y. (1992). Improving generalisation performance using double back-propagation. IEEE Transactions on Neural Networks, 3(6), 991-997. 271",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7012",
    "text": "Duchi, J., Hazan, E., and Singer, Y. (2011). Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research. 307",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7013",
    "text": "Dudik, M., Langford, J., and Li, L. (2011). Doubly robust policy evaluation and learning.",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7014",
    "text": "In Proceedings of the 28th International Conference on Machine learning, ICML \u201911. 484",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7015",
    "text": "Dugas, C., Bengio, Y., Belisle, F., and Nadeau, C. (2001). Incorporating second-order functional knowledge for better option pricing. In T. Leen, T. Dietterich, and V. Tresp,\u00a0editors, Advances in Neural Information Processing Systems 13 (NIPS\u201900), pages\u00a0472-478. MIT Press. 68, 196",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7016",
    "text": "Dziugaite, G. K., Roy, D. M., and Ghahramani, Z. (2015). Training generative neural networks via maximum mean discrepancy optimization. arXiv preprint arXiv:1505.03906. 705",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7017",
    "text": "El Hihi, S. and Bengio, Y. (1996). Hierarchical recurrent neural networks for long-term dependencies. In NIPS\u20191995. 400, 409",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7018",
    "text": "Elkahky, A. M., Song, Y., and He, X. (2015). A multi-view deep learning approach for cross domain user modeling in recommendation systems. In Proceedings of the 24th\u00a0International Conference on World Wide Web, pages 278-288. 482",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7019",
    "text": "Elman, J. L. (1993). Learning and development in neural networks: The importance of starting small. Cognition, 48, 781-799. 328",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7020",
    "text": "Erhan, D., Manzagol, P.-A., Bengio, Y., Bengio, S., and Vincent, P. (2009). The difficulty of training deep architectures and the effect of unsupervised pre-training. In Proceedings\u00a0of A IS TA TS \u20192009. 200",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7021",
    "text": "Erhan, D., Bengio, Y., Courville, A., Manzagol, P., Vincent, P., and Bengio, S. (2010). Why does unsupervised pre-training help deep learning? J. Machine Learning Res.\u00a0531, 535, 536",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7022",
    "text": "Fahlman, S. E., Hinton, G. E., and Sejnowski, T. J. (1983). Massively parallel architectures for AI: NETL, thistle, and Boltzmann machines. In Proceedings of the National\u00a0Conference on Artificial Intelligence AAAI-83. 572, 656",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7023",
    "text": "Fang, H., Gupta, S., Iandola, F., Srivastava, R., Deng, L., Dollar, P., Gao, J., He, X., Mitchell, M., Platt, J. C., Zitnick, C. L., and Zweig, G. (2015). From captions to visual\u00a0concepts and back. arXiv:1411.4952. 102",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7024",
    "text": "Farabet, C., LeCun, Y., Kavukcuoglu, K., Culurciello, E., Martini, B., Akselrod, P., and Talay, S. (2011). Large-scale FPGA-based convolutional networks. In R. Bekkerman,\u00a0M. Bilenko, and J. Langford, editors, Scaling up Machine Learning: Parallel and\u00a0Distributed Approaches. Cambridge University Press. 525",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7025",
    "text": "Farabet, C., Couprie, C., Najman, L., and LeCun, Y. (2013). Learning hierarchical features for scene labeling. IEEE Transactions on Pattern Analysis and Machine Intelligence,\u00a035(8), 1915-1929. 23, 200, 359",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7026",
    "text": "Fei-Fei, L., Fergus, R., and Perona, P. (2006). One-shot learning of object categories. IEEE Transactions on Pattern Analysis and Machine Intelligence,28(4), 594-611. 540",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7027",
    "text": "Finn, C., Tan, X. Y., Duan, Y., Darrell, T., Levine, S., and Abbeel, P. (2015). Learning visual feature spaces for robotic manipulation with deep spatial autoencoders. arXiv\u00a0preprint arXiv:1509.06113. 25",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7028",
    "text": "Fisher, R. A. (1936). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7, 179-188. 21, 105",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7029",
    "text": "Foldiak, P. (1989). Adaptive network for optimal linear feature extraction. In International Joint Conference on Neural Networks (IJCNN), volume 1, pages 401-405, Washington\u00a01989. IEEE, New York. 496",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7030",
    "text": "Franzius, M., Sprekeler, H., and Wiskott, L. (2007). Slowness and sparseness lead to place, head-direction, and spatial-view cells. 497",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7031",
    "text": "Franzius, M., Wilbert, N., and Wiskott, L. (2008). Invariant object recognition with slow feature analysis. In Artificial Neural Networks-ICANN 2008, pages 961-970. Springer.\u00a0498",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7032",
    "text": "Frasconi, P., Gori, M., and Sperduti, A. (1997). On the efficient classification of data structures by neural networks. In Proc. Int. Joint Conf. on Artificial Intelligence. 400,\u00a0402",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7033",
    "text": "Frasconi, P., Gori, M., and Sperduti, A. (1998). A general framework for adaptive processing of data structures. IEEE Transactions on Neural Networks,9(5), 768-786.\u00a0400, 402",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7034",
    "text": "Freund, Y. and Schapire, R. E. (1996a). Experiments with a new boosting algorithm. In Machine Learning: Proceedings of Thirteenth International Conference, pages 148-156,\u00a0USA. ACM. 258",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7035",
    "text": "Freund, Y. and Schapire, R. E. (1996b). Game theory, on-line prediction and boosting. In",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7036",
    "text": "Proceedings of the Ninth Annual Conference on Computational Learning Theory, pages 325-332. 258",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7037",
    "text": "Frey, B. J. (1998). Graphical models for machine learning and digital communication. MIT Press. 707, 708",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7038",
    "text": "Frey, B. J., Hinton, G. E., and Dayan, P. (1996). Does the wake-sleep algorithm learn good density estimators? In D. Touretzky, M. Mozer, and M. Hasselmo, editors, Advances\u00a0in Neural Information Processing Systems 8 (NIPS\u201995), pages 661-670. MIT Press,\u00a0Cambridge, MA. 653",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7039",
    "text": "Frobenius, G. (1908). Uber matrizen aus positiven elementen, s. B. Preuss. Akad. Wiss. Berlin, Germany. 599",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7040",
    "text": "Fukushima, K. (1975). Cognitron: A self-organizing multilayered neural network. Biological Cybernetics, 20, 121-136. 16, 225, 530",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7041",
    "text": "Fukushima, K. (1980). Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. Biological Cybernetics,\u00a036, 193-202. 16, 24, 27, 225, 367",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7042",
    "text": "Gal, Y. and Ghahramani, Z. (2015). Bayesian convolutional neural networks with Bernoulli approximate variational inference. arXiv preprint arXiv:1506.02158. 264",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7043",
    "text": "Gallinari, P., LeCun, Y., Thiria, S., and Fogelman-Soulie, F. (1987). Memoires associatives distribuees. In Proceedings of COGNITIVA 87, Paris, La Villette. 517",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7044",
    "text": "Garcia-Duran, A., Bordes, A., Usunier, N., and Grandvalet, Y. (2015). Combining two and three-way embeddings models for link prediction in knowledge bases. arXiv preprint\u00a0arXiv:1506.00999. 486",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7045",
    "text": "Garofolo, J. S., Lamel, L. F., Fisher, W. M., Fiscus, J. G., and Pallett, D. S. (1993). Darpa timit acoustic-phonetic continous speech corpus cd-rom. nist speech disc 1-1.1.\u00a0NASA STI/Recon Technical Report N, 93, 27403. 461",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7046",
    "text": "Garson, J. (1900). The metric system of identification of criminals, as used in Great Britain and Ireland. The Journal of the Anthropological Institute of Great Britain and\u00a0Ireland, (2), 177-227. 21",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7047",
    "text": "Gers, F. A., Schmidhuber, J., and Cummins, F. (2000). Learning to forget: Continual prediction with LSTM. Neural computation, 12(10), 2451-2471. 410, 414",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7048",
    "text": "Ghahramani, Z. and Hinton, G. E. (1996). The EM algorithm for mixtures of factor analyzers. Technical Report CRG-TR-96-1, Dpt. of Comp. Sci., Univ. of Toronto. 491",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7049",
    "text": "Gillick, D., Brunk, C., Vinyals, O., and Subramanya, A. (2015). Multilingual language processing from bytes. arXiv preprint arXiv:1512.00103. 479",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7050",
    "text": "Girshick, R., Donahue, J., Darrell, T., and Malik, J. (2015). Region-based convolutional networks for accurate object detection and segmentation. 428",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7051",
    "text": "Giudice, M. D., Manera, V., and Keysers, C. (2009). Programmed to learn? The ontogeny of mirror neurons. Dev. Sci., 12(2), 350\u2014363. 658",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7052",
    "text": "Glorot, X. and Bengio, Y. (2010). Understanding the difficulty of training deep feedforward neural networks. In AISTATS\u20192010. 303",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7053",
    "text": "Glorot, X., Bordes, A., and Bengio, Y. (2011a). Deep sparse rectifier neural networks. In AISTATS\u20192011. 16, 173, 196, 226",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7054",
    "text": "Glorot, X., Bordes, A., and Bengio, Y. (2011b). Domain adaptation for large-scale sentiment classification: A deep learning approach. In ICML\u20192011. 509, 539",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7055",
    "text": "Goldberger, J., Roweis, S., Hinton, G. E., and Salakhutdinov, R. (2005). Neighbourhood components analysis. In L. Saul, Y. Weiss, and L. Bottou, editors, Advances in Neural\u00a0Information Processing Systems 17 (NIPS\u201904). MIT Press. 115",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7056",
    "text": "Gong, S., McKenna, S., and Psarrou, A. (2000). Dynamic Vision: From Images to Face Recognition. Imperial College Press. 164, 521",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7057",
    "text": "Goodfellow, I., Le, Q., Saxe, A., and Ng, A. (2009). Measuring invariances in deep networks. In NIPS\u20192009, pages 646-654. 255",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7058",
    "text": "Goodfellow, I., Koenig, N., Muja, M., Pantofaru, C., Sorokin, A., and Takayama, L. (2010). Help me help you: Interfaces for personal robots. In Proc. of Human Robot Interaction\u00a0(HRI), Osaka, Japan. ACM Press, ACM Press. 100",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7059",
    "text": "Goodfellow, I. J. (2010). Technical report: Multidimensional, downsampled convolution for autoencoders. Technical report, Universite de Montreal. 357",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7060",
    "text": "Goodfellow, I. J. (2014). On distinguishability criteria for estimating generative models. In International Conference on Learning Representations, Workshops Track. 624, 702,\u00a0703",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7061",
    "text": "Goodfellow, I. J., Courville, A., and Bengio, Y. (2011). Spike-and-slab sparse coding for unsupervised feature discovery. In NIPS Workshop on Challenges in Learning\u00a0Hierarchical Models. 534, 540",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7062",
    "text": "Goodfellow, I. J., Warde-Farley, D., Mirza, M., Courville, A., and Bengio, Y. (2013a). Maxout networks. In S. Dasgupta and D. McAllester, editors, ICML\u201913, pages 13191327. 192, 264, 344, 365, 457",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7063",
    "text": "Goodfellow, I. J., Mirza, M., Courville, A., and Bengio, Y. (2013b). Multi-prediction deep Boltzmann machines. In NIPS26. NIPS Foundation. 100, 619, 673, 674, 675, 676, 677,\u00a0700",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7064",
    "text": "Goodfellow, I. J., Warde-Farley, D., Lamblin, P., Dumoulin, V., Mirza, M., Pascanu, R., Bergstra, J., Bastien, F., and Bengio, Y. (2013c). Pylearn2: a machine learning research\u00a0library. arXiv preprint arXiv:1308.4214. 25,448",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7065",
    "text": "Goodfellow, I. J., Courville, A., and Bengio, Y. (2013d). Scaling up spike-and-slab models for unsupervised feature learning. IEEE Transactions on Pattern Analysis and Machine\u00a0Intelligence, 35(8), 1902-1914. 499, 500, 501, 652, 685",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7066",
    "text": "Goodfellow, I. J., Mirza, M., Xiao, D., Courville, A., and Bengio, Y. (2014a). An empirical investigation of catastrophic forgeting in gradient-based neural networks. In ICLR \u20192014.\u00a0193",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7067",
    "text": "Goodfellow, I. J., Shlens, J., and Szegedy, C. (2014b). Explaining and harnessing adversarial examples. CoRR, abs/1412.6572. 268, 269, 271, 557, 558",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7068",
    "text": "Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y. (2014c). Generative adversarial networks. In NIPS\u20192014.\u00a0546, 691, 702, 703, 706",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7069",
    "text": "Goodfellow, I. J., Bulatov, Y., Ibarz, J., Arnoud, S., and Shet, V. (2014d). Multi-digit number recognition from Street View imagery using deep convolutional neural networks.\u00a0In International Conference on Learning Representations. 25, 101, 200, 201, 202, 390,\u00a0424, 451",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7070",
    "text": "Goodfellow, I. J., Vinyals, O., and Saxe, A. M. (2015). Qualitatively characterizing neural network optimization problems. In International Conference on Learning Representations. 285, 286, 287, 291",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7071",
    "text": "Goodman, J. (2001). Classes for fast maximum entropy training. In International Conference on Acoustics, Speech and Signal Processing (ICASSP), Utah. 469",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7072",
    "text": "Gori, M. and Tesi, A. (1992). On the problem of local minima in backpropagation. IEEE",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7073",
    "text": "Transactions on Pattern Analysis and Machine Intelligence, PAMI-14(1), 76-86. 284",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7074",
    "text": "Gosset, W. S. (1908). The probable error of a mean. Biometrika, 6(1), 1-25. Originally published under the pseudonym \u201cStudent\u201d. 21",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7075",
    "text": "Gouws, S., Bengio, Y., and Corrado, G. (2014). BilBOWA: Fast bilingual distributed representations without word alignments. Technical report, arXiv:1410.2455. 478, 541",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7076",
    "text": "Graf, H. P. and Jackel, L. D. (1989). Analog electronic neural network circuits. Circuits and Devices Magazine, IEEE, 5(4), 44-49. 453",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7077",
    "text": "Graves, A. (2011). Practical variational inference for neural networks. In NIPS\u20192011. 242",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7078",
    "text": "Graves, A. (2012). Supervised Sequence Labelling with Recurrent Neural Networks. Studies in Computational Intelligence. Springer. 374, 395, 413, 462",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7079",
    "text": "Graves, A. (2013). Generating sequences with recurrent neural networks. Technical report, arXiv:1308.0850. 189, 410, 417, 421",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7080",
    "text": "Graves, A. and Jaitly, N. (2014). Towards end-to-end speech recognition with recurrent neural networks. In ICML \u20192014. 410",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7081",
    "text": "Graves, A. and Schmidhuber, J. (2005). Framewise phoneme classification with bidirectional LSTM and other neural network architectures. Neural Networks, 18(5), 602-610. 395",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7082",
    "text": "Graves, A. and Schmidhuber, J. (2009). Offline handwriting recognition with multidimensional recurrent neural networks. In D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, NIPS\u20192008, pages 545-552. 395",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7083",
    "text": "Graves, A., Fernandez, S., Gomez, F., and Schmidhuber, J. (2006). Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks. In\u00a0ICML\u20192006, pages 369-376, Pittsburgh, USA. 462",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7084",
    "text": "Graves, A., Liwicki, M., Bunke, H., Schmidhuber, J., and Fernandez, S. (2008). Unconstrained on-line handwriting recognition with recurrent neural networks. In J. Platt, D. Koller, Y. Singer, and S. Roweis, editors, NIPS\u20192007, pages 577-584. 395",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7085",
    "text": "Graves, A., Liwicki, M., Fernandez, S., Bertolami, R., Bunke, H., and Schmidhuber, J. (2009). A novel connectionist system for unconstrained handwriting recognition. Pattern\u00a0Analysis and Machine Intelligence, IEEE Transactions on, 31(5), 855-868. 410",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7086",
    "text": "Graves, A., Mohamed, A., and Hinton, G. (2013). Speech recognition with deep recurrent neural networks. In ICASSP\u20192013, pages 6645-6649. 395, 398, 400, 410, 412, 413, 462",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7087",
    "text": "Graves, A., Wayne, G., and Danihelka, I. (2014a). Neural Turing machines. arXiv:1410.5401. 25",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7088",
    "text": "Graves, A., Wayne, G., and Danihelka, I. (2014b). Neural Turing machines. arXiv preprint arXiv:1410.5401. 418, 420",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7089",
    "text": "Grefenstette, E., Hermann, K. M., Suleyman, M., and Blunsom, P. (2015). Learning to transduce with unbounded memory. In NIPS\u20192015. 420",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7090",
    "text": "Greff, K., Srivastava, R. K., Koutmk, J., Steunebrink, B. R., and Schmidhuber, J. (2015). LSTM: a search space odyssey. arXiv preprint arXiv:1503.04 069 . 414",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7091",
    "text": "Gregor, K. and LeCun, Y. (2010a). Emergence of complex-like cells in a temporal product network with local receptive fields. Technical report, arXiv:1006.0448. 352",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7092",
    "text": "Gregor, K. and LeCun, Y. (2010b). Learning fast approximations of sparse coding. In L. Bottou and M. Littman, editors, Proceedings of the Twenty-seventh International\u00a0Conference on Machine Learning (ICML-10). ACM. 654",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7093",
    "text": "Gregor, K., Danihelka, I., Mnih, A., Blundell, C., and Wierstra, D. (2014). Deep autoregressive networks. In International Conference on Machine Learning (ICML\u20192014).\u00a0695",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7094",
    "text": "Gregor, K., Danihelka, I., Graves, A., and Wierstra, D. (2015). DRAW: A recurrent neural network for image generation. arXiv preprint arXiv:1502.04623. 700",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7095",
    "text": "Gretton, A., Borgwardt, K. M., Rasch, M. J., Scholkopf, B., and Smola, A. (2012). A kernel two-sample test. The Journal of Machine Learning Research, 13(1), 723-773.\u00a0705",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7096",
    "text": "Gfilgehre, Q. and Bengio, Y. (2013). Knowledge matters: Importance of prior information for optimization. In International Conference on Learning Representations (ICLR\u20192013).\u00a025",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7097",
    "text": "Guo, H. and Gelfand, S. B. (1992). Classification trees with neural network feature extraction. Neural Networks, IEEE Transactions on, 3(6), 923-933. 452",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7098",
    "text": "Gupta, S., Agrawal, A., Gopalakrishnan, K., and Narayanan, P. (2015). Deep learning with limited numerical precision. CoRR, abs/1502.02551. 454",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7099",
    "text": "Gutmann, M. and Hyvarinen, A. (2010). Noise-contrastive estimation: A new estimation principle for unnormalized statistical models. In Proceedings of The Thirteenth International Conference on Artificial Intelligence and Statistics (AISTATS\u201910). 622",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7100",
    "text": "Hadsell, R., Sermanet, P., Ben, J., Erkan, A., Han, J., Muller, U., and LeCun, Y. (2007). Online learning for offroad robots: Spatial label propagation to learn long-range\u00a0traversability. In Proceedings of Robotics: Science and Systems, Atlanta, GA, USA. 455",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7101",
    "text": "Hajnal, A., Maass, W., Pudlak, P., Szegedy, M., and Turan, G. (1993). Threshold circuits of bounded depth. J. Comput. System. Sci., 46, 129-154. 198",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7102",
    "text": "Hastad, J. (1986). Almost optimal lower bounds for small depth circuits. In Proceedings of the 18th annual ACM Symposium on Theory of Computing, pages 6-20, Berkeley,\u00a0California. ACM Press. 198",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7103",
    "text": "Hastad, J. and Goldmann, M. (1991). On the power of small-depth threshold circuits. Computational Complexity, 1, 113-129. 198",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7104",
    "text": "Hastie, T., Tibshirani, R., and Friedman, J. (2001). The elements of statistical learning: data mining, inference and prediction. Springer Series in Statistics. Springer Verlag.\u00a0145",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7105",
    "text": "He, K., Zhang, X., Ren, S., and Sun, J. (2015). Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. arXiv preprint arXiv:1502.01852.\u00a028, 192",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7106",
    "text": "Hebb, D. O. (1949). The Organization of Behavior. Wiley, New York. 14, 17, 658",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7107",
    "text": "Henaff, M., Jarrett, K., Kavukcuoglu, K., and LeCun, Y. (2011). Unsupervised learning of sparse features for scalable audio classification. In ISMIR\u201911. 525",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7108",
    "text": "Henderson, J. (2003). Inducing history representations for broad coverage statistical parsing. In HLT-NAACL, pages 103-110. 479",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7109",
    "text": "Henderson, J. (2004). Discriminative training of a neural network statistical parser. In",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7110",
    "text": "Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, page 95. 479",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7111",
    "text": "Henniges, M., Puertas, G., Bornschein, J., Eggert, J., and Lucke, J. (2010). Binary sparse coding. In Latent Variable Analysis and Signal Separation, pages 450-457. Springer.\u00a0642",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7112",
    "text": "Herault, J. and Ans, B. (1984). Circuits neuronaux a synapses modifiables: Decodage de messages composites par apprentissage non supervise. Comptes Rendus de l\u2019Academie\u00a0des Sciences, 299(111-13), 525\u2014528. 493",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7113",
    "text": "Hinton, G. (2012). Neural networks for machine learning. Coursera, video lectures. 307",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7114",
    "text": "Hinton, G., Deng, L., Dahl, G. E., Mohamed, A., Jaitly, N., Senior, A., Vanhoucke, V., Nguyen, P., Sainath, T., and Kingsbury, B. (2012a). Deep neural networks for acoustic\u00a0modeling in speech recognition. IEEE Signal Processing Magazine, 29(6), 82-97. 23,\u00a0462",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7115",
    "text": "Hinton, G., Vinyals, O., and Dean, J. (2015). Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531. 450",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7116",
    "text": "Hinton, G. E. (1989). Connectionist learning procedures. Artificial Intelligence, 40, 185-234. 496",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7117",
    "text": "Hinton, G. E. (1990). Mapping part-whole hierarchies into connectionist networks. Artificial Intelligence, 46(1), 47-75. 420",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7118",
    "text": "Hinton, G. E. (1999). Products of experts. In ICANN\u20191999. 572",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7119",
    "text": "Hinton, G. E. (2000). Training products of experts by minimizing contrastive divergence. Technical Report GCNU TR 2000-004, Gatsby Unit, University College London. 612,\u00a0678",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7120",
    "text": "Hinton, G. E. (2006). To recognize shapes, first learn to generate images. Technical Report UTML TR 2006-003, University of Toronto. 530, 597",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7121",
    "text": "Hinton, G. E. (2007a). How to do backpropagation in a brain. Invited talk at the NIPS\u20192007 Deep Learning Workshop. 658",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7122",
    "text": "Hinton, G. E. (2007b). Learning multiple layers of representation. Trends in cognitive sciences, 11(10), 428-434. 662",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7123",
    "text": "Hinton, G. E. (2010). A practical guide to training restricted Boltzmann machines. Technical Report UTML TR 2010-003, Department of Computer Science, University of\u00a0Toronto. 612",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7124",
    "text": "Hinton, G. E. and Ghahramani, Z. (1997). Generative models for discovering sparse distributed representations. Philosophical Transactions of the Royal Society of London.\u00a0146",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7125",
    "text": "Hinton, G. E. and McClelland, J. L. (1988). Learning representations by recirculation. In NIPS\u20191987, pages 358-366. 504",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7126",
    "text": "Hinton, G. E. and Roweis, S. (2003). Stochastic neighbor embedding. In NIPS\u20192002. 521",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7127",
    "text": "Hinton, G. E. and Salakhutdinov, R. (2006). Reducing the dimensionality of data with neural networks. Science, 313(5786), 504-507. 511, 526, 530, 531, 536",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7128",
    "text": "Hinton, G. E. and Sejnowski, T. J. (1986). Learning and relearning in Boltzmann machines. In D. E. Rumelhart and J. L. McClelland, editors, Parallel Distributed Processing,\u00a0volume 1, chapter 7, pages 282-317. MIT Press, Cambridge. 572, 656",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7129",
    "text": "Hinton, G. E. and Sejnowski, T. J. (1999). Unsupervised learning: foundations of neural computation. MIT press. 543",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7130",
    "text": "Hinton, G. E. and Shallice, T. (1991). Lesioning an attractor network: investigations of acquired dyslexia. Psychologica,l review, 98(1), 74. 13",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7131",
    "text": "Hinton, G. E. and Zemel, R. S. (1994). Autoencoders, minimum description length, and Helmholtz free energy. In NIPS\u20191993. 504",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7132",
    "text": "Hinton, G. E., Sejnowski, T. J., and Ackley, D. H. (1984). Boltzmann machines: Constraint satisfaction networks that learn. Technical Report TR-CMU-CS-84-119, Carnegie-Mellon\u00a0University, Dept. of Computer Science. 572, 656",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7133",
    "text": "Hinton, G. E., McClelland, J., and Rumelhart, D. (1986). Distributed representations. In D. E. Rumelhart and J. L. McClelland, editors, Parallel Distributed Processing:\u00a0Explorations in the Microstructure of Cognition, volume 1, pages 77-109. MIT Press,\u00a0Cambridge. 17, 225, 528",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7134",
    "text": "Hinton, G. E., Revow, M., and Dayan, P. (1995a). Recognizing handwritten digits using mixtures of linear models. In G. Tesauro, D. Touretzky, and T. Leen, editors, Advances\u00a0in Neural Information Processing Systems 7 (NIPS\u201994), pages 1015-1022. MIT Press,\u00a0Cambridge, MA. 491",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7135",
    "text": "Hinton, G. E., Dayan, P., Frey, B. J., and Neal, R. M. (1995b). The wake-sleep algorithm for unsupervised neural networks. Science, 268, 1558-1161. 506, 653",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7136",
    "text": "Hinton, G. E., Dayan, P., and Revow, M. (1997). Modelling the manifolds of images of handwritten digits. IEEE Transactions on Neural Networks, 8, 65-74. 501",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7137",
    "text": "Hinton, G. E., Welling, M., Teh, Y. W., and Osindero, S. (2001). A new view of ICA. In",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7138",
    "text": "Proceedings of 3rd International Conference on Independent Component Analysis and Blind Signal Separation (ICA\u201901), pages 746-751, San Diego, CA. 493",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7139",
    "text": "Hinton, G. E., Osindero, S., and Teh, Y. (2006). A fast learning algorithm for deep belief nets. Neural Computation, 18, 1527-1554. 14, 19, 27, 142, 530, 531, 662, 663",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7140",
    "text": "Hinton, G. E., Deng, L., Yu, D., Dahl, G. E., Mohamed, A., Jaitly, N., Senior, A., Vanhoucke, V., Nguyen, P., Sainath, T. N., and Kingsbury, B. (2012b). Deep neural\u00a0networks for acoustic modeling in speech recognition: The shared views of four research\u00a0groups. IEEE Signal Process. Mag., 29(6), 82-97. 101",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7141",
    "text": "Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. (2012c). Improving neural networks by preventing co-adaptation of feature detectors. Technical\u00a0report, arXiv:1207.0580. 238, 263, 267",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7142",
    "text": "Hinton, G. E., Vinyals, O., and Dean, J. (2014). Dark knowledge. Invited talk at the BayLearn Bay Area Machine Learning Symposium. 450",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7143",
    "text": "Hochreiter, S. (1991). Untersuchungen zu dynamischen neuronalen Netzen. Diploma thesis, T.U. Munchen. 18, 402, 404",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7144",
    "text": "Hochreiter, S. and Schmidhuber, J. (1995). Simplifying neural nets by discovering flat minima. In Advances in Neural Information Processing Systems 7, pages 529-536. MIT\u00a0Press. 243",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7145",
    "text": "Hochreiter, S. and Schmidhuber, J. (1997). Long short-term memory. Neural Computation, 9(8), 1735-1780. 18, 410, 413",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7146",
    "text": "Hochreiter, S., Bengio, Y., and Frasconi, P. (2001). Gradient flow in recurrent nets: the difficulty of learning long-term dependencies. In J. Kolen and S. Kremer, editors, Field\u00a0Guide to Dynamical Recurrent Networks. IEEE Press. 413",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7147",
    "text": "Holi, J. L. and Hwang, J.-N. (1993). Finite precision error analysis of neural network hardware implementations. Computers, IEEE Transactions on, 42(3), 281-290. 453",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7148",
    "text": "Holt, J. L. and Baker, T. E. (1991). Back propagation simulations using limited precision calculations. In Neural Networks, 1991., IJCNN-91-Seattle International Joint Conference on, volume 2, pages 121-126. IEEE. 453",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7149",
    "text": "Hornik, K., Stinchcombe, M., and White, H. (1989). Multilayer feedforward networks are universal approximators. Neural Networks, 2, 359-366. 197",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7150",
    "text": "Hornik, K., Stinchcombe, M., and White, H. (1990). Universal approximation of an unknown mapping and its derivatives using multilayer feedforward networks. Neural\u00a0networks, 3(5), 551-560. 197",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7151",
    "text": "Hsu, F.-H. (2002). Behind Deep Blue: Building the Computer That Defeated the World Chess Champion. Princeton University Press, Princeton, NJ, USA. 2",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7152",
    "text": "Huang, F. and Ogata, Y. (2002). Generalized pseudo-likelihood estimates for Markov random fields on lattice. Annals of the Institute of Statistical Mathematics, 54(1), 1-18.\u00a0618",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7153",
    "text": "Huang, P.-S., He, X., Gao, J., Deng, L., Acero, A., and Heck, L. (2013). Learning deep structured semantic models for web search using clickthrough data. In Proceedings of\u00a0the 22nd ACM international conference on Conference on information & knowledge\u00a0management, pages 2333-2338. ACM. 482",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7154",
    "text": "Hubel, D. and Wiesel, T. (1968). Receptive fields and functional architecture of monkey striate cortex. Journal of Physiology (London), 195, 215-243. 364",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7155",
    "text": "Hubel, D. H. and Wiesel, T. N. (1959). Receptive fields of single neurons in the cat\u2019s striate cortex. Journal of Physiology, 148, 574-591. 364",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7156",
    "text": "Hubel, D. H. and Wiesel, T. N. (1962). Receptive fields, binocular interaction, and functional architecture in the cat\u2019s visual cortex. Journal of Physiology (London), 160,\u00a0106-154. 364",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7157",
    "text": "Huszar, F. (2015). How (not) to train your generative model: schedule sampling, likelihood, adversary? arXiv:1511.05101. 699",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7158",
    "text": "Hutter, F., Hoos, H., and Leyton-Brown, K. (2011). Sequential model-based optimization for general algorithm configuration. In LION-5. Extended version as UBC Tech report\u00a0TR-2010-10. 438",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7159",
    "text": "Hyotyniemi, H. (1996). Turing machines are recurrent neural networks. In STeP\u201996, pages 13-24. 379",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7160",
    "text": "Hyvarinen, A. (1999). Survey on independent component analysis. Neural Computing Surveys, 2, 94-128. 493",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7161",
    "text": "Hyvarinen, A. (2005). Estimation of non-normalized statistical models using score matching. Journal of Machine Learning Research, 6, 695-709. 515, 619",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7162",
    "text": "Hyvarinen, A. (2007a). Connections between score matching, contrastive divergence, and pseudolikelihood for continuous-valued variables. IEEE Transactions on Neural\u00a0Networks, 18, 1529-1531. 620",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7163",
    "text": "Hyvarinen, A. (2007b). Some extensions of score matching. Computational Statistics and Data Analysis, 51, 2499-2512. 620",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7164",
    "text": "Hyvarinen, A. and Hoyer, P. O. (1999). Emergence of topography and complex cell properties from natural images using extensions of ica. In NIPS, pages 827-833. 495",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7165",
    "text": "Hyvarinen, A. and Pajunen, P. (1999). Nonlinear independent component analysis: Existence and uniqueness results. Neural Networks, 12(3), 429-439. 495",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7166",
    "text": "Hyvarinen, A., Karhunen, J., and Oja, E. (2001a). Independent Component Analysis. Wiley-Interscience. 493",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7167",
    "text": "Hyvarinen, A., Hoyer, P. O., and Inki, M. O. (2001b). Topographic independent component analysis. Neural Computation, 13(7), 1527-1558. 495",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7168",
    "text": "Hyvarinen, A., Hurri, J., and Hoyer, P. O. (2009). Natural Image Statistics: A probabilistic approach to early computational vision. Springer-Verlag. 370",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7169",
    "text": "Iba, Y. (2001). Extended ensemble Monte Carlo. International Journal of Modern Physics, C12, 623-656. 605",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7170",
    "text": "Inayoshi, H. and Kurita, T. (2005). Improved generalization by adding both autoassociation and hidden-layer noise to neural-network-based-classifiers. IEEE Workshop on Machine Learning for Signal Processing, pages 141\u2014-146. 517",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7171",
    "text": "Ioffe, S. and Szegedy, C. (2015). Batch normalization: Accelerating deep network training by reducing internal covariate shift. 100, 317, 320",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7172",
    "text": "Jacobs, R. A. (1988). Increased rates of convergence through learning rate adaptation. Neural networks, 1(4), 295-307. 307",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7173",
    "text": "Jacobs, R. A., Jordan, M. I., Nowlan, S. J., and Hinton, G. E. (1991). Adaptive mixtures of local experts. Neural Computation, 3, 79-87. 188, 452",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7174",
    "text": "Jaeger, H. (2003). Adaptive nonlinear system identification with echo state networks. In",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7175",
    "text": "Advances in Neural Information Processing Systems 15. 405",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7176",
    "text": "Jaeger, H. (2007a). Discovering multiscale dynamical features with hierarchical echo state networks. Technical report, Jacobs University. 400",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7177",
    "text": "Jaeger, H. (2007b). Echo state network. Scholarpedia, 2(9), 2330. 405",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7178",
    "text": "Jaeger, H. (2012). Long short-term memory in echo state networks: Details of a simulation study. Technical report, Technical report, Jacobs University Bremen. 406",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7179",
    "text": "Jaeger, H. and Haas, H. (2004). Harnessing nonlinearity: Predicting chaotic systems and saving energy in wireless communication. Science, 304(5667), 78-80. 27, 405",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7180",
    "text": "Jaeger, H., Lukosevicius, M., Popovici, D., and Siewert, U. (2007). Optimization and applications of echo state networks with leaky- integrator neurons. Neural Networks,\u00a020(3), 335-352. 409",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7181",
    "text": "Jain, V., Murray, J. F., Roth, F., Turaga, S., Zhigulin, V., Briggman, K. L., Helmstaedter, M. N., Denk, W., and Seung, H. S. (2007). Supervised learning of image restoration\u00a0with convolutional networks. In Computer Vision, 2007. ICCV 2007. IEEE 11th\u00a0International Conference on, pages 1-8. IEEE. 359",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7182",
    "text": "Jaitly, N. and Hinton, G. (2011). Learning a better representation of speech soundwaves using restricted Boltzmann machines. In Acoustics, Speech and Signal Processing\u00a0(ICASSP), 2011 IEEE International Conference on, pages 5884-5887. IEEE. 460",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7183",
    "text": "Jaitly, N. and Hinton, G. E. (2013). Vocal tract length perturbation (VTLP) improves speech recognition. In ICML\u20192013. 241",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7184",
    "text": "Jarrett, K., Kavukcuoglu, K., Ranzato, M., and LeCun, Y. (2009). What is the best multi-stage architecture for object recognition? In ICCV\u201909. 16, 24, 27, 173, 192, 226,\u00a0363, 364, 525",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7185",
    "text": "Jarzynski, C. (1997). Nonequilibrium equality for free energy differences. Phys. Rev. Lett., 78, 2690-2693. 627, 630",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7186",
    "text": "Jaynes, E. T. (2003). Probability Theory: The Logic of Science. Cambridge University Press. 53",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7187",
    "text": "Jean, S., Cho, K., Memisevic, R., and Bengio, Y. (2014). On using very large target vocabulary for neural machine translation. arXiv:1412.2007. 476",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7188",
    "text": "Jelinek, F. and Mercer, R. L. (1980). Interpolated estimation of Markov source parameters from sparse data. In E. S. Gelsema and L. N. Kanal, editors, Pattern Recognition in\u00a0Practice. North-Holland, Amsterdam. 464, 475",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7189",
    "text": "Jia, Y. (2013). Caffe: An open source convolutional architecture for fast feature embedding. http://caffe.berkeleyvision.org/. 25,210",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7190",
    "text": "Jia, Y., Huang, C., and Darrell, T. (2012). Beyond spatial pyramids: Receptive field learning for pooled image features. In Computer Vision and Pattern Recognition\u00a0(CVPR), 2012 IEEE Conference on, pages 3370-3377. IEEE. 345",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7191",
    "text": "Jim, K.-C., Giles, C. L., and Horne, B. G. (1996). An analysis of noise in recurrent neural networks: convergence and generalization. IEEE Transactions on Neural Networks,\u00a07(6), 1424-1438. 242",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7192",
    "text": "Jordan, M. I. (1998). Learning in Graphical Models. Kluwer, Dordrecht, Netherlands. 18",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7193",
    "text": "Joulin, A. and Mikolov, T. (2015). Inferring algorithmic patterns with stack-augmented recurrent nets. arXiv preprint arXiv:1503.01007. 420",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7194",
    "text": "Jozefowicz, R., Zaremba, W., and Sutskever, I. (2015). An empirical evaluation of recurrent network architectures. In ICML\u20192015. 306, 413, 414",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7195",
    "text": "Judd, J. S. (1989). Neural Network Design and the Complexity of Learning. MIT press. 293",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7196",
    "text": "Jutten, C. and Herault, J. (1991). Blind separation of sources, part I: an adaptive algorithm based on neuromimetic architecture. Signal Processing, 24, 1-10. 493",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7197",
    "text": "Kahou, S. E., Pal, C., Bouthillier, X., Froumenty, P., Gulgehre, c., Memisevic, R., Vincent, P., Courville, A., Bengio, Y., Ferrari, R. C., Mirza, M., Jean, S., Carrier, P. L., Dauphin,\u00a0Y., Boulanger-Lewandowski, N., Aggarwal, A., Zumer, J., Lamblin, P., Raymond,\u00a0J.-P., Desjardins, G., Pascanu, R., Warde-Farley, D., Torabi, A., Sharma, A., Bengio,\u00a0E., Cote, M., Konda, K. R., and Wu, Z. (2013). Combining modality specific deep\u00a0neural networks for emotion recognition in video. In Proceedings of the 15th ACM on\u00a0International Conference on Multimodal Interaction. 200",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7198",
    "text": "Kalchbrenner, N. and Blunsom, P. (2013). Recurrent continuous translation models. In EMNLP\u20192013. 476",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7199",
    "text": "Kalchbrenner, N., Danihelka, I., and Graves, A. (2015). Grid long short-term memory. arXiv preprint arXiv:1507.01526. 396",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7200",
    "text": "Kamyshanska, H. and Memisevic, R. (2015). The potential energy of an autoencoder. IEEE Transactions on Pattern Analysis and Machine Intelligence. 517",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7201",
    "text": "Karpathy, A. and Li, F.-F. (2015). Deep visual-semantic alignments for generating image descriptions. In CVPR\u20192015. arXiv:1412.2306. 102",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7202",
    "text": "Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., and Fei-Fei, L. (2014). Large-scale video classification with convolutional neural networks. In CVPR. 21",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7203",
    "text": "Karush, W. (1939). Minima of Functions of Several Variables with Inequalities as Side Constraints. Master\u2019s thesis, Dept. of Mathematics, Univ. of Chicago. 95",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7204",
    "text": "Katz, S. M. (1987). Estimation of probabilities from sparse data for the language model component of a speech recognizer. IEEE Transactions on Acoustics, Speech, and Signal\u00a0Processing, ASSP-35(3), 400-401. 464, 475",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7205",
    "text": "Kavukcuoglu, K., Ranzato, M., and LeCun, Y. (2008). Fast inference in sparse coding algorithms with applications to object recognition. Technical report, Computational and\u00a0Biological Learning Lab, Courant Institute, NYU. Tech Report CBLL-TR-2008-12-01.\u00a0525",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7206",
    "text": "Kavukcuoglu, K., Ranzato, M.-A., Fergus, R., and LeCun, Y. (2009). Learning invariant features through topographic filter maps. In CVPR\u20192009. 525",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7207",
    "text": "Kavukcuoglu, K., Sermanet, P., Boureau, Y.-L., Gregor, K., Mathieu, M., and LeCun, Y. (2010). Learning convolutional feature hierarchies for visual recognition. In NIPS\u20192010.\u00a0364, 525",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7208",
    "text": "Kelley, H. J. (1960). Gradient theory of optimal flight paths. ARS Journal, 30(10), 947-954. 224",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7209",
    "text": "Khan, F., Zhu, X., and Mutlu, B. (2011). How do humans teach: On curriculum learning and teaching dimension. In Advances in Neural Information Processing Systems 24\u00a0(NIPS\u201911), pages 1449-1457. 328",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7210",
    "text": "Kim, S. K., McAfee, L. C., McMahon, P. L., and Olukotun, K. (2009). A highly scalable restricted Boltzmann machine FPGA implementation. In Field Programmable Logic\u00a0and Applications, 2009. FPL 2009. International Conference on, pages 367-372. IEEE.\u00a0453",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7211",
    "text": "Kindermann, R. (1980). Markov Random Fields and Their Applications (Contemporary Mathematics ; V. 1). American Mathematical Society. 568",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7212",
    "text": "Kingma, D. and Ba, J. (2014). Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980. 308",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7213",
    "text": "Kingma, D. and LeCun, Y. (2010). Regularized estimation of image statistics by score matching. In NIPS\u20192010. 515, 622",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7214",
    "text": "Kingma, D., Rezende, D., Mohamed, S., and Welling, M. (2014). Semi-supervised learning with deep generative models. In NIPS\u20192014. 428",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7215",
    "text": "Kingma, D. P. (2013). Fast gradient-based inference with continuous latent variable models in auxiliary form. Technical report, arxiv:1306.0733. 654, 691, 698",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7216",
    "text": "Kingma, D. P. and Welling, M. (2014a). Auto-encoding variational bayes. In Proceedings of the International Conference on Learning Representations (ICLR). 691, 701",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7217",
    "text": "Kingma, D. P. and Welling, M. (2014b). Efficient gradient-based inference through transformations between bayes nets and neural nets. Technical report, arxiv:1402.0480.\u00a0691",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7218",
    "text": "Kirkpatrick, S., Jr., C. D. G., , and Vecchi, M. P. (1983). Optimization by simulated annealing. Science, 220, 671-680. 327",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7219",
    "text": "Kiros, R., Salakhutdinov, R., and Zemel, R. (2014a). Multimodal neural language models. In ICML \u20192014. 102",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7220",
    "text": "Kiros, R., Salakhutdinov, R., and Zemel, R. (2014b). Unifying visual-semantic embeddings with multimodal neural language models. arXiv:1411.2539 [cs.LG]. 102, 410",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7221",
    "text": "Klementiev, A., Titov, I., and Bhattarai, B. (2012). Inducing crosslingual distributed representations of words. In Proceedings of COLING 2012. 478, 541",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7222",
    "text": "Knowles-Barley, S., Jones, T. R., Morgan, J., Lee, D., Kasthuri, N., Lichtman, J. W., and Pfister, H. (2014). Deep learning for the connectome. GPU Technology Conference. 26",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7223",
    "text": "Koller, D. and Friedman, N. (2009). Probabilistic Graphical Models: Principles and Techniques. MIT Press. 585, 597, 647",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7224",
    "text": "Konig, Y., Bourlard, H., and Morgan, N. (1996). REMAP: Recursive estimation and maximization of a posteriori probabilities - application to transition-based connectionist\u00a0speech recognition. In D. Touretzky, M. Mozer, and M. Hasselmo, editors, Advances in\u00a0Neural Information Processing Systems 8 (NIPS\u201995). MIT Press, Cambridge, MA. 461",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7225",
    "text": "Koren, Y. (2009). The BellKor solution to the Netflix grand prize. 258, 481",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7226",
    "text": "Kotzias, D., Denil, M., de Freitas, N., and Smyth, P. (2015). From group to individual labels using deep features. In ACM SIGKDD. 106",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7227",
    "text": "Koutnik, J., Greff, K., Gomez, F., and Schmidhuber, J. (2014). A clockwork RNN. In ICML \u20192014. 409",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7228",
    "text": "Kocisky, T., Hermann, K. M., and Blunsom, P. (2014). Learning Bilingual Word Representations by Marginalizing Alignments. In Proceedings of ACL. 478",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7229",
    "text": "Krause, O., Fischer, A., Glasmachers, T., and Igel, C. (2013). Approximation properties of DBNs with binary hidden units and real-valued visible units. In ICML\u20192013. 555",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7230",
    "text": "Krizhevsky, A. (2010). Convolutional deep belief networks on CIFAR-10. Technical report, University of Toronto. Unpublished Manuscript: http://www.cs.utoronto.ca/ kriz/conv-cifar10-aug2010.pdf. 448",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7231",
    "text": "Krizhevsky, A. and Hinton, G. (2009). Learning multiple layers of features from tiny images. Technical report, University of Toronto. 21, 563",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7232",
    "text": "Krizhevsky, A. and Hinton, G. E. (2011). Using very deep autoencoders for content-based image retrieval. In ESANN. 527",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7233",
    "text": "Krizhevsky, A., Sutskever, I., and Hinton, G. (2012). ImageNet classification with deep convolutional neural networks. In NIPS\u20192012. 23, 24, 27, 100, 200, 371, 456, 460",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7234",
    "text": "Krueger, K. A. and Dayan, P. (2009). Flexible shaping: how learning in small steps helps. Cognition, 110, 380-394. 328",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7235",
    "text": "Kuhn, H. W. and Tucker, A. W. (1951). Nonlinear programming. In Proceedings of the Second Berkeley Symposium on Mathematical Statistics and Probability, pages 481-492,\u00a0Berkeley, Calif. University of California Press. 95",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7236",
    "text": "Kumar, A., Irsoy, O., Su, J., Bradbury, J., English, R., Pierce, B., Ondruska, P., Iyyer, M., Gulrajani, I., and Socher, R. (2015). Ask me anything: Dynamic memory networks\u00a0for natural language processing. arXiv:1506.07285. 420, 487",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7237",
    "text": "Kumar, M. P., Packer, B., and Koller, D. (2010). Self-paced learning for latent variable models. In NIPS\u20192010. 328",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7238",
    "text": "Lang, K. J. and Hinton, G. E. (1988). The development of the time-delay neural network architecture for speech recognition. Technical Report CMU-CS-88-152, Carnegie-Mellon\u00a0University. 367, 374, 408",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7239",
    "text": "Lang, K. J., Waibel, A. H., and Hinton, G. E. (1990). A time-delay neural network architecture for isolated word recognition. Neural networks, 3(1), 23-43. 374",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7240",
    "text": "Langford, J. and Zhang, T. (2008). The epoch-greedy algorithm for contextual multi-armed bandits. In NIPS\u20192008, pages 1096\u20141103. 482",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7241",
    "text": "Lappalainen, H., Giannakopoulos, X., Honkela, A., and Karhunen, J. (2000). Nonlinear independent component analysis using ensemble learning: Experiments and discussion.\u00a0In Proc. ICA. Citeseer. 495",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7242",
    "text": "Larochelle, H. and Bengio, Y. (2008). Classification using discriminative restricted Boltzmann machines. In ICML\u20192008. 244, 255, 532, 688, 717",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7243",
    "text": "Larochelle, H. and Hinton, G. E. (2010). Learning to combine foveal glimpses with a third-order Boltzmann machine. In Advances in Neural Information Processing Systems\u00a023, pages 1243-1251. 367",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7244",
    "text": "Larochelle, H. and Murray, I. (2011). The Neural Autoregressive Distribution Estimator. In AISTATS\u20192011. 707, 710",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7245",
    "text": "Larochelle, H., Erhan, D., and Bengio, Y. (2008). Zero-data learning of new tasks. In AAAI Conference on Artificial Intelligence. 541",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7246",
    "text": "Larochelle, H., Bengio, Y., Louradour, J., and Lamblin, P. (2009). Exploring strategies for training deep neural networks. Journal of Machine Learning Research, 10, 1-40. 537",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7247",
    "text": "Lasserre, J. A., Bishop, C. M., and Minka, T. P. (2006). Principled hybrids of generative and discriminative models. In Proceedings of the Computer Vision and Pattern Recognition\u00a0Conference (CVPR\u201906), pages 87-94, Washington, DC, USA. IEEE Computer Society.\u00a0244, 253",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7248",
    "text": "Le, Q., Ngiam, J., Chen, Z., hao Chia, D. J., Koh, P. W., and Ng, A. (2010). Tiled convolutional neural networks. In J. Lafferty, C. K. I. Williams, J. Shawe-Taylor,\u00a0R. Zemel, and A. Culotta, editors, Advances in Neural Information Processing Systems\u00a023 (NIPS\u201910), pages 1279-1287. 352",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7249",
    "text": "Le, Q., Ngiam, J., Coates, A., Lahiri, A., Prochnow, B., and Ng, A. (2011). On optimization methods for deep learning. In Proc. ICML\u20192011. ACM. 316",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7250",
    "text": "Le, Q., Ranzato, M., Monga, R., Devin, M., Corrado, G., Chen, K., Dean, J., and Ng, A. (2012). Building high-level features using large scale unsupervised learning. In\u00a0ICML\u20192012. 24, 27",
    "chapter": "",
    "chapter_id": "main-42.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7251",
    "text": "Le Roux, N. and Bengio, Y. (2008). Representational power of restricted Boltzmann machines and deep belief networks. Neural Computation, 20(6), 1631-1649. 555, 657",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7252",
    "text": "Le Roux, N. and Bengio, Y. (2010). Deep belief networks are compact universal approximators. Neural Computation, 22(8), 2192-2207. 555",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7253",
    "text": "LeCun, Y. (1985). Une procedure d\u2019apprentissage pour Reseau a seuil assymetrique. In Cognitiva 85: A la Frontiere de l\u2019Intelligence Artificielle, des Sciences de la Connaissance\u00a0et des Neurosciences, pages 599-604, Paris 1985. CESTA, Paris. 224",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7254",
    "text": "LeCun, Y. (1986). Learning processes in an asymmetric threshold network. In F. Fogelman-Soulie, E. Bienenstock, and G. Weisbuch, editors, Disordered Systems and Biological Organization, pages 233-240. Springer-Verlag, Les Houches, France. 350",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7255",
    "text": "LeCun, Y. (1987). Modeles connexionistes de l\u2019apprentissage. Ph.D. thesis, Universite de Paris VI. 18, 504, 517",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7256",
    "text": "LeCun, Y. (1989). Generalization and network design strategies. Technical Report CRG-TR-89-4, University of Toronto. 330, 350",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7257",
    "text": "LeCun, Y., Jackel, L. D., Boser, B., Denker, J. S., Graf, H. P., Guyon, I., Henderson, D., Howard, R. E., and Hubbard, W. (1989). Handwritten digit recognition: Applications\u00a0of neural network chips and automatic learning. IEEE Communications Magazine,\u00a027(11), 41-46. 368",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7258",
    "text": "LeCun, Y., Bottou, L., Orr, G. B., and Muller, K.-R. (1998a). Efficient backprop. In Neural Networks, Tricks of the Trade, Lecture Notes in Computer Science LNCS 1524.\u00a0Springer Verlag. 310, 431",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7259",
    "text": "LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P. (1998b). Gradient based learning applied to document recognition. Proc. IEEE. 16, 18, 21, 27, 371, 460, 462",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7260",
    "text": "LeCun, Y., Kavukcuoglu, K., and Farabet, C. (2010). Convolutional networks and applications in vision. In Circuits and Systems (ISCAS), Proceedings of 2010 IEEE\u00a0International Symposium on, pages 253-256. IEEE. 371",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7261",
    "text": "L\u2019Ecuyer, P. (1994). Efficiency improvement and variance reduction. In Proceedings of the 1994 Winter Simulation Conference, pages 122\u2014132. 692",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7262",
    "text": "Lee, C.-Y., Xie, S., Gallagher, P., Zhang, Z., and Tu, Z. (2014). Deeply-supervised nets. arXiv preprint arXiv:1409.5185. 326",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7263",
    "text": "Lee, H., Battle, A., Raina, R., and Ng, A. (2007). Efficient sparse coding algorithms. In B. Scholkopf, J. Platt, and T. Hoffman, editors, Advances in Neural Information\u00a0Processing Systems 19 (NIPS\u201906), pages 801-808. MIT Press. 639",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7264",
    "text": "Lee, H., Ekanadham, C., and Ng, A. (2008). Sparse deep belief net model for visual area V2. In NIPS\u201907. 255",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7265",
    "text": "Lee, H., Grosse, R., Ranganath, R., and Ng, A. Y. (2009). Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations. In L. Bottou\u00a0and M. Littman, editors, Proceedings of the Twenty-sixth International Conference on\u00a0Machine Learning (ICML\u201909). ACM, Montreal, Canada. 363, 685, 686",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7266",
    "text": "Lee, Y. J. and Grauman, K. (2011). Learning the easy things first: self-paced visual category discovery. In CVPR \u20192011. 328",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7267",
    "text": "Leibniz, G. W. (1676). Memoir using the chain rule. (Cited in TMME 7:2&3 p 321-332, 2010). 224",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7268",
    "text": "Lenat, D. B. and Guha, R. V. (1989). Building large knowledge-based systems; representation and inference in the Cyc project. Addison-Wesley Longman Publishing Co., Inc. 2",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7269",
    "text": "Leshno, M., Lin, V. Y., Pinkus, A., and Schocken, S. (1993). Multilayer feedforward networks with a nonpolynomial activation function can approximate any function.\u00a0Neural Networks, 6, 861\u2014867. 197, 198",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7270",
    "text": "Levenberg, K. (1944). A method for the solution of certain non-linear problems in least squares. Quarterly Journal of Applied Mathematics, II(2), 164-168. 312",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7271",
    "text": "L\u2019Hopital, G. F. A. (1696). Analyse des infiniment petits, pour intelligence des lignes courbes. Paris: L\u2019Imprimerie Royale. 224",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7272",
    "text": "Li, Y., Swersky, K., and Zemel, R. S. (2015). Generative moment matching networks. CoRR, abs/1502.02761. 705",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7273",
    "text": "Lin, T., Horne, B. G., Tino, P., and Giles, C. L. (1996). Learning long-term dependencies is not as difficult with NARX recurrent neural networks. IEEE Transactions on Neural\u00a0Networks, 7(6), 1329-1338. 408",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7274",
    "text": "Lin, Y., Liu, Z., Sun, M., Liu, Y., and Zhu, X. (2015). Learning entity and relation embeddings for knowledge graph completion. In Proc. AAAI\u201915. 486",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7275",
    "text": "Linde, N. (1992). The machine that changed the world, episode 3. Documentary miniseries. 2",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7276",
    "text": "Lindsey, C. and Lindblad, T. (1994). Review of hardware neural networks: a user\u2019s perspective. In Proc. Third Workshop on Neural Networks: From Biology to High\u00a0Energy Physics, pages 195\u2014202, Isola d\u2019Elba, Italy. 453",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7277",
    "text": "Linnainmaa, S. (1976). Taylor expansion of the accumulated rounding error. BIT Numerical Mathematics, 16(2), 146-160. 224",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7278",
    "text": "LISA (2008). Deep learning tutorials: Restricted Boltzmann machines. Technical report, LISA Lab, Universite de Montreal. 590",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7279",
    "text": "Long, P. M. and Servedio, R. A. (2010). Restricted Boltzmann machines are hard to approximately evaluate or simulate. In Proceedings of the 27th International Conference\u00a0on Machine Learning (ICML\u201910). 660",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7280",
    "text": "Lotter, W., Kreiman, G., and Cox, D. (2015). Unsupervised learning of visual structure using predictive generative networks. arXiv preprint arXiv:1511.06380. 546, 547",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7281",
    "text": "Lovelace, A. (1842). Notes upon L. F. Menabrea\u2019s \u201cSketch of the Analytical Engine invented by Charles Babbage\u201d. 1",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7282",
    "text": "Lu, L., Zhang, X., Cho, K., and Renals, S. (2015). A study of the recurrent neural network encoder-decoder for large vocabulary speech recognition. In Proc. Interspeech. 462",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7283",
    "text": "Lu, T., Pal, D., and Pal, M. (2010). Contextual multi-armed bandits. In International Conference on Artificial Intelligence and Statistics, pages 485-492. 482",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7284",
    "text": "Luenberger, D. G. (1984). Linear and Nonlinear Programming. Addison Wesley. 316",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7285",
    "text": "Lukosevicius, M. and Jaeger, H. (2009). Reservoir computing approaches to recurrent neural network training. Computer Science Review, 3(3), 127-149. 405",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7286",
    "text": "Luo, H., Shen, R., Niu, C., and Ullrich, C. (2011). Learning class-relevant features and class-irrelevant features via a hybrid third-order RBM. In International Conference on\u00a0Artificial Intelligence and Statistics, pages 470-478. 688",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7287",
    "text": "Luo, H., Carrier, P. L., Courville, A., and Bengio, Y. (2013). Texture modeling with convolutional spike-and-slab RBMs and deep extensions. In AISTATS\u20192013. 102",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7288",
    "text": "Lyu, S. (2009). Interpretation and generalization of score matching. In Proceedings of the Twenty-fifth Conference in Uncertainty in Artificial Intelligence (UAI\u201909). 620",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7289",
    "text": "Ma, J., Sheridan, R. P., Liaw, A., Dahl, G. E., and Svetnik, V. (2015). Deep neural nets as a method for quantitative structure - activity relationships. J. Chemical information\u00a0and modeling. 532",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7290",
    "text": "Maas, A. L., Hannun, A. Y., and Ng, A. Y. (2013). Rectifier nonlinearities improve neural network acoustic models. In ICML Workshop on Deep Learning for Audio, Speech, and\u00a0Language Processing. 192",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7291",
    "text": "Maass, W. (1992). Bounds for the computational power and learning complexity of analog neural nets (extended abstract). In Proc. of the 25th ACM Symp. Theory of Computing,\u00a0pages 335-344. 198",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7292",
    "text": "Maass, W., Schnitger, G., and Sontag, E. D. (1994). A comparison of the computational power of sigmoid and Boolean threshold circuits. Theoretical Advances in Neural\u00a0Computation and Learning, pages 127-151. 198",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7293",
    "text": "Maass, W., Natschlaeger, T., and Markram, H. (2002). Real-time computing without stable states: A new framework for neural computation based on perturbations. Neural\u00a0Computation, 14(11), 2531-2560. 405",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7294",
    "text": "MacKay, D. (2003). Information Theory, Inference and Learning Algorithms. Cambridge University Press. 73",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7295",
    "text": "Maclaurin, D., Duvenaud, D., and Adams, R. P. (2015). Gradient-based hyperparameter optimization through reversible learning. arXiv preprint arXiv:1502.03492. 437",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7296",
    "text": "Mao, J., Xu, W., Yang, Y., Wang, J., Huang, Z., and Yuille, A. L. (2015). Deep captioning with multimodal recurrent neural networks. In ICLR\u20192015. arXiv:1410.1090. 102",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7297",
    "text": "Marcotte, P. and Savard, G. (1992). Novel approaches to the discrimination problem. Zeitschrift fur Operations Research (Theory), 36, 517-545. 276",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7298",
    "text": "Marlin, B. and de Freitas, N. (2011). Asymptotic efficiency of deterministic estimators for discrete energy-based models: Ratio matching and pseudolikelihood. In UAI\u20192011. 619,\u00a0621",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7299",
    "text": "Marlin, B., Swersky, K., Chen, B., and de Freitas, N. (2010). Inductive principles for restricted Boltzmann machine learning. In Proceedings of The Thirteenth International\u00a0Conference on Artificial Intelligence and Statistics (AISTATS\u201910), volume 9, pages\u00a0509-516. 615, 620, 621",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7300",
    "text": "Marquardt, D. W. (1963). An algorithm for least-squares estimation of non-linear parameters. Journal of the Society of Industrial and Applied Mathematics, 11(2), 431-441. 312",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7301",
    "text": "Marr, D. and Poggio, T. (1976). Cooperative computation of stereo disparity. Science, 194. 367",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7302",
    "text": "Martens, J. (2010). Deep learning via Hessian-free optimization. In L. Bottou and M. Littman, editors, Proceedings of the Twenty-seventh International Conference on\u00a0Machine Learning (ICML-10), pages 735-742. ACM. 304",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7303",
    "text": "Martens, J. and Medabalimi, V. (2014). On the expressive efficiency of sum product networks. arXiv:1411.7717. 556",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7304",
    "text": "Martens, J. and Sutskever, I. (2011). Learning recurrent neural networks with Hessian-free optimization. In Proc. ICML\u20192011. ACM. 414",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7305",
    "text": "Mase, S. (1995). Consistency of the maximum pseudo-likelihood estimator of continuous state space Gibbsian processes. The Annals of Applied Probability, 5(3), pp. 603-612.\u00a0618",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7306",
    "text": "McClelland, J., Rumelhart, D., and Hinton, G. (1995). The appeal of parallel distributed processing. In Computation & intelligence, pages 305-341. American Association for\u00a0Artificial Intelligence. 17",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7307",
    "text": "McCulloch, W. S. and Pitts, W. (1943). A logical calculus of ideas immanent in nervous activity. Bulletin of Mathematical Biophysics, 5, 115-133. 14, 15",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7308",
    "text": "Mead, C. and Ismail, M. (2012). Analog VLSI implementation of neural systems, volume 80. Springer Science & Business Media. 453",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7309",
    "text": "Melchior, J., Fischer, A., and Wiskott, L. (2013). How to center binary deep Boltzmann machines. arXiv preprint arXiv:1311.1354 . 675",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7310",
    "text": "Memisevic, R. and Hinton, G. E. (2007). Unsupervised learning of image transformations.",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7311",
    "text": "In Proceedings of the Computer Vision and Pattern Recognition Conference (CVPR\u201907). 688",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7312",
    "text": "Memisevic, R. and Hinton, G. E. (2010). Learning to represent spatial transformations with factored higher-order Boltzmann machines. Neural Computation,22(6), 1473-1492.\u00a0688",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7313",
    "text": "Mesnil, G., Dauphin, Y., Glorot, X., Rifai, S., Bengio, Y., Goodfellow, I., Lavoie, E., Muller, X., Desjardins, G., Warde-Farley, D., Vincent, P., Courville, A., and Bergstra,\u00a0J. (2011). Unsupervised and transfer learning challenge: a deep learning approach. In\u00a0JMLR W&CP: Proc. Unsupervised and Transfer Learning, volume 7. 200, 534, 540",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7314",
    "text": "Mesnil, G., Rifai, S., Dauphin, Y., Bengio, Y., and Vincent, P. (2012). Surfing on the manifold. Learning Workshop, Snowbird. 713",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7315",
    "text": "Miikkulainen, R. and Dyer, M. G. (1991). Natural language processing with modular PDP networks and distributed lexicon. Cognitive Science, 15, 343-399. 479",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7316",
    "text": "Mikolov, T. (2012). Statistical Language Models based on Neural Networks. Ph.D. thesis, Brno University of Technology. 416",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7317",
    "text": "Mikolov, T., Deoras, A., Kombrink, S., Burget, L., and Cernocky, J. (2011a). Empirical evaluation and combination of advanced language modeling techniques. In Proc. 12th annual conference of the international speech communication association (INTERSPEECH\u00a02011). 474",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7318",
    "text": "Mikolov, T., Deoras, A., Povey, D., Burget, L., and Cernocky, J. (2011b). Strategies for training large scale neural network language models. In Proc. ASRU\u20192011. 328, 474",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7319",
    "text": "Mikolov, T., Chen, K., Corrado, G., and Dean, J. (2013a). Efficient estimation of word representations in vector space. In International Conference on Learning Representations: Workshops Track. 538",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7320",
    "text": "Mikolov, T., Le, Q. V., and Sutskever, I. (2013b). Exploiting similarities among languages for machine translation. Technical report, arXiv:1309.4168. 541",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7321",
    "text": "Minka, T. (2005). Divergence measures and message passing. Microsoft Research Cambridge UK Tech Rep MSRTR2005173 , 72(TR-2005-173). 626",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7322",
    "text": "Minsky, M. L. and Papert, S. A. (1969). Perceptrons. MIT Press, Cambridge. 15",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7323",
    "text": "Mirza, M. and Osindero, S. (2014). Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784 . 703",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7324",
    "text": "Mishkin, D. and Matas, J. (2015). All you need is a good init. arXiv preprint arXiv:1511.06422 . 305",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7325",
    "text": "Misra, J. and Saha, I. (2010). Artificial neural networks in hardware: A survey of two decades of progress. Neurocomputing, 74(1), 239-255. 453",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7326",
    "text": "Mitchell, T. M. (1997). Machine Learning. McGraw-Hill, New York. 99",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7327",
    "text": "Miyato, T., Maeda, S., Koyama, M., Nakae, K., and Ishii, S. (2015). Distributional smoothing with virtual adversarial training. In ICLR. Preprint: arXiv:1507.00677. 269",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7328",
    "text": "Mnih, A. and Gregor, K. (2014). Neural variational inference and learning in belief networks. In ICML\u20192014. 693, 695",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7329",
    "text": "Mnih, A. and Hinton, G. E. (2007). Three new graphical models for statistical language modelling. In Z. Ghahramani, editor, Proceedings of the Twenty-fourth International\u00a0Conference on Machine Learning (ICML\u201907), pages 641-648. ACM. 466",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7330",
    "text": "Mnih, A. and Hinton, G. E. (2009). A scalable hierarchical distributed language model. In D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, Advances in Neural\u00a0Information Processing Systems 21 (NIPS\u201908), pages 1081-1088. 469",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7331",
    "text": "Mnih, A. and Kavukcuoglu, K. (2013). Learning word embeddings efficiently with noise-contrastive estimation. In C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Weinberger, editors, Advances in Neural Information Processing Systems 26, pages\u00a02265-2273. Curran Associates, Inc. 474, 624",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7332",
    "text": "Mnih, A. and Teh, Y. W. (2012). A fast and simple algorithm for training neural probabilistic language models. In ICML\u20192012, pages 1751-1758. 474",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7333",
    "text": "Mnih, V. and Hinton, G. (2010). Learning to detect roads in high-resolution aerial images. In Proceedings of the 11th European Conference on Computer Vision (ECCV). 102",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7334",
    "text": "Mnih, V., Larochelle, H., and Hinton, G. (2011). Conditional restricted Boltzmann machines for structure output prediction. In Proc. Conf. on Uncertainty in Artificial\u00a0Intelligence (UAI). 687",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7335",
    "text": "Mnih, V., Kavukcuoglo, K., Silver, D., Graves, A., Antonoglou, I., and Wierstra, D. (2013). Playing Atari with deep reinforcement learning. Technical report, arXiv:1312.5602. 106",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7336",
    "text": "Mnih, V., Heess, N., Graves, A., and Kavukcuoglu, K. (2014). Recurrent models of visual attention. In Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K. Weinberger,\u00a0editors, NIPS\u20192014, pages 2204-2212. 693",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7337",
    "text": "Mnih, V., Kavukcuoglo, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., Graves, A., Riedmiller, M., Fidgeland, A. K., Ostrovski, G., Petersen, S., Beattie, C., Sadik, A.,\u00a0Antonoglou, I., King, H., Kumaran, D., Wierstra, D., Legg, S., and Hassabis, D. (2015).\u00a0Human-level control through deep reinforcement learning. Nature, 518, 529-533. 25",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7338",
    "text": "Mobahi, H. and Fisher, III, J. W. (2015). A theoretical analysis of optimization by Gaussian continuation. In AAAI\u20192015. 327",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7339",
    "text": "Mobahi, H., Collobert, R., and Weston, J. (2009). Deep learning from temporal coherence in video. In L. Bottou and M. Littman, editors, Proceedings of the 26th International\u00a0Conference on Machine Learning, pages 737-744, Montreal. Omnipress. 496",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7340",
    "text": "Mohamed, A., Dahl, G., and Hinton, G. (2009). Deep belief networks for phone recognition. 461",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7341",
    "text": "Mohamed, A., Sainath, T. N., Dahl, G., Ramabhadran, B., Hinton, G. E., and Picheny, M. A. (2011). Deep belief networks using discriminative features for phone recognition. In\u00a0Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference\u00a0on, pages 5060-5063. IEEE. 461",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7342",
    "text": "Mohamed, A., Dahl, G., and Hinton, G. (2012a). Acoustic modeling using deep belief networks. IEEE Trans. on Audio, Speech and Language Processing, 20(1), 14-22. 461",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7343",
    "text": "Mohamed, A., Hinton, G., and Penn, G. (2012b). Understanding how deep belief networks perform acoustic modelling. In Acoustics, Speech and Signal Processing (ICASSP),\u00a02012 IEEE International Conference on, pages 4273-4276. IEEE. 461",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7344",
    "text": "Moller, M. F. (1993). A scaled conjugate gradient algorithm for fast supervised learning. Neural Networks, 6, 525-533. 316",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7345",
    "text": "Montavon, G. and Muller, K.-R. (2012). Deep Boltzmann machines and the centering trick. In G. Montavon, G. Orr, and K.-R. Muller, editors, Neural Networks: Tricks of\u00a0the Trade, volume 7700 of Lecture Notes in Computer Science, pages 621-637. Preprint:\u00a0http://arxiv.org/abs/1203.3783. 675",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7346",
    "text": "Montufar, G. (2014). Universal approximation depth and errors of narrow belief networks with discrete units. Neural Computation, 26. 555",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7347",
    "text": "Montufar, G. and Ay, N. (2011). Refinements of universal approximation results for deep belief networks and restricted Boltzmann machines. Neural Computation, 23(5),\u00a01306-1319. 555",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7348",
    "text": "Montufar, G. F., Pascanu, R., Cho, K., and Bengio, Y. (2014). On the number of linear regions of deep neural networks. In NIPS\u20192014. 19, 199",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7349",
    "text": "Mor-Yosef, S., Samueloff, A., Modan, B., Navot, D., and Schenker, J. G. (1990). Ranking the risk factors for cesarean: logistic regression analysis of a nationwide study. Obstet\u00a0Gynecol, 75(6), 944-7. 3",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7350",
    "text": "Morin, F. and Bengio, Y. (2005). Hierarchical probabilistic neural network language model. In AISTATS\u20192005. 469, 471",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7351",
    "text": "Mozer, M. C. (1992). The induction of multiscale temporal structure. In J. M. S. Hanson and R. Lippmann, editors, Advances in Neural Information Processing Systems 4\u00a0(NIPS\u201991), pages 275-282, San Mateo, CA. Morgan Kaufmann. 409",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7352",
    "text": "Murphy, K. P. (2012). Machine Learning: a Probabilistic Perspective. MIT Press, Cambridge, MA, USA. 62, 98, 145",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7353",
    "text": "Murray, B. U. I. and Larochelle, H. (2014). A deep and tractable density estimator. In ICML\u20192014. 189, 712",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7354",
    "text": "Nair, V. and Hinton, G. (2010). Rectified linear units improve restricted Boltzmann machines. In ICML\u20192010. 16, 173, 196",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7355",
    "text": "Nair, V. and Hinton, G. E. (2009). 3d object recognition with deep belief nets. In Y. Bengio, D. Schuurmans, J. D. Lafferty, C. K. I. Williams, and A. Culotta, editors, Advances in\u00a0Neural Information Processing Systems 22, pages 1339-1347. Curran Associates, Inc.\u00a0688",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7356",
    "text": "Narayanan, H. and Mitter, S. (2010). Sample complexity of testing the manifold hypothesis. In NIPS\u20192010. 163",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7357",
    "text": "Naumann, U. (2008). Optimal Jacobian accumulation is NP-complete. Mathematical Programming, 112(2), 427-441. 221",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7358",
    "text": "Navigli, R. and Velardi, P. (2005). Structural semantic interconnections: a knowledge-based approach to word sense disambiguation. IEEE Trans. Pattern Analysis and Machine Intelligence, 27(7), 1075\u20141086. 486",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7359",
    "text": "Neal, R. and Hinton, G. (1999). A view of the EM algorithm that justifies incremental, sparse, and other variants. In M. I. Jordan, editor, Learning in Graphical Models. MIT\u00a0Press, Cambridge, MA. 636",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7360",
    "text": "Neal, R. M. (1990). Learning stochastic feedforward networks. Technical report. 694",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7361",
    "text": "Neal, R. M. (1993). Probabilistic inference using Markov chain Monte-Carlo methods. Technical Report CRG-TR-93-1, Dept. of Computer Science, University of Toronto. 682",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7362",
    "text": "Neal, R. M. (1994). Sampling from multimodal distributions using tempered transitions. Technical Report 9421, Dept. of Statistics, University of Toronto. 605",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7363",
    "text": "Neal, R. M. (1996). Bayesian Learning for Neural Networks. Lecture Notes in Statistics. Springer. 265",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7364",
    "text": "Neal, R. M. (2001). Annealed importance sampling. Statistics and Computing, 11(2), 125-139. 627, 629, 630",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7365",
    "text": "Neal, R. M. (2005). Estimating ratios of normalizing constants using linked importance sampling. 631",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7366",
    "text": "Nesterov, Y. (1983). A method of solving a convex programming problem with convergence rate O(1/k2). Soviet Mathematics Doklady, 27, 372-376. 300",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7367",
    "text": "Nesterov, Y. (2004). Introductory lectures on convex optimization : a basic course. Applied optimization. Kluwer Academic Publ., Boston, Dordrecht, London. 300",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7368",
    "text": "Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., and Ng, A. Y. (2011). Reading digits in natural images with unsupervised feature learning. Deep Learning and\u00a0Unsupervised Feature Learning Workshop, NIPS. 21",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7369",
    "text": "Ney, H. and Kneser, R. (1993). Improved clustering techniques for class-based statistical language modelling. In European Conference on Speech Communication and Technology\u00a0(Eurospeech), pages 973-976, Berlin. 465",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7370",
    "text": "Ng, A. (2015). \u00a0\u00a0\u00a0Advice for applying machine learning.",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7371",
    "text": "https://see.stanford.edu/materials/aimlcs229/ML-advice.pdf. 423",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7372",
    "text": "Niesler, T. R., Whittaker, E. W. D., and Woodland, P. C. (1998). Comparison of part-of-speech and automatically derived category-based language models for speech recognition. In International Conference on Acoustics, Speech and Signal Processing (ICASSP),\u00a0pages 177-180. 465",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7373",
    "text": "Ning, F., Delhomme, D., LeCun, Y., Piano, F., Bottou, L., and Barbano, P. E. (2005). Toward automatic phenotyping of developing embryos from videos. Image Processing,\u00a0IEEE Transactions on, 14(9), 1360-1371. 360",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7374",
    "text": "Nocedal, J. and Wright, S. (2006). Numerical Optimization. Springer. 92, 95",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7375",
    "text": "Norouzi, M. and Fleet, D. J. (2011). Minimal loss hashing for compact binary codes. In ICML \u20192011. 527",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7376",
    "text": "Nowlan, S. J. (1990). Competing experts: An experimental investigation of associative mixture models. Technical Report CRG-TR-90-5, University of Toronto. 452",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7377",
    "text": "Nowlan, S. J. and Hinton, G. E. (1992). Simplifying neural networks by soft weight-sharing. Neural Computation, 4(4), 473-493. 139",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7378",
    "text": "Olshausen, B. and Field, D. J. (2005). How close are we to understanding V1? Neural Computation, 17, 1665-1699. 16",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7379",
    "text": "Olshausen, B. A. and Field, D. J. (1996). Emergence of simple-cell receptive field properties by learning a sparse code for natural images. Nature, 381, 607-609. 146, 255, 370, 498",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7380",
    "text": "Olshausen, B. A., Anderson, C. H., and Van Essen, D. C. (1993). A neurobiological model of visual attention and invariant pattern recognition based on dynamic routing\u00a0of information. J. Neurosci., 13(11), 4700-4719. 452",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7381",
    "text": "Opper, M. and Archambeau, C. (2009). The variational Gaussian approximation revisited. Neural computation, 21(3), 786-792. 691",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7382",
    "text": "Oquab, M., Bottou, L., Laptev, I., and Sivic, J. (2014). Learning and transferring mid-level image representations using convolutional neural networks. In Computer Vision and\u00a0Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 1717-1724. IEEE. 538",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7383",
    "text": "Osindero, S. and Hinton, G. E. (2008). Modeling image patches with a directed hierarchy of Markov random fields. In J. Platt, D. Koller, Y. Singer, and S. Roweis, editors,\u00a0Advances in Neural Information Processing Systems 20 (NIPS\u201907), pages 1121-1128,\u00a0Cambridge, MA. MIT Press. 634",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7384",
    "text": "Ovid and Martin, C. (2004). Metamorphoses. W.W. Norton. 1",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7385",
    "text": "Paccanaro, A. and Hinton, G. E. (2000). Extracting distributed representations of concepts and relations from positive and negative propositions. In International Joint Conference\u00a0on Neural Networks (IJCNN), Como, Italy. IEEE, New York. 486",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7386",
    "text": "Paine, T. L., Khorrami, P., Han, W., and Huang, T. S. (2014). An analysis of unsupervised pre-training in light of recent advances. arXiv preprint arXiv:1412.6597. 534",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7387",
    "text": "Palatucci, M., Pomerleau, D., Hinton, G. E., and Mitchell, T. M. (2009). Zero-shot learning with semantic output codes. In Y. Bengio, D. Schuurmans, J. D. Lafferty,\u00a0C. K. I. Williams, and A. Culotta, editors, Advances in Neural Information Processing\u00a0Systems 22, pages 1410-1418. Curran Associates, Inc. 541",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7388",
    "text": "Parker, D. B. (1985). Learning-logic. Technical Report TR-47, Center for Comp. Research in Economics and Management Sci., MIT. 224",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7389",
    "text": "Pascanu, R., Mikolov, T., and Bengio, Y. (2013a). On the difficulty of training recurrent neural networks. In ICML\u20192013. 289, 402, 405, 409, 416, 418",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7390",
    "text": "Pascanu, R., Montufar, G., and Bengio, Y. (2013b). On the number of inference regions of deep feed forward networks with piece-wise linear activations. Technical report, U.\u00a0Montreal, arXiv:1312.6098. 198",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7391",
    "text": "Pascanu, R., Gulgehre, Q., Cho, K., and Bengio, Y. (2014a). How to construct deep recurrent neural networks. In ICLR\u20192014. 19, 199, 265, 398, 399, 400, 412, 462",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7392",
    "text": "Pascanu, R., Montufar, G., and Bengio, Y. (2014b). On the number of inference regions of deep feed forward networks with piece-wise linear activations. In ICLR\u20192014. 552",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7393",
    "text": "Pati, Y., Rezaiifar, R., and Krishnaprasad, P. (1993). Orthogonal matching pursuit: Recursive function approximation with applications to wavelet decomposition. In Proceedings of the 27 th Annual Asilomar Conference on Signals, Systems, and Computers,\u00a0pages 40-44. 255",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7394",
    "text": "Pearl, J. (1985). Bayesian networks: A model of self-activated memory for evidential reasoning. In Proceedings of the 7th Conference of the Cognitive Science Society,\u00a0University of California, Irvine, pages 329-334. 565",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7395",
    "text": "Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann. 54",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7396",
    "text": "Perron, O. (1907). Zur theorie der matrices. Mathematische Annalen,64(2), 248-263. 599",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7397",
    "text": "Petersen, K. B. and Pedersen, M. S. (2006). The matrix cookbook. Version 20051003. 31",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7398",
    "text": "Peterson, G. B. (2004). A day of great illumination: B. F. Skinner\u2019s discovery of shaping. Journal of the Experimental Analysis of Behavior, 82(3), 317-328. 328",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7399",
    "text": "Pham, D.-T., Garat, P., and Jutten, C. (1992). Separation of a mixture of independent sources through a maximum likelihood approach. In EUSIPCO, pages 771-774. 493",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7400",
    "text": "Pham, P.-H., Jelaca, D., Farabet, C., Martini, B., LeCun, Y., and Culurcieho, E. (2012). NeuFlow: dataflow vision processing system-on-a-chip. In Circuits and Systems (MWS-CAS), 2012 IEEE 55th International Midwest Symposium on, pages 1044-1047. IEEE.\u00a0453",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7401",
    "text": "Pinheiro, P. H. O. and Collobert, R. (2014). Recurrent convolutional neural networks for scene labeling. In ICML\u20192014. 359",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7402",
    "text": "Pinheiro, P. H. O. and Collobert, R. (2015). From image-level to pixel-level labeling with convolutional networks. In Conference on Computer Vision and Pattern Recognition\u00a0(CVPR). 359",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7403",
    "text": "Pinto, N., Cox, D. D., and DiCarlo, J. J. (2008). Why is real-world visual object recognition hard? PLoS Comput Biol, 4. 458",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7404",
    "text": "Pinto, N., Stone, Z., Zickler, T., and Cox, D. (2011). Scaling up biologically-inspired computer vision: A case study in unconstrained face recognition on facebook. In\u00a0Computer Vision and Pattern Recognition Workshops (CVPRW), 2011 IEEE Computer\u00a0Society Conference on, pages 35-42. IEEE. 363",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7405",
    "text": "Pollack, J. B. (1990). Recursive distributed representations. Artificial Intelligence,46(1), 77-105. 400",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7406",
    "text": "Polyak, B. and Juditsky, A. (1992). Acceleration of stochastic approximation by averaging. SIAM J. Control and Optimization, 30(4), 838-855. 322",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7407",
    "text": "Polyak, B. T. (1964). Some methods of speeding up the convergence of iteration methods. USSR Computational Mathematics and Mathematical Physics, 4(5), 1-17. 296",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7408",
    "text": "Poole, B., Sohl-Dickstein, J., and Ganguli, S. (2014). Analyzing noise in autoencoders and deep networks. CoRR, abs/1406.1831. 241",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7409",
    "text": "Poon, H. and Domingos, P. (2011). Sum-product networks: A new deep architecture. In",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7410",
    "text": "Proceedings of the Twenty-seventh Conference in Uncertainty in Artificial Intelligence (UAI), Barcelona, Spain. 556",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7411",
    "text": "Presley, R. K. and Haggard, R. L. (1994). A fixed point implementation of the backpropa-gation learning algorithm. In Southeastcon\u201994\u25a0 Creative Technology Transfer-A Global Affair., Proceedings of the 1994 IEEE, pages 136-138. IEEE. 453",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7412",
    "text": "Price, R. (1958). A useful theorem for nonlinear devices having Gaussian inputs. IEEE Transactions on Information Theory, 4(2), 69-72. 691",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7413",
    "text": "Quiroga, R. Q., Reddy, L., Kreiman, G., Koch, C., and Fried, I. (2005). Invariant visual representation by single neurons in the human brain. Nature, 435(7045), 1102-1107.\u00a0366",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7414",
    "text": "Radford, A., Metz, L., and Chintala, S. (2015). Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434.\u00a0554, 703, 704",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7415",
    "text": "Raiko, T., Yao, L., Cho, K., and Bengio, Y. (2014). Iterative neural autoregressive distribution estimator (NADE-k). Technical report, arXiv:1406.1485. 678, 711",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7416",
    "text": "Raina, R., Madhavan, A., and Ng, A. Y. (2009). Large-scale deep unsupervised learning using graphics processors. In L. Bottou and M. Littman, editors, Proceedings of the\u00a0Twenty-sixth International Conference on Machine Learning (ICML\u201909), pages 873-880,\u00a0New York, NY, USA. ACM. 27, 448",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7417",
    "text": "Ramsey, F. P. (1926). Truth and probability. In R. B. Braithwaite, editor, The Foundations of Mathematics and other Logical Essays, chapter 7, pages 156-198. McMaster University\u00a0Archive for the History of Economic Thought. 56",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7418",
    "text": "Ranzato, M. and Hinton, G. H. (2010). Modeling pixel means and covariances using factorized third-order Boltzmann machines. In CVPR\u20192010, pages 2551-2558. 682",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7419",
    "text": "Ranzato, M., Poultney, C., Chopra, S., and LeCun, Y. (2007a). Efficient learning of sparse representations with an energy-based model. In NIPS\u20192006. 14, 19, 509, 530, 532",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7420",
    "text": "Ranzato, M., Huang, F., Boureau, Y., and LeCun, Y. (2007b). Unsupervised learning of invariant feature hierarchies with applications to object recognition. In Proceedings of\u00a0the Computer Vision and Pattern Recognition Conference (CVPR\u201907). IEEE Press. 364",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7421",
    "text": "Ranzato, M., Boureau, Y., and LeCun, Y. (2008). Sparse feature learning for deep belief networks. In NIPS\u20192007. 509",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7422",
    "text": "Ranzato, M., Krizhevsky, A., and Hinton, G. E. (2010a). Factored 3-way restricted Boltzmann machines for modeling natural images. In Proceedings of AISTATS 2010.\u00a0680, 681",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7423",
    "text": "Ranzato, M., Mnih, V., and Hinton, G. (2010b). Generating more realistic images using gated MRFs. In NIPS\u20192010. 682",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7424",
    "text": "Rao, C. (1945). Information and the accuracy attainable in the estimation of statistical parameters. Bulletin of the Calcutta Mathematical Society, 37, 81-89. 135, 295",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7425",
    "text": "Rasmus, A., Valpola, H., Honkala, M., Berglund, M., and Raiko, T. (2015). Semi-supervised learning with ladder network. arXiv preprint arXiv:1507.02672. 428, 532",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7426",
    "text": "Recht, B., Re, C., Wright, S., and Niu, F. (2011). Hogwild: A lock-free approach to parallelizing stochastic gradient descent. In NIPS\u20192011. 449",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7427",
    "text": "Reichert, D. P., Series, P., and Storkey, A. J. (2011). Neuronal adaptation for sampling-based probabilistic inference in perceptual bistability. In Advances in Neural Information Processing Systems, pages 2357-2365. 668",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7428",
    "text": "Rezende, D. J., Mohamed, S., and Wierstra, D. (2014). Stochastic backpropagation and approximate inference in deep generative models. In ICML\u20192014. Preprint:\u00a0arXiv:1401.4082. 654, 691, 698",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7429",
    "text": "Rifai, S., Vincent, P., Muller, X., Glorot, X., and Bengio, Y. (2011a). Contractive auto-encoders: Explicit invariance during feature extraction. In ICML\u20192011. 523, 524,\u00a0525",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7430",
    "text": "Rifai, S., Mesnil, G., Vincent, P., Muller, X., Bengio, Y., Dauphin, Y., and Glorot, X. (2011b). Higher order contractive auto-encoder. In ECML PKDD. 523, 524",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7431",
    "text": "Rifai, S., Dauphin, Y., Vincent, P., Bengio, Y., and Muller, X. (2011c). The manifold tangent classifier. In NIPS\u20192011. 271, 272",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7432",
    "text": "Rifai, S., Bengio, Y., Dauphin, Y., and Vincent, P. (2012). A generative process for sampling contractive auto-encoders. In ICML\u20192012. 713",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7433",
    "text": "Ringach, D. and Shapley, R. (2004). Reverse correlation in neurophysiology. Cognitive Science, 28(2), 147-166. 368",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7434",
    "text": "Roberts, S. and Everson, R. (2001). Independent component analysis: principles and practice. Cambridge University Press. 495",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7435",
    "text": "Robinson, A. J. and Fallside, F. (1991). A recurrent error propagation network speech recognition system. Computer Speech and Language, 5(3), 259-274. 27, 461",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7436",
    "text": "Rockafellar, R. T. (1997). Convex analysis. princeton landmarks in mathematics. 93",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7437",
    "text": "Romero, A., Ballas, N., Ebrahimi Kahou, S., Chassang, A., Gatta, C., and Bengio, Y. (2015). Fitnets: Hints for thin deep nets. In ICLR\u20192015, arXiv:1412.6550. 325",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7438",
    "text": "Rosen, J. B. (1960). The gradient projection method for nonlinear programming. part i. linear constraints. Journal of the Society for Industrial and Applied Mathematics, 8(1),\u00a0pp. 181-217. 93",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7439",
    "text": "Rosenblatt, F. (1958). The perceptron: A probabilistic model for information storage and organization in the brain. Psychological Review, 65, 386-408. 14, 15, 27",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7440",
    "text": "Rosenblatt, F. (1962). Principles of Neurodynamics. Spartan, New York. 15, 27",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7441",
    "text": "Roweis, S. and Saul, L. K. (2000). Nonlinear dimensionality reduction by locally linear embedding. Science, 290(5500). 163, 520",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7442",
    "text": "Roweis, S., Saul, L., and Hinton, G. (2002). Global coordination of local linear models. In T. Dietterich, S. Becker, and Z. Ghahramani, editors, Advances in Neural Information\u00a0Processing Systems 14 (NIPS\u201901), Cambridge, MA. MIT Press. 491",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7443",
    "text": "Rubin, D. B. et al. (1984). Bayesianly justifiable and relevant frequency calculations for the applied statistician. The Annals of Statistics, 12(4), 1151-1172. 718",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7444",
    "text": "Rumelhart, D., Hinton, G., and Williams, R. (1986a). Learning representations by back-propagating errors. Nature, 323, 533-536. 14, 18, 23, 203, 225, 373, 478, 484",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7445",
    "text": "Rumelhart, D. E., Hinton, G. E., and Williams, R. J. (1986b). Learning internal representations by error propagation. In D. E. Rumelhart and J. L. McClelland, editors, Parallel Distributed Processing, volume 1, chapter 8, pages 318-362. MIT Press, Cambridge. 21,\u00a027, 225",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7446",
    "text": "Rumelhart, D. E., McClelland, J. L., and the PDP Research Group (1986c). Parallel Distributed Processing: Explorations in the Microstructure of Cognition. MIT Press,\u00a0Cambridge. 17",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7447",
    "text": "Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A. C., and Fei-Fei, L. (2014a). ImageNet Large\u00a0Scale Visual Recognition Challenge. 21",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7448",
    "text": "Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., et al. (2014b). Imagenet large scale visual recognition\u00a0challenge. arXiv preprint arXiv: 1409.0575. 28",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7449",
    "text": "Russel, S. J. and Norvig, P. (2003). Artificial Intelligence: a Modern Approach. Prentice Hall. 86",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7450",
    "text": "Rust, N., Schwartz, O., Movshon, J. A., and Simoncelli, E. (2005). Spatiotemporal elements of macaque V1 receptive fields. Neuron, 46(6), 945-956. 367",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7451",
    "text": "Sainath, T., Mohamed, A., Kingsbury, B., and Ramabhadran, B. (2013). Deep convolutional neural networks for LVCSR. In ICASSP 2013. 462",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7452",
    "text": "Salakhutdinov, R. (2010). Learning in Markov random fields using tempered transitions. In Y. Bengio, D. Schuurmans, C. Williams, J. Lafferty, and A. Culotta, editors, Advances\u00a0in Neural Information Processing Systems 22 (NIPS\u201909). 605",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7453",
    "text": "Salakhutdinov, R. and Hinton, G. (2009a). Deep Boltzmann machines. In Proceedings of the International Conference on Artificial Intelligence and Statistics, volume 5, pages\u00a0448-455. 24, 27, 531, 665, 668, 673, 674",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7454",
    "text": "Salakhutdinov, R. and Hinton, G. (2009b). Semantic hashing. In International Journal of Approximate Reasoning. 527",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7455",
    "text": "Salakhutdinov, R. and Hinton, G. E. (2007a). Learning a nonlinear embedding by preserving class neighbourhood structure. In Proceedings of the Eleventh International\u00a0Conference on Artificial Intelligence and Statistics (AISTATS\u201907), San Juan, Porto\u00a0Rico. Omnipress. 529",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7456",
    "text": "Salakhutdinov, R. and Hinton, G. E. (2007b). Semantic hashing. In SIGIR\u20192007. 527",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7457",
    "text": "Salakhutdinov, R. and Hinton, G. E. (2008). Using deep belief nets to learn covariance kernels for Gaussian processes. In J. Platt, D. Koller, Y. Singer, and S. Roweis, editors,\u00a0Advances in Neural Information Processing Systems 20 (NIPS\u201907), pages 1249-1256,\u00a0Cambridge, MA. MIT Press. 244",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7458",
    "text": "Salakhutdinov, R. and Larochelle, H. (2010). Efficient learning of deep Boltzmann machines. In Proceedings of the Thirteenth International Conference on Artificial Intelligence and\u00a0Statistics (AISTATS 2010), JMLR W&CP, volume 9, pages 693-700. 654",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7459",
    "text": "Salakhutdinov, R. and Mnih, A. (2008). Probabilistic matrix factorization. In NIPS\u20192008. 481",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7460",
    "text": "Salakhutdinov, R. and Murray, I. (2008). On the quantitative analysis of deep belief networks. In W. W. Cohen, A. McCallum, and S. T. Roweis, editors, Proceedings of\u00a0the Twenty-fifth International Conference on Machine Learning (ICML\u201908), volume 25,\u00a0pages 872-879. ACM. 630, 664",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7461",
    "text": "Salakhutdinov, R., Mnih, A., and Hinton, G. (2007). Restricted Boltzmann machines for collaborative filtering. In ICML. 481",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7462",
    "text": "Sanger, T. D. (1994). Neural network learning control of robot manipulators using gradually increasing task difficulty. IEEE Transactions on Robotics and Automation,\u00a010(3). 328",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7463",
    "text": "Saul, L. K. and Jordan, M. I. (1996). Exploiting tractable substructures in intractable networks. In D. Touretzky, M. Mozer, and M. Hasselmo, editors, Advances in Neural\u00a0Information Processing Systems 8 (NIPS\u201995). MIT Press, Cambridge, MA. 640",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7464",
    "text": "Saul, L. K., Jaakkola, T., and Jordan, M. I. (1996). Mean field theory for sigmoid belief networks. Journal of Artificial Intelligence Research, 4, 61-76. 27, 695",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7465",
    "text": "Savich, A. W., Moussa, M., and Areibi, S. (2007). The impact of arithmetic representation on implementing mlp-bp on fpgas: A study. Neural Networks, IEEE Transactions on,\u00a018(1), 240-252. 453",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7466",
    "text": "Saxe, A. M., Koh, P. W., Chen, Z., Bhand, M., Suresh, B., and Ng, A. (2011). On random weights and unsupervised feature learning. In Proc. ICML\u20192011. ACM. 363",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7467",
    "text": "Saxe, A. M., McClelland, J. L., and Ganguli, S. (2013). Exact solutions to the nonlinear dynamics of learning in deep linear neural networks. In ICLR. 285, 286, 303",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7468",
    "text": "Schaul, T., Antonoglou, I., and Silver, D. (2014). Unit tests for stochastic optimization. In International Conference on Learning Representations. 309",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7469",
    "text": "Schmidhuber, J. (1992). Learning complex, extended sequences using the principle of history compression. Neural Computation, 4(2), 234-242. 400",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7470",
    "text": "Schmidhuber, J. (1996). Sequential neural text compression. IEEE Transactions on Neural Networks, 7(1), 142-146. 479",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7471",
    "text": "Schmidhuber, J. (2012). Self-delimiting neural networks. arXiv preprint arXiv:1210.0118. 390",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7472",
    "text": "Scholkopf, B. and Smola, A. J. (2002). Learning with kernels: Support vector machines, regularization, optimization, and beyond. MIT press. 705",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7473",
    "text": "Scholkopf, B., Smola, A., and Muller, K.-R. (1998). Nonlinear component analysis as a kernel eigenvalue problem. Neural Computation, 10, 1299-1319. 163, 520",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7474",
    "text": "Scholkopf, B., Burges, C. J. C., and Smola, A. J. (1999). Advances in Kernel Methods \u2014 Support Vector Learning. MIT Press, Cambridge, MA. 18, 142",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7475",
    "text": "Scholkopf, B., Janzing, D., Peters, J., Sgouritsa, E., Zhang, K., and Mooij, J. (2012). On causal and anticausal learning. In ICML\u20192012, pages 1255-1262. 547",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7476",
    "text": "Schuster, M. (1999). On supervised learning from sequential data with applications for speech recognition. 189",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7477",
    "text": "Schuster, M. and Paliwal, K. (1997). Bidirectional recurrent neural networks. IEEE Transactions on Signal Processing, 45(11), 2673-2681. 395",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7478",
    "text": "Schwenk, H. (2007). Continuous space language models. Computer speech and language, 21, 492-518. 468",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7479",
    "text": "Schwenk, H. (2010). Continuous space language models for statistical machine translation. The Prague Bulletin of Mathematical Linguistics, 93, 137-146. 475",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7480",
    "text": "Schwenk, H. (2014). Cleaned subset of WMT \u201914 dataset. 21",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7481",
    "text": "Schwenk, H. and Bengio, Y. (1998). Training methods for adaptive boosting of neural networks. In M. Jordan, M. Kearns, and S. Solla, editors, Advances in Neural Information Processing Systems 10 (NIPS\u201997), pages 647-653. MIT Press. 258",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7482",
    "text": "Schwenk, H. and Gauvain, J.-L. (2002). Connectionist language modeling for large vocabulary continuous speech recognition. In International Conference on Acoustics,\u00a0Speech and Signal Processing (ICASSP), pages 765-768, Orlando, Florida. 468",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7483",
    "text": "Schwenk, H., Costa-jussa, M. R., and Fonollosa, J. A. R. (2006). Continuous space language models for the IWSLT 2006 task. In International Workshop on Spoken\u00a0Language Translation, pages 166-173. 475",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7484",
    "text": "Seide, F., Li, G., and Yu, D. (2011). Conversational speech transcription using context-dependent deep neural networks. In Interspeech 2011, pages 437-440. 23",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7485",
    "text": "Sejnowski, T. (1987). Higher-order Boltzmann machines. In AIP Conference Proceedings 151 on Neural Networks for Computing, pages 398-403. American Institute of Physics\u00a0Inc. 688",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7486",
    "text": "Series, P., Reichert, D. P., and Storkey, A. J. (2010). Hallucinations in Charles Bonnet syndrome induced by homeostasis: a deep Boltzmann machine model. In Advances in\u00a0Neural Information Processing Systems, pages 2020-2028. 668",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7487",
    "text": "Sermanet, P., Chintala, S., and LeCun, Y. (2012). Convolutional neural networks applied to house numbers digit classification. CoRR, abs/1204.3968. 458",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7488",
    "text": "Sermanet, P., Kavukcuoglu, K., Chintala, S., and LeCun, Y. (2013). Pedestrian detection with unsupervised multi-stage feature learning. In Proc. International Conference on\u00a0Computer Vision and Pattern Recognition (CVPR\u201913). IEEE. 23, 200",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7489",
    "text": "Shilov, G. (1977). Linear Algebra. Dover Books on Mathematics Series. Dover Publications. 31",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7490",
    "text": "Siegelmann, H. (1995). Computation beyond the Turing limit. Science, 268(5210), 545-548. 379",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7491",
    "text": "Siegelmann, H. and Sontag, E. (1991). Turing computability with neural nets. Applied Mathematics Letters, 4(6), 77-80. 379",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7492",
    "text": "Siegelmann, H. T. and Sontag, E. D. (1995). On the computational power of neural nets. Journal of Computer and Systems Sciences, 50(1), 132-150. 379, 405",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7493",
    "text": "Sietsma, J. and Dow, R. (1991). Creating artificial neural networks that generalize. Neural Networks, 4(1), 67-79. 241",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7494",
    "text": "Simard, D., Steinkraus, P. Y., and Platt, J. C. (2003). Best practices for convolutional neural networks. In ICDAR\u20192003. 371",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7495",
    "text": "Simard, P. and Graf, H. P. (1994). Backpropagation without multiplication. In Advances in Neural Information Processing Systems, pages 232-239. 453",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7496",
    "text": "Simard, P., Victorri, B., LeCun, Y., and Denker, J. (1992). Tangent prop - A formalism for specifying selected invariances in an adaptive network. In NIPS\u20191991. 270, 271, 272,\u00a0356",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7497",
    "text": "Simard, P. Y., LeCun, Y., and Denker, J. (1993). Efficient pattern recognition using a new transformation distance. In NIPS\u201992. 270",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7498",
    "text": "Simard, P. Y., LeCun, Y. A., Denker, J. S., and Victorri, B. (1998). Transformation invariance in pattern recognition \u2014 tangent distance and tangent propagation. Lecture\u00a0Notes in Computer Science, 1524. 270",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7499",
    "text": "Simons, D. J. and Levin, D. T. (1998). Failure to detect changes to people during a real-world interaction. Psychonomic Bulletin & Review, 5(4), 644-649. 545",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7500",
    "text": "Simonyan, K. and Zisserman, A. (2015). Very deep convolutional networks for large-scale image recognition. In ICLR. 323",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7501",
    "text": "Sjoberg, J. and Ljung, L. (1995). Overtraining, regularization and searching for a minimum, with application to neural networks. International Journal of Control,62(6), 1391-1407.\u00a0250",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7502",
    "text": "Skinner, B. F. (1958). Reinforcement today. American Psychologist, 13, 94-99. 328",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7503",
    "text": "Smolensky, P. (1986). Information processing in dynamical systems: Foundations of harmony theory. In D. E. Rumelhart and J. L. McClelland, editors, Parallel Distributed\u00a0Processing, volume 1, chapter 6, pages 194-281. MIT Press, Cambridge. 573, 589, 658",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7504",
    "text": "Snoek, J., Larochelle, H., and Adams, R. P. (2012). Practical Bayesian optimization of machine learning algorithms. In NIPS\u20192012. 438",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7505",
    "text": "Socher, R., Huang, E. H., Pennington, J., Ng, A. Y., and Manning, C. D. (2011a). Dynamic pooling and unfolding recursive autoencoders for paraphrase detection. In NIPS\u20192011.\u00a0400, 402",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7506",
    "text": "Socher, R., Manning, C., and Ng, A. Y. (2011b). Parsing natural scenes and natural language with recursive neural networks. In Proceedings of the Twenty-Eighth International Conference on Machine Learning (ICML\u20192011). 400",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7507",
    "text": "Socher, R., Pennington, J., Huang, E. H., Ng, A. Y., and Manning, C. D. (2011c). Semi-supervised recursive autoencoders for predicting sentiment distributions. In\u00a0EMNLP\u20192011. 400",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7508",
    "text": "Socher, R., Perelygin, A., Wu, J. Y., Chuang, J., Manning, C. D., Ng, A. Y., and Potts, C. (2013a). Recursive deep models for semantic compositionality over a sentiment\u00a0treebank. In EMNLP\u20192013. 400, 402",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7509",
    "text": "Socher, R., Ganjoo, M., Manning, C. D., and Ng, A. Y. (2013b). Zero-shot learning through cross-modal transfer. In 27th Annual Conference on Neural Information Processing\u00a0Systems (NIPS 2013). 541",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7510",
    "text": "Sohl-Dickstein, J., Weiss, E. A., Maheswaranathan, N., and Ganguli, S. (2015). Deep unsupervised learning using nonequilibrium thermodynamics. 717, 718",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7511",
    "text": "Sohn, K., Zhou, G., and Lee, H. (2013). Learning and selecting features jointly with point-wise gated Boltzmann machines. In ICML\u20192013. 689",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7512",
    "text": "Solomonoff, R. J. (1989). A system for incremental learning based on algorithmic probability. 328",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7513",
    "text": "Sontag, E. D. (1998). VC dimension of neural networks. NATO ASI Series F Computer and Systems Sciences, 168, 69-96. 549, 553",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7514",
    "text": "Sontag, E. D. and Sussman, H. J. (1989). Backpropagation can give rise to spurious local minima even for networks without hidden layers. Complex Systems, 3, 91-106. 284",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7515",
    "text": "Sparkes, B. (1996). The Red and the Black: Studies in Greek Pottery. Routledge. 1",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7516",
    "text": "Spitkovsky, V. I., Alshawi, H., and Jurafsky, D. (2010). From baby steps to leapfrog: how \u201cless is more\u201d in unsupervised dependency parsing. In HLT\u201910. 328",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7517",
    "text": "Squire, W. and Trapp, G. (1998). Using complex variables to estimate derivatives of real functions. SIAM Rev., 40(1), 110\u2014112. 441",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7518",
    "text": "Srebro, N. and Shraibman, A. (2005). Rank, trace-norm and max-norm. In Proceedings of the 18th Annual Conference on Learning Theory, pages 545-560. Springer-Verlag. 238",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7519",
    "text": "Srivastava, N. (2013). Improving Neural Networks With Dropout. Master\u2019s thesis, U. Toronto. 537",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7520",
    "text": "Srivastava, N. and Salakhutdinov, R. (2012). Multimodal learning with deep Boltzmann machines. In NIPS\u20192012. 543",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7521",
    "text": "Srivastava, N., Salakhutdinov, R. R., and Hinton, G. E. (2013). Modeling documents with deep Boltzmann machines. arXiv preprint arXiv:1309.6865. 665",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7522",
    "text": "Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. (2014). Dropout: A simple way to prevent neural networks from overfitting. Journal of Machine\u00a0Learning Research, 15, 1929-1958. 258, 265, 267, 674",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7523",
    "text": "Srivastava, R. K., Greff, K., and Schmidhuber, J. (2015). Highway networks. arXiv:1505.00387. 326",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7524",
    "text": "Steinkrau, D., Simard, P. Y., and Buck, I. (2005). Using GPUs for machine learning algorithms. 2013 12th International Conference on Document Analysis and Recognition,\u00a00, 1115-1119. 447",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7525",
    "text": "Stoyanov, V., Ropson, A., and Eisner, J. (2011). Empirical risk minimization of graphical model parameters given approximate inference, decoding, and model structure. In\u00a0Proceedings of the 1fth International Conference on Artificial Intelligence and Statistics\u00a0(AISTATS), volume 15 of JMLR Workshop and Conference Proceedings, pages 725-733,\u00a0Fort Lauderdale. Supplementary material (4 pages) also available. 676, 700",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7526",
    "text": "Sukhbaatar, S., Szlam, A., Weston, J., and Fergus, R. (2015). Weakly supervised memory networks. arXiv preprint arXiv:1503.08895. 420",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7527",
    "text": "Supancic, J. and Ramanan, D. (2013). Self-paced learning for long-term tracking. In CVPR\u20192013. 328",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7528",
    "text": "Sussillo, D. (2014). Random walks: Training very deep nonlinear feed-forward networks with smart initialization. CoRR, abs/1412.6558. 290, 303, 305, 404",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7529",
    "text": "Sutskever, I. (2012). Training Recurrent Neural Networks. Ph.D. thesis, Department of computer science, University of Toronto. 407, 414",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7530",
    "text": "Sutskever, I. and Hinton, G. E. (2008). Deep narrow sigmoid belief networks are universal approximators. Neural Computation, 20(11), 2629-2636. 695",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7531",
    "text": "Sutskever, I. and Tieleman, T. (2010). On the Convergence Properties of Contrastive Divergence. In Y. W. Teh and M. Titterington, editors, Proc. of the International\u00a0Conference on Artificial Intelligence and Statistics (AISTATS), volume 9, pages 789-795.\u00a0614",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7532",
    "text": "Sutskever, I., Hinton, G., and Taylor, G. (2009). The recurrent temporal restricted Boltzmann machine. In NIPS\u20192008. 687",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7533",
    "text": "Sutskever, I., Martens, J., and Hinton, G. E. (2011). Generating text with recurrent neural networks. In ICML\u20192011, pages 1017-1024. 479",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7534",
    "text": "Sutskever, I., Martens, J., Dahl, G., and Hinton, G. (2013). On the importance of initialization and momentum in deep learning. In ICML. 300, 407, 414",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7535",
    "text": "Sutskever, I., Vinyals, O., and Le, Q. V. (2014). Sequence to sequence learning with neural networks. In NIPS\u20192014, arXiv:1409.3215. 25, 101, 396, 410, 413, 476, 477",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7536",
    "text": "Sutton, R. and Barto, A. (1998). Reinforcement Learning: An Introduction. MIT Press. 106",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7537",
    "text": "Sutton, R. S., Mcallester, D., Singh, S., and Mansour, Y. (2000). Policy gradient methods for reinforcement learning with function approximation. In NIPS\u20191999, pages 1057-1063. MIT Press. 693",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7538",
    "text": "Swersky, K., Ranzato, M., Buchman, D., Marlin, B., and de Freitas, N. (2011). On autoencoders and score matching for energy based models. In ICML\u20192011. ACM. 515",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7539",
    "text": "Swersky, K., Snoek, J., and Adams, R. P. (2014). Freeze-thaw Bayesian optimization. arXiv preprint arXiv:1406.3896. 438",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7540",
    "text": "Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., and Rabinovich, A. (2014a). Going deeper with convolutions. Technical report,\u00a0arXiv:1409.4842. 24, 27, 200, 258, 269, 326, 347",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7541",
    "text": "Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I. J., and Fergus, R. (2014b). Intriguing properties of neural networks. ICLR, abs/1312.6199.\u00a0268, 271",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7542",
    "text": "Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z. (2015). Rethinking the Inception Architecture for Computer Vision. ArXiv e-prints. 243, 322",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7543",
    "text": "Taigman, Y., Yang, M., Ranzato, M., and Wolf, L. (2014). DeepFace: Closing the gap to human-level performance in face verification. In CVPR \u20192014. 100",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7544",
    "text": "Tandy, D. W. (1997). Works and Days: A Translation and Commentary for the Social Sciences. University of California Press. 1",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7545",
    "text": "Tang, Y. and Eliasmith, C. (2010). Deep networks for robust visual recognition. In",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7546",
    "text": "Proceedings of the 27th International Conference on Machine Learning, June 21-24, 2010, Haifa, Israel. 241",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7547",
    "text": "Tang, Y., Salakhutdinov, R., and Hinton, G. (2012). Deep mixtures of factor analysers. arXiv preprint arXiv:1206.4635. 491",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7548",
    "text": "Taylor, G. and Hinton, G. (2009). Factored conditional restricted Boltzmann machines for modeling motion style. In L. Bottou and M. Littman, editors, Proceedings of\u00a0the Twenty-sixth International Conference on Machine Learning (ICML\u201909), pages\u00a01025-1032, Montreal, Quebec, Canada. ACM. 687",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7549",
    "text": "Taylor, G., Hinton, G. E., and Roweis, S. (2007). Modeling human motion using binary latent variables. In B. Scholkopf, J. Platt, and T. Hoffman, editors, Advances in Neural\u00a0Information Processing Systems 19 (NIPS\u201906), pages 1345-1352. MIT Press, Cambridge,\u00a0MA. 687",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7550",
    "text": "Teh, Y., Welling, M., Osindero, S., and Hinton, G. E. (2003). Energy-based models for sparse overcomplete representations. Journal of Machine Learning Research, 4,\u00a01235-1260. 493",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7551",
    "text": "Tenenbaum, J., de Silva, V., and Langford, J. C. (2000). A global geometric framework for nonlinear dimensionality reduction. Science, 290(5500), 2319-2323. 163, 520, 535",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7552",
    "text": "Theis, L., van den Oord, A., and Bethge, M. (2015). A note on the evaluation of generative models. arXiv:1511.01844. 699, 721",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7553",
    "text": "Thompson, J., Jain, A., LeCun, Y., and Bregler, C. (2014). Joint training of a convolutional network and a graphical model for human pose estimation. In NIPS\u20192014. 360",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7554",
    "text": "Thrun, S. (1995). Learning to play the game of chess. In NIPS\u20191994 . 271",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7555",
    "text": "Tibshirani, R. J. (1995). Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society B, 58, 267-288. 236",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7556",
    "text": "Tieleman, T. (2008). Training restricted Boltzmann machines using approximations to the likelihood gradient. In W. W. Cohen, A. McCallum, and S. T. Roweis, editors, Proceedings of the Twenty-fifth International Conference on Machine Learning (ICML\u201908),\u00a0pages 1064-1071. ACM. 614",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7557",
    "text": "Tieleman, T. and Hinton, G. (2009). Using fast weights to improve persistent contrastive divergence. In L. Bottou and M. Littman, editors, Proceedings of the Twenty-sixth\u00a0International Conference on Machine Learning (ICML\u201909), pages 1033-1040. ACM.\u00a0616",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7558",
    "text": "Tipping, M. E. and Bishop, C. M. (1999). Probabilistic principal components analysis. Journal of the Royal Statistical Society B, 61(3), 611-622. 493",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7559",
    "text": "Torralba, A., Fergus, R., and Weiss, Y. (2008). Small codes and large databases for recognition. In Proceedings of the Computer Vision and Pattern Recognition Conference\u00a0(CVPR\u201908), pages 1-8. 527",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7560",
    "text": "Touretzky, D. S. and Minton, G. E. (1985). Symbols among the neurons: Details of a connectionist inference architecture. In Proceedings of the 9th International Joint\u00a0Conference on Artificial Intelligence - Volume 1, IJCAI\u201985, pages 238-243, San Francisco,\u00a0CA, USA. Morgan Kaufmann Publishers Inc. 17",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7561",
    "text": "Tu, K. and Honavar, V. (2011). On the utility of curricula in unsupervised learning of probabilistic grammars. In IJCAI\u20192011. 328",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7562",
    "text": "Turaga, S. C., Murray, J. F., Jain, V., Roth, F., Helmstaedter, M., Briggman, K., Denk, W., and Seung, H. S. (2010). Convolutional networks can learn to generate affinity\u00a0graphs for image segmentation. Neural Computation, 22(2), 511-538. 359",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7563",
    "text": "Turian, J., Ratinov, L., and Bengio, Y. (2010). Word representations: A simple and general method for semi-supervised learning. In Proc. ACL\u20192010, pages 384-394. 537",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7564",
    "text": "Toscher, A., Jahrer, M., and Bell, R. M. (2009). The BigChaos solution to the Netflix grand prize. 481",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7565",
    "text": "Uria, B., Murray, I., and Larochelle, H. (2013). Rnade: The real-valued neural autoregressive density-estimator. In NIPS\u20192013. 711",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7566",
    "text": "van den Oord, A., Dieleman, S., and Schrauwen, B. (2013). Deep content-based music recommendation. In NIPS\u20192013. 482",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7567",
    "text": "van der Maaten, L. and Hinton, G. E. (2008). Visualizing data using t-SNE. J. Machine Learning Res., 9. 479, 521",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7568",
    "text": "Vanhoucke, V., Senior, A., and Mao, M. Z. (2011). Improving the speed of neural networks on CPUs. In Proc. Deep Learning and Unsupervised Feature Learning NIPS Workshop.\u00a0446, 454",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7569",
    "text": "Vapnik, V. N. (1982). Estimation of Dependences Based on Empirical Data. Springer-Verlag, Berlin. 114",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7570",
    "text": "Vapnik, V. N. (1995). The Nature of Statistical Learning Theory. Springer, New York. 114",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7571",
    "text": "Vapnik, V. N. and Chervonenkis, A. Y. (1971). On the uniform convergence of relative frequencies of events to their probabilities. Theory of Probability and Its Applications,\u00a016, 264-280. 114",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7572",
    "text": "Vincent, P. (2011). A connection between score matching and denoising autoencoders. Neural Computation, 23(7). 515, 517, 714",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7573",
    "text": "Vincent, P. and Bengio, Y. (2003). Manifold Parzen windows. In NIPS\u20192002. MIT Press. 522",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7574",
    "text": "Vincent, P., Larochelle, H., Bengio, Y., and Manzagol, P.-A. (2008). Extracting and composing robust features with denoising autoencoders. In ICML 2008. 241, 517",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7575",
    "text": "Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., and Manzagol, P.-A. (2010). Stacked denoising autoencoders: Learning useful representations in a deep network with a local\u00a0denoising criterion. J. Machine Learning Res., 11. 517",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7576",
    "text": "Vincent, P., de Brebisson, A., and Bouthillier, X. (2015). Efficient exact gradient update for training deep networks with very large sparse targets. In C. Cortes, N. D. Lawrence,\u00a0D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information\u00a0Processing Systems 28, pages 1108-1116. Curran Associates, Inc. 467",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7577",
    "text": "Vinyals, O., Kaiser, L., Koo, T., Petrov, S., Sutskever, I., and Hinton, G. (2014a). Grammar as a foreign language. Technical report, arXiv:1412.7449. 410",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7578",
    "text": "Vinyals, O., Toshev, A., Bengio, S., and Erhan, D. (2014b). Show and tell: a neural image caption generator. arXiv 1411.4555. 410",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7579",
    "text": "Vinyals, O., Fortunato, M., and Jaitly, N. (2015a). Pointer networks. arXiv preprint arXiv:1506.03134 . 420",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7580",
    "text": "Vinyals, O., Toshev, A., Bengio, S., and Erhan, D. (2015b). Show and tell: a neural image caption generator. In CVPR\u20192015. arXiv:1411.4555. 102",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7581",
    "text": "Viola, P. and Jones, M. (2001). Robust real-time object detection. In International Journal of Computer Vision. 451",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7582",
    "text": "Visin, F., Kastner, K., Cho, K., Matteucci, M., Courville, A., and Bengio, Y. (2015). ReNet: A recurrent neural network based alternative to convolutional networks. arXiv\u00a0preprint arXiv:1505.00393. 396",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7583",
    "text": "Von Melchner, L., Pallas, S. L., and Sur, M. (2000). Visual behaviour mediated by retinal projections directed to the auditory pathway. Nature, 404(6780), 871-876. 16",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7584",
    "text": "Wager, S., Wang, S., and Liang, P. (2013). Dropout training as adaptive regularization.",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7585",
    "text": "In Advances in Neural Information Processing Systems 26, pages 351-359. 265",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7586",
    "text": "Waibel, A., Hanazawa, T., Hinton, G. E., Shikano, K., and Lang, K. (1989). Phoneme recognition using time-delay neural networks. IEEE Transactions on Acoustics, Speech,\u00a0and Signal Processing, 37, 328-339. 374, 455, 461",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7587",
    "text": "Wan, L., Zeiler, M., Zhang, S., LeCun, Y., and Fergus, R. (2013). Regularization of neural networks using dropconnect. In ICML\u20192013. 266",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7588",
    "text": "Wang, S. and Manning, C. (2013). Fast dropout training. In ICML\u20192013. 266",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7589",
    "text": "Wang, Z., Zhang, J., Feng, J., and Chen, Z. (2014a). Knowledge graph and text jointly embedding. In Proc. EMNLP\u20192014. 486",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7590",
    "text": "Wang, Z., Zhang, J., Feng, J., and Chen, Z. (2014b). Knowledge graph embedding by translating on hyperplanes. In Proc. AAAI\u20192014. 486",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7591",
    "text": "Warde-Farley, D., Goodfellow, I. J., Courville, A., and Bengio, Y. (2014). An empirical analysis of dropout in piecewise linear networks. In ICLR\u20192014. 262, 266, 267",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7592",
    "text": "Wawrzynek, J., Asanovic, K., Kingsbury, B., Johnson, D., Beck, J., and Morgan, N. (1996). Spert-II: A vector microprocessor system. Computer, 29(3), 79-86. 453",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7593",
    "text": "Weaver, L. and Tao, N. (2001). The optimal reward baseline for gradient-based reinforcement learning. In Proc. UAI\u20192001, pages 538-545. 693",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7594",
    "text": "Weinberger, K. Q. and Saul, L. K. (2004). Unsupervised learning of image manifolds by semidefinite programming. In CVPR\u20192004, pages 988-995. 163, 521",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7595",
    "text": "Weiss, Y., Torralba, A., and Fergus, R. (2008). Spectral hashing. In NIPS, pages 1753-1760. 527",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7596",
    "text": "Welling, M., Zemel, R. S., and Hinton, G. E. (2002). Self supervised boosting. In Advances in Neural Information Processing Systems, pages 665-672. 705",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7597",
    "text": "Welling, M., Hinton, G. E., and Osindero, S. (2003a). Learning sparse topographic representations with products of Student-t distributions. In NIPS\u20192002. 682",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7598",
    "text": "Welling, M., Zemel, R., and Hinton, G. E. (2003b). Self-supervised boosting. In S. Becker, S. Thrun, and K. Obermayer, editors, Advances in Neural Information Processing\u00a0Systems 15 (NIPS\u201902), pages 665-672. MIT Press. 624",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7599",
    "text": "Welling, M., Rosen-Zvi, M., and Hinton, G. E. (2005). Exponential family harmoniums with an application to information retrieval. In L. Saul, Y. Weiss, and L. Bottou,\u00a0editors, Advances in Neural Information Processing Systems 17 (NIPS\u201904), volume 17,\u00a0Cambridge, MA. MIT Press. 678",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7600",
    "text": "Werbos, P. J. (1981). Applications of advances in nonlinear sensitivity analysis. In Proceedings of the 10th IFIP Conference, 31.8 - 4-9, NYC, pages 762-770. 224",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7601",
    "text": "Weston, J., Bengio, S., and Usunier, N. (2010). Large scale image annotation: learning to rank with joint word-image embeddings. Machine Learning, 81(1), 21-35. 402",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7602",
    "text": "Weston, J., Chopra, S., and Bordes, A. (2014). Memory networks. arXiv preprint arXiv:1410.3916. 420, 487",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7603",
    "text": "Widrow, B. and Hoff, M. E. (1960). Adaptive switching circuits. In 1960 IRE WESCON Convention Record, volume 4, pages 96-104. IRE, New York. 15, 21, 24, 27",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7604",
    "text": "Wikipedia (2015). List of animals by number of neurons \u2014 Wikipedia, the free encyclopedia. [Online; accessed 4-March-2015]. 24, 27",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7605",
    "text": "Williams, C. K. I. and Agakov, F. V. (2002). Products of Gaussians and Probabilistic Minor Component Analysis. Neural Computation, 14(5), 1169-1182. 684",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7606",
    "text": "Williams, C. K. I. and Rasmussen, C. E. (1996). Gaussian processes for regression. In D. Touretzky, M. Mozer, and M. Hasselmo, editors, Advances in Neural Information\u00a0Processing Systems 8 (NIPS\u201995), pages 514-520. MIT Press, Cambridge, MA. 142",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7607",
    "text": "Williams, R. J. (1992). Simple statistical gradient-following algorithms connectionist reinforcement learning. Machine Learning, 8, 229-256. 690, 691",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7608",
    "text": "Williams, R. J. and Zipser, D. (1989). A learning algorithm for continually running fully recurrent neural networks. Neural Computation, 1, 270-280. 222",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7609",
    "text": "Wilson, D. R. and Martinez, T. R. (2003). The general inefficiency of batch training for gradient descent learning. Neural Networks, 16(10), 1429-1451. 279",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7610",
    "text": "Wilson, J. R. (1984). Variance reduction techniques for digital simulation. American Journal of Mathematical and Management Sciences, 4(3), 277\u2014312. 692",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7611",
    "text": "Wiskott, L. and Sejnowski, T. J. (2002). Slow feature analysis: Unsupervised learning of invariances. Neural Computation, 14(4), 715-770. 496",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7612",
    "text": "Wolpert, D. and MacReady, W. (1997). No free lunch theorems for optimization. IEEE Transactions on Evolutionary Computation, 1, 67-82. 293",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7613",
    "text": "Wolpert, D. H. (1996). The lack of a priori distinction between learning algorithms. Neural Computation, 8(7), 1341-1390. 116",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7614",
    "text": "Wu, R., Yan, S., Shan, Y., Dang, Q., and Sun, G. (2015). Deep image: Scaling up image recognition. arXiv:1501.02876. 449",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7615",
    "text": "Wu, Z. (1997). Global continuation for distance geometry problems. SIAM Journal of Optimization, 7, 814-836. 327",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7616",
    "text": "Xiong, H. Y., Barash, Y., and Frey, B. J. (2011). Bayesian prediction of tissue-regulated splicing using RNA sequence and cellular context. Bioinformatics, 27(18), 2554-2562.\u00a0265",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7617",
    "text": "Xu, K., Ba, J. L., Kiros, R., Cho, K., Courville, A., Salakhutdinov, R., Zemel, R. S., and Bengio, Y. (2015). Show, attend and tell: Neural image caption generation with visual\u00a0attention. In ICML\u20192015, arXiv:1502.03044. 102 , 410, 693",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7618",
    "text": "Yildiz, I. B., Jaeger, H., and Kiebel, S. J. (2012). Re-visiting the echo state property. Neural networks, 35, 1-9. 406",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7619",
    "text": "Yosinski, J., Clune, J., Bengio, Y., and Lipson, H. (2014). How transferable are features in deep neural networks? In NIPS\u20192014. 323, 538",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7620",
    "text": "Younes, L. (1998). On the convergence of Markovian stochastic algorithms with rapidly decreasing ergodicity rates. In Stochastics and Stochastics Models, pages 177-228. 614",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7621",
    "text": "Yu, D., Wang, S., and Deng, L. (2010). Sequential labeling using deep-structured conditional random fields. IEEE Journal of Selected Topics in Signal Processing. 323",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7622",
    "text": "Zaremba, W. and Sutskever, I. (2014). Learning to execute. arXiv 1410.4615. 329",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7623",
    "text": "Zaremba, W. and Sutskever, I. (2015). Reinforcement learning neural Turing machines. arXiv:1505.00521. 421",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7624",
    "text": "Zaslavsky, T. (1975). Facing Up to Arrangements: Face-Count Formulas for Partitions of Space by Hyperplanes. Number no. 154 in Memoirs of the American Mathematical\u00a0Society. American Mathematical Society. 552",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7625",
    "text": "Zeiler, M. D. and Fergus, R. (2014). Visualizing and understanding convolutional networks. In ECCV\u201914. 6",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7626",
    "text": "Zeiler, M. D., Ranzato, M., Monga, R., Mao, M., Yang, K., Le, Q., Nguyen, P., Senior, A., Vanhoucke, V., Dean, J., and Hinton, G. E. (2013). On rectified linear units for\u00a0speech processing. In ICASSP 2013. 461",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7627",
    "text": "Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., and Torralba, A. (2015). Object detectors emerge in deep scene CNNs. ICLR\u20192015, arXiv:1412.6856. 553",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7628",
    "text": "Zhou, J. and Troyanskaya, O. G. (2014). Deep supervised and convolutional generative stochastic network for protein secondary structure prediction. In ICML\u20192014. 717",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7629",
    "text": "Zhou, Y. and Chellappa, R. (1988). Computation of optical flow using a neural network. In Neural Networks, 1988., IEEE International Conference on, pages 71-78. IEEE. 339",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7630",
    "text": "Zohrer, M. and Pernkopf, F. (2014). General stochastic networks for classification. In NIPS\u20192014. 717",
    "chapter": "",
    "chapter_id": "main-43.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7631",
    "text": "0-1 loss, 104, 276",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7632",
    "text": "Absolute value rectification, 192 Accuracy, 425\u00a0Activation function, 170\u00a0Active constraint, 95\u00a0AdaGrad, 307",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7633",
    "text": "ADALINE, see adaptive linear element Adam, 308, 427",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7634",
    "text": "Adaptive linear element, 15, 24, 27 Adversarial example, 268\u00a0Adversarial training, 268, 271, 532\u00a0Affine, 110",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7635",
    "text": "AIS, see annealed importance sampling Almost everywhere, 71\u00a0Almost sure convergence, 130\u00a0Ancestral sampling, 582, 597\u00a0ANN, see Artificial neural network\u00a0Annealed importance sampling, 627, 670,\u00a0719",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7636",
    "text": "Approximate Bayesian computation, 718 Approximate inference, 585\u00a0Artificial intelligence, 1",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7637",
    "text": "Artificial neural network, see Neural network",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7638",
    "text": "ASR, see automatic speech recognition Asymptotically unbiased, 124\u00a0Audio, 102, 360, 460\u00a0Autoencoder, 4, 356, 504\u00a0Automatic speech recognition, 460",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7639",
    "text": "Back-propagation, 203 Back-propagation through time, 384\u00a0Backprop, see back-propagation",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7640",
    "text": "Bag of words, 473 Bagging, 256",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7641",
    "text": "Batch normalization, 268, 427 Bayes error, 117\u00a0Bayes\u2019 rule, 70",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7642",
    "text": "Bayesian hyperparameter optimization, 438 Bayesian network, see directed graphical\u00a0model",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7643",
    "text": "Bayesian probability, 55",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7644",
    "text": "Bayesian statistics, 135",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7645",
    "text": "Belief network, see directed graphical model",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7646",
    "text": "Bernoulli distribution, 62",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7647",
    "text": "BFGS, 316",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7648",
    "text": "Bias, 124, 229",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7649",
    "text": "Bias parameter, 110",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7650",
    "text": "Biased importance sampling, 595",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7651",
    "text": "Bigram, 464",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7652",
    "text": "Binary relation, 484",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7653",
    "text": "Block Gibbs sampling, 601",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7654",
    "text": "Boltzmann distribution, 572",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7655",
    "text": "Boltzmann machine, 572, 656",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7656",
    "text": "BPTT, see back-propagation through time",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7657",
    "text": "Broadcasting, 34",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7658",
    "text": "Burn-in, 599",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7659",
    "text": "CAE, see contractive autoencoder Calculus of variations, 179\u00a0Categorical distribution, see multinoulli distribution",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7660",
    "text": "CD, see contrastive divergence Centering trick (DBM), 675\u00a0Central limit theorem, 63\u00a0Chain rule (calculus), 206\u00a0Chain rule of probability, 59",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7661",
    "text": "Chess, 2",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7662",
    "text": "Chord, 581",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7663",
    "text": "Chordal graph, 581",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7664",
    "text": "Class-based language models, 465",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7665",
    "text": "Classical dynamical system, 375",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7666",
    "text": "Classification, 100",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7667",
    "text": "Clique potential, see factor (graphical model)",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7668",
    "text": "CNN, see convolutional neural network",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7669",
    "text": "Collaborative Filtering, 480",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7670",
    "text": "Collider, see explaining away",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7671",
    "text": "Color images, 360",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7672",
    "text": "Complex cell, 365",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7673",
    "text": "Computational graph, 204",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7674",
    "text": "Computer vision, 454",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7675",
    "text": "Concept drift, 540",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7676",
    "text": "Condition number, 279",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7677",
    "text": "Conditional computation, see dynamic structure",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7678",
    "text": "Conditional independence, xiii, 60 Conditional probability, 59\u00a0Conditional RBM, 687\u00a0Connectionism, 17, 445\u00a0Connectionist temporal classification, 462\u00a0Consistency, 130, 515\u00a0Constrained optimization, 93, 237\u00a0Content-based addressing, 421\u00a0Content-based recommender systems, 482\u00a0Context-specific independence, 575\u00a0Contextual bandits, 482\u00a0Continuation methods, 327\u00a0Contractive autoencoder, 523\u00a0Contrast, 456",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7679",
    "text": "Contrastive divergence, 291, 612, 674 Convex optimization, 141\u00a0Convolution, 330, 685\u00a0Convolutional network, 16\u00a0Convolutional neural network, 254, 330, 427,\u00a0462",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7680",
    "text": "Coordinate descent, 321, 673 Correlation, 61",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7681",
    "text": "Cost function, see objective function Covariance, xiii, 61\u00a0Covariance matrix, 62\u00a0Coverage, 426",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7682",
    "text": "Critical temperature, 605 Cross-correlation, 332\u00a0Cross-entropy, 75, 132\u00a0Cross-validation, 122",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7683",
    "text": "CTC, see connectionist temporal classification",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7684",
    "text": "Curriculum learning, 328 Curse of dimensionality, 154\u00a0Cyc, 2",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7685",
    "text": "D-separation, 574",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7686",
    "text": "DAE, see denoising autoencoder",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7687",
    "text": "Data generating distribution, 111, 131",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7688",
    "text": "Data generating process, 111",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7689",
    "text": "Data parallelism, 449",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7690",
    "text": "Dataset, 105",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7691",
    "text": "Dataset augmentation, 271, 459 DBM, see deep Boltzmann machine\u00a0DCGAN, 553, 554, 703\u00a0Decision tree, 145, 550\u00a0Decoder, 4",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7692",
    "text": "Deep belief network, 27, 531, 633, 659, 662, 686, 694\u00a0Deep Blue, 2",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7693",
    "text": "Deep Boltzmann machine, 24, 27, 531, 633, 654, 659, 665, 674, 686\u00a0Deep feedforward network, 167, 427\u00a0Deep learning, 2, 5\u00a0Denoising autoencoder, 512, 691\u00a0Denoising score matching, 621\u00a0Density estimation, 103\u00a0Derivative, xiii, 83\u00a0Design matrix, 106\u00a0Detector layer, 339\u00a0Determinant, xii\u00a0Diagonal matrix, 41\u00a0Differential entropy, 74, 648\u00a0Dirac delta function, 65\u00a0Directed graphical model, 77, 509, 565, 694\u00a0Directional derivative, 85\u00a0Discriminative fine-tuning, see supervised\u00a0fine-tuning",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7694",
    "text": "Discriminative RBM, 688 Distributed representation, 17, 150, 548\u00a0Domain adaptation, 538",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7695",
    "text": "Dot product, 34, 141 Double backprop, 271\u00a0Doubly block circulant matrix, 333\u00a0Dream sleep, 611, 654\u00a0DropConnect, 266",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7696",
    "text": "Dropout, 258, 427, 432, 433, 674, 691 Dynamic structure, 450, 451",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7697",
    "text": "E-step, 636",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7698",
    "text": "Early stopping, 246, 247, 249, 250, 427 EBM, see energy-based model\u00a0Echo state network, 24, 27, 405\u00a0Effective capacity, 114\u00a0Eigendecomposition, 42\u00a0Eigenvalue, 42\u00a0Eigenvector, 42",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7699",
    "text": "ELBO, see evidence lower bound Element-wise product, see Hadamard product, see Hadamard product\u00a0EM, see expectation maximization\u00a0Embedding, 518\u00a0Empirical distribution, 66\u00a0Empirical risk, 276\u00a0Empirical risk minimization, 276\u00a0Encoder, 4\u00a0Energy function, 571\u00a0Energy-based model, 571, 597, 656, 665\u00a0Ensemble methods, 256\u00a0Epoch, 246",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7700",
    "text": "Equality constraint, 94 Equivariance, 338",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7701",
    "text": "Error function, see objective function ESN, see echo state network\u00a0Euclidean norm, 39\u00a0Euler-Lagrange equation, 648\u00a0Evidence lower bound, 635, 663\u00a0Example, 99\u00a0Expectation, 60\u00a0Expectation maximization, 636\u00a0Expected value, see expectation\u00a0Explaining away, 576, 633, 646\u00a0Exploitation, 483\u00a0Exploration, 483\u00a0Exponential distribution, 65",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7702",
    "text": "F-score, 425",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7703",
    "text": "Factor (graphical model), 569",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7704",
    "text": "Factor analysis, 492",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7705",
    "text": "Factor graph, 581",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7706",
    "text": "Factors of variation, 4",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7707",
    "text": "Feature, 99",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7708",
    "text": "Feature selection, 236",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7709",
    "text": "Feedforward neural network, 167",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7710",
    "text": "Fine-tuning, 323",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7711",
    "text": "Finite differences, 441",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7712",
    "text": "Forget gate, 306",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7713",
    "text": "Forward propagation, 203",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7714",
    "text": "Fourier transform, 360, 362",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7715",
    "text": "Fovea, 366",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7716",
    "text": "FPCD, 616",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7717",
    "text": "Free energy, 573, 682",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7718",
    "text": "Freebase, 485",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7719",
    "text": "Frequentist probability, 55",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7720",
    "text": "Frequentist statistics, 135",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7721",
    "text": "Frobenius norm, 46",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7722",
    "text": "Fully-visible Bayes network, 707",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7723",
    "text": "Functional derivatives, 647",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7724",
    "text": "FVBN, see fully-visible Bayes network",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7725",
    "text": "Gabor function, 368",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7726",
    "text": "GANs, see generative adversarial networks Gated recurrent unit, 427\u00a0Gaussian distribution, see normal distribution",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7727",
    "text": "Gaussian kernel, 142",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7728",
    "text": "Gaussian mixture, 67, 188",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7729",
    "text": "GCN, see global contrast normalization",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7730",
    "text": "GeneOntology, 485",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7731",
    "text": "Generalization, 110",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7732",
    "text": "Generalized Lagrange function, see generalized Lagrangian Generalized Lagrangian, 94\u00a0Generative adversarial networks, 691, 702\u00a0Generative moment matching networks, 705\u00a0Generator network, 695\u00a0Gibbs distribution, 570\u00a0Gibbs sampling, 583, 601\u00a0Global contrast normalization, 456\u00a0GPU, see graphics processing unit\u00a0Gradient, 84",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7733",
    "text": "Gradient clipping, 289, 416 Gradient descent, 83, 85\u00a0Graph, xii",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7734",
    "text": "Graphical model, see structured probabilistic model",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7735",
    "text": "Graphics processing unit, 446 Greedy algorithm, 323",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7736",
    "text": "Greedy layer-wise unsupervised pretraining, 530",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7737",
    "text": "Greedy supervised pretraining, 323 Grid search, 434",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7738",
    "text": "Hadamard product, xii, 34 Hard tanh, 196",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7739",
    "text": "Harmonium, see restricted Boltzmann machine",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7740",
    "text": "Harmony theory, 573",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7741",
    "text": "Helmholtz free energy, see evidence lower bound\u00a0Hessian, 223\u00a0Hessian matrix, xiii, 87\u00a0Heteroscedastic, 187\u00a0Hidden layer, 6, 167\u00a0Hill climbing, 86",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7742",
    "text": "Hyperparameter optimization, 434 Hyperparameters, 120, 432\u00a0Hypothesis space, 112, 118",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7743",
    "text": "i.i.d. assumptions, 111, 122, 268 Identity matrix, 36",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7744",
    "text": "ILSVRC, see ImageNet Large-Scale Visual Recognition Challenge\u00a0ImageNet Large-Scale Visual Recognition\u00a0Challenge, 23\u00a0Immorality, 579",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7745",
    "text": "Importance sampling, 594, 626, 700 Importance weighted autoencoder, 700\u00a0Independence, xiii, 60",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7746",
    "text": "Independent and identically distributed, see i.i.d. assumptions",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7747",
    "text": "Independent component analysis, 493 Independent subspace analysis, 495\u00a0Inequality constraint, 94\u00a0Inference, 564, 585, 633, 635, 637, 640, 650,\u00a0653",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7748",
    "text": "Information retrieval, 527 Initialization, 301\u00a0Integral, xiii\u00a0Invariance, 342\u00a0Isotropic, 65",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7749",
    "text": "Jacobian matrix, xiii, 72, 86 Joint probability, 57",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7750",
    "text": "k-means, 364, 548 k-nearest neighbors, 143, 550\u00a0Karush-Kuhn-Tucker conditions, 95, 237\u00a0Karush-Kuhn-Tucker, 94\u00a0Kernel (convolution), 331, 332\u00a0Kernel machine, 550\u00a0Kernel trick, 141\u00a0KKT, see Karush-Kuhn-Tucker\u00a0KKT conditions, see Karush-Kuhn-Tucker\u00a0conditions",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7751",
    "text": "KL divergence, see Kullback-Leibler divergence",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7752",
    "text": "Knowledge base, 2, 485 Krylov methods, 223\u00a0Kullback-Leibler divergence, xiii, 74",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7753",
    "text": "Label smoothing, 243 Lagrange multipliers, 94, 648\u00a0Lagrangian, see generalized Lagrangian\u00a0LAPGAN, 704",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7754",
    "text": "Laplace distribution, 65, 498, 499",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7755",
    "text": "Latent variable, 67",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7756",
    "text": "Layer (neural network), 167",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7757",
    "text": "LCN, see local contrast normalization",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7758",
    "text": "Leaky ReLU, 192",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7759",
    "text": "Leaky units, 408",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7760",
    "text": "Learning rate, 85",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7761",
    "text": "Line search, 85, 86, 93",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7762",
    "text": "Linear combination, 37",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7763",
    "text": "Linear dependence, 38",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7764",
    "text": "Linear factor models, 491",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7765",
    "text": "Linear regression, 107, 110, 140",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7766",
    "text": "Link prediction, 486",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7767",
    "text": "Lipschitz constant, 92",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7768",
    "text": "Lipschitz continuous, 92",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7769",
    "text": "Liquid state machine, 405",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7770",
    "text": "Local conditional probability distribution, 566",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7771",
    "text": "Local contrast normalization, 458 Logistic regression, 3, 140, 140\u00a0Logistic sigmoid, 7, 67\u00a0Long short-term memory, 18, 25, 306, 410,\u00a0427",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7772",
    "text": "Loop, 581",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7773",
    "text": "Loopy belief propagation, 587 Loss function, see objective function\u00a0Lp norm, 39",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7774",
    "text": "LSTM, see long short-term memory",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7775",
    "text": "M-step, 636",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7776",
    "text": "Machine learning, 2",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7777",
    "text": "Machine translation, 101",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7778",
    "text": "Main diagonal, 33",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7779",
    "text": "Manifold, 160",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7780",
    "text": "Manifold hypothesis, 161",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7781",
    "text": "Manifold learning, 161",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7782",
    "text": "Manifold tangent classifier, 272",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7783",
    "text": "MAP approximation, 138, 507",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7784",
    "text": "Marginal probability, 58",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7785",
    "text": "Markov chain, 597",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7786",
    "text": "Markov chain Monte Carlo, 597",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7787",
    "text": "Markov network, see undirected model",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7788",
    "text": "Markov random field, see undirected model",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7789",
    "text": "Matrix, xi, xii, 32",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7790",
    "text": "Matrix inverse, 36",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7791",
    "text": "Matrix product, 34",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7792",
    "text": "Max norm, 40",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7793",
    "text": "Max pooling, 339",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7794",
    "text": "Maximum likelihood, 131",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7795",
    "text": "Maxout, 192, 427",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7796",
    "text": "MCMC, see Markov chain Monte Carlo Mean field, 640, 641, 674\u00a0Mean squared error, 108\u00a0Measure theory, 71\u00a0Measure zero, 71\u00a0Memory network, 418, 420\u00a0Method of steepest descent, see gradient\u00a0descent",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7797",
    "text": "Minibatch, 279 Missing inputs, 100\u00a0Mixing (Markov chain), 603",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7798",
    "text": "Mixture density networks, 188 Mixture distribution, 66\u00a0Mixture model, 188, 512\u00a0Mixture of experts, 452, 550\u00a0MLP, see multilayer perception\u00a0MNIST, 21, 22, 674\u00a0Model averaging, 256\u00a0Model compression, 450\u00a0Model identifiability, 284\u00a0Model parallelism, 449\u00a0Moment matching, 705\u00a0Moore-Penrose pseudoinverse, 45, 239\u00a0Moralized graph, 579\u00a0MP-DBM, see multi-prediction DBM\u00a0MRF (Markov Random Field), see undi\u25a0\u00a0rected model",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7799",
    "text": "MSE, see mean squared error Multi-modal learning, 541\u00a0Multi-prediction DBM, 676\u00a0Multi-task learning, 244, 540\u00a0Multilayer perception, 5\u00a0Multilayer perceptron, 27\u00a0Multinomial distribution, 62\u00a0Multinoulli distribution, 62",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7800",
    "text": "n-gram, 463 NADE, 710\u00a0Naive Bayes, 3\u00a0Nat, 73",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7801",
    "text": "Natural image, 561 Natural language processing, 463\u00a0Nearest neighbor regression, 115\u00a0Negative definite, 89\u00a0Negative phase, 472, 608, 610\u00a0Neocognitron, 16, 24, 27, 367\u00a0Nesterov momentum, 300\u00a0Netflix Grand Prize, 258, 481\u00a0Neural language model, 465, 478\u00a0Neural network, 13\u00a0Neural Turing machine, 420\u00a0Neuroscience, 15\u00a0Newton\u2019s method, 89, 310\u00a0NLM, see neural language model\u00a0NLP, see natural language processing\u00a0No free lunch theorem, 116",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7802",
    "text": "Noise-contrastive estimation, 622 Non-parametric model, 114\u00a0Norm, xiv, 39",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7803",
    "text": "Normal distribution, 63, 64, 125 Normal equations, 109, 109, 112, 234\u00a0Normalized initialization, 303\u00a0Numerical differentiation, see finite differences",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7804",
    "text": "Object detection, 455",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7805",
    "text": "Object recognition, 455",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7806",
    "text": "Objective function, 82",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7807",
    "text": "OMP-k, see orthogonal matching pursuit",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7808",
    "text": "One-shot learning, 540",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7809",
    "text": "Operation, 204",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7810",
    "text": "Optimization, 80, 82",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7811",
    "text": "Orthodox statistics, see frequentist statistics Orthogonal matching pursuit, 27, 255\u00a0Orthogonal matrix, 42\u00a0Orthogonality, 41\u00a0Output layer, 167",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7812",
    "text": "Parallel distributed processing, 17",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7813",
    "text": "Parameter initialization, 301, 407",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7814",
    "text": "Parameter sharing, 253, 335, 373, 375, 389",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7815",
    "text": "Parameter tying, see Parameter sharing",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7816",
    "text": "Parametric model, 114",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7817",
    "text": "Parametric ReLU, 192",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7818",
    "text": "Partial derivative, 84",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7819",
    "text": "Partition function, 570, 607, 671",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7820",
    "text": "PCA, see principal components analysis",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7821",
    "text": "PCD, see stochastic maximum likelihood",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7822",
    "text": "Perceptron, 15, 27",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7823",
    "text": "Persistent contrastive divergence, see stochastic maximum likelihood Perturbation analysis, see reparametrization\u00a0trick",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7824",
    "text": "Point estimator, 122",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7825",
    "text": "Policy, 482",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7826",
    "text": "Pooling, 330, 685",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7827",
    "text": "Positive definite, 89",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7828",
    "text": "Positive phase, 472, 608, 610, 658, 670",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7829",
    "text": "Precision, 425",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7830",
    "text": "Precision (of a normal distribution), 63, 65 Predictive sparse decomposition, 525",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7831",
    "text": "Preprocessing, 455 Pretraining, 323, 530\u00a0Primary visual cortex, 365\u00a0Principal components analysis, 48, 146-148,\u00a0492, 633",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7832",
    "text": "Prior probability distribution, 135 Probabilistic max pooling, 685\u00a0Probabilistic PCA, 492, 493, 634\u00a0Probability density function, 58\u00a0Probability distribution, 56\u00a0Probability mass function, 56\u00a0Probability mass function estimation, 103\u00a0Product of experts, 572\u00a0Product rule of probability, see chain rule\u00a0of probability",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7833",
    "text": "PSD, see predictive sparse decomposition Pseudolikelihood, 617",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7834",
    "text": "Quadrature pair, 369 Quasi-Newton methods, 316",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7835",
    "text": "Radial basis function, 196 Random search, 436\u00a0Random variable, 56\u00a0Ratio matching, 620\u00a0RBF, 196",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7836",
    "text": "RBM, see restricted Boltzmann machine Recall, 425\u00a0Receptive field, 337\u00a0Recommender Systems, 480\u00a0Rectified linear unit, 171, 192, 427, 509\u00a0Recurrent network, 27\u00a0Recurrent neural network, 378\u00a0Regression, 101",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7837",
    "text": "Regularization, 120, 120, 177, 228, 432 Regularizer, 119\u00a0REINFORCE, 691",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7838",
    "text": "Reinforcement learning, 25, 106, 482, 691 Relational database, 485\u00a0Reparametrization trick, 690\u00a0Representation learning, 3\u00a0Representational capacity, 114\u00a0Restricted Boltzmann machine, 356, 461,\u00a0481, 589, 633, 658, 659, 674, 678,\u00a0680, 682, 685",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7839",
    "text": "Ridge regression, see weight decay Risk, 275\u00a0RNN-RBM, 687",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7840",
    "text": "Saddle points, 285",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7841",
    "text": "Sample mean, 125",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7842",
    "text": "Scalar, xi, xii, 31",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7843",
    "text": "Score matching, 515, 619",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7844",
    "text": "Second derivative, 86",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7845",
    "text": "Second derivative test, 89",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7846",
    "text": "Self-information, 73",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7847",
    "text": "Semantic hashing, 527",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7848",
    "text": "Semi-supervised learning, 243",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7849",
    "text": "Separable convolution, 362",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7850",
    "text": "Separation (probabilistic modeling), 574",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7851",
    "text": "Set, xii",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7852",
    "text": "SGD, see stochastic gradient descent Shannon entropy, xiii, 73\u00a0Shortlist, 468",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7853",
    "text": "Sigmoid, xiv, see logistic sigmoid Sigmoid belief network, 27\u00a0Simple cell, 365",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7854",
    "text": "Singular value, see singular value decomposition",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7855",
    "text": "Singular value decomposition, 44, 148, 481 Singular vector, see singular value decomposition",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7856",
    "text": "Slow feature analysis, 495",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7857",
    "text": "SML, see stochastic maximum likelihood",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7858",
    "text": "Softmax, 183, 420, 452",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7859",
    "text": "Softplus, xiv, 68, 196",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7860",
    "text": "Spam detection, 3",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7861",
    "text": "Sparse coding, 321, 356, 498, 633, 694 Sparse initialization, 304, 407\u00a0Sparse representation, 146, 226, 254, 507,\u00a0558",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7862",
    "text": "Spearmint, 438 Spectral radius, 406",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7863",
    "text": "Speech recognition, see automatic speech recognition",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7864",
    "text": "Sphering, see whitening Spike and slab restricted Boltzmann machine, 682",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7865",
    "text": "SPN, see sum-product network Square matrix, 38\u00a0ssRBM, see spike and slab restricted Boltzmann machine\u00a0Standard deviation, 61\u00a0Standard error, 127\u00a0Standard error of the mean, 128, 278\u00a0Statistic, 122",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7866",
    "text": "Statistical learning theory, 110 Steepest descent, see gradient descent\u00a0Stochastic back-propagation, see reparametriza\u25a0\u00a0tion trick",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7867",
    "text": "Stochastic gradient descent, 15, 150, 279, 294, 674",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7868",
    "text": "Stochastic maximum likelihood, 614, 674 Stochastic pooling, 266\u00a0Structure learning, 584\u00a0Structured output, 101, 687\u00a0Structured probabilistic model, 77, 560\u00a0Sum rule of probability, 58\u00a0Sum-product network, 555\u00a0Supervised fine-tuning, 531, 664\u00a0Supervised learning, 105\u00a0Support vector machine, 140\u00a0Surrogate loss function, 276\u00a0SVD, see singular value decomposition\u00a0Symmetric matrix, 41, 43",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7869",
    "text": "Tangent distance, 270 Tangent plane, 518\u00a0Tangent prop, 270",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7870",
    "text": "TDNN, see time-delay neural network Teacher forcing, 382, 383\u00a0Tempering, 605\u00a0Template matching, 141\u00a0Tensor, xi, xii, 33\u00a0Test set, 110",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7871",
    "text": "Tikhonov regularization, see weight decay",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7872",
    "text": "Tiled convolution, 352",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7873",
    "text": "Time-delay neural network, 368, 374",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7874",
    "text": "Toeplitz matrix, 333",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7875",
    "text": "Topographic ICA, 495",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7876",
    "text": "Trace operator, 46",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7877",
    "text": "Training error, 110",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7878",
    "text": "Transcription, 101",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7879",
    "text": "Transfer learning, 538",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7880",
    "text": "Transpose, xii, 33",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7881",
    "text": "Triangle inequality, 39 Triangulated graph, see chordal graph\u00a0Trigram, 464",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7882",
    "text": "Unbiased, 124",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7883",
    "text": "Undirected graphical model, 77, 509",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7884",
    "text": "Undirected model, 568",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7885",
    "text": "Uniform distribution, 57",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7886",
    "text": "Unigram, 464",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7887",
    "text": "Unit norm, 41",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7888",
    "text": "Unit vector, 41",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7889",
    "text": "Universal approximation theorem, 197 Universal approximator, 555\u00a0Unnormalized probability distribution, 569\u00a0Unsupervised learning, 105, 146\u00a0Unsupervised pretraining, 461, 530",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7890",
    "text": "V-structure, see explaining away V1, 365",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7891",
    "text": "VAE, see variational autoencoder Vapnik-Chervonenkis dimension, 114\u00a0Variance, xiii, 61, 229\u00a0Variational autoencoder, 691, 698\u00a0Variational derivatives, see functional derivatives",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7892",
    "text": "Variational free energy, see evidence lower bound",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7893",
    "text": "VC dimension, see Vapnik-Chervonenkis dimension Vector, xi, xii, 32\u00a0Virtual adversarial examples, 269\u00a0Visible layer, 6\u00a0Volumetric data, 360",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7894",
    "text": "Wake-sleep, 653, 663",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7895",
    "text": "Weight decay, 118, 177, 231, 433",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7896",
    "text": "Weight space symmetry, 284",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7897",
    "text": "Weights, 15, 107",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7898",
    "text": "Whitening, 457",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7899",
    "text": "Wikibase, 485",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7900",
    "text": "Wikibase, 485",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7901",
    "text": "Word embedding, 466",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7902",
    "text": "Word-sense disambiguation, 486",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7903",
    "text": "WordNet, 485",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7904",
    "text": "Zero-data learning, see zero-shot learning",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  },
  {
    "id": "7905",
    "text": "Zero-shot learning, 540",
    "chapter": "",
    "chapter_id": "main-44.xhtml",
    "source": "Deep Learning Book, Goodfellow et Al. 2016",
    "source_id": "Goodfellow-et-al-2016",
    "author": "Ian Goodfellow and Yoshua Bengio and Aaron Courville"
  }
]